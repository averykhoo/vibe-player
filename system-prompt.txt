
System Prompt:

You will be provided with a snapshot of a repository, including its directory structure and the content of its key text files.

**Your primary task is to carefully read, analyze, and thoroughly understand the *entirety* of this provided information.** Do not just skim the contents. Process the directory structure, the relationships between files (e.g., how they might link, import, or relate thematically), and the substance within each file.

**Synthesize this information to build a comprehensive internal understanding of the repository's:**
*   **Overall purpose:** What is this repository *for*? (e.g., a software project, documentation, recipe collection, project plan, notes)
*   **Structure and Organization:** How are the files and directories laid out? How do they logically group together?
*   **Key Components and Content:** What are the most important files, concepts, topics, data points, or pieces of information contained within?

Your goal is to develop a robust mental model of this repository based *only* on the provided snapshot. This understanding is crucial for you to accurately and effectively answer subsequent user questions about any aspect of the repository.


**Repository Structure:**
````
.
├── .github
│   └── workflows
│       ├── ci.yml
│       ├── deploy.yml
│       └── release.yml
├── .gitignore
├── .llmignore
├── README.md
├── REFACTOR_PLAN.txt
├── build_system_prompt.py
├── system-prompt.txt
├── test-audio
│   ├── CGI_Animated_Short_Film：_＂Watermelon_A_Cautionary_Tale＂_by_Kefei.m4a
│   ├── Dial DTMF sound _Busy Tone_ (480Hz+620Hz) [OnlineSound.net].mp3
│   ├── Dial DTMF sound _Ringing Tone_ (400Hz+450Hz) [OnlineSound.net].mp3
│   ├── IELTS13-Tests1-4CD1Track_01.mp3
│   ├── LearningEnglishConversations-20250325-TheEnglishWeSpeakTwistSomeonesArm.mp3
│   ├── Michael Jackson - Bad.mp3
│   ├── Rename me to just Music.mp3
│   ├── Tracing the thoughts of a large language model [Bj9BD2D3DzA].m4a
│   ├── call going to voicemail - sound effect [SozAG1STa08].m4a
│   ├── dtmf-123A456B789C(star)0(hex)D.mp3
│   ├── file_example_MP3_5MG.mp3
│   ├── off-hook-tone-43891.mp3
│   ├── overlordVol14Prologue.mp3
│   ├── warning.mp3
│   └── 【Sound_of_Japan】Outgoing_Phone_Call_Dial_Sound⧸_Answering_Machine.m4a
├── vibe-player
│   ├── CONTRIBUTING-LLM.md
│   ├── README.md
│   ├── TODO.md
│   ├── architecture.md
│   ├── css
│   │   ├── 98.css
│   │   └── styles.css
│   ├── fonts
│   │   ├── ms_sans_serif.woff
│   │   ├── ms_sans_serif.woff2
│   │   ├── ms_sans_serif_bold.woff
│   │   └── ms_sans_serif_bold.woff2
│   ├── index.html
│   ├── js
│   │   ├── app.js
│   │   ├── goertzel.js
│   │   ├── player
│   │   │   ├── audioEngine.js
│   │   │   └── rubberbandProcessor.js
│   │   ├── sparkles.js
│   │   ├── state
│   │   │   ├── appState.js
│   │   │   └── constants.js
│   │   ├── uiManager.js
│   │   ├── utils.js
│   │   ├── vad
│   │   │   ├── LocalWorkerStrategy.js
│   │   │   ├── RemoteApiStrategy.js
│   │   │   ├── sileroProcessor.js
│   │   │   ├── sileroWrapper.js
│   │   │   └── vadAnalyzer.js
│   │   └── visualizers
│   │       ├── spectrogram.worker.js
│   │       ├── spectrogramVisualizer.js
│   │       └── waveformVisualizer.js
│   ├── lib
│   │   ├── fft.js
│   │   ├── ort-wasm-simd-threaded.jsep.mjs
│   │   ├── ort-wasm-simd-threaded.jsep.wasm
│   │   ├── ort-wasm-simd-threaded.mjs
│   │   ├── ort-wasm-simd-threaded.wasm
│   │   ├── ort.min.js
│   │   ├── ort.min.js.map
│   │   ├── rubberband-loader.js
│   │   └── rubberband.wasm
│   └── model
│       └── silero_vad.onnx
└── vibe-player-v2
    ├── .gitignore
    ├── .npmrc
    ├── .prettierrc
    ├── README.md
    ├── eslint.config.js
    ├── package-lock.json
    ├── package.json
    ├── playwright.config.ts
    ├── postcss.config.js
    ├── src
    │   ├── app.css
    │   ├── app.d.ts
    │   ├── app.html
    │   ├── hooks.server.ts
    │   ├── lib
    │   │   ├── actions
    │   │   │   └── sparkles.action.ts
    │   │   ├── components
    │   │   │   ├── Controls.svelte
    │   │   │   ├── Controls.test.ts
    │   │   │   ├── FileLoader.svelte
    │   │   │   ├── FileLoader.test.ts
    │   │   │   ├── ToneDisplay.svelte
    │   │   │   ├── __mocks__
    │   │   │   │   ├── Button.svelte
    │   │   │   │   ├── Generic.svelte
    │   │   │   │   ├── ProgressBar.svelte
    │   │   │   │   └── RangeSlider.svelte
    │   │   │   └── visualizers
    │   │   │       ├── Spectrogram.svelte
    │   │   │       └── Waveform.svelte
    │   │   ├── index.ts
    │   │   ├── services
    │   │   │   ├── analysis.service.test.ts
    │   │   │   ├── analysis.service.ts
    │   │   │   ├── audioEngine.service.test.ts
    │   │   │   ├── audioEngine.service.ts
    │   │   │   ├── dtmf.service.test.ts
    │   │   │   ├── dtmf.service.ts
    │   │   │   ├── spectrogram.service.test.ts
    │   │   │   └── spectrogram.service.ts
    │   │   ├── stores
    │   │   │   ├── analysis.store.ts
    │   │   │   ├── derived.store.ts
    │   │   │   ├── dtmf.store.ts
    │   │   │   ├── player.store.ts
    │   │   │   └── status.store.ts
    │   │   ├── types
    │   │   │   ├── analysis.types.ts
    │   │   │   ├── player.types.ts
    │   │   │   ├── status.types.ts
    │   │   │   └── worker.types.ts
    │   │   ├── utils
    │   │   │   ├── assert.ts
    │   │   │   ├── async.test.ts
    │   │   │   ├── async.ts
    │   │   │   ├── constants.test.ts
    │   │   │   ├── constants.ts
    │   │   │   ├── dsp.test.ts
    │   │   │   ├── dsp.ts
    │   │   │   ├── formatters.test.ts
    │   │   │   ├── formatters.ts
    │   │   │   ├── index.ts
    │   │   │   ├── urlState.test.ts
    │   │   │   └── urlState.ts
    │   │   └── workers
    │   │       ├── dtmf.worker.ts
    │   │       ├── rubberband.worker.ts
    │   │       ├── sileroVad.worker.ts
    │   │       └── spectrogram.worker.ts
    │   ├── routes
    │   │   ├── +layout.svelte
    │   │   └── +page.svelte
    │   └── setupTests.ts
    ├── static
    │   ├── favicon.png
    │   ├── models
    │   │   └── silero_vad.onnx
    │   ├── test-audio
    │   │   ├── 449496_9289636-lq.mp3
    │   │   ├── C.Noisy_Voice.wav
    │   │   └── dtmf-123A456B789C(star)0(hex)D.mp3
    │   └── vendor
    │       ├── fft.js
    │       └── rubberband
    │           ├── rubberband-loader.js
    │           └── rubberband.wasm
    ├── svelte.config.js
    ├── tailwind.config.ts
    ├── tests-e2e
    │   ├── 00-load.e2e.spec.js
    │   ├── PlayerPage.mjs
    │   └── player.e2e.spec.js
    ├── tsconfig.json
    └── vite.config.ts
````

**File Contents:**

--- File: .github/workflows/ci.yml ---
````yaml
# File: .github/workflows/ci.yml

name: Vibe Player CI

on:
  push:
    branches: [ "**" ] # Run on pushes to all branches
  pull_request:
    branches: [ "main", "master" ] # Run on PRs targeting main or master

jobs:
  test:
    timeout-minutes: 60
    runs-on: ubuntu-latest

    steps:
      - name: Check out code
        uses: actions/checkout@v4

      # 1. Setup Node.js and configure caching for npm packages
      # This step handles caching for both the root and the /vibe-player-v2 directories
      # by looking at both package-lock.json files.
      - name: Use Node.js 18.x
        uses: actions/setup-node@v4
        with:
          node-version: '18.x'
          cache: 'npm'
          cache-dependency-path: 'vibe-player-v2/package-lock.json'

      # 2. Install dependencies for the V2 app and the root project.
      # The `setup-node` action automatically handles skipping this if the cache was restored.
      - name: Install V2 dependencies
        working-directory: ./vibe-player-v2
        run: npm ci

      # 3. Run all tests and builds as before
      - name: Lint V2
        working-directory: ./vibe-player-v2
        run: npm run lint

      - name: Run V2 unit and component tests
        working-directory: ./vibe-player-v2
        run: npm run test:unit

      - name: Build Vibe Player V2
        working-directory: ./vibe-player-v2
        run: npm run build

      # 4. Correctly cache Playwright browsers
      - name: Cache Playwright browsers
        id: cache-playwright-browsers
        uses: actions/cache@v4
        with:
          path: ~/.cache/ms-playwright
          key: playwright-browsers-${{ runner.os }}-${{ hashFiles('vibe-player-v2/package-lock.json') }}

      # 5. Install Playwright browsers only if the cache was not restored
      - name: Install Playwright and OS dependencies
        if: steps.cache-playwright-browsers.outputs.cache-hit != 'true'
        working-directory: ./vibe-player-v2
        run: npx playwright install --with-deps

      - name: Run Playwright E2E tests
        working-directory: ./vibe-player-v2
        run: npx playwright test

      # 6. Cleanup and Reporting
      - name: Upload Playwright report
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: playwright-report
          path: playwright-report/
          retention-days: 7

````
--- End of File: .github/workflows/ci.yml ---
--- File: .github/workflows/deploy.yml ---
````yaml
# .github/workflows/deploy.yml
name: Deploy Vibe Player to GitHub Pages

on:
  # Runs on pushes targeting the default branch (main or master)
  push:
    branches: ["main"] # Or "master", depending on your default branch name
  # Allows you to run this workflow manually from the Actions tab
  workflow_dispatch:

# Sets permissions of the GITHUB_TOKEN to allow deployment to GitHub Pages
permissions:
  contents: read
  pages: write
  id-token: write

# Allow only one concurrent deployment, skipping runs queued between the run in-progress and latest queued.
# However, do NOT cancel in-progress runs as we want to allow these production deployments to complete.
concurrency:
  group: "pages"
  cancel-in-progress: false

jobs:
  # Single deploy job since we're just deploying static files
  deploy:
    environment:
      name: github-pages
      url: ${{ steps.deployment.outputs.page_url }}
    runs-on: ubuntu-latest
    steps:
      - name: Checkout
        uses: actions/checkout@v4 # Use latest checkout action

      - name: Setup Pages
        uses: actions/configure-pages@v5 # Use latest configure-pages action

      # This is the crucial step: Upload the *contents* of ./vibe-player as the artifact
      - name: Upload artifact
        uses: actions/upload-pages-artifact@v3 # Use latest upload-artifact action
        with:
          # Upload content from the vibe-player directory
          path: './vibe-player-v2/build'

      - name: Deploy to GitHub Pages
        id: deployment
        uses: actions/deploy-pages@v4 # Use latest deploy-pages action

````
--- End of File: .github/workflows/deploy.yml ---
--- File: .github/workflows/release.yml ---
````yaml
# .github/workflows/create-release-official.yml
name: Create Release Zip (Official Actions Only)

on:
  push:
    tags:
      - 'v*.*.*'

permissions:
  # Need write access to repository contents to create releases and upload assets
  contents: write

jobs:
  build-release:
    runs-on: ubuntu-latest # Using Ubuntu for easy access to 'zip' command
    steps:
      - name: Checkout code
        uses: actions/checkout@v4 # Official: Checks out the repository code at the specific tag

      - name: Get the version tag
        id: get_tag
        run: echo "TAG_NAME=${GITHUB_REF_NAME}" >> $GITHUB_ENV
        # Standard shell command + GitHub Actions environment variable feature

      - name: Build the zip archive
        run: |
          zip -r vibe-player-${{ env.TAG_NAME }}.zip ./vibe-player-v2/build -x "./vibe-player-v2/build/.DS_Store"
        # Standard shell commands

      - name: Create GitHub Release
        id: create_release # Give this step an ID to reference its outputs
        uses: actions/create-release@v1 # Official: Creates the release entry
        env:
          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }} # Required for authentication
        with:
          tag_name: ${{ env.TAG_NAME }}
          release_name: Release ${{ env.TAG_NAME }}
          body: | # Optional: Add release notes here, can be simple or more complex
            Automated release for version ${{ env.TAG_NAME }}.
            Contains the static build of the Vibe Player V2 application.
          draft: false
          prerelease: false # Set to true if needed based on tag format

      - name: Upload Release Asset (Zip)
        uses: actions/upload-release-asset@v1 # Official: Uploads a file to the created release
        env:
          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }} # Required for authentication
        with:
          upload_url: ${{ steps.create_release.outputs.upload_url }} # Get upload URL from the previous step's output
          asset_path: ./vibe-player-${{ env.TAG_NAME }}.zip # Path to the zip file we created
          asset_name: vibe-player-${{ env.TAG_NAME }}.zip # Name for the asset file on GitHub Releases
          asset_content_type: application/zip # MIME type for zip files

````
--- End of File: .github/workflows/release.yml ---
--- File: .gitignore ---
````.gitignore
# Byte-compiled / optimized / DLL files
__pycache__/
*.py[cod]
*$py.class

# C extensions
*.so

# Distribution / packaging
.Python
build/
develop-eggs/
dist/
downloads/
eggs/
.eggs/
#lib/
lib64/
parts/
sdist/
var/
wheels/
share/python-wheels/
*.egg-info/
.installed.cfg
*.egg
MANIFEST

# PyInstaller
#  Usually these files are written by a python script from a template
#  before PyInstaller builds the exe, so as to inject date/other infos into it.
*.manifest
*.spec

# Installer logs
pip-log.txt
pip-delete-this-directory.txt

# Unit test / coverage reports
htmlcov/
.tox/
.nox/
.coverage
.coverage.*
.cache
nosetests.xml
coverage.xml
*.cover
*.py,cover
.hypothesis/
.pytest_cache/
cover/

# Translations
*.mo
*.pot

# Django stuff:
*.log
local_settings.py
db.sqlite3
db.sqlite3-journal

# Flask stuff:
instance/
.webassets-cache

# Scrapy stuff:
.scrapy

# Sphinx documentation
docs/_build/

# PyBuilder
.pybuilder/
target/

# Jupyter Notebook
.ipynb_checkpoints

# IPython
profile_default/
ipython_config.py

# pyenv
#   For a library or package, you might want to ignore these files since the code is
#   intended to run in multiple environments; otherwise, check them in:
# .python-version

# pipenv
#   According to pypa/pipenv#598, it is recommended to include Pipfile.lock in version control.
#   However, in case of collaboration, if having platform-specific dependencies or dependencies
#   having no cross-platform support, pipenv may install dependencies that don't work, or not
#   install all needed dependencies.
#Pipfile.lock

# UV
#   Similar to Pipfile.lock, it is generally recommended to include uv.lock in version control.
#   This is especially recommended for binary packages to ensure reproducibility, and is more
#   commonly ignored for libraries.
#uv.lock

# poetry
#   Similar to Pipfile.lock, it is generally recommended to include poetry.lock in version control.
#   This is especially recommended for binary packages to ensure reproducibility, and is more
#   commonly ignored for libraries.
#   https://python-poetry.org/docs/basic-usage/#commit-your-poetrylock-file-to-version-control
#poetry.lock

# pdm
#   Similar to Pipfile.lock, it is generally recommended to include pdm.lock in version control.
#pdm.lock
#   pdm stores project-wide configurations in .pdm.toml, but it is recommended to not include it
#   in version control.
#   https://pdm.fming.dev/latest/usage/project/#working-with-version-control
.pdm.toml
.pdm-python
.pdm-build/

# PEP 582; used by e.g. github.com/David-OConnor/pyflow and github.com/pdm-project/pdm
__pypackages__/

# Celery stuff
celerybeat-schedule
celerybeat.pid

# SageMath parsed files
*.sage.py

# Environments
.env
.venv
env/
venv/
ENV/
env.bak/
venv.bak/

# Spyder project settings
.spyderproject
.spyproject

# Rope project settings
.ropeproject

# mkdocs documentation
/site

# mypy
.mypy_cache/
.dmypy.json
dmypy.json

# Pyre type checker
.pyre/

# pytype static type analyzer
.pytype/

# Cython debug symbols
cython_debug/

# PyCharm
#  JetBrains specific template is maintained in a separate JetBrains.gitignore that can
#  be found at https://github.com/github/gitignore/blob/main/Global/JetBrains.gitignore
#  and can be added to the global gitignore or merged into this file.  For a more nuclear
#  option (not recommended) you can uncomment the following to ignore the entire idea folder.
.idea/

# Ruff stuff:
.ruff_cache/

# PyPI configuration file
.pypirc

# Node.js
node_modules/

# test
playwright-report/
test-results/

````
--- End of File: .gitignore ---
--- File: .llmignore ---
````.llmignore
package.json
package-lock.json
vibe-player/lib/*.mjs

````
--- End of File: .llmignore ---
--- File: README.md ---
````markdown
<!-- README.md -->
# Vibe Player

Vibe Player is a simple, browser-based audio player designed for analyzing and manipulating audio files, inspired by classic desktop application aesthetics. It runs entirely client-side using static files.

**Live Demo: [Vibe Player](https://averykhoo.github.io/vibe-player/)**

## Features

*   Load local audio files (common formats supported by browser `decodeAudioData`) and from URLs.
*   Real-time playback control (Play, Pause, Seek).
*   Adjust playback Speed (0.25x - 2.0x) using Rubberband WASM.
*   Adjust playback Pitch (0.25x - 2.0x) using Rubberband WASM.
*   Adjust playback Gain (Volume Boost up to 5x).
*   Voice Activity Detection (VAD) using Silero VAD model (ONNX Runtime):
    *   Displays VAD progress during analysis.
    *   Highlights detected speech segments on the waveform.
    *   Allows tuning VAD thresholds (Positive/Negative) after initial analysis.
*   Visualizations:
    *   Real-time Waveform display.
    *   Spectrogram display.
*   **DTMF and Call Progress Tone (CPT) detection and display.**
*   Keyboard shortcuts for common actions (visible in the application UI).

## Usage

1.  Serve the project files using a simple static file server (e.g., `python -m http.server` or VS Code Live Server). The server should be run from the project root directory.
2.  Open `vibe-player/index.html` in your web browser (Chrome/Edge/Firefox recommended).
3.  Click "Choose File..." and select an audio file, or provide a URL.
4.  Wait for the initial processing (decoding, visuals). The waveform and spectrogram will appear.
5.  Playback controls (Play, Seek, Speed, Pitch, Gain) become active once the audio engine is ready.
6.  VAD processing runs in the background. Its progress is shown, and waveform highlights appear upon completion. VAD tuning sliders become active then.
7.  Use the controls or click on the waveform/spectrogram to interact.

## Controls

*   **Choose File...:** Select a local audio file.
*   **Load URL:** Load audio from a URL.
*   **Speed Slider:** Adjust playback speed (0.25x - 2.0x).
*   **Pitch Slider:** Adjust playback pitch scale (0.25x - 2.0x).
*   **Gain Slider:** Adjust output volume boost (1x - 5x).
*   **Play/Pause Button:** Toggle playback.
*   **Back/Forward Buttons & Input:** Jump backward or forward by the specified number of seconds.
*   **Seek Bar / Time Display:** Shows current position / total duration. Click or drag seek bar to jump.
*   **Waveform/Spectrogram:** Click to seek to that position.
*   **VAD Threshold Sliders:** (Enabled after VAD) Adjust positive/negative thresholds to re-evaluate speech segments based on the initial analysis probabilities.
*   **(Keyboard Shortcuts are listed within the application UI)**

## Developer Notes

*   **Static Environment:** This application is designed to run entirely client-side without any build steps or server-side logic. See `vibe-player/architecture.md` for more details.
*   **Key Technologies/Dependencies:** Vanilla JS (ES6), Web Audio API, ONNX Runtime Web (`ort.min.js`), Rubberband WASM (`rubberband.wasm`, `rubberband-loader.js`), FFT.js. These are included in the `vibe-player/lib/` directory.
*   **Code Structure:** Uses Vanilla JS (ES6) with an IIFE module pattern. See `vibe-player/architecture.md` for more details.

## Contributing / LLM Collaboration

Development involving LLM assistance should follow the guidelines outlined in `vibe-player/CONTRIBUTING-LLM.md`. Please ensure this file is loaded into the LLM's context before starting work. If the file is missing, please request it.

<!-- README.md -->
````
--- End of File: README.md ---
--- File: REFACTOR_PLAN.txt ---
````
Of course. This is the right approach—solidifying the plan with all the new information and recommendations before starting implementation.

Here is the complete, rewritten V3 plan. It incorporates the decision to use a modern UI, the NPM package for ONNX, and all the architectural and risk-mitigation strategies we've discussed. This document is designed to be a definitive blueprint for the project.

---

## **Vibe Player V2: The SvelteKit Refactoring Plan (Version 3.0 - Final)**

### **1. Vision & Executive Summary**

This document outlines the complete plan to refactor Vibe Player from its original IIFE-based architecture to a modern, robust, and maintainable application built on SvelteKit and TypeScript.

The primary goals are to eliminate the architectural problems of the original version—specifically the reliance on global variables, script load order, and manual DOM manipulation—and to create a superior developer and user experience. A key design decision for V2 is to create a **clean, modern, and accessible user interface**, moving away from the original retro aesthetic to improve usability and maintainability.

The final "V2" application will be:

*   **Declarative & Reactive:** The UI will be a direct function of the application's state, updating automatically.
*   **Type-Safe:** Leveraging TypeScript to prevent common bugs and improve code clarity.
*   **Modular & Decoupled:** A clean separation between UI components, state stores, business logic services, and intensive background workers.
*   **Performant:** Built with Svelte's compile-time optimizations and Vite's fast tooling.
*   **Statically Deployable:** The final output will be a folder of static files, fully compatible with GitHub Pages or any simple web server, preserving the original's deployment simplicity.
*   **Feature-Complete:** All core features of the original, including URL state serialization for sharing links with specific settings, will be preserved and enhanced.

### **2. The Final Technology Stack**

| Category                  | Tool / Technology                                       | Role & Rationale                                                                                                                                                            |
| :------------------------ | :------------------------------------------------------ | :-------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| **Framework**             | **SvelteKit**                                           | Provides the application structure, file-based routing, and a powerful build system powered by Vite. Its `adapter-static` is perfect for our deployment needs.            |
| **UI Library**            | **Svelte**                                              | A compiler that turns components into highly efficient vanilla JavaScript. Its reactivity model is ideal for this project.                                              |
| **Language**              | **TypeScript**                                          | Enforces type safety across the entire codebase, eliminating a major class of runtime errors and making the code self-documenting.                                     |
| **Styling**               | **Tailwind CSS**                                        | A utility-first CSS framework for rapidly building a custom, modern design without writing extensive custom CSS. Ensures a tiny, optimized final CSS file.               |
| **Component Library**     | **Skeleton UI**                                         | A Svelte-native component library built on Tailwind CSS. It provides pre-built, accessible components (Buttons, Sliders, etc.) to accelerate modern UI development.       |
| **State Management**      | **Svelte Stores**                                       | The simple, powerful, and built-in solution for reactive state management. We will use multiple stores for clear separation of concerns, including `derived` stores.       |
| **WASM/ML Libraries**     | **`onnxruntime-web` (NPM)** & `rubberband-wasm` (static) | `onnxruntime-web` will be managed via NPM for robust VAD analysis. `rubberband` assets will be served statically from the `static` folder.                              |
| **Testing**               | **Vitest & Playwright**                                 | A complete testing suite. Vitest for fast unit/component tests, and Playwright for robust end-to-end browser tests.                                                  |
| **Code Quality**          | **ESLint & Prettier**                                   | Essential tools for automatically enforcing consistent code style and catching potential bugs before they happen.                                                        |
| **Build Tooling**         | **Vite**                                                | SvelteKit's underlying build tool. We will leverage its first-class support for Web Workers (`?worker`) and static asset handling.                                    |

### **3. The Final Architecture**

The V2 architecture uses a **unidirectional data flow** for a clear and predictable application state.

**Core Data Flow:**
`User Action in Component` -> `Calls Service Method` -> `Service Performs Logic` -> `Service Updates Store` -> `Component Reactively Updates`

#### **3.1. Directory Structure**

```
.
├── .github/
├── build/                  <-- Final static output folder
├── static/                 <-- Non-NPM assets (rubberband.wasm, silero_vad.onnx)
├── src/
│   ├── lib/
│   │   ├── actions/
│   │   │   └── sparkles.action.ts
│   │   ├── components/
│   │   │   ├── visualizers/
│   │   │   │   ├── Waveform.svelte
│   │   │   │   └── Spectrogram.svelte
│   │   │   ├── Controls.svelte
│   │   │   └── FileLoader.svelte
│   │   ├── services/
│   │   │   ├── audioEngine.service.ts
│   │   │   └── analysis.service.ts
│   │   ├── stores/
│   │   │   ├── player.store.ts
│   │   │   ├── status.store.ts
│   │   │   ├── analysis.store.ts
│   │   │   └── derived.store.ts      <-- For computed state like isAppBusy
│   │   ├── types/
│   │   │   ├── index.ts
│   │   │   └── worker.types.ts       <-- For type-safe worker messages
│   │   ├── utils/
│   │   │   └── index.ts
│   │   └── workers/
│   │       ├── rubberband.worker.ts
│   │       ├── sileroVad.worker.ts
│   │       └── spectrogram.worker.ts
│   ├── routes/
│   │   └── +page.svelte
│   └── app.html
├── tests/
└── svelte.config.js
```

#### **3.2. Architectural Layers**

1.  **Service Layer (`src/lib/services/`):**
    *   The "brain" of the application. Services are UI-agnostic TypeScript **singletons** (created once and exported) that handle complex logic.
    *   Each service will expose `initialize()` and `dispose()` methods to be called from the main component's lifecycle hooks (`onMount`, `onDestroy`).
    *   `audioEngine.service.ts`: Manages the Web Audio API and the Rubberband WASM worker.
    *   `analysis.service.ts`: Manages the Silero VAD worker and contains the rewritten Goertzel logic for tone detection.

2.  **State Layer (`src/lib/stores/`):**
    *   The reactive "heart" and single source of truth, composed of multiple Svelte stores.
    *   `derived.store.ts` will be used to compute values from other stores (e.g., an `isAppBusy` flag) to simplify logic in components.

3.  **Component Layer (`src/lib/components/` & `src/routes/`):**
    *   The "face" of the application. Components are "dumb" and focused on presentation.
    *   They **read** from stores to display data and **call** service methods to trigger actions.
    *   Visualizers (`Waveform.svelte`, `Spectrogram.svelte`) are now self-contained Svelte components.

4.  **Worker Layer (`src/lib/workers/`):**
    *   A dedicated home for all Web Worker scripts, used for computationally intensive tasks.
    *   Vite's `?worker` import syntax will be used to handle bundling and pathing automatically.

5.  **Actions Layer (`src/lib/actions/`):**
    *   Home for Svelte Actions, which are functions that provide a clean way to interact directly with DOM elements.
    *   `sparkles.action.ts` will encapsulate the sparkle effect.

### **4. Step-by-Step Migration Process**

This will be performed on a dedicated `feature/svelte-refactor` branch.

1.  **Phase 0: Project Scaffolding & Configuration:**
    *   Run `npm create svelte@latest vibe-player-v2`. Select "Skeleton project" with TypeScript, ESLint, Prettier, Playwright, Vitest.
    *   `cd vibe-player-v2` and `npm install`.
    *   Install dependencies: `npm install onnxruntime-web` and `npm install -D tailwindcss postcss autoprefixer vite-plugin-static-copy`.
    *   Initialize Tailwind: `npx svelte-add@latest tailwindcss`.
    *   Configure `adapter-static` in `svelte.config.js`.
    *   In `vite.config.js`, configure `vite-plugin-static-copy` to copy the `onnxruntime-web` WASM files to the build output directory.

2.  **Phase 1: Asset & Core Logic Migration:**
    *   Copy `rubberband.wasm`, `rubberband-loader.js`, and `silero_vad.onnx` into `vibe-player-v2/static/`.
    *   Create the Svelte stores in `src/lib/stores/`, including `derived.store.ts`.
    *   Rewrite `constants.js` and `utils.js` as typed TypeScript modules in `src/lib/utils/index.ts`.
    *   Implement URL State Serialization: Create a utility that subscribes to stores and updates the URL via `goto()`. This utility must use **debouncing** to avoid excessive updates and a flag to prevent loops during initial page load.

3.  **Phase 2: Service & Worker Implementation:**
    *   Create a shared `src/lib/types/worker.types.ts` file to define interfaces for all `postMessage` data, ensuring type-safe communication.
    *   Implement the singleton `audioEngine.service.ts` and its `rubberband.worker.ts`.
    *   Implement the singleton `analysis.service.ts` and its `sileroVad.worker.ts`. This service will import `onnxruntime-web` as a module.

4.  **Phase 3: UI Reconstruction:**
    *   Clear `src/routes/+page.svelte` and build the main layout using Skeleton UI components for a modern, clean aesthetic. This is a full UI redesign.
    *   In `+page.svelte`, use `onMount` and `onDestroy` to call the `initialize()` and `dispose()` methods of the services.
    *   Create reusable Svelte components (`FileLoader.svelte`, `Controls.svelte`, etc.) and the visualizer components.
    *   Implement `sparkles.action.ts` and apply it to a root layout element.

5.  **Phase 4: Test Rewrite:**
    *   Write Vitest unit tests for utility functions and services. **Plan for extensive mocking** of browser-only APIs (`AudioContext`, `Worker`, `ort.InferenceSession`) using Vitest's `vi.mock()` capabilities.
    *   Write Vitest + Svelte Testing Library component tests for key UI interactions.
    *   Rewrite the Playwright E2E tests to target the new component structure and user flows.

6.  **Phase 5: Documentation & The Switchover:**
    *   Rewrite `architecture.md` to fully document the new SvelteKit architecture. Update `README.md`.
    *   Once the feature branch is complete, merge it into `main`.
    *   Update all `.github/workflows/*.yml` files. The `path` for `upload-pages-artifact` in `deploy.yml` will now be `./build`, and test/build commands will be `npm run test` and `npm run build`.
    *   In a separate PR, delete the old `vibe-player` directory and all obsolete root-level files to finalize the transition.

### **5. Key Challenges & Solutions**

*   **Challenge: `AudioContext` User Gesture Policy.** Modern browsers block audio until a user interaction.
    *   **Solution:** The `audioEngine.service` will have an `unlockAudio()` method. This method will be called only once, after the first user click (e.g., on the "Choose File" button), ensuring the `AudioContext` is properly resumed.

*   **Challenge: Dual WASM Loading Patterns.** `onnxruntime-web` fetches its own WASM, while Rubberband uses a legacy loader.
    *   **Solution:** The `audioEngine.service` will pass the public path to `rubberband.wasm` (constructed using SvelteKit's `$app/paths`) as an initialization message to its worker. This ensures the worker knows where to find its static asset.

*   **Challenge: Worker Type-Safety.** `postMessage` is inherently untyped.
    *   **Solution:** We will create and use a shared `src/lib/types/worker.types.ts` file that defines interfaces for all worker message payloads. Both the services and the workers will import these types.

*   **Challenge: Testing Browser-Dependent Services.** Vitest runs in Node.js and lacks browser APIs.
    *   **Solution:** The test plan explicitly includes a phase for creating robust mocks for `AudioContext`, `Worker`, and other browser-only globals, allowing for isolated unit testing of service logic.

### **6. Architectural Principles (The V2 Golden Rules)**

*   **Prefer Svelte Reactivity over Direct DOM Manipulation.** All UI updates should be a result of store changes.
*   **Keep Components Focused on Presentation.** Complex logic, state management, and side effects belong in services and stores.
*   **Maintain Unidirectional Data Flow.** Services update stores; components read from stores and call services. Services do not read from stores to prevent circular dependencies.
*   **Encapsulate Intensive Tasks in Workers.** Any long-running or CPU-intensive task (VAD, spectrograms, audio processing) must be offloaded to a Web Worker to keep the UI responsive.
````
--- End of File: REFACTOR_PLAN.txt ---
--- File: vibe-player/architecture.md ---
````markdown
<!-- /vibe-player/architecture.md -->

# Vibe Player Architecture

## 1. Overview

* **Purpose:** Browser-based audio player focused on playback speed/pitch manipulation, voice activity detection (VAD)
  visualization, and waveform/spectrogram display. Designed for static file deployment.
* **Core Philosophy:** Prioritize simplicity and minimal dependencies by using Vanilla JS, HTML, and CSS. Leverage
  WebAssembly (WASM) via standardized Web APIs (`AudioWorklet`, `ONNX Runtime Web`) for computationally intensive
  tasks (audio processing, ML inference) that would otherwise be difficult or impossible client-side. The application
  follows an event-driven interaction flow managed by a central controller (`app.js`).

## 2. Key Technologies

* **Frontend:** HTML5, CSS3 (98.css for styling + custom `styles.css`), Vanilla JavaScript (ES6 Modules via IIFE pattern
  on `AudioApp` namespace)
* **Audio Engine:** Web Audio API (`AudioContext`, `GainNode`, `AudioWorkletNode`, `OfflineAudioContext` for resampling)
* **Time/Pitch Shifting:** Rubberband WASM library (via `js/player/rubberbandProcessor.js` AudioWorklet).
    * **Loader (`lib/rubberband-loader.js`):** ***Note:*** *This is a heavily modified version of the standard
      Emscripten loader, adapted specifically for use within the AudioWorklet context and to handle WASM instantiation
      via a hook.*
    * **Temporal Accuracy:** ***Note:*** *Rubberband prioritizes audio quality over strict temporal accuracy. The number
      of output frames generated may not perfectly match the requested time ratio for a given input block, and its
      internal time/latency reporting can drift relative to the Web Audio clock. Therefore, its time reports are not
      used directly for precise UI indicator synchronization.*
* **VAD:** Silero VAD model (`model/silero_vad.onnx`) executed via ONNX Runtime Web (WASM backend in `lib/`)
* **Visualizations:** HTML Canvas API (2D Context), FFT.js library (`lib/fft.js`).
    * **FFT Library (`lib/fft.js`):** ***Note:*** *This is based on indutny/fft.js but contains modifications made
      during initial development to ensure compatibility or functionality.*
* **DTMF & Call Progress Tone (CPT) Detection:**
    * The application can detect and display common DTMF tones (0-9, *, #, A-D) and Call Progress Tones (e.g., Dial
      Tone, Busy Signal, Ringback).
    * This is achieved using JavaScript implementations of the Goertzel algorithm and custom parsers (`DTMFParser`,
      `CallProgressToneParser`) located in `js/goertzel.js`.
    * `DTMFParser` identifies DTMF characters by detecting pairs of specific frequencies.
    * `CallProgressToneParser` identifies CPTs by detecting specific frequencies and their cadences (on/off patterns).

## 3. Code Structure (`js/` directory)

* **`app.js` (Controller):** Initializes modules, orchestrates loading/VAD/DTMF-CPT/playback flow, handles events,
  manages core state. Manages main-thread time updates using `AudioContext.currentTime`. For DTMF/CPT detection, it
  resamples audio to 16kHz mono, iterates through it in blocks, passes these to `DTMFParser` and
  `CallProgressToneParser` instances, and relays results to `uiManager.js` for display.
* **`constants.js`:** Defines shared constants (paths, parameters, colors, etc.).
* **`goertzel.js`:** Contains implementations of the Goertzel algorithm (`GoertzelFilter`), `DTMFParser`, and
  `CallProgressToneParser` for detecting specific frequencies and patterns for DTMF and CPTs.
* **`utils.js`:** Contains shared utility functions (e.g., `formatTime`, `yieldToMainThread`, `hannWindow`,
  `viridisColor`).
* **`uiManager.js` (View/UI Logic):** Handles all direct DOM manipulation, UI event listeners, and dispatches UI events.
  Manages VAD progress bar UI.
* **`js/player/`:**
    * **`audioEngine.js` (Audio Backend):** Manages Web Audio API, `AudioWorkletNode` lifecycle/communication, audio
      decoding, and resampling capability. Relays time updates from worklet but isn't the primary source for UI timing.
    * **`rubberbandProcessor.js` (AudioWorklet):** Runs in worklet thread. Interfaces with Rubberband WASM for
      time/pitch processing. Communicates via messages with `audioEngine.js`. Reports its consumed source time,
      acknowledging potential inaccuracies.
* **`js/vad/`:**
    * **`sileroWrapper.js` (VAD ONNX Interface):** Wraps ONNX Runtime session for the Silero VAD model. Handles
      inference calls and state tensors.
    * **`sileroProcessor.js` (VAD Frame Logic):** Iterates audio frames, calls `sileroWrapper`, calculates regions based
      on probabilities/thresholds, yields to main thread, reports progress.
    * **`vadAnalyzer.js` (VAD State Manager):** Bridges `app.js` and VAD processing. Holds VAD results/thresholds.
      Initiates analysis and recalculation.
* **`js/visualizers/`:**
    * **`waveformVisualizer.js`:** Computes and draws the waveform display, handles highlighting, resizing, progress
      indicator, and click-to-seek.
    * **`spectrogramVisualizer.js`:** Computes (using FFT.js) and draws the spectrogram display, manages caching,
      resizing, progress indicator, click-to-seek, and loading spinner.

## 4. Interaction Flow & State Management

* **Loading Sequence:**
    1. `UI (Choose File)` -> `uiManager` dispatches `audioapp:fileSelected`.
    2. `app.js (handleFileSelected)`: Resets state/UI, shows spinner, calls `audioEngine.loadAndProcessFile`.
    3. `audioEngine`: Decodes audio, dispatches `audioapp:audioLoaded`. Sets up worklet asynchronously.
    4. `app.js (handleAudioLoaded)`: Stores `currentAudioBuffer`, updates time/seek UI, calls
       `visualizer.computeAndDrawVisuals([])` (triggers gray waveform + spectrogram draw), hides main spinner, calls
       `runVadInBackground` (async), and calls `processAudioForTones` (async).
    5. `audioEngine`: When worklet setup is complete, dispatches `audioapp:workletReady`.
    6. `app.js (handleWorkletReady)`: Sets `workletPlaybackReady=true`, enables playback controls/seek bar. **Playback
       is now possible.**
    7. `app.js (runVadInBackground)` (Running concurrently with tone detection):
        * Initializes VAD model if needed (`sileroWrapper.create`).
        * Shows VAD progress bar (`uiManager`).
        * Calls `audioEngine.resampleTo16kMono` (if not already done for tones, or uses existing resampled data).
        * Calls `vadAnalyzer.analyze` (which calls `sileroProcessor.analyzeAudio` with progress callback).
        * `sileroProcessor`: Iterates frames, calls `sileroWrapper.process`, yields, calls progress callback ->
          `uiManager.updateVadProgress`.
        * On VAD completion/error: Updates VAD results in `app.js`, updates VAD slider UI (`uiManager`), redraws
          waveform highlights (`visualizer.redrawWaveformHighlight`), updates progress bar to 100% or 0%.
    8. `app.js (processAudioForTones)` (Running concurrently with VAD):
        * Calls `audioEngine.resampleTo16kMono` (if not already done for VAD, or uses existing resampled data).
        * Initializes `DTMFParser` and `CallProgressToneParser`.
        * Iterates through resampled audio data in blocks, feeding them to the parsers.
        * Collects results and passes them to `uiManager.setDtmfCptResults` for display.
* **Playback Control:** `UI (Button Click)` -> `uiManager` dispatches event -> `app.js (handlePlayPause/Jump/Seek)` ->
  `audioEngine` (sends command message) -> `rubberbandProcessor`. Status feedback: `rubberbandProcessor` (sends state
  message) -> `audioEngine` (dispatches event) -> `app.js (handlePlaybackStateChange)` -> `uiManager` (updates button).
* **Parameter Control (Speed/Pitch/Gain):** `UI (Slider Input)` -> `uiManager` dispatches event ->
  `app.js (handleSpeed/Pitch/GainChange)` -> `audioEngine`. Gain applied directly via `GainNode`. Speed/Pitch command
  message sent to `rubberbandProcessor`.
* **VAD Threshold Tuning:** `UI (Slider Input)` -> `uiManager` dispatches `audioapp:thresholdChanged` ->
  `app.js (handleThresholdChange)` (checks if VAD done) -> `vadAnalyzer.handleThresholdUpdate` ->
  `sileroProcessor.recalculateSpeechRegions` -> `app.js` receives new regions -> `visualizer.redrawWaveformHighlight` &
  `uiManager.setSpeechRegionsText`.
* **State:** Core state (`currentAudioBuffer`, playback flags, `currentVadResults`, DTMF/CPT results) managed centrally
  in `app.js`. `audioEngine` manages worklet communication state. `vadAnalyzer` manages VAD results/thresholds.
  `uiManager` reflects state in the DOM. `sileroWrapper` and `rubberbandProcessor` manage internal WASM state.
* **Key Points:** Loading involves: Decode -> Initial Visuals (Waveform+Spectrogram) -> Background VAD & DTMF/CPT
  Processing (concurrently) -> Waveform Highlighting & Tone Display. Playback enabled after worklet ready, independent
  of VAD/Tone completion.
* **Time Synchronization:** UI progress indicator is driven by `app.js` using main-thread `AudioContext.currentTime`
  calculations, compensated for speed changes. Explicit seeks are sent to `audioEngine` on pause and after speed slider
  adjustments (debounced) to force engine synchronization with the main thread's estimate, mitigating drift from
  Rubberband's internal timing.

### 4.1 GUI State Transitions

The following diagram illustrates the primary states and transitions of the Vibe Player GUI.

```mermaid
stateDiagram-v2
    direction LR

    [*] --> S_Initial
    S_Initial: Initial (No File Loaded)

    S_Initial --> S_LoadingFile: File/URL selected
    S_LoadingFile: Loading File (Fetching/Decoding)

    S_LoadingFile --> S_ProcessingAudio: Audio Decoded (audioLoaded event)
    note right of S_LoadingFile: Can transition to S_Error on decode/load failure

    S_LoadingFile --> S_Error: Decoding/Network Error

    S_ProcessingAudio: Processing Audio (Worklet Setup, VAD/Tone Analysis Initiated)
    note right of S_ProcessingAudio
        - Worklet being set up.
        - VAD analysis starts.
        - DTMF/CPT analysis starts.
        - Initial visuals (waveform/spectrogram) drawn.
    end note
    S_ProcessingAudio --> S_Ready: Worklet Ready (workletReady event)

    S_Ready: Ready to Play (Paused by default)
    note right of S_Ready
        - Playback controls active.
        - VAD/Tone results may still be processing
          or may complete in this state.
    end note

    S_Ready --> S_Playing: Play clicked
    S_Playing: Playing Audio

    S_Playing --> S_Ready: Pause clicked
    S_Playing --> S_Ready: Playback ended
    S_Playing --> S_Playing: Seek operation

    S_Ready --> S_Ready: Seek operation

    S_Ready --> S_LoadingFile: New File/URL selected (resets flow)
    S_Playing --> S_LoadingFile: New File/URL selected (resets flow)

    S_Error: Error State (e.g., Load/Decode Failed)
    S_Error --> S_Initial: UI Reset (user can select new file)

```

## 5. Design Decisions, Constraints & Tradeoffs

* **Static Hosting:** Simplifies deployment, no backend required. Limits features requiring server interaction. (
  Constraint C1)
* **Vanilla JS:** Reduces dependency footprint, avoids framework overhead/learning curve. Requires manual implementation
  of patterns (modules, state management). (Constraint C2)
* **IIFE Module Pattern:** Provides simple namespacing (`AudioApp`) without requiring a build step. Relies on careful
  script loading order.
* **Custom Events (`audioapp:*`):** Decouples UI Manager and Audio Engine from the main App controller, allowing modules
  to signal state changes or requests without direct dependencies on `app.js`'s internal methods. (Constraint C3)
* **AudioWorklet for Rubberband:** Essential for performing complex audio processing (time-stretching) off the main
  thread without blocking UI or audio playback. Adds architectural complexity for message passing and state
  synchronization between main thread (`audioEngine`) and worklet thread (`rubberbandProcessor`). Required a *
  *customized WASM loader** (`lib/rubberband-loader.js`).
    * **Alternative Considered (SoundTouchJS):** SoundTouchJS was evaluated, but the audio quality, especially at slower
      speeds, was significantly worse than Rubberband. Rubberband's computational cost was deemed acceptable for the
      quality improvement. Native Web Audio playback rate changes were also too choppy at low speeds.
    * **Rubberband Flags:** The primary goal for flag tuning was improving voice quality. The primary flags used are
      `ProcessRealTime`, `PitchHighQuality`, and `PhaseIndependent`. Other flags like `TransientsCrisp` might be part of
      the default behavior of the Rubberband library version used or were considered in earlier configurations.
      `EngineFiner` was tested but resulted in stuttering playback, likely due to exceeding CPU limits on the test
      machine; the default (faster) engine is currently used.
    * **Rubberband Temporal Inaccuracy:** ***(RESTORED)*** Rubberband prioritizes audio quality, leading to potential
      drift in its output duration and time reporting relative to Web Audio clock. This necessitates **main-thread time
      calculation** for the UI indicator and periodic seek-based synchronization. Analogy: Cannot use a rubber band as a
      precise ruler.
* **ONNX Runtime Web for VAD:** Enables use of standard ML models (like Silero VAD) directly in the browser via WASM.
  Avoids needing a dedicated VAD implementation.
* **Main-Thread VAD (Async):** VAD processing (`sileroProcessor`) runs on the main thread but uses `async/await` and
  `setTimeout(0)` to yield periodically.
    * **Tradeoff:** Simpler implementation for MVP compared to setting up a dedicated Web Worker for VAD. Avoids
      additional complexity of worker communication and state transfer.
    * **Downside:** Can still cause minor UI sluggishness during intense computation phases within
      `sileroWrapper.process`. Susceptible to browser throttling in background tabs (prevents VAD completion if tab is
      unfocused for a long time).
    * **(Clarification):** VAD processing currently does *not* run in a Web Worker. The idea was considered to allow
      completion even when the tab is backgrounded, but not implemented yet.
* **VAD Progress Updates:** Initial attempts at direct UI updates or simple `setTimeout(0)` from the VAD loop were
  unreliable for progress bar updates. The current solution uses a callback function passed down to `sileroProcessor`
  which calls `uiManager.updateVadProgress`.
* **JSDoc:** Chosen standard for JavaScript documentation in this project. (Constraint C7)
* **Manual Testing:** Adopted for rapid iteration during MVP phase. Lacks automated checks for regressions. (Constraint
  C5)
* **Visualizer Computation:** Waveform data calculated per-pixel. Spectrogram data computed entirely upfront (using *
  *modified `lib/fft.js`**) before being drawn asynchronously chunk-by-chunk.
    * **Tradeoff:** Faster waveform display. Spectrogram has an initial computation delay before drawing starts, but
      avoids the complexity of streaming FFT computation. Async drawing prevents blocking during render.
* **File Structure:** Modular approach with separate files/folders for distinct responsibilities (UI, Player, VAD,
  Visualizers, Controller, Constants, Utils). Asset types (CSS, Fonts) organized into folders. (Constraint C6, Asset
  Reorg)

## 6. Known Issues & Development Log

* **Formant Shifting (Non-Functional):** The mechanism for formant shifting is implemented, but it produces no audible
  effect with the current Rubberband WASM build and configuration.
    * **Details:** Attempts were made to enable formant scaling using `_rubberband_set_formant_scale`. Rubberband flags
      tested included permutations of `EngineFiner`, `PhaseIndependent`, `FormantPreserved`, and the current default
      flag set. Formant scaling was tested alone and in combination with phase/speed shifting (0.25x to 2.0x). Debugging
      confirmed the target scale value was successfully passed to the WASM function via the correct API call.
    * **Result:** No errors were thrown, but **no audible effect** from formant shifting was ever observed. The feature
      was abandoned as non-functional in the current Rubberband WASM build/configuration. It's uncertain if the issue is
      in the WASM compilation, the underlying library's formant preservation interaction with other flags, or a
      misunderstanding of the scale parameter (though multiplier is standard).
* **VAD Performance & Backgrounding:** Runs on main thread; may cause minor UI jank and pauses when tab unfocused.
* **Spectrogram Latency:** Initial computation delay before drawing begins.
* **Rubberband Engine Choice:** `EngineFiner` caused stuttering; using default (faster) engine.
* **Playback Indicator Drift (Mitigated):** Reliance on main-thread calculation and sync-on-pause/speed-change
  significantly reduces drift compared to trusting worklet time reports, but minor visual discrepancies *during* rapid
  parameter changes might still occur due to inherent system latencies.

<!-- /vibe-player/architecture.md -->

````
--- End of File: vibe-player/architecture.md ---
--- File: vibe-player/CONTRIBUTING-LLM.md ---
````markdown
<!-- /CONTRIBUTING-LLM.md -->

# Coding Agent Collaboration Guidelines

This document outlines the principles and procedures for collaborating with a coding agent or automated/semi-automated
development assistant on software projects. Adherence to these guidelines ensures efficient, maintainable, and
architecturally sound development. These guidelines can also support various LLM collaboration models, but the primary
focus is on agent-based development.

### P0: Agent Autonomy & Minimized Interaction

**Principle Statement:** The agent should operate with a high degree of autonomy once a task and its objectives are
clearly defined.

* **Reason:** To improve development velocity, reduce unnecessary user interruptions, and allow the agent to perform
  comprehensive tasks efficiently.
* **Context:** After the initial plan or task has been approved by the user, or for routine tasks that align with
  established patterns and guidelines.
* **Action:**
    * The agent must proceed with task implementation without seeking confirmation for intermediate steps, unless a step
      involves significant architectural deviation, conflicts with core guidelines, or encounters critical ambiguity not
      solvable with P2.1 (Proactive Clarification Seeking).
    * Confirmation should primarily be reserved for: initial plan approval, major changes to agreed-upon plans,
      situations explicitly requiring user choice, or when critical information is missing after an attempt to clarify.
    * The agent should default to making reasonable, well-documented decisions to keep work flowing, reporting these
      decisions in its task summary or commit messages.

### P1: Task-Driven Workflow & Initial Confirmation

**Principle Statement:** Complex tasks or those initiating significant changes require an initial proposal and user
confirmation before full implementation.

* **Reason:** Ensures user alignment on scope and approach for major work, prevents wasted effort on undesired
  solutions, and maintains user oversight on architectural decisions.
* **Context:** When initiating any non-trivial change (new features, significant refactoring, extensive documentation
  rewrites) or when explicitly requested by the user.
* **Action:** The agent first analyzes the task, then outlines a proposed solution (e.g., affected files, high-level
  logic changes, key components to be developed/modified). This proposal is presented to the user for explicit
  confirmation. Only after confirmation should the agent proceed with the detailed implementation of that proposal.
  Minor, clearly defined sub-tasks within an approved plan generally do not require re-confirmation (see P0).

### P2: Clarity & Explicit Communication

#### P2.1: Proactive Clarification Seeking

**Principle Statement:** The agent must seek clarification for ambiguous tasks or requirements.

* **Reason:** Avoids incorrect assumptions and wasted effort. Leverages user's domain/project knowledge.
* **Context:** Whenever requirements, existing code, constraints, or user intent seem ambiguous or underspecified.
* **Action:** The agent **must halt and ask** clarifying questions before making assumptions or generating potentially
  incorrect output.

#### P2.2: Explanation of Changes (Structured Output)

**Principle Statement:** The agent must explain its actions and rationale in a structured manner.

* **Reason:** Provides a clear record of actions and rationale, especially regarding design choices or non-obvious
  logic. Aids user review and architectural oversight.
* **Context:** When providing any generated code, text block, or completing a task.
* **Action:** The agent explains *what* it did and *why* the specific approach was taken (e.g., in a commit message
  draft, task report, or logs), especially if there were alternatives.

### P3: Maintainability & Consistency

#### P3.1: Adherence to Existing Patterns & Controlled Refactoring

**Principle Statement:** The agent must adhere to existing project patterns by default and propose refactoring only with
explicit user approval.

* **Reason:** Ensures codebase remains cohesive and allows for controlled improvements. Reduces cognitive load.
* **Context:** When adding or modifying code or documentation.
* **Action:**
    * The agent **must analyze and strictly adhere** to existing project patterns (style, structure, naming conventions)
      during initial implementation or when not explicitly told to refactor. This is the default operational mode.
    * If the agent identifies areas where deviation from existing patterns could significantly improve code health,
      maintainability, performance, or align better with best practices, it **may propose these refactoring changes** to
      the user, explaining the rationale clearly. Such refactoring requires explicit user approval and activation of a "
      Refactor phase" before implementation.

#### P3.2: High-Quality Documentation & Comments

**Principle Statement:** The agent must generate high-quality documentation and comments for the code it produces and
preserve existing relevant comments.

* **Reason:** Critical for future agent understanding and maintenance (including historical context), aids human
  comprehension, enables IDE features.
* **Context:** When generating or modifying functions, classes, complex variables, modules, or significant logic blocks.
* **Action:**
    * The agent generates comprehensive Doc comments compatible with project standards (e.g., JSDoc, reST - specify
      further if needed). Include descriptions, parameters, returns, types, and potentially exceptions/raises.
    * Use inline comments for complex logic steps.
    * **Crucially, preserve existing meaningful comments unless the code they refer to is removed. These comments serve
      as a historical log for future agent context to understand *why* code evolved.** Maintain documentation alongside
      code.

#### P3.3: Conciseness and Non-Redundancy in Documentation

**Principle Statement:** All generated documentation and explanations should be concise and non-redundant.

* **Reason:** Optimizes agent processing time/cost, reduces noise for human readers, improves maintainability of the
  documentation itself.
* **Context:** When generating or updating *any* documentation, including this `CONTRIBUTING-LLM.md`, `README.md`,
  `architecture.md`, or code comments/docstrings.
* **Action:** The agent should strive for concise language in all generated text. Avoid redundancy. Use precise
  terminology. However, when explaining complex logic or design choices, **prioritize the clarity needed for both human
  and future agent understanding**, even if it requires slightly more detail than absolute minimum brevity would allow.

#### P3.4: File Identification Comments (Full Files Only)

**Principle Statement:** Full file content generated by the agent must include file identification comments.

* **Reason:** Allows agent to identify file context when receiving pasted content; allows user to verify paste location.
* **Context:** When generating the *entire content* of a file.
* **Action:** The agent includes file path comments at the **absolute start and end** of the generated file content (
  e.g., `# /path/to/script.py`, `<!-- /path/to/file.html -->`). Use the appropriate comment style for the file type. Not
  needed for partial replacements.

#### P3.5: Logical Sectioning (Long Files)

**Principle Statement:** Long files should be logically sectioned using comments.

* **Reason:** Improves readability and navigation for humans and agents. Facilitates targeted section replacements.
* **Context:** When working with files containing multiple distinct logical parts.
* **Action:** The agent uses clear section header comments (e.g., `# --- Initialization ---`,
  `/* === API Handlers === */`) to delineate logical blocks. Use the appropriate comment style.

### P4: Guideline Adherence & Conflict Reporting

#### P4.1: Proactive Viability Check & Reporting

**Principle Statement:** The agent should report if its knowledge suggests a guideline or constraint is suboptimal for a
task.

* **Reason:** To proactively identify guidelines or constraints that might be outdated or conflict with best practices,
  based on the agent's internal knowledge.
* **Context:** When a task relates to specific guidelines or constraints.
* **Action:** If the agent's internal knowledge suggests a guideline might be outdated or conflict with best practices
  for the given task, it **must report** this to the user as part of its analysis or proposal. It should not
  independently act against the guideline but await user instruction.

#### P4.2: Identify and Report Guideline Conflicts

**Principle Statement:** The agent must identify and report conflicts between user instructions and established
guidelines, seeking explicit direction.

* **Reason:** To resolve discrepancies when user instructions contradict established guidelines, ensuring consistent
  application or conscious deviation.
* **Context:** When a direct user instruction conflicts with a specific rule in these guidelines.
* **Action:** The agent **must** identify and clearly point out any conflict between user instructions and established
  guidelines, referencing the specific rule. It must then report this conflict and ask the user for explicit instruction
  on how to proceed for that instance.

### P6: README Generation Requirement

**Principle Statement:** A reference to these coding agent collaboration guidelines must be included in the project's
main README.md.

* **Reason:** Ensures project users and future agents are aware these collaboration guidelines exist and should be
  followed for consistency.
* **Context:** When generating or significantly updating a project's `README.md` file.
* **Action:** The agent **must** include a statement in the `README.md` (e.g., in a "Developer Notes" or "Contributing"
  section) advising that development involving agent assistance should follow the rules outlined in
  `CONTRIBUTING-LLM.md` (adjust path if needed) and instructing potential contributors/agents to request this file if it
  wasn't provided.

### P7: Branch-Based Code Submission

**Principle Statement:** The agent submits work by committing to feature branches and pushing to the remote repository,
enabling review and CI/CD.

* **Reason:** Ensures code changes are visible for review, allows CI/CD integration, facilitates collaboration, and
  avoids inaccessible local code.
* **Context:** Upon completion of a defined task, a logical sub-task, or when needing to share work-in-progress that is
  stable enough for review.
* **Action:** The agent commits changes with clear, descriptive messages to a dedicated feature branch and pushes it to
  the remote repository. The agent should not require users to perform local tests before code is pushed; testing is
  assumed to occur post-push (automated or manual review). Commits should represent logical units of work.

<!-- /CONTRIBUTING-LLM.md -->

````
--- End of File: vibe-player/CONTRIBUTING-LLM.md ---
--- File: vibe-player/css/98.css ---
````css
/*! 98.css v0.1.20 - https://github.com/jdan/98.css */
@font-face {
    font-family: "Pixelated MS Sans Serif";
    font-style: normal;
    font-weight: 400;
    src: url(../fonts/ms_sans_serif.woff) format("woff");
    src: url(../fonts/ms_sans_serif.woff2) format("woff2")
}

@font-face {
    font-family: "Pixelated MS Sans Serif";
    font-style: normal;
    font-weight: 700;
    src: url(../fonts/ms_sans_serif_bold.woff) format("woff");
    src: url(../fonts/ms_sans_serif_bold.woff2) format("woff2")
}

body {
    color: #222;
    font-family: Arial;
    font-size: 12px
}

.title-bar, .window, button, input, label, legend, li[role=tab], option, select, table, textarea, ul.tree-view {
    -webkit-font-smoothing: none;
    font-family: "Pixelated MS Sans Serif", Arial;
    font-size: 11px
}

h1 {
    font-size: 5rem
}

h2 {
    font-size: 2.5rem
}

h3 {
    font-size: 2rem
}

h4 {
    font-size: 1.5rem
}

u {
    border-bottom: .5px solid #222;
    text-decoration: none
}

button, input[type=reset], input[type=submit] {
    background: silver;
    border: none;
    border-radius: 0;
    box-shadow: inset -1px -1px #0a0a0a, inset 1px 1px #fff, inset -2px -2px grey, inset 2px 2px #dfdfdf;
    box-sizing: border-box;
    color: transparent;
    min-height: 23px;
    min-width: 75px;
    padding: 0 12px;
    text-shadow: 0 0 #222
}

button.default, input[type=reset].default, input[type=submit].default {
    box-shadow: inset -2px -2px #0a0a0a, inset 1px 1px #0a0a0a, inset 2px 2px #fff, inset -3px -3px grey, inset 3px 3px #dfdfdf
}

.vertical-bar {
    background: silver;
    box-shadow: inset -1px -1px #0a0a0a, inset 1px 1px #fff, inset -2px -2px grey, inset 2px 2px #dfdfdf;
    height: 20px;
    width: 4px
}

button:not(:disabled):active, input[type=reset]:not(:disabled):active, input[type=submit]:not(:disabled):active {
    box-shadow: inset -1px -1px #fff, inset 1px 1px #0a0a0a, inset -2px -2px #dfdfdf, inset 2px 2px grey;
    text-shadow: 1px 1px #222
}

button.default:not(:disabled):active, input[type=reset].default:not(:disabled):active, input[type=submit].default:not(:disabled):active {
    box-shadow: inset 2px 2px #0a0a0a, inset -1px -1px #0a0a0a, inset -2px -2px #fff, inset 3px 3px grey, inset -3px -3px #dfdfdf
}

/*
@media (not(hover)) {
    button:not(:disabled):hover,input[type=reset]:not(:disabled):hover,input[type=submit]:not(:disabled):hover {
        box-shadow:inset -1px -1px #fff,inset 1px 1px #0a0a0a,inset -2px -2px #dfdfdf,inset 2px 2px grey
    }
}
*/

button:focus, input[type=reset]:focus, input[type=submit]:focus {
    outline: 1px dotted #000;
    outline-offset: -4px
}

button::-moz-focus-inner, input[type=reset]::-moz-focus-inner, input[type=submit]::-moz-focus-inner {
    border: 0
}

:disabled, :disabled + label, input[readonly], input[readonly] + label {
    color: grey
}

:disabled + label, button:disabled, input[type=reset]:disabled, input[type=submit]:disabled {
    text-shadow: 1px 1px 0 #fff
}

.window {
    background: silver;
    box-shadow: inset -1px -1px #0a0a0a, inset 1px 1px #dfdfdf, inset -2px -2px grey, inset 2px 2px #fff;
    padding: 3px
}

.title-bar {
    align-items: center;
    background: linear-gradient(90deg, navy, #1084d0);
    display: flex;
    justify-content: space-between;
    padding: 3px 2px 3px 3px
}

.title-bar.inactive {
    background: linear-gradient(90deg, grey, #b5b5b5)
}

.title-bar-text {
    color: #fff;
    font-weight: 700;
    letter-spacing: 0;
    margin-right: 24px
}

.title-bar-controls {
    display: flex
}

.title-bar-controls button {
    display: block;
    min-height: 14px;
    min-width: 16px;
    padding: 0
}

.title-bar-controls button:active {
    padding: 0
}

.title-bar-controls button:focus {
    outline: none
}

.title-bar-controls button[aria-label=Minimize], .title-bar-controls button[aria-label].minimize {
    background-image: url("data:image/svg+xml;charset=utf-8,%3Csvg width='6' height='2' fill='none' xmlns='http://www.w3.org/2000/svg'%3E%3Cpath fill='%23000' d='M0 0h6v2H0z'/%3E%3C/svg%3E");
    background-position: bottom 3px left 4px;
    background-repeat: no-repeat
}

.title-bar-controls button[aria-label=Maximize], .title-bar-controls button[aria-label].maximize {
    background-image: url("data:image/svg+xml;charset=utf-8,%3Csvg width='9' height='9' fill='none' xmlns='http://www.w3.org/2000/svg'%3E%3Cpath fill-rule='evenodd' clip-rule='evenodd' d='M9 0H0v9h9V0zM8 2H1v6h7V2z' fill='%23000'/%3E%3C/svg%3E");
    background-position: top 2px left 3px;
    background-repeat: no-repeat
}

.title-bar-controls button[aria-label=Maximize]:disabled, .title-bar-controls button[aria-label].maximize:disabled {
    background-image: url("data:image/svg+xml;charset=utf-8,%3Csvg width='10' height='10' fill='none' xmlns='http://www.w3.org/2000/svg'%3E%3Cpath fill-rule='evenodd' clip-rule='evenodd' d='M10 1H1v9h9V1zM9 3H2v6h7V3z' fill='%23fff'/%3E%3Cpath fill-rule='evenodd' clip-rule='evenodd' d='M9 0H0v9h9V0zM8 2H1v6h7V2z' fill='gray'/%3E%3C/svg%3E");
    background-position: top 2px left 3px;
    background-repeat: no-repeat
}

.title-bar-controls button[aria-label=Restore], .title-bar-controls button[aria-label].restore {
    background-image: url("data:image/svg+xml;charset=utf-8,%3Csvg width='8' height='9' fill='none' xmlns='http://www.w3.org/2000/svg'%3E%3Cpath fill='%23000' d='M2 0h6v2H2zM7 2h1v4H7zM2 2h1v1H2zM6 5h1v1H6zM0 3h6v2H0zM5 5h1v4H5zM0 5h1v4H0zM1 8h4v1H1z'/%3E%3C/svg%3E");
    background-position: top 2px left 3px;
    background-repeat: no-repeat
}

.title-bar-controls button[aria-label=Help], .title-bar-controls button[aria-label].help {
    background-image: url("data:image/svg+xml;charset=utf-8,%3Csvg width='6' height='9' fill='none' xmlns='http://www.w3.org/2000/svg'%3E%3Cpath fill='%23000' d='M0 1h2v2H0zM1 0h4v1H1zM4 1h2v2H4zM3 3h2v1H3zM2 4h2v2H2zM2 7h2v2H2z'/%3E%3C/svg%3E");
    background-position: top 2px left 5px;
    background-repeat: no-repeat
}

.title-bar-controls button[aria-label=Close], .title-bar-controls button[aria-label].close {
    background-image: url("data:image/svg+xml;charset=utf-8,%3Csvg width='8' height='7' fill='none' xmlns='http://www.w3.org/2000/svg'%3E%3Cpath fill-rule='evenodd' clip-rule='evenodd' d='M0 0h2v1h1v1h2V1h1V0h2v1H7v1H6v1H5v1h1v1h1v1h1v1H6V6H5V5H3v1H2v1H0V6h1V5h1V4h1V3H2V2H1V1H0V0z' fill='%23000'/%3E%3C/svg%3E");
    background-position: top 3px left 4px;
    background-repeat: no-repeat;
    margin-left: 2px
}

.status-bar {
    gap: 1px;
    display: flex;
    margin: 0 1px
}

.status-bar-field {
    box-shadow: inset -1px -1px #dfdfdf, inset 1px 1px grey;
    flex-grow: 1;
    margin: 0;
    padding: 2px 3px
}

.window-body {
    margin: 8px
}

fieldset {
    border-image: url("data:image/svg+xml;charset=utf-8,%3Csvg width='5' height='5' fill='gray' xmlns='http://www.w3.org/2000/svg'%3E%3Cpath fill-rule='evenodd' clip-rule='evenodd' d='M0 0h5v5H0V2h2v1h1V2H0' fill='%23fff'/%3E%3Cpath fill-rule='evenodd' clip-rule='evenodd' d='M0 0h4v4H0V1h1v2h2V1H0'/%3E%3C/svg%3E") 2;
    margin: 0;
    padding: 10px;
    padding-block-start: 8px
}

legend {
    background: silver
}

.field-row {
    align-items: center;
    display: flex
}

[class^=field-row] + [class^=field-row] {
    margin-top: 6px
}

.field-row > * + * {
    margin-left: 6px
}

.field-row-stacked {
    display: flex;
    flex-direction: column
}

.field-row-stacked * + * {
    margin-top: 6px
}

label {
    align-items: center;
    display: inline-flex
}

input[type=checkbox], input[type=radio] {
    appearance: none;
    -webkit-appearance: none;
    -moz-appearance: none;
    background: 0;
    border: none;
    margin: 0;
    opacity: 0;
    position: fixed
}

input[type=checkbox] + label, input[type=radio] + label {
    line-height: 13px
}

input[type=radio] + label {
    margin-left: 18px;
    position: relative
}

input[type=radio] + label:before {
    background: url("data:image/svg+xml;charset=utf-8,%3Csvg width='12' height='12' fill='none' xmlns='http://www.w3.org/2000/svg'%3E%3Cpath fill-rule='evenodd' clip-rule='evenodd' d='M8 0H4v1H2v1H1v2H0v4h1v2h1V8H1V4h1V2h2V1h4v1h2V1H8V0z' fill='gray'/%3E%3Cpath fill-rule='evenodd' clip-rule='evenodd' d='M8 1H4v1H2v2H1v4h1v1h1V8H2V4h1V3h1V2h4v1h2V2H8V1z' fill='%23000'/%3E%3Cpath fill-rule='evenodd' clip-rule='evenodd' d='M9 3h1v1H9V3zm1 5V4h1v4h-1zm-2 2V9h1V8h1v2H8zm-4 0v1h4v-1H4zm0 0V9H2v1h2z' fill='%23DFDFDF'/%3E%3Cpath fill-rule='evenodd' clip-rule='evenodd' d='M11 2h-1v2h1v4h-1v2H8v1H4v-1H2v1h2v1h4v-1h2v-1h1V8h1V4h-1V2z' fill='%23fff'/%3E%3Cpath fill-rule='evenodd' clip-rule='evenodd' d='M4 2h4v1h1v1h1v4H9v1H8v1H4V9H3V8H2V4h1V3h1V2z' fill='%23fff'/%3E%3C/svg%3E");
    content: "";
    display: inline-block;
    height: 12px;
    left: -18px;
    margin-right: 6px;
    position: absolute;
    top: 0;
    width: 12px
}

input[type=radio]:active + label:before {
    background: url("data:image/svg+xml;charset=utf-8,%3Csvg width='12' height='12' fill='none' xmlns='http://www.w3.org/2000/svg'%3E%3Cpath fill-rule='evenodd' clip-rule='evenodd' d='M8 0H4v1H2v1H1v2H0v4h1v2h1V8H1V4h1V2h2V1h4v1h2V1H8V0z' fill='gray'/%3E%3Cpath fill-rule='evenodd' clip-rule='evenodd' d='M8 1H4v1H2v2H1v4h1v1h1V8H2V4h1V3h1V2h4v1h2V2H8V1z' fill='%23000'/%3E%3Cpath fill-rule='evenodd' clip-rule='evenodd' d='M9 3h1v1H9V3zm1 5V4h1v4h-1zm-2 2V9h1V8h1v2H8zm-4 0v1h4v-1H4zm0 0V9H2v1h2z' fill='%23DFDFDF'/%3E%3Cpath fill-rule='evenodd' clip-rule='evenodd' d='M11 2h-1v2h1v4h-1v2H8v1H4v-1H2v1h2v1h4v-1h2v-1h1V8h1V4h-1V2z' fill='%23fff'/%3E%3Cpath fill-rule='evenodd' clip-rule='evenodd' d='M4 2h4v1h1v1h1v4H9v1H8v1H4V9H3V8H2V4h1V3h1V2z' fill='silver'/%3E%3C/svg%3E")
}

input[type=radio]:checked + label:after {
    background: url("data:image/svg+xml;charset=utf-8,%3Csvg width='4' height='4' fill='none' xmlns='http://www.w3.org/2000/svg'%3E%3Cpath fill-rule='evenodd' clip-rule='evenodd' d='M3 0H1v1H0v2h1v1h2V3h1V1H3V0z' fill='%23000'/%3E%3C/svg%3E");
    content: "";
    display: block;
    height: 4px;
    left: -14px;
    position: absolute;
    top: 4px;
    width: 4px
}

input[type=checkbox]:focus + label, input[type=radio]:focus + label {
    outline: 1px dotted #000
}

input[type=radio][disabled] + label:before {
    background: url("data:image/svg+xml;charset=utf-8,%3Csvg width='12' height='12' fill='none' xmlns='http://www.w3.org/2000/svg'%3E%3Cpath fill-rule='evenodd' clip-rule='evenodd' d='M8 0H4v1H2v1H1v2H0v4h1v2h1V8H1V4h1V2h2V1h4v1h2V1H8V0z' fill='gray'/%3E%3Cpath fill-rule='evenodd' clip-rule='evenodd' d='M8 1H4v1H2v2H1v4h1v1h1V8H2V4h1V3h1V2h4v1h2V2H8V1z' fill='%23000'/%3E%3Cpath fill-rule='evenodd' clip-rule='evenodd' d='M9 3h1v1H9V3zm1 5V4h1v4h-1zm-2 2V9h1V8h1v2H8zm-4 0v1h4v-1H4zm0 0V9H2v1h2z' fill='%23DFDFDF'/%3E%3Cpath fill-rule='evenodd' clip-rule='evenodd' d='M11 2h-1v2h1v4h-1v2H8v1H4v-1H2v1h2v1h4v-1h2v-1h1V8h1V4h-1V2z' fill='%23fff'/%3E%3Cpath fill-rule='evenodd' clip-rule='evenodd' d='M4 2h4v1h1v1h1v4H9v1H8v1H4V9H3V8H2V4h1V3h1V2z' fill='silver'/%3E%3C/svg%3E")
}

input[type=radio][disabled]:checked + label:after {
    background: url("data:image/svg+xml;charset=utf-8,%3Csvg width='4' height='4' fill='none' xmlns='http://www.w3.org/2000/svg'%3E%3Cpath fill-rule='evenodd' clip-rule='evenodd' d='M3 0H1v1H0v2h1v1h2V3h1V1H3V0z' fill='gray'/%3E%3C/svg%3E")
}

input[type=checkbox] + label {
    margin-left: 19px;
    position: relative
}

input[type=checkbox] + label:before {
    background: #fff;
    box-shadow: inset -1px -1px #fff, inset 1px 1px grey, inset -2px -2px #dfdfdf, inset 2px 2px #0a0a0a;
    content: "";
    display: inline-block;
    height: 13px;
    left: -19px;
    margin-right: 6px;
    position: absolute;
    width: 13px
}

input[type=checkbox]:active + label:before {
    background: silver
}

input[type=checkbox]:checked + label:after {
    background: url("data:image/svg+xml;charset=utf-8,%3Csvg width='7' height='7' fill='none' xmlns='http://www.w3.org/2000/svg'%3E%3Cpath fill-rule='evenodd' clip-rule='evenodd' d='M7 0H6v1H5v1H4v1H3v1H2V3H1V2H0v3h1v1h1v1h1V6h1V5h1V4h1V3h1V0z' fill='%23000'/%3E%3C/svg%3E");
    content: "";
    display: block;
    height: 7px;
    left: -16px;
    position: absolute;
    width: 7px
}

input[type=checkbox][disabled] + label:before {
    background: silver
}

input[type=checkbox][disabled]:checked + label:after {
    background: url("data:image/svg+xml;charset=utf-8,%3Csvg width='7' height='7' fill='none' xmlns='http://www.w3.org/2000/svg'%3E%3Cpath fill-rule='evenodd' clip-rule='evenodd' d='M7 0H6v1H5v1H4v1H3v1H2V3H1V2H0v3h1v1h1v1h1V6h1V5h1V4h1V3h1V0z' fill='gray'/%3E%3C/svg%3E")
}

input[type=email], input[type=number], input[type=password], input[type=search], input[type=tel], input[type=text] {
    -webkit-appearance: none;
    -moz-appearance: none;
    appearance: none;
    border: none;
    border-radius: 0
}

input[type=email], input[type=number], input[type=password], input[type=search], input[type=tel], input[type=text], select {
    background-color: #fff;
    box-shadow: inset -1px -1px #fff, inset 1px 1px grey, inset -2px -2px #dfdfdf, inset 2px 2px #0a0a0a;
    box-sizing: border-box;
    padding: 3px 4px
}

select, textarea {
    border: none
}

textarea {
    -webkit-appearance: none;
    -moz-appearance: none;
    appearance: none;
    background-color: #fff;
    border-radius: 0;
    box-shadow: inset -1px -1px #fff, inset 1px 1px grey, inset -2px -2px #dfdfdf, inset 2px 2px #0a0a0a;
    box-sizing: border-box;
    padding: 3px 4px
}

input[type=email], input[type=password], input[type=search], input[type=tel], input[type=text], select {
    height: 21px
}

input[type=number] {
    height: 22px
}

input[type=search]::-ms-clear, input[type=search]::-ms-reveal {
    display: none;
    height: 0;
    width: 0
}

input[type=search]::-webkit-search-cancel-button, input[type=search]::-webkit-search-decoration, input[type=search]::-webkit-search-results-button, input[type=search]::-webkit-search-results-decoration {
    display: none
}

input[type=email], input[type=number], input[type=password], input[type=search], input[type=tel], input[type=text] {
    line-height: 2
}

input[type=email]:disabled, input[type=email]:read-only, input[type=number]:disabled, input[type=number]:read-only, input[type=password]:disabled, input[type=password]:read-only, input[type=search]:disabled, input[type=search]:read-only, input[type=tel]:disabled, input[type=tel]:read-only, input[type=text]:disabled, input[type=text]:read-only, textarea:disabled {
    background-color: silver
}

select {
    appearance: none;
    -webkit-appearance: none;
    -moz-appearance: none;
    background-image: url("data:image/svg+xml;charset=utf-8,%3Csvg width='16' height='17' fill='none' xmlns='http://www.w3.org/2000/svg'%3E%3Cpath fill-rule='evenodd' clip-rule='evenodd' d='M15 0H0v16h1V1h14V0z' fill='%23DFDFDF'/%3E%3Cpath fill-rule='evenodd' clip-rule='evenodd' d='M2 1H1v14h1V2h12V1H2z' fill='%23fff'/%3E%3Cpath fill-rule='evenodd' clip-rule='evenodd' d='M16 17H0v-1h15V0h1v17z' fill='%23000'/%3E%3Cpath fill-rule='evenodd' clip-rule='evenodd' d='M15 1h-1v14H1v1h14V1z' fill='gray'/%3E%3Cpath fill='silver' d='M2 2h12v13H2z'/%3E%3Cpath fill-rule='evenodd' clip-rule='evenodd' d='M11 6H4v1h1v1h1v1h1v1h1V9h1V8h1V7h1V6z' fill='%23000'/%3E%3C/svg%3E");
    background-position: top 2px right 2px;
    background-repeat: no-repeat;
    border-radius: 0;
    padding-right: 32px;
    position: relative
}

input[type=email]:focus, input[type=number]:focus, input[type=password]:focus, input[type=search]:focus, input[type=tel]:focus, input[type=text]:focus, select:focus, textarea:focus {
    outline: none
}

input[type=range] {
    -webkit-appearance: none;
    background: transparent;
    width: 100%
}

input[type=range]:focus {
    outline: none
}

input[type=range]::-webkit-slider-thumb {
    -webkit-appearance: none;
    background: url("data:image/svg+xml;charset=utf-8,%3Csvg width='11' height='21' fill='none' xmlns='http://www.w3.org/2000/svg'%3E%3Cpath fill-rule='evenodd' clip-rule='evenodd' d='M0 0v16h2v2h2v2h1v-1H3v-2H1V1h9V0z' fill='%23fff'/%3E%3Cpath fill-rule='evenodd' clip-rule='evenodd' d='M1 1v15h1v1h1v1h1v1h2v-1h1v-1h1v-1h1V1z' fill='%23C0C7C8'/%3E%3Cpath fill-rule='evenodd' clip-rule='evenodd' d='M9 1h1v15H8v2H6v2H5v-1h2v-2h2z' fill='%2387888F'/%3E%3Cpath fill-rule='evenodd' clip-rule='evenodd' d='M10 0h1v16H9v2H7v2H5v1h1v-2h2v-2h2z' fill='%23000'/%3E%3C/svg%3E");
    border: none;
    box-shadow: none;
    height: 21px;
    transform: translateY(-8px);
    width: 11px
}

input[type=range].has-box-indicator::-webkit-slider-thumb {
    background: url("data:image/svg+xml;charset=utf-8,%3Csvg width='11' height='21' fill='none' xmlns='http://www.w3.org/2000/svg'%3E%3Cpath fill-rule='evenodd' clip-rule='evenodd' d='M0 0v20h1V1h9V0z' fill='%23fff'/%3E%3Cpath fill='%23C0C7C8' d='M1 1h8v18H1z'/%3E%3Cpath fill-rule='evenodd' clip-rule='evenodd' d='M9 1h1v19H1v-1h8z' fill='%2387888F'/%3E%3Cpath fill-rule='evenodd' clip-rule='evenodd' d='M10 0h1v21H0v-1h10z' fill='%23000'/%3E%3C/svg%3E");
    transform: translateY(-10px)
}

input[type=range]::-moz-range-thumb {
    background: url("data:image/svg+xml;charset=utf-8,%3Csvg width='11' height='21' fill='none' xmlns='http://www.w3.org/2000/svg'%3E%3Cpath fill-rule='evenodd' clip-rule='evenodd' d='M0 0v16h2v2h2v2h1v-1H3v-2H1V1h9V0z' fill='%23fff'/%3E%3Cpath fill-rule='evenodd' clip-rule='evenodd' d='M1 1v15h1v1h1v1h1v1h2v-1h1v-1h1v-1h1V1z' fill='%23C0C7C8'/%3E%3Cpath fill-rule='evenodd' clip-rule='evenodd' d='M9 1h1v15H8v2H6v2H5v-1h2v-2h2z' fill='%2387888F'/%3E%3Cpath fill-rule='evenodd' clip-rule='evenodd' d='M10 0h1v16H9v2H7v2H5v1h1v-2h2v-2h2z' fill='%23000'/%3E%3C/svg%3E");
    border: 0;
    border-radius: 0;
    height: 21px;
    transform: translateY(2px);
    width: 11px
}

input[type=range].has-box-indicator::-moz-range-thumb {
    background: url("data:image/svg+xml;charset=utf-8,%3Csvg width='11' height='21' fill='none' xmlns='http://www.w3.org/2000/svg'%3E%3Cpath fill-rule='evenodd' clip-rule='evenodd' d='M0 0v20h1V1h9V0z' fill='%23fff'/%3E%3Cpath fill='%23C0C7C8' d='M1 1h8v18H1z'/%3E%3Cpath fill-rule='evenodd' clip-rule='evenodd' d='M9 1h1v19H1v-1h8z' fill='%2387888F'/%3E%3Cpath fill-rule='evenodd' clip-rule='evenodd' d='M10 0h1v21H0v-1h10z' fill='%23000'/%3E%3C/svg%3E");
    transform: translateY(0)
}

input[type=range]::-webkit-slider-runnable-track {
    background: #000;
    border-bottom: 1px solid grey;
    border-right: 1px solid grey;
    box-shadow: 1px 0 0 #fff, 1px 1px 0 #fff, 0 1px 0 #fff, -1px 0 0 #a9a9a9, -1px -1px 0 #a9a9a9, 0 -1px 0 #a9a9a9, -1px 1px 0 #fff, 1px -1px #a9a9a9;
    box-sizing: border-box;
    height: 2px;
    width: 100%
}

input[type=range]::-moz-range-track {
    background: #000;
    border-bottom: 1px solid grey;
    border-right: 1px solid grey;
    box-shadow: 1px 0 0 #fff, 1px 1px 0 #fff, 0 1px 0 #fff, -1px 0 0 #a9a9a9, -1px -1px 0 #a9a9a9, 0 -1px 0 #a9a9a9, -1px 1px 0 #fff, 1px -1px #a9a9a9;
    box-sizing: border-box;
    height: 2px;
    width: 100%
}

.is-vertical {
    display: inline-block;
    height: 150px;
    transform: translateY(50%);
    width: 4px
}

.is-vertical > input[type=range] {
    height: 4px;
    margin: 0 16px 0 10px;
    transform: rotate(270deg) translateX(calc(-50% + 8px));
    transform-origin: left;
    width: 150px
}

.is-vertical > input[type=range]::-webkit-slider-runnable-track {
    border-bottom: 1px solid grey;
    border-left: 1px solid grey;
    border-right: 0;
    box-shadow: -1px 0 0 #fff, -1px 1px 0 #fff, 0 1px 0 #fff, 1px 0 0 #a9a9a9, 1px -1px 0 #a9a9a9, 0 -1px 0 #a9a9a9, 1px 1px 0 #fff, -1px -1px #a9a9a9
}

.is-vertical > input[type=range]::-moz-range-track {
    border-bottom: 1px solid grey;
    border-left: 1px solid grey;
    border-right: 0;
    box-shadow: -1px 0 0 #fff, -1px 1px 0 #fff, 0 1px 0 #fff, 1px 0 0 #a9a9a9, 1px -1px 0 #a9a9a9, 0 -1px 0 #a9a9a9, 1px 1px 0 #fff, -1px -1px #a9a9a9
}

.is-vertical > input[type=range]::-webkit-slider-thumb {
    transform: translateY(-8px) scaleX(-1)
}

.is-vertical > input[type=range].has-box-indicator::-webkit-slider-thumb {
    transform: translateY(-10px) scaleX(-1)
}

.is-vertical > input[type=range]::-moz-range-thumb {
    transform: translateY(2px) scaleX(-1)
}

.is-vertical > input[type=range].has-box-indicator::-moz-range-thumb {
    transform: translateY(0) scaleX(-1)
}

select:focus {
    background-color: navy;
    color: #fff
}

select:focus option {
    background-color: #fff;
    color: #000
}

select:active {
    background-image: url("data:image/svg+xml;charset=utf-8,%3Csvg width='16' height='17' fill='none' xmlns='http://www.w3.org/2000/svg'%3E%3Cpath fill-rule='evenodd' clip-rule='evenodd' d='M0 0h16v17H0V0zm1 16h14V1H1v15z' fill='gray'/%3E%3Cpath fill='silver' d='M1 1h14v15H1z'/%3E%3Cpath fill-rule='evenodd' clip-rule='evenodd' d='M12 7H5v1h1v1h1v1h1v1h1v-1h1V9h1V8h1V7z' fill='%23000'/%3E%3C/svg%3E")
}

a {
    color: #00f
}

a:focus {
    outline: 1px dotted #00f
}

ul.tree-view {
    background: #fff;
    box-shadow: inset -1px -1px #fff, inset 1px 1px grey, inset -2px -2px #dfdfdf, inset 2px 2px #0a0a0a;
    display: block;
    margin: 0;
    padding: 6px
}

ul.tree-view li {
    list-style-type: none
}

ul.tree-view a {
    color: #000;
    text-decoration: none
}

ul.tree-view a:focus {
    background-color: navy;
    color: #fff
}

ul.tree-view li, ul.tree-view ul {
    margin-top: 3px
}

ul.tree-view ul {
    border-left: 1px dotted grey;
    margin-left: 16px;
    padding-left: 16px
}

ul.tree-view ul > li {
    position: relative
}

ul.tree-view ul > li:before {
    border-bottom: 1px dotted grey;
    content: "";
    display: block;
    left: -16px;
    position: absolute;
    top: 6px;
    width: 12px
}

ul.tree-view ul > li:last-child:after {
    background: #fff;
    bottom: 0;
    content: "";
    display: block;
    left: -20px;
    position: absolute;
    top: 7px;
    width: 8px
}

ul.tree-view details {
    margin-top: 0
}

ul.tree-view details[open] summary {
    margin-bottom: 0
}

ul.tree-view ul details > summary:before {
    margin-left: -22px;
    position: relative;
    z-index: 1
}

ul.tree-view details > summary:before {
    background-color: #fff;
    border: 1px solid grey;
    content: "+";
    display: block;
    float: left;
    height: 9px;
    line-height: 8px;
    margin-right: 5px;
    padding-left: 1px;
    text-align: center;
    width: 8px
}

ul.tree-view details[open] > summary:before {
    content: "-"
}

ul.tree-view details > summary::-webkit-details-marker, ul.tree-view details > summary::marker {
    content: ""
}

pre {
    background: #fff;
    box-shadow: inset -1px -1px #fff, inset 1px 1px grey, inset -2px -2px #dfdfdf, inset 2px 2px #0a0a0a;
    display: block;
    margin: 0;
    padding: 12px 8px
}

code, code * {
    font-family: monospace
}

summary:focus {
    outline: 1px dotted #000
}

::-webkit-scrollbar {
    width: 16px
}

::-webkit-scrollbar:horizontal {
    height: 17px
}

::-webkit-scrollbar-corner {
    background: #dfdfdf
}

::-webkit-scrollbar-track {
    background-image: url("data:image/svg+xml;charset=utf-8,%3Csvg width='2' height='2' fill='none' xmlns='http://www.w3.org/2000/svg'%3E%3Cpath fill-rule='evenodd' clip-rule='evenodd' d='M1 0H0v1h1v1h1V1H1V0z' fill='silver'/%3E%3Cpath fill-rule='evenodd' clip-rule='evenodd' d='M2 0H1v1H0v1h1V1h1V0z' fill='%23fff'/%3E%3C/svg%3E")
}

::-webkit-scrollbar-thumb {
    background-color: #dfdfdf;
    box-shadow: inset -1px -1px #0a0a0a, inset 1px 1px #fff, inset -2px -2px grey, inset 2px 2px #dfdfdf
}

::-webkit-scrollbar-button:horizontal:end:increment, ::-webkit-scrollbar-button:horizontal:start:decrement, ::-webkit-scrollbar-button:vertical:end:increment, ::-webkit-scrollbar-button:vertical:start:decrement {
    display: block
}

::-webkit-scrollbar-button:vertical:start {
    background-image: url("data:image/svg+xml;charset=utf-8,%3Csvg width='16' height='17' fill='none' xmlns='http://www.w3.org/2000/svg'%3E%3Cpath fill-rule='evenodd' clip-rule='evenodd' d='M15 0H0v16h1V1h14V0z' fill='%23DFDFDF'/%3E%3Cpath fill-rule='evenodd' clip-rule='evenodd' d='M2 1H1v14h1V2h12V1H2z' fill='%23fff'/%3E%3Cpath fill-rule='evenodd' clip-rule='evenodd' d='M16 17H0v-1h15V0h1v17z' fill='%23000'/%3E%3Cpath fill-rule='evenodd' clip-rule='evenodd' d='M15 1h-1v14H1v1h14V1z' fill='gray'/%3E%3Cpath fill='silver' d='M2 2h12v13H2z'/%3E%3Cpath fill-rule='evenodd' clip-rule='evenodd' d='M8 6H7v1H6v1H5v1H4v1h7V9h-1V8H9V7H8V6z' fill='%23000'/%3E%3C/svg%3E");
    height: 17px
}

::-webkit-scrollbar-button:vertical:end {
    background-image: url("data:image/svg+xml;charset=utf-8,%3Csvg width='16' height='17' fill='none' xmlns='http://www.w3.org/2000/svg'%3E%3Cpath fill-rule='evenodd' clip-rule='evenodd' d='M15 0H0v16h1V1h14V0z' fill='%23DFDFDF'/%3E%3Cpath fill-rule='evenodd' clip-rule='evenodd' d='M2 1H1v14h1V2h12V1H2z' fill='%23fff'/%3E%3Cpath fill-rule='evenodd' clip-rule='evenodd' d='M16 17H0v-1h15V0h1v17z' fill='%23000'/%3E%3Cpath fill-rule='evenodd' clip-rule='evenodd' d='M15 1h-1v14H1v1h14V1z' fill='gray'/%3E%3Cpath fill='silver' d='M2 2h12v13H2z'/%3E%3Cpath fill-rule='evenodd' clip-rule='evenodd' d='M11 6H4v1h1v1h1v1h1v1h1V9h1V8h1V7h1V6z' fill='%23000'/%3E%3C/svg%3E");
    height: 17px
}

::-webkit-scrollbar-button:horizontal:start {
    background-image: url("data:image/svg+xml;charset=utf-8,%3Csvg width='16' height='17' fill='none' xmlns='http://www.w3.org/2000/svg'%3E%3Cpath fill-rule='evenodd' clip-rule='evenodd' d='M15 0H0v16h1V1h14V0z' fill='%23DFDFDF'/%3E%3Cpath fill-rule='evenodd' clip-rule='evenodd' d='M2 1H1v14h1V2h12V1H2z' fill='%23fff'/%3E%3Cpath fill-rule='evenodd' clip-rule='evenodd' d='M16 17H0v-1h15V0h1v17z' fill='%23000'/%3E%3Cpath fill-rule='evenodd' clip-rule='evenodd' d='M15 1h-1v14H1v1h14V1z' fill='gray'/%3E%3Cpath fill='silver' d='M2 2h12v13H2z'/%3E%3Cpath fill-rule='evenodd' clip-rule='evenodd' d='M9 4H8v1H7v1H6v1H5v1h1v1h1v1h1v1h1V4z' fill='%23000'/%3E%3C/svg%3E");
    width: 16px
}

::-webkit-scrollbar-button:horizontal:end {
    background-image: url("data:image/svg+xml;charset=utf-8,%3Csvg width='16' height='17' fill='none' xmlns='http://www.w3.org/2000/svg'%3E%3Cpath fill-rule='evenodd' clip-rule='evenodd' d='M15 0H0v16h1V1h14V0z' fill='%23DFDFDF'/%3E%3Cpath fill-rule='evenodd' clip-rule='evenodd' d='M2 1H1v14h1V2h12V1H2z' fill='%23fff'/%3E%3Cpath fill-rule='evenodd' clip-rule='evenodd' d='M16 17H0v-1h15V0h1v17z' fill='%23000'/%3E%3Cpath fill-rule='evenodd' clip-rule='evenodd' d='M15 1h-1v14H1v1h14V1z' fill='gray'/%3E%3Cpath fill='silver' d='M2 2h12v13H2z'/%3E%3Cpath fill-rule='evenodd' clip-rule='evenodd' d='M7 4H6v7h1v-1h1V9h1V8h1V7H9V6H8V5H7V4z' fill='%23000'/%3E%3C/svg%3E");
    width: 16px
}

.window[role=tabpanel] {
    position: relative;
    z-index: 2
}

menu[role=tablist] {
    display: flex;
    list-style-type: none;
    margin: 0 0 -2px;
    padding-left: 3px;
    position: relative;
    text-indent: 0
}

menu[role=tablist] > li {
    border-top-left-radius: 3px;
    border-top-right-radius: 3px;
    box-shadow: inset -1px 0 #0a0a0a, inset 1px 1px #dfdfdf, inset -2px 0 grey, inset 2px 2px #fff;
    z-index: 1
}

menu[role=tablist] > li[aria-selected=true] {
    background-color: silver;
    margin-left: -3px;
    margin-top: -2px;
    padding-bottom: 2px;
    position: relative;
    z-index: 8
}

menu[role=tablist] > li > a {
    color: #222;
    display: block;
    margin: 6px;
    text-decoration: none
}

menu[role=tablist] > li[aria-selected=true] > a:focus {
    outline: none
}

menu[role=tablist] > li > a:focus {
    outline: 1px dotted #222
}

menu[role=tablist].multirows > li {
    flex-grow: 1;
    text-align: center
}

.sunken-panel {
    border: 2px groove transparent;
    border-image: url("data:image/svg+xml;charset=utf-8,%3Csvg width='5' height='5' xmlns='http://www.w3.org/2000/svg'%3E%3Cpath fill='gray' d='M0 0h4v1H0z'/%3E%3Cpath fill='gray' d='M0 0h1v4H0z'/%3E%3Cpath fill='%230a0a0a' d='M1 1h2v1H1z'/%3E%3Cpath fill='%230a0a0a' d='M1 1h1v2H1z'/%3E%3Cpath fill='%23fff' d='M0 4h5v1H0z'/%3E%3Cpath fill='%23fff' d='M4 0h1v5H4z'/%3E%3Cpath fill='%23dfdfdf' d='M3 1h1v3H3z'/%3E%3Cpath fill='%23dfdfdf' d='M1 3h3v1H1z'/%3E%3C/svg%3E") 2;
    box-sizing: border-box;
    overflow: auto
}

.sunken-panel, table {
    background-color: #fff
}

table {
    border-collapse: collapse;
    position: relative;
    text-align: left;
    white-space: nowrap
}

table > thead > tr > * {
    background: silver;
    box-shadow: inset -1px -1px #0a0a0a, inset 1px 1px #fff, inset -2px -2px grey, inset 2px 2px #dfdfdf;
    box-sizing: border-box;
    font-weight: 400;
    height: 17px;
    padding: 0 6px;
    position: sticky;
    top: 0
}

table.interactive > tbody > tr {
    cursor: pointer
}

table > tbody > tr.highlighted {
    background-color: navy;
    color: #fff
}

table > tbody > tr > * {
    height: 14px;
    padding: 0 6px
}

.progress-indicator {
    -webkit-appearance: none;
    -moz-appearance: none;
    appearance: none;
    border: none;
    border-radius: 0;
    box-shadow: inset -2px -2px #dfdfdf, inset 2px 2px grey;
    box-sizing: border-box;
    height: 32px;
    padding: 4px;
    position: relative
}

.progress-indicator > .progress-indicator-bar {
    background-color: navy;
    display: block;
    height: 100%
}

.progress-indicator.segmented > .progress-indicator-bar {
    background-color: transparent;
    background-image: linear-gradient(90deg, navy 16px, transparent 0 2px);
    background-repeat: repeat;
    background-size: 18px 100%;
    width: 100%
}

/*# sourceMappingURL=98.css.map */

````
--- End of File: vibe-player/css/98.css ---
--- File: vibe-player/css/styles.css ---
````css
/* --- /vibe-player/styles.css --- */

/* --- Global Styles --- */
body {
    font-family: "Pixelated MS Sans Serif", Arial;
    font-size: 15px;
    margin: 8px;
    background-color: silver;
    color: #222;
    -webkit-font-smoothing: none;
    -moz-osx-font-smoothing: grayscale;
    font-smooth: never;
    text-rendering: optimizeSpeed;
    image-rendering: pixelated;
    image-rendering: -moz-crisp-edges;
    image-rendering: crisp-edges;
}

/* Style H2 and H3 */
h2, h3 {
    border-bottom: 1px solid grey;
    padding-bottom: 1px;
    margin-top: 0.8em;
    margin-bottom: 0.4em;
    font-weight: bold;
    font-size: 15px;
}

/* --- Layout Sections --- */
section {
    margin-bottom: 8px;
    background: silver;
    box-shadow: inset -1px -1px #0a0a0a, inset 1px 1px #dfdfdf, inset -2px -2px grey, inset 2px 2px #fff;
    padding: 8px 8px;
}

section h2, section h3 {
    margin-top: 0;
    margin-bottom: 0.4em;
}

/* --- File Input --- */
#hiddenAudioFile {
    display: none;
}

#file-loader .field-row {
    align-items: baseline;
}

#file-loader .field-row button {
    flex-shrink: 0;
    font-size: 15px;
    min-height: 26px;
    padding: 1px 10px;
}

#file-loader .field-row span#fileNameDisplay {
    margin-left: 6px;
    white-space: nowrap;
    overflow: hidden;
    text-overflow: ellipsis;
    flex-shrink: 1;
    min-width: 80px;
    font-size: 15px;
    line-height: 1.4;
}

#file-loader p#fileInfo {
    margin: 0 0 0 10px;
    flex-grow: 1;
    font-size: 15px;
    color: grey;
    white-space: nowrap;
    overflow: hidden;
    text-overflow: ellipsis;
}

/* --- URL Input Styling --- */
#audioUrlInput.url-style-default {
    color: black;
    background-color: white;
}

#audioUrlInput.url-style-success {
    color: blue;
    background-color: white;
}

#audioUrlInput.url-style-error {
    color: red;
    background-color: white;
}

#audioUrlInput.url-style-file {
    color: dimgray;
    background-color: white;
}

.url-input.url-style-modified {
    color: black;
    background-color: #ffffff; /* Assuming a white background like default */
}

/* --- REMOVED Old VAD Progress Bar Styles --- */
/* (No rules here anymore) */

/* --- NEW: Style for 98.css VAD progress bar container --- */
#vadProgressContainer {
    margin-top: 5px; /* Add space above the progress bar */
    display: block; /* Ensure it's always visible */
    /* Height is determined by 98.css */
}


/* --- Seek Bar Section --- */
#playback-progress {
    display: flex;
    align-items: center;
    padding: 2px 0px;
    margin-bottom: 4px;
    background: none;
    box-shadow: none;
    border-image: none;
    border: none;
}

#playback-progress input[type=range]#seekBar {
    flex-grow: 1;
    margin: 0 8px;
    height: auto;
    vertical-align: middle;
}

#playback-progress #timeDisplay {
    margin: 0;
    flex-shrink: 0;
    font-size: 15px;
    font-weight: normal;
}

.visually-hidden {
    position: absolute;
    width: 1px;
    height: 1px;
    padding: 0;
    margin: -1px;
    overflow: hidden;
    clip: rect(0, 0, 0, 0);
    white-space: nowrap;
    border: 0;
}


/* --- Controls Section --- */
#controls button, #controls input[type=number] {
    margin: 0 4px;
    cursor: pointer;
    vertical-align: middle;
    font-size: 15px;
}

#controls button {
    min-height: 26px;
    padding: 1px 10px;
}

#controls .control-group {
    margin-bottom: 5px;
}

#controls .control-group:last-child {
    margin-bottom: 0;
}

#controls .jump-controls {
    margin-bottom: 8px;
    margin-top: 6px;
    display: flex;
    align-items: center;
    justify-content: center;
}

#controls .jump-controls input[type=number] {
    width: 50px;
    height: 26px;
    padding: 2px 3px;
    box-shadow: inset -1px -1px #fff, inset 1px 1px grey, inset -2px -2px #dfdfdf, inset 2px 2px #0a0a0a;
    border: none;
    text-align: center; /* Center the number */
}

/* Horizontal Slider Layout (Applies to Controls and VAD) */
.horizontal-sliders {
    display: flex;
    flex-wrap: wrap;
    gap: 8px;
    margin-top: 6px;
    align-items: flex-start;
}

.horizontal-sliders .slider-unit {
    flex: 1;
    min-width: 180px;
    margin-bottom: 0;
    padding: 6px 15px 1.0em 15px;
}


/* --- Slider Units Styling (General) --- */
.slider-unit {
    position: relative;
    border: 2px groove transparent;
    border-image: url("data:image/svg+xml;charset=utf-8,%3Csvg width='5' height='5' xmlns='http://www.w3.org/2000/svg'%3E%3Cpath fill='gray' d='M0 0h4v1H0z'/%3E%3Cpath fill='gray' d='M0 0h1v4H0z'/%3E%3Cpath fill='%230a0a0a' d='M1 1h2v1H1z'/%3E%3Cpath fill='%230a0a0a' d='M1 1h1v2H1z'/%3E%3Cpath fill='%23fff' d='M0 4h5v1H0z'/%3E%3Cpath fill='%23fff' d='M4 0h1v5H4z'/%3E%3Cpath fill='%23dfdfdf' d='M3 1h1v3H3z'/%3E%3Cpath fill='%23dfdfdf' d='M1 3h3v1H1z'/%3E%3C/svg%3E") 2;
    box-sizing: border-box;
    background-color: silver;
}

.slider-label-value {
    margin-bottom: 2px;
    font-size: 15px;
}

.slider-label-value label {
    margin-right: 4px;
    font-weight: bold;
    display: inline;
    font-size: 15px;
}

.slider-label-value span {
    display: inline;
    margin-left: 3px;
    font-size: 15px;
}

input[type=range] {
    width: 100%;
    box-sizing: border-box;
    margin: 4px 0 4px 0;
    height: 21px;
    cursor: pointer;
    display: block;
    vertical-align: middle;
}

.slider-markers {
    position: relative;
    width: 100%;
    height: 1.3em;
    margin-top: 2px;
}

.slider-markers span {
    position: absolute;
    bottom: 0;
    color: #222;
    cursor: pointer;
    transform: translateX(-50%);
    white-space: nowrap;
    font-size: 15px;
}

.slider-markers span:hover {
    color: #00f;
}


/* --- VAD Tuning Section --- */
#vad-tuning .horizontal-sliders {
    margin-top: 0;
}

#vad-tuning .slider-unit {
    padding: 6px 15px 6px 15px;
}

#vad-tuning .control-group {
    margin-bottom: 0;
}

#vad-tuning .slider-label-value {
    display: flex;
    justify-content: flex-start;
    align-items: center;
    width: 100%;
    margin-bottom: 2px;
    font-size: 15px;
}

#vad-tuning .slider-label-value label {
    font-size: 15px;
}

#vad-tuning .slider-label-value span {
    margin-left: 6px;
    font-size: 15px;
}

#vad-tuning input[type=range] {
    margin: 4px 0 4px 0;
    height: 21px;
}


/* --- Visualizations Section --- */
.visualization {
    margin-bottom: 8px;
    border: 2px groove transparent;
    border-image: url("data:image/svg+xml;charset=utf-8,%3Csvg width='5' height='5' xmlns='http://www.w3.org/2000/svg'%3E%3Cpath fill='gray' d='M0 0h4v1H0z'/%3E%3Cpath fill='gray' d='M0 0h1v4H0z'/%3E%3Cpath fill='%230a0a0a' d='M1 1h2v1H1z'/%3E%3Cpath fill='%230a0a0a' d='M1 1h1v2H1z'/%3E%3Cpath fill='%23fff' d='M0 4h5v1H0z'/%3E%3Cpath fill='%23fff' d='M4 0h1v5H4z'/%3E%3Cpath fill='%23dfdfdf' d='M3 1h1v3H3z'/%3E%3Cpath fill='%23dfdfdf' d='M1 3h3v1H1z'/%3E%3C/svg%3E") 2;
    box-sizing: border-box;
    padding: 7px 7px;
    background-color: silver;
}

.canvas-container {
    position: relative;
}

.visualization h3 {
    margin: 0 0 4px 0;
    display: flex;
    justify-content: space-between;
    align-items: center;
    border-bottom: none;
    font-size: 15px;
}

.visualization h3 small {
    font-size: 15px;
    font-weight: normal;
}

/* Removed .vad-indicator styles */
canvas {
    display: block;
    width: 100%;
    height: 120px;
    cursor: crosshair;
    box-sizing: border-box;
    border: 1px solid grey;
    box-shadow: inset 1px 1px #dfdfdf, inset -1px -1px grey;
    image-rendering: pixelated;
}

#waveformCanvas {
    background-color: #000;
}

#spectrogramCanvas {
    height: 200px;
    background-color: #000;
}


/* ---* --- Progress Bar Overlay --- */
/* Container for the overlay elements */
.progress-bar {
    position: absolute;
    top: 0;
    left: 0;
    width: 100%;
    pointer-events: none; /* Allow clicks through */
    box-sizing: border-box;
}

/* Match height to corresponding canvas */
#waveformProgressBar {
    height: 120px;
}

#spectrogramProgressBar {
    height: 200px;
}

/* The actual red line indicator - uses the NEW class name */
.playback-position-indicator {
    position: absolute;
    top: 0;
    bottom: 0;
    left: 0px; /* Position set by JS */
    width: 2px; /* Width of the red line */
    background: rgba(255, 0, 0, 0.7); /* Semi-transparent red */
    pointer-events: none; /* Allow clicks through */
    /* Reset styles inherited from 98.css if necessary */
    height: 100%; /* Make sure it spans full height */
    padding: 0;
    margin: 0;
    box-shadow: none;
    min-height: auto; /* Override 98.css min-height */
}

/* --- UI Elements --- */
.spinner {
    display: none;
    font-size: 15px;
    color: #222;
    font-weight: normal;
}

#speechRegionsDisplay {
    white-space: pre-wrap;
    word-break: break-all;
    max-height: 120px;
    overflow-y: auto;
    border: 2px groove transparent;
    border-image: url("data:image/svg+xml;charset=utf-8,%3Csvg width='5' height='5' xmlns='http://www.w3.org/2000/svg'%3E%3Cpath fill='gray' d='M0 0h4v1H0z'/%3E%3Cpath fill='gray' d='M0 0h1v4H0z'/%3E%3Cpath fill='%230a0a0a' d='M1 1h2v1H1z'/%3E%3Cpath fill='%230a0a0a' d='M1 1h1v2H1z'/%3E%3Cpath fill='%23fff' d='M0 4h5v1H0z'/%3E%3Cpath fill='%23fff' d='M4 0h1v5H4z'/%3E%3Cpath fill='%23dfdfdf' d='M3 1h1v3H3z'/%3E%3Cpath fill='%23dfdfdf' d='M1 3h3v1H1z'/%3E%3C/svg%3E") 2;
    background-color: #fff;
    padding: 2px 3px;
    font-family: monospace;
    font-size: 15px;
    line-height: 1.2;
}


/* --- Keybinds Table --- */
#keybinds {
    margin-top: 8px;
}

#keybinds table {
    width: 100%;
    border-collapse: collapse;
    border: 2px groove transparent;
    border-image: url("data:image/svg+xml;charset=utf-8,%3Csvg width='5' height='5' xmlns='http://www.w3.org/2000/svg'%3E%3Cpath fill='gray' d='M0 0h4v1H0z'/%3E%3Cpath fill='gray' d='M0 0h1v4H0z'/%3E%3Cpath fill='%230a0a0a' d='M1 1h2v1H1z'/%3E%3Cpath fill='%230a0a0a' d='M1 1h1v2H1z'/%3E%3Cpath fill='%23fff' d='M0 4h5v1H0z'/%3E%3Cpath fill='%23fff' d='M4 0h1v5H4z'/%3E%3Cpath fill='%23dfdfdf' d='M3 1h1v3H3z'/%3E%3Cpath fill='%23dfdfdf' d='M1 3h3v1H1z'/%3E%3C/svg%3E") 2;
    background-color: #fff;
    font-size: 15px;
}

#keybinds th, #keybinds td {
    padding: 2px 4px;
    border-bottom: 1px solid silver;
    text-align: left;
    font-size: 15px;
}

#keybinds tr:last-child td {
    border-bottom: none;
}

#keybinds th {
    background: silver;
    box-shadow: inset -1px -1px #0a0a0a, inset 1px 1px #fff, inset -2px -2px grey, inset 2px 2px #dfdfdf;
    box-sizing: border-box;
    font-weight: normal;
    padding: 2px 4px;
    border-bottom: 1px solid #0a0a0a;
    font-size: 15px;
}

/* --- Small Tag --- */
small {
    font-size: 15px;
}

/* --- Drop Zone Overlay Styles --- */
#dropZoneOverlay {
    display: none; /* This ensures it's hidden initially */
    position: fixed;
    top: 0;
    left: 0;
    right: 0;
    bottom: 0;
    background-color: rgba(0, 0, 0, 0.75);
    z-index: 10000;
    /* Flexbox for centering will be applied when JS changes display to 'flex' */
    align-items: center; /* These are fine to keep for when it becomes flex */
    justify-content: center; /* These are fine to keep for when it becomes flex */
    color: white;
    font-size: 1.5em;
    text-align: center;
}

#dropZoneMessage {
    padding: 20px;
    background-color: rgba(0, 0, 0, 0.5); /* Darker, slightly transparent background for the message box */
    border-radius: 5px;
    box-shadow: 0 4px 8px rgba(0, 0, 0, 0.3); /* Optional: some shadow for the message box */
}

/* Class to apply blur/grayscale effect to the background content */
.blurred-background {
    filter: blur(4px) grayscale(50%);
    /* transition: filter 0.3s ease-out; */ /* Optional: smooth transition for the filter effect */
}

/* /vibe-player/styles.css */

````
--- End of File: vibe-player/css/styles.css ---
--- File: vibe-player/index.html ---
````html
<!-- /vibe-player/index.html -->
<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Vibe Player</title>
    <!-- Add 98.css -->
    <link rel="stylesheet" href="css/98.css"/>
    <!-- Your custom styles (load after 98.css) -->
    <link rel="stylesheet" href="css/styles.css">
    <script src="js/sparkles.js"></script>
</head>
<body>

<!-- === File Loading Section === -->
<section id="file-loader">
    <h2>Load Audio File</h2>
    <!-- Row for button, name, info -->
    <div class="field-row" style="align-items: baseline;">
        <button id="chooseFileButton">Choose File...</button>
        <span id="fileNameDisplay" style="margin-left: 5px; flex-shrink: 1; min-width: 5px;"></span>
        <p id="fileInfo" style="margin-left: 10px; flex-grow: 1; color: grey;"></p>
    </div>
    <!-- Hidden actual file input -->
    <input type="file" id="hiddenAudioFile" accept="audio/*" style="display: none;">

    <!-- New Row for URL input -->
    <div class="field-row" style="margin-top: 10px;">
        <input type="text" id="audioUrlInput" placeholder="Enter audio URL" style="flex-grow: 1; margin-right: 5px;">
        <button id="loadUrlButton">Load from URL</button>
    </div>
    <span id="urlLoadingErrorDisplay" style="color: red; display: block; margin-top: 5px;"></span>
</section>

<!-- === Controls Section === -->
<section id="controls">
    <h2>Controls</h2>


    <!-- Horizontal Slider Container -->
    <div class="horizontal-sliders">
        <!-- Speed Control Unit -->
        <div class="control-group slider-unit">
            <div class="slider-label-value">
                <label for="playbackSpeed">Speed:</label>
                <span id="speedValue">1.00x</span>
            </div>
            <input type="range" id="playbackSpeed" min="0.25" max="2.0" value="1.0" step="0.01">
            <div class="slider-markers" id="speedMarkers">
                <span data-value="0.5">0.5x</span>
                <span data-value="1.0">1.0x</span>
                <span data-value="1.5">1.5x</span>
                <span data-value="2.0">2.0x</span>
            </div>
        </div>

        <!-- Pitch Control Unit -->
        <div class="control-group slider-unit">
            <div class="slider-label-value">
                <label for="pitchControl">Pitch:</label>
                <span id="pitchValue">1.00x</span>
            </div>
            <input type="range" id="pitchControl" min="0.25" max="2.0" value="1.0" step="0.01">
            <div class="slider-markers" id="pitchMarkers">
                <span data-value="0.5">0.5x</span>
                <span data-value="1.0">1.0x</span>
                <span data-value="1.5">1.5x</span>
                <span data-value="2.0">2.0x</span>
            </div>
        </div>

        <!-- Gain Control Unit -->
        <div class="control-group slider-unit">
            <div class="slider-label-value">
                <label for="gainControl">Gain:</label>
                <span id="gainValue">1.00x</span>
            </div>
            <input type="range" id="gainControl" min="1" max="5" value="1.0" step="0.01">
            <!-- Gain enabled by default -->
            <div class="slider-markers" id="gainMarkers">
                <span data-value="1.0">1x</span>
                <span data-value="2.0">2x</span>
                <span data-value="3.0">3x</span>
                <span data-value="4.0">4x</span>
                <span data-value="5.0">5x</span>
            </div>
        </div>
    </div> <!-- End Horizontal Slider Container -->

    <!-- Jump Controls -->
    <div class="control-group jump-controls">
        <button id="playPause" disabled>Play</button>
        <button id="jumpBack" disabled>◀◀ Back</button>
        <input type="number" id="jumpTime" value="5" min="1" step="1" title="Seconds to jump"> seconds
        <!-- Changed 's' to 'seconds' -->
        <button id="jumpForward" disabled>Forward ▶▶</button>
    </div>

    <!-- === Seek Bar and Time Display Section === -->
    <section id="playback-progress">
        <label for="seekBar" class="visually-hidden">Seek:</label> <!-- Hidden label for accessibility -->
        <input type="range" id="seekBar" min="0" max="1" value="0" step="any" disabled>
        <div id="timeDisplay">0:00 / 0:00</div>
    </section>

</section>


<!-- === Visualizations Section === -->
<section class="visualization">
    <h3>Spectrogram <span id="spectrogramSpinner" class="spinner">(Computing...)</span></h3>
    <div class="canvas-container">
        <canvas id="spectrogramCanvas"></canvas>
        <div id="spectrogramProgressBar" class="progress-bar">
            <div id="spectrogramProgressIndicator" class="playback-position-indicator"></div>
        </div>
    </div>
</section>

<section class="visualization">
    <h3>Waveform <small>(Speech in Yellow)</small></h3>
    <div class="canvas-container">
        <canvas id="waveformCanvas"></canvas>
        <div id="waveformProgressBar" class="progress-bar">
            <div id="waveformProgressIndicator" class="playback-position-indicator"></div>
        </div>
    </div>
</section>

<!-- === VAD Tuning Section === -->
<section id="vad-tuning">
    <h2>Voice Activity Detection (Silero)</h2>

    <!-- NEW: VAD Progress Bar using 98.css structure -->
    <div id="vadProgressContainer" class="progress-indicator segmented vad-progress-indicator-container"
         style="margin-top: 5px; margin-bottom: 5px;">
        <span id="vadProgressBar" class="progress-indicator-bar" style="width: 0;"></span>
        <!-- Corrected width attribute -->
    </div>

    <!-- Corrected Structure: Both VAD controls inside one horizontal container -->
    <div class="horizontal-sliders">
        <div class="control-group slider-unit"> <!-- Unit for Positive -->
            <div class="control-group">
                <div class="slider-label-value">
                    <label for="vadThreshold"
                           title="Probability above which a frame is considered speech.">Positive Threshold:</label>
                    <span id="vadThresholdValue">N/A</span>
                </div>
                <input type="range" id="vadThreshold" min="0.01" max="0.99" value="0.5" step="0.01">
            </div>
        </div>
        <div class="control-group slider-unit"> <!-- Unit for Negative -->
            <div class="control-group">
                <div class="slider-label-value">
                    <label for="vadNegativeThreshold"
                           title="Probability below which non-speech frames trigger ending the segment (after redemption).">Negative
                        Threshold:</label>
                    <span id="vadNegativeThresholdValue">N/A</span>
                </div>
                <input type="range" id="vadNegativeThreshold" min="0.01" max="0.99" value="0.35" step="0.01">
            </div>
        </div>
    </div> <!-- End horizontal-sliders for VAD -->

</section>

<!-- === Keyboard Shortcuts Section === -->
<section id="keybinds">
    <h2>Keyboard Shortcuts</h2>
    <table>
        <thead>
        <tr>
            <th>Key</th>
            <th>Action</th>
        </tr>
        </thead>
        <tbody>
        <tr>
            <td>Space</td>
            <td>Play / Pause</td>
        </tr>
        <tr>
            <td>Left Arrow</td>
            <td>Jump Back (by specified seconds)</td>
        </tr>
        <tr>
            <td>Right Arrow</td>
            <td>Jump Forward (by specified seconds)</td>
        </tr>
        </tbody>
    </table>
</section>

<!-- === DTMF Tones Section === -->
<section id="dtmf-tones">
    <h2>Dual Tone Multi Frequency (Dial Tones) & Call Progress Tones </h2>
    <div id="dtmfDisplay" style="min-height: 50px; background-color: #f0f0f0; border: 1px solid #ccc; padding: 5px;">
        No DTMF tones detected yet.
    </div>
    <br>
    <div id="cpt-display-content"
         style="min-height: 50px; background-color: #f0f0f0; border: 1px solid #ccc; padding: 5px;">
        No ringtones detected yet.
    </div>
</section>

<!-- Drop Zone Overlay -->
<div id="dropZoneOverlay">
    <div id="dropZoneMessage"></div>
</div>

<!-- === SCRIPT LOADING ORDER (CRITICAL!) === -->
<!-- External Libs -->
<script src="lib/ort.min.js"></script> <!-- ONNX Runtime -->
<script src="lib/fft.js"></script> <!-- FFT for Visualizer -->

<!-- Core App Namespace & Foundational Modules -->
<!-- 2. utils.js: Defines AudioApp.Utils. Needed by many modules. -->
<script src="js/utils.js"></script>
<!-- 3. state/constants.js: Defines the new Constants class. Needed by many modules. -->
<script src="js/state/constants.js"></script>
<!-- 4. state/appState.js: Defines the AppState class for managing application state. -->
<script src="js/state/appState.js"></script>

<!-- 1. app.js: Establishes AudioApp IIFE structure. Other files attach to this. -->
<script src="js/app.js"></script>

<!-- App Feature Modules & Components -->
<!-- These may depend on AudioApp, Constants, Utils -->
<!-- 5. goertzel.js: Defines AudioApp.GoertzelFilter & AudioApp.DTMFParser. May use Constants. DTMFParser is checked by app.js's init. -->
<!-- 5. goertzel.js: Defines AudioApp.GoertzelFilter & AudioApp.DTMFParser. May use Constants. DTMFParser is checked by app.js's init. -->
<script src="js/goertzel.js"></script>
<!-- 6. uiManager.js: Defines AudioApp.uiManager. Uses Utils. Checked by app.js's init. -->
<script src="js/uiManager.js"></script>
<!-- 7. player/audioEngine.js: Defines AudioApp.audioEngine. Uses Constants. Checked by app.js's init. -->
<script src="js/player/audioEngine.js"></script>

<!-- VAD Modules (Order within this group matters) -->
<!-- 8. Load the new strategy files FIRST. -->
<script src="js/vad/RemoteApiStrategy.js"></script>
<script src="js/vad/LocalWorkerStrategy.js"></script>

<!-- 9. THEN load the analyzer that uses them. -->
<script src="js/vad/vadAnalyzer.js"></script>

<!-- 10. The original VAD modules are now loaded inside the worker, so we can remove them from here. -->
<!-- REMOVE <script src="js/vad/sileroWrapper.js"></script> -->
<!-- REMOVE <script src="js/vad/sileroProcessor.js"></script> -->

<!-- Visualizer Modules -->
<!-- 11. visualizers/waveformVisualizer.js: Defines AudioApp.waveformVisualizer. Uses Constants, Utils. Checked by app.js's init. -->
<script src="js/visualizers/waveformVisualizer.js"></script>
<!-- 12. visualizers/spectrogramVisualizer.js: Defines AudioApp.spectrogramVisualizer. Uses FFT, Constants, Utils. Checked by app.js's init. -->
<script src="js/visualizers/spectrogramVisualizer.js"></script>
<!-- <script src="js/visualizers/visualizer.js"></script> --> <!-- REMOVED OLD COMBINED VISUALIZER -->

<!-- App Initialization -->
<script>
    // Ensure DOM is fully loaded before initializing the application
    document.addEventListener('DOMContentLoaded', () => {
        // Check if core AudioApp is defined before init
        if (window.AudioApp && typeof window.AudioApp.init === 'function') {
            AudioApp.init(); // Call the main init function
        } else {
            console.error("CRITICAL: AudioApp or AudioApp.init not defined! Check script loading order and errors.");
            // Optionally display error to user in the UI
            const fileInfo = document.getElementById('fileInfo');
            if (fileInfo) fileInfo.textContent = "Fatal Error: Application failed to load. Check console.";
        }
    });
</script>

<!-- Sparkle when the filename is double-clicked -->
<script>
    document.addEventListener("DOMContentLoaded", () => {
        // 1) Wire up dblclick → toggle sparkle
        const fileSpan = document.getElementById("file-loader");
        if (fileSpan) {
            fileSpan.addEventListener("dblclick", () => {
                sparkle(); // calling with no args toggles on/off
            });
        }

        // 2) If today is April 1st, automatically enable on page load
        const today = new Date();
        if (today.getMonth() === 3 && today.getDate() === 1) {
            // Month is zero-based: 3 = April
            sparkle(true);
        }
    });
</script>

</body>
</html>
<!-- /vibe-player/index.html -->

````
--- End of File: vibe-player/index.html ---
--- File: vibe-player/js/app.js ---
````javascript
// --- /vibe-player/js/app.js ---
// Creates the global namespace and orchestrates the application flow.
// MUST be loaded AFTER all its dependency modules.

/**
 * @namespace AudioApp
 * @description Main application namespace for Vibe Player.
 */
var AudioApp = AudioApp || {};

/**
 * @fileoverview Main application logic for Vibe Player.
 * Orchestrates UI, audio engine, visualizers, and VAD processing.
 * Handles user interactions and manages application state.
 * @version 1.0.0
 */

// REFACTORED: Pass AudioApp as an argument 'app' to the IIFE.
// This prevents overwriting the namespace and allows this script
// to correctly augment the existing AudioApp object.
(function (app) {
    'use strict';

    // Instantiate AppState and expose it on the AudioApp namespace
    const appState = new AppState();
    app.state = appState; // Use the passed-in 'app' object

    /** @type {AudioApp.Utils} Reference to the Utils module. */
    const Utils = app.Utils; // Use the passed-in 'app' object

    // --- Application State ---
    /** @type {number} Counter for drag enter/leave events to manage drop zone visibility. */
    let dragCounter = 0;
    /** @type {AudioApp.DTMFParser|null} The DTMF parser instance. */
    let dtmfParser = null;
    /** @type {AudioApp.CallProgressToneParser|null} The Call Progress Tone parser instance. */
    let cptParser = null;

    /** @type {number|null} Handle for the requestAnimationFrame UI update loop. Null if not running. */
    let rAFUpdateHandle = null;

    // --- Debounced Functions ---
    /** @type {Function|null} Debounced function for synchronizing the audio engine after speed changes. */
    let debouncedSyncEngine = null;
    /** @type {Function|null} Debounced function for updating the URL hash from current settings. */
    let debouncedUpdateUrlHash = null;

    /**
     * Generates a URL hash string from the current AppState and playback position.
     * @private
     */
    function updateUrlHashFromState() {
        if (!app.state || !app.audioEngine) return;

        const newHash = app.state.serialize(app.audioEngine.getCurrentTime().currentTime);

        if (newHash) {
            history.replaceState(null, '', `#${newHash}`);
        } else {
            history.replaceState(null, '', window.location.pathname + window.location.search);
        }
    }


    /**
     * Initializes the main application.
     * Sets up modules, event listeners, and applies initial settings from URL hash.
     * @public
     * @memberof AudioApp
     */
    function init() {
        console.log("AudioApp: Initializing...");

        if (!app.uiManager || !app.audioEngine || !app.waveformVisualizer ||
            !app.spectrogramVisualizer || !app.vadAnalyzer ||
            !app.Utils || !app.DTMFParser || !app.CallProgressToneParser || typeof Constants === 'undefined') {
            console.error("AudioApp: CRITICAL - One or more required modules not found! Check script loading order.");
            app.uiManager?.setFileInfo("Initialization Error: Missing modules. Check console.");
            return;
        }

        debouncedSyncEngine = app.Utils.debounce(syncEngineToEstimatedTime, Constants.UI.SYNC_DEBOUNCE_WAIT_MS);
        debouncedUpdateUrlHash = app.Utils.debounce(updateUrlHashFromState, Constants.UI.DEBOUNCE_HASH_UPDATE_MS);

        app.uiManager.init();

        if (app.state && typeof app.state.deserialize === 'function') {
            app.state.deserialize(window.location.hash.substring(1));
        }

        setupAppEventListeners();

        const initialAudioUrlFromState = app.state.params.audioUrl;
        if (initialAudioUrlFromState) {
            console.log("App: Applying audioUrl from AppState (from hash):", initialAudioUrlFromState);
            if (initialAudioUrlFromState.startsWith('file:///')) {
                app.state.updateStatus('urlInputStyle', 'error');
                app.uiManager.setUrlLoadingError("Local files cannot be automatically reloaded from the URL. Please re-select the file.");
            } else {
                app.state.updateStatus('urlInputStyle', 'modified');
                document.dispatchEvent(new CustomEvent('audioapp:urlSelected', {detail: {url: initialAudioUrlFromState}}));
            }
        }

        setTimeout(() => {
            app.uiManager?.unfocusUrlInput();
        }, 100);

        app.audioEngine.init();
        app.waveformVisualizer.init();
        app.spectrogramVisualizer.init(() => app.state.runtime.currentAudioBuffer);

        // EAGER LOAD VAD MODEL
        app.vadAnalyzer.init();

        if (app.DTMFParser) dtmfParser = new app.DTMFParser();
        if (app.CallProgressToneParser) cptParser = new app.CallProgressToneParser();

        console.log("AudioApp: Initialized. Waiting for file...");
    }

    /**
     * Sets up global event listeners for the application.
     * @private
     */
    function setupAppEventListeners() {
        document.addEventListener('audioapp:fileSelected', (handleFileSelected));
        document.addEventListener('audioapp:urlSelected', (handleUrlSelected));
        document.addEventListener('audioapp:playPauseClicked', handlePlayPause);
        document.addEventListener('audioapp:jumpClicked', (handleJump));
        document.addEventListener('audioapp:seekRequested', (handleSeek));
        document.addEventListener('audioapp:seekBarInput', (handleSeekBarInput));
        document.addEventListener('audioapp:speedChanged', (handleSpeedChange));
        document.addEventListener('audioapp:pitchChanged', (handlePitchChange));
        document.addEventListener('audioapp:gainChanged', (handleGainChange));
        document.addEventListener('audioapp:thresholdChanged', (handleThresholdChange));
        document.addEventListener('audioapp:keyPressed', (handleKeyPress));
        document.addEventListener('audioapp:jumpTimeChanged', (handleJumpTimeChange)); // New listener
        document.addEventListener('audioapp:audioLoaded', (handleAudioLoaded));
        document.addEventListener('audioapp:workletReady', (handleWorkletReady));
        document.addEventListener('audioapp:decodingError', (handleAudioError));
        document.addEventListener('audioapp:resamplingError', (handleAudioError));
        document.addEventListener('audioapp:playbackError', (handleAudioError));
        document.addEventListener('audioapp:engineError', (handleAudioError));
        document.addEventListener('audioapp:playbackEnded', handlePlaybackEnded);
        document.addEventListener('audioapp:playbackStateChanged', (handlePlaybackStateChange));
        document.addEventListener('audioapp:internalSpeedChanged', (handleInternalSpeedChange));
        window.addEventListener('resize', handleWindowResize);
        window.addEventListener('beforeunload', handleBeforeUnload);
        window.addEventListener('dragenter', handleDragEnter);
        window.addEventListener('dragover', handleDragOver);
        window.addEventListener('dragleave', handleDragLeave);
        window.addEventListener('drop', handleDrop);
    }

    /**
     * Handles changes to the jump time from the UI.
     * @param {CustomEvent<{value: number}>} e - The event containing the new jump time.
     * @private
     */
    function handleJumpTimeChange(e) {
        const newJumpTime = e.detail.value;
        if (typeof newJumpTime === 'number' && newJumpTime > 0) {
            app.state.updateParam('jumpTime', newJumpTime);
            if (debouncedUpdateUrlHash) debouncedUpdateUrlHash(); // Update URL hash if jump time changes
        }
    }

    function handleDragEnter(event) {
        event.preventDefault();
        event.stopPropagation();
        dragCounter++;
        if (dragCounter === 1 && event.dataTransfer?.items) {
            let filePresent = false;
            for (let i = 0; i < event.dataTransfer.items.length; i++) {
                if (event.dataTransfer.items[i].kind === 'file') {
                    filePresent = true;
                    break;
                }
            }
            if (filePresent && event.dataTransfer.files.length > 0) {
                app.uiManager.showDropZone(event.dataTransfer.files[0]);
            }
        }
    }

    function handleDragOver(event) {
        event.preventDefault();
        event.stopPropagation();
        if (event.dataTransfer) event.dataTransfer.dropEffect = 'copy';
    }

    function handleDragLeave(event) {
        event.preventDefault();
        event.stopPropagation();
        dragCounter--;
        if (dragCounter === 0) {
            app.uiManager.hideDropZone();
        }
    }

    function handleDrop(event) {
        event.preventDefault();
        event.stopPropagation();
        app.uiManager.hideDropZone();
        dragCounter = 0;
        const files = event.dataTransfer?.files;
        if (files && files.length > 0) {
            const file = files[0];
            if (file.type.startsWith('audio/')) {
                console.log("App: File dropped -", file.name);
                document.dispatchEvent(new CustomEvent('audioapp:fileSelected', {detail: {file: file}}));
            } else {
                console.warn("App: Invalid file type dropped -", file.name, file.type);
                app.uiManager.setFileInfo("Invalid file type. Please drop an audio file.");
            }
        }
    }

    async function handleFileSelected(e) {
        const file = e.detail.file;
        if (!file) return;
        const newDisplayUrl = 'file:///' + file.name;
        const previousDisplayUrl = app.state.params.audioUrl;
        app.state.updateRuntime('currentFile', file);
        app.state.updateParam('audioUrl', newDisplayUrl);
        app.state.updateStatus('urlInputStyle', 'file');
        app.uiManager.setAudioUrlInputValue(newDisplayUrl);
        app.uiManager.setUrlInputStyle('file');
        console.log("App: File selected -", file.name);
        resetAudioStateAndUI(file.name, newDisplayUrl !== previousDisplayUrl);
        try {
            await app.audioEngine.loadAndProcessFile(file);
        } catch (error) {
            console.error("App: Error initiating file processing -", error);
            app.uiManager.setFileInfo(`Error loading: ${error?.message || 'Unknown error'}`);
            app.uiManager.resetUI();
            app.spectrogramVisualizer.showSpinner(false);
            stopUIUpdateLoop();
        }
    }

    async function handleUrlSelected(e) {
        const newUrlFromEvent = e.detail.url;
        const previousDisplayUrl = app.state.params.audioUrl;
        app.state.updateParam('audioUrl', newUrlFromEvent);
        app.state.updateStatus('urlInputStyle', 'default');
        app.uiManager.setUrlInputStyle('default');
        if (!newUrlFromEvent) {
            console.warn("App: URL selected event received, but URL is empty.");
            app.uiManager.setAudioUrlInputValue("");
            app.state.updateStatus('urlInputStyle', 'error');
            app.uiManager.setUrlInputStyle('error');
            app.state.updateStatus('fileInfoMessage', "Error: No URL provided.");
            return;
        }
        console.log("App: URL selected -", newUrlFromEvent);
        app.state.updateStatus('urlLoadingErrorMessage', "");
        let filename = "loaded_from_url";
        try {
            const urlPath = new URL(newUrlFromEvent).pathname;
            const lastSegment = urlPath.substring(urlPath.lastIndexOf('/') + 1);
            if (lastSegment) filename = decodeURIComponent(lastSegment);
        } catch (urlError) {
            filename = newUrlFromEvent;
        }
        resetAudioStateAndUI(filename, newUrlFromEvent !== previousDisplayUrl, true);
        app.uiManager.setAudioUrlInputValue(newUrlFromEvent);
        try {
            app.state.updateStatus('fileInfoMessage', `Fetching: ${filename}...`);
            const response = await fetch(newUrlFromEvent);
            if (!response.ok) throw new Error(`Network response was not ok: ${response.status} ${response.statusText}`);
            const arrayBuffer = await response.arrayBuffer();
            app.state.updateStatus('fileInfoMessage', `Processing: ${filename}...`);
            let mimeType = response.headers.get('Content-Type')?.split(';')[0] || 'audio/*';
            const ext = filename.substring(filename.lastIndexOf('.') + 1).toLowerCase();
            if (mimeType === 'application/octet-stream' || mimeType === 'audio/*') {
                if (ext === 'mp3') mimeType = 'audio/mpeg';
                else if (ext === 'wav') mimeType = 'audio/wav';
                else if (ext === 'ogg') mimeType = 'audio/ogg';
            }
            const newFileObject = new File([arrayBuffer], filename, {type: mimeType});
            app.state.updateRuntime('currentFile', newFileObject);
            await app.audioEngine.loadAndProcessFile(newFileObject);
            app.state.updateStatus('urlInputStyle', 'success');
            app.uiManager.setUrlInputStyle('success');
            if (debouncedUpdateUrlHash) debouncedUpdateUrlHash();
        } catch (error) {
            console.error(`App: Error fetching/processing URL ${newUrlFromEvent}:`, error);
            app.uiManager.resetUI();
            app.state.updateStatus('urlInputStyle', 'error');
            app.uiManager.setAudioUrlInputValue(newUrlFromEvent);
            app.uiManager.setUrlInputStyle('error');
            app.state.updateStatus('urlLoadingErrorMessage', `Error loading from URL. (${error?.message?.substring(0, 100) || 'Unknown error'})`);
            app.state.updateStatus('fileInfoMessage', "Failed to load audio from URL.");
            app.spectrogramVisualizer.showSpinner(false);
            stopUIUpdateLoop();
            app.state.updateRuntime('currentFile', null);
        }
    }

    function resetAudioStateAndUI(displayName, fullUIRestart, isUrl = false) {
        stopUIUpdateLoop();
        app.state.updateStatus('isActuallyPlaying', false);
        app.state.updateStatus('playbackNaturallyEnded', false);
        app.state.updateStatus('isVadProcessing', false);
        app.state.updateRuntime('playbackStartTimeContext', null);
        app.state.updateRuntime('playbackStartSourceTime', 0.0);
        app.state.updateRuntime('currentSpeedForUpdate', 1.0);
        app.state.updateRuntime('currentAudioBuffer', null);
        app.state.updateRuntime('currentVadResults', null);
        app.state.updateStatus('workletPlaybackReady', false);
        if (!isUrl) app.state.updateRuntime('currentFile', null);
        if (fullUIRestart) {
            app.uiManager.resetUI();
        } else {
            app.uiManager.updateTimeDisplay(0, 0);
            app.uiManager.updateSeekBar(0);
            app.uiManager.setSpeechRegionsText("None");
            app.uiManager.showVadProgress(false);
            app.uiManager.updateVadProgress(0);
            app.state.updateStatus('urlLoadingErrorMessage', "");
        }
        app.uiManager.updateFileName(displayName);
        app.state.updateStatus('fileInfoMessage', `Loading: ${displayName}...`);
        app.uiManager.setAudioUrlInputValue(app.state.params.audioUrl || "");
        app.uiManager.setUrlInputStyle(app.state.status.urlInputStyle);
        app.waveformVisualizer.clearVisuals();
        app.spectrogramVisualizer.clearVisuals();
        app.spectrogramVisualizer.showSpinner(true);
        if (debouncedUpdateUrlHash) debouncedUpdateUrlHash();
    }

    async function handleAudioLoaded(e) {
        app.state.updateRuntime('currentAudioBuffer', e.detail.audioBuffer);
        const audioBuffer = app.state.runtime.currentAudioBuffer;
        console.log(`App: Audio decoded (${audioBuffer.duration.toFixed(2)}s). Starting parallel analysis.`);
        app.uiManager.updateTimeDisplay(0, audioBuffer.duration);
        app.uiManager.updateSeekBar(0);
        app.waveformVisualizer.updateProgressIndicator(0, audioBuffer.duration);
        app.spectrogramVisualizer.updateProgressIndicator(0, audioBuffer.duration);
        app.state.updateRuntime('playbackStartSourceTime', 0.0);
        await app.waveformVisualizer.computeAndDrawWaveform(audioBuffer, []);
        console.log("App: Kicking off Spectrogram, VAD, and Tone analysis in parallel.");
        app.spectrogramVisualizer.computeAndDrawSpectrogram(audioBuffer);
        runVadInBackground(audioBuffer);
        if (dtmfParser || cptParser) {
            processAudioForTones(audioBuffer);
        }
        app.state.updateStatus('fileInfoMessage', `Processing Analyses: ${app.state.runtime.currentFile?.name || app.state.params.audioUrl || 'Loaded Audio'}`);
        if (app.state.runtime.currentFile && app.state.params.audioUrl && app.state.status.urlInputStyle === 'file') {
            app.uiManager.setAudioUrlInputValue(app.state.params.audioUrl);
            app.uiManager.setUrlInputStyle('file');
        }
    }

    function handleWorkletReady(e) {
        console.log("App: AudioWorklet processor is ready.");
        app.state.updateStatus('workletPlaybackReady', true);
        app.uiManager.enablePlaybackControls(true);
        app.uiManager.enableSeekBar(true);
        app.state.updateStatus('fileInfoMessage', `Ready: ${app.state.runtime.currentFile?.name || app.state.params.audioUrl || 'Loaded Audio'}`);
        app.uiManager.unfocusUrlInput();
        if (app.audioEngine) {
            app.audioEngine.setSpeed(app.state.params.speed);
            app.audioEngine.setPitch(app.state.params.pitch);
            app.audioEngine.setGain(app.state.params.gain);
        }
        const audioBuffer = app.state.runtime.currentAudioBuffer;
        if (app.state.params.initialSeekTime !== null && audioBuffer) {
            const targetTime = Math.max(0, Math.min(app.state.params.initialSeekTime, audioBuffer.duration));
            console.log(`App: Applying initialSeekTime from AppState: ${targetTime.toFixed(3)}s`);
            app.audioEngine.seek(targetTime);
            app.state.updateRuntime('playbackStartSourceTime', targetTime);
            app.state.updateRuntime('playbackStartTimeContext', null);
            updateUIWithTime(targetTime);
            app.state.updateParam('initialSeekTime', null);
        }
    }

    async function runVadInBackground(audioBuffer) {
        if (!audioBuffer || !app.vadAnalyzer || !app.audioEngine || !app.uiManager || !app.waveformVisualizer) {
            console.error("App (VAD): Missing dependencies for VAD task.");
            app.state.updateStatus('isVadProcessing', false);
            return;
        }
        if (app.state.status.isVadProcessing) {
            console.warn("App (VAD): Processing already running.");
            return;
        }

        app.state.updateStatus('isVadProcessing', true);

        try {
            // REMOVED: await app.vadAnalyzer.init(); -- This is now done at startup.
            app.uiManager.showVadProgress(true);
            app.uiManager.updateVadProgress(0);
            const pcm16k = await app.audioEngine.resampleTo16kMono(audioBuffer);
            if (!pcm16k || pcm16k.length === 0) {
                app.uiManager.setSpeechRegionsText("No VAD data (empty audio?)");
                app.uiManager.updateVadProgress(100);
                app.state.updateStatus('isVadProcessing', false);
                return;
            }
            const vadProgressCallback = (progress) => {
                if (!app.uiManager) return;
                const percentage = progress.totalFrames > 0 ? (progress.processedFrames / progress.totalFrames) * 100 : 0;
                app.uiManager.updateVadProgress(percentage);
            };
            const vadResults = await app.vadAnalyzer.analyze(pcm16k, {
                onProgress: vadProgressCallback,
                positiveSpeechThreshold: app.state.params.vadPositive,
                negativeSpeechThreshold: app.state.params.vadNegative
            });
            app.state.updateRuntime('currentVadResults', vadResults);
            const speechRegions = vadResults.regions || [];
            app.uiManager.setSpeechRegionsText(speechRegions);
            app.waveformVisualizer.redrawWaveformHighlight(audioBuffer, speechRegions);
            app.uiManager.updateVadProgress(100);
        } catch (error) {
            console.error("App (VAD): Error during VAD processing -", error);
            app.state.updateStatus('fileInfoMessage', `VAD Error: ${error?.message || 'Unknown error'}`);
            app.uiManager.updateVadProgress(0);
            app.state.updateRuntime('currentVadResults', null);
        } finally {
            app.state.updateStatus('isVadProcessing', false);
        }
    }

    async function processAudioForTones(audioBuffer) {
        if (!audioBuffer || !app.audioEngine || !app.uiManager || (!dtmfParser && !cptParser)) {
            console.warn("App (Tones): Missing dependencies or parsers for tone processing.");
            return;
        }
        const pcmSampleRate = Constants.DTMF.SAMPLE_RATE;
        const pcmBlockSize = Constants.DTMF.BLOCK_SIZE;
        let pcmData = null;
        try {
            pcmData = await app.audioEngine.resampleTo16kMono(audioBuffer);
            if (!pcmData || pcmData.length === 0) {
                if (dtmfParser) app.uiManager.updateDtmfDisplay("DTMF: No audio data.");
                if (cptParser) app.uiManager.updateCallProgressTonesDisplay(["CPT: No audio data."]);
                return;
            }
        } catch (error) {
            if (dtmfParser) app.uiManager.updateDtmfDisplay(`DTMF Error: ${error?.message?.substring(0, 100) || 'Resample error'}`);
            if (cptParser) app.uiManager.updateCallProgressTonesDisplay([`CPT Error: ${error?.message?.substring(0, 100) || 'Resample error'}`]);
            return;
        }
        if (dtmfParser) {
            app.uiManager.updateDtmfDisplay("Processing DTMF...");
            try {
                const detectedDtmfTones = [];
                let lastDetectedDtmf = null;
                let consecutiveDtmfDetections = 0;
                const minConsecutiveDtmf = 2;
                for (let i = 0; (i + pcmBlockSize) <= pcmData.length; i += pcmBlockSize) {
                    const audioBlock = pcmData.subarray(i, i + pcmBlockSize);
                    const tone = dtmfParser.processAudioBlock(audioBlock);
                    if (tone) {
                        if (tone === lastDetectedDtmf) {
                            consecutiveDtmfDetections++;
                        } else {
                            lastDetectedDtmf = tone;
                            consecutiveDtmfDetections = 1;
                        }
                        if (consecutiveDtmfDetections === minConsecutiveDtmf) {
                            if (detectedDtmfTones.length === 0 || detectedDtmfTones[detectedDtmfTones.length - 1] !== tone) {
                                detectedDtmfTones.push(tone);
                            }
                        }
                    } else {
                        lastDetectedDtmf = null;
                        consecutiveDtmfDetections = 0;
                    }
                }
                app.uiManager.updateDtmfDisplay(detectedDtmfTones.length > 0 ? detectedDtmfTones : "No DTMF detected.");
            } catch (error) {
                app.uiManager.updateDtmfDisplay(`DTMF Error: ${error?.message?.substring(0, 100) || 'Processing error'}`);
            }
        }
        if (cptParser) {
            app.uiManager.updateCallProgressTonesDisplay(["Processing CPTs..."]);
            try {
                const detectedCptSet = new Set();
                for (let i = 0; (i + pcmBlockSize) <= pcmData.length; i += pcmBlockSize) {
                    const audioBlock = pcmData.subarray(i, i + pcmBlockSize);
                    const toneName = cptParser.processAudioBlock(audioBlock);
                    if (toneName) detectedCptSet.add(toneName);
                }
                app.uiManager.updateCallProgressTonesDisplay(detectedCptSet.size > 0 ? Array.from(detectedCptSet) : ["No CPTs detected."]);
            } catch (error) {
                app.uiManager.updateCallProgressTonesDisplay([`CPT Error: ${error?.message?.substring(0, 100) || 'Processing error'}`]);
            }
        }
    }

    function handleAudioError(e) {
        const errorType = e.detail.type || 'Unknown Error';
        const errorMessage = e.detail.error?.message || 'An unknown error occurred';
        console.error(`App: Audio Error - Type: ${errorType}, Message: ${errorMessage}`, e.detail.error);
        stopUIUpdateLoop();
        app.state.updateStatus('fileInfoMessage', `Error (${errorType}): ${errorMessage.substring(0, 100)}`);
        app.uiManager.resetUI();
        app.waveformVisualizer?.clearVisuals();
        app.spectrogramVisualizer?.clearVisuals();
        app.spectrogramVisualizer?.showSpinner(false);
        app.state.updateRuntime('currentAudioBuffer', null);
        app.state.updateRuntime('currentVadResults', null);
        app.state.updateRuntime('currentFile', null);
        app.state.updateStatus('workletPlaybackReady', false);
        app.state.updateStatus('isActuallyPlaying', false);
        app.state.updateStatus('isVadProcessing', false);
        app.state.updateRuntime('playbackStartTimeContext', null);
        app.state.updateRuntime('playbackStartSourceTime', 0.0);
        app.state.updateRuntime('currentSpeedForUpdate', 1.0);
    }

    function handlePlayPause() {
        if (!app.state.status.workletPlaybackReady || !app.audioEngine) {
            console.warn("App: Play/Pause ignored - Engine/Worklet not ready.");
            return;
        }
        const audioCtx = app.audioEngine.getAudioContext();
        if (!audioCtx) {
            console.error("App: Cannot play/pause, AudioContext not available.");
            return;
        }
        const aboutToPlay = !app.state.status.isActuallyPlaying;
        if (!aboutToPlay) {
            app.state.updateStatus('playbackNaturallyEnded', false);
            const finalEstimatedTime = calculateEstimatedSourceTime();
            app.audioEngine.seek(finalEstimatedTime);
            app.state.updateRuntime('playbackStartSourceTime', finalEstimatedTime);
            app.state.updateRuntime('playbackStartTimeContext', null);
            stopUIUpdateLoop();
            updateUIWithTime(finalEstimatedTime);
            if (debouncedUpdateUrlHash) debouncedUpdateUrlHash();
        }
        app.audioEngine.togglePlayPause();
    }

    function handleJump(e) {
        app.state.updateStatus('playbackNaturallyEnded', false);
        const audioBuffer = app.state.runtime.currentAudioBuffer;
        if (!app.state.status.workletPlaybackReady || !audioBuffer || !app.audioEngine) return;
        const audioCtx = app.audioEngine.getAudioContext();
        if (!audioCtx) return;
        const duration = audioBuffer.duration;
        if (isNaN(duration) || duration <= 0) return;
        const currentTime = calculateEstimatedSourceTime();
        const direction = e.detail.direction; // Get direction
        const jumpTime = app.state.params.jumpTime; // Get jumpTime from state
        const jumpAmount = jumpTime * direction; // Calculate jumpAmount
        const targetTime = Math.max(0, Math.min(currentTime + jumpAmount, duration)); // Use jumpAmount
        app.audioEngine.seek(targetTime);
        app.state.updateRuntime('playbackStartSourceTime', targetTime);
        if (app.state.status.isActuallyPlaying) {
            app.state.updateRuntime('playbackStartTimeContext', audioCtx.currentTime);
        } else {
            app.state.updateRuntime('playbackStartTimeContext', null);
            updateUIWithTime(targetTime);
        }
        if (debouncedUpdateUrlHash) debouncedUpdateUrlHash();
    }

    function handleSeek(e) {
        app.state.updateStatus('playbackNaturallyEnded', false);
        const audioBuffer = app.state.runtime.currentAudioBuffer;
        if (!app.state.status.workletPlaybackReady || !audioBuffer || isNaN(audioBuffer.duration) || audioBuffer.duration <= 0 || !app.audioEngine) return;
        const audioCtx = app.audioEngine.getAudioContext();
        if (!audioCtx) return;
        const targetTime = e.detail.fraction * audioBuffer.duration;
        app.audioEngine.seek(targetTime);
        app.state.updateRuntime('playbackStartSourceTime', targetTime);
        if (app.state.status.isActuallyPlaying) {
            app.state.updateRuntime('playbackStartTimeContext', audioCtx.currentTime);
        } else {
            app.state.updateRuntime('playbackStartTimeContext', null);
            updateUIWithTime(targetTime);
        }
        if (debouncedUpdateUrlHash) debouncedUpdateUrlHash();
    }

    const handleSeekBarInput = handleSeek;

    function handleSpeedChange(e) {
        app.state.updateParam('speed', e.detail.speed);
        if (debouncedSyncEngine) debouncedSyncEngine();
        if (debouncedUpdateUrlHash) debouncedUpdateUrlHash();
    }

    function handlePitchChange(e) {
        app.state.updateParam('pitch', e.detail.pitch);
        if (debouncedUpdateUrlHash) debouncedUpdateUrlHash();
    }

    function handleGainChange(e) {
        app.state.updateParam('gain', e.detail.gain);
        if (debouncedUpdateUrlHash) debouncedUpdateUrlHash();
    }

    function syncEngineToEstimatedTime() {
        const audioBuffer = app.state.runtime.currentAudioBuffer;
        if (!app.state.status.workletPlaybackReady || !audioBuffer || !app.audioEngine) return;
        const audioCtx = app.audioEngine.getAudioContext();
        if (!audioCtx) return;
        const targetTime = calculateEstimatedSourceTime();
        app.audioEngine.seek(targetTime);
        app.state.updateRuntime('playbackStartSourceTime', targetTime);
        if (app.state.status.isActuallyPlaying) {
            app.state.updateRuntime('playbackStartTimeContext', audioCtx.currentTime);
        } else {
            app.state.updateRuntime('playbackStartTimeContext', null);
            updateUIWithTime(targetTime);
        }
    }

    function handleInternalSpeedChange(e) {
        const newSpeed = e.detail.speed;
        const oldSpeed = app.state.runtime.currentSpeedForUpdate;
        app.state.updateRuntime('currentSpeedForUpdate', newSpeed);
        const audioCtx = app.audioEngine?.getAudioContext();
        if (app.state.status.isActuallyPlaying && app.state.runtime.playbackStartTimeContext !== null && audioCtx) {
            const elapsedContextTime = audioCtx.currentTime - app.state.runtime.playbackStartTimeContext;
            const elapsedSourceTime = elapsedContextTime * oldSpeed;
            const previousSourceTime = app.state.runtime.playbackStartSourceTime + elapsedSourceTime;
            app.state.updateRuntime('playbackStartSourceTime', previousSourceTime);
            app.state.updateRuntime('playbackStartTimeContext', audioCtx.currentTime);
        }
    }

    function handleThresholdChange(e) {
        const {type, value} = e.detail;
        if (type === 'positive') {
            app.state.updateParam('vadPositive', value);
        } else if (type === 'negative') {
            app.state.updateParam('vadNegative', value);
        }

        const currentAudioBuffer = app.state.runtime.currentAudioBuffer;
        const vadResults = app.state.runtime.currentVadResults;

        if (currentAudioBuffer && vadResults && vadResults.probabilities &&
            typeof vadResults.frameSamples === 'number' &&
            typeof vadResults.sampleRate === 'number' &&
            typeof vadResults.redemptionFrames === 'number') {

            // Ensure VAD is not currently processing a full analysis
            if (app.state.status.isVadProcessing) {
                console.log("App.handleThresholdChange: VAD is currently processing, skipping re-calculation for now.");
                return;
            }

            const newRegions = generateSpeechRegionsFromProbs(vadResults.probabilities, {
                frameSamples: vadResults.frameSamples,
                sampleRate: vadResults.sampleRate,
                positiveSpeechThreshold: app.state.params.vadPositive,
                negativeSpeechThreshold: app.state.params.vadNegative,
                redemptionFrames: vadResults.redemptionFrames,
                // Add the missing parameters from Constants
                minSpeechDurationMs: Constants.VAD.MIN_SPEECH_DURATION_MS,
                speechPadMs: Constants.VAD.SPEECH_PAD_MS
            });

            // Update the UI text for speech regions
            app.uiManager.setSpeechRegionsText(newRegions);

            // Redraw the waveform with the new speech regions
            app.waveformVisualizer.redrawWaveformHighlight(currentAudioBuffer, newRegions);

            // Update the VAD display in the UI to reflect the thresholds being used for the current highlight
            // (even though these might be different from vadResults.initialPositiveThreshold if changed since initial analysis)
            app.uiManager.updateVadDisplay(app.state.params.vadPositive, app.state.params.vadNegative, false);

        } else {
            // This case might occur if thresholds are changed before VAD analysis has run at all,
            // or if vadResults is incomplete.
            console.log("App.handleThresholdChange: Skipping speech region recalculation - VAD results or necessary data not available yet.");
            // Optionally, still update the VAD display to show N/A or the current slider values
            // if no audio is loaded or VAD hasn't run.
            if (!currentAudioBuffer) {
                app.uiManager.updateVadDisplay(app.state.params.vadPositive, app.state.params.vadNegative, true); // true for N/A
            } else {
                app.uiManager.updateVadDisplay(app.state.params.vadPositive, app.state.params.vadNegative, false);
            }
        }

        if (debouncedUpdateUrlHash) debouncedUpdateUrlHash();
    }

    function handlePlaybackEnded() {
        console.log("App: Playback ended event received.");
        app.state.updateStatus('isActuallyPlaying', false);
        stopUIUpdateLoop();
        app.state.updateRuntime('playbackStartTimeContext', null);
        const audioBuffer = app.state.runtime.currentAudioBuffer;
        if (audioBuffer) {
            app.state.updateRuntime('playbackStartSourceTime', audioBuffer.duration);
            updateUIWithTime(audioBuffer.duration);
        }
        app.state.updateStatus('playbackNaturallyEnded', true);
        app.uiManager.setPlayButtonState(false);
        if (debouncedUpdateUrlHash) debouncedUpdateUrlHash();
    }

    function handlePlaybackStateChange(e) {
        const workletIsPlaying = e.detail.isPlaying;
        const wasPlaying = app.state.status.isActuallyPlaying;
        app.state.updateStatus('isActuallyPlaying', workletIsPlaying);
        app.uiManager.setPlayButtonState(workletIsPlaying);
        if (workletIsPlaying) {
            const audioCtx = app.audioEngine?.getAudioContext();
            if (!wasPlaying && audioCtx) {
                const audioBuffer = app.state.runtime.currentAudioBuffer;
                if (app.state.status.playbackNaturallyEnded && audioBuffer) {
                    app.state.updateRuntime('playbackStartSourceTime', 0);
                    app.state.updateStatus('playbackNaturallyEnded', false);
                } else {
                    app.state.updateRuntime('playbackStartSourceTime', app.audioEngine.getCurrentTime().currentTime);
                }
                app.state.updateRuntime('playbackStartTimeContext', audioCtx.currentTime);
                updateUIWithTime(app.state.runtime.playbackStartSourceTime);
            }
            startUIUpdateLoop();
        } else {
            stopUIUpdateLoop();
            app.state.updateRuntime('playbackStartTimeContext', null);
        }
    }

    function handleKeyPress(e) {
        if (!app.state.status.workletPlaybackReady) return;
        const key = e.detail.key;
        // const jumpTimeValue = app.uiManager.getJumpTime(); // Removed
        switch (key) {
            case 'Space':
                handlePlayPause();
                break;
            // ArrowLeft and ArrowRight cases are removed as they are handled by uiManager
            // and dispatch 'audioapp:jumpClicked' directly.
        }
    }

    function handleWindowResize() {
        const regions = app.state.runtime.currentVadResults?.regions || [];
        app.waveformVisualizer?.resizeAndRedraw(app.state.runtime.currentAudioBuffer, regions);
        app.spectrogramVisualizer?.resizeAndRedraw(app.state.runtime.currentAudioBuffer);
    }

    function handleBeforeUnload() {
        console.log("App: Unloading...");
        stopUIUpdateLoop();
        app.audioEngine?.cleanup();
    }

    function startUIUpdateLoop() {
        if (rAFUpdateHandle === null) {
            rAFUpdateHandle = requestAnimationFrame(updateUIBasedOnContextTime);
        }
    }

    function stopUIUpdateLoop() {
        if (rAFUpdateHandle !== null) {
            cancelAnimationFrame(rAFUpdateHandle);
            rAFUpdateHandle = null;
        }
    }

    function calculateEstimatedSourceTime() {
        const audioCtx = app.audioEngine?.getAudioContext();
        const audioBuffer = app.state.runtime.currentAudioBuffer;
        const duration = audioBuffer ? audioBuffer.duration : 0;
        if (!app.state.status.isActuallyPlaying || app.state.runtime.playbackStartTimeContext === null ||
            !audioCtx || !audioBuffer || duration <= 0 || app.state.runtime.currentSpeedForUpdate <= 0) {
            return app.state.runtime.playbackStartSourceTime;
        }
        const elapsedContextTime = audioCtx.currentTime - app.state.runtime.playbackStartTimeContext;
        const elapsedSourceTime = elapsedContextTime * app.state.runtime.currentSpeedForUpdate;
        let estimatedCurrentSourceTime = app.state.runtime.playbackStartSourceTime + elapsedSourceTime;
        return Math.max(0, Math.min(estimatedCurrentSourceTime, duration));
    }

    function updateUIWithTime(time) {
        const audioBuffer = app.state.runtime.currentAudioBuffer;
        const duration = audioBuffer ? audioBuffer.duration : 0;
        if (isNaN(duration)) return;
        const clampedTime = Math.max(0, Math.min(time, duration));
        const fraction = duration > 0 ? clampedTime / duration : 0;
        app.uiManager.updateTimeDisplay(clampedTime, duration);
        app.uiManager.updateSeekBar(fraction);
        app.waveformVisualizer?.updateProgressIndicator(clampedTime, duration);
        app.spectrogramVisualizer?.updateProgressIndicator(clampedTime, duration);
    }

    function updateUIBasedOnContextTime(timestamp) {
        if (!app.state.status.isActuallyPlaying) {
            rAFUpdateHandle = null;
            return;
        }
        const estimatedTime = calculateEstimatedSourceTime();
        updateUIWithTime(estimatedTime);
        rAFUpdateHandle = requestAnimationFrame(updateUIBasedOnContextTime);
    }

    /**
     * Generates speech regions from VAD probabilities using specified thresholds.
     * Logic adapted from sileroProcessor.recalculateSpeechRegions.
     * @private
     * @param {Float32Array} probabilities - Probabilities for each frame.
     * @param {object} options - Parameters for region calculation.
     * @param {number} options.frameSamples - Samples per frame used during original analysis.
     * @param {number} options.sampleRate - Sample rate used (e.g., Constants.VAD.SAMPLE_RATE).
     * @param {number} options.positiveSpeechThreshold - Current positive threshold.
     * @param {number} options.negativeSpeechThreshold - Current negative threshold.
     * @param {number} options.redemptionFrames - Redemption frames value.
     * @returns {Array<{start: number, end: number}>} Newly calculated speech regions.
     */
    function generateSpeechRegionsFromProbs(probabilities, options) {
        const {
            frameSamples,
            sampleRate,
            positiveSpeechThreshold,
            negativeSpeechThreshold,
            redemptionFrames,
            minSpeechDurationMs, // New option
            speechPadMs          // New option
        } = options;

        // Removed check for global Constants here as these are now passed in.
        // We still need global Constants for Constants.VAD.SAMPLE_RATE if we want to keep that safety check.
        // However, sampleRate is passed in options, so direct comparison can be done if needed.
        // For now, assuming options.sampleRate is the one to be used.

        // if (typeof probabilities === 'undefined' || probabilities === null ||
        //     typeof probabilities.length !== 'number' ||
        //     typeof frameSamples !== 'number' || typeof sampleRate !== 'number' || sampleRate === 0 ||
        //     typeof positiveSpeechThreshold !== 'number' || typeof negativeSpeechThreshold !== 'number' ||
        //     typeof redemptionFrames !== 'number' ||
        //     typeof minSpeechDurationMs !== 'number' || // Validate new options
        //     typeof speechPadMs !== 'number') {       // Validate new options
        //     console.warn("App.generateSpeechRegionsFromProbs: Invalid arguments (e.g., probabilities not an array, or critical options missing/invalid). Returning empty array. Options:", options, "Probabilities length:", probabilities ? probabilities.length : 'N/A');
        //     return [];
        // }

        // 1. Must have a non-null/undefined probabilities
        if (probabilities == null) {
            console.warn(
                "generateSpeechRegionsFromProbs: `probabilities` is null or undefined.",
                {options: arguments[1]}
            );
            return [];
        }

        // 2. probabilities must be array-like
        if (typeof probabilities.length !== "number") {
            console.warn(
                "generateSpeechRegionsFromProbs: `probabilities.length` is not a number.",
                {length: probabilities.length}
            );
            return [];
        }

        // 3. Numeric options
        if (typeof frameSamples !== "number") {
            console.warn("generateSpeechRegionsFromProbs: `frameSamples` is not a number.", {frameSamples});
            return [];
        }

        if (typeof sampleRate !== "number" || sampleRate === 0) {
            console.warn("generateSpeechRegionsFromProbs: `sampleRate` must be a non-zero number.", {sampleRate});
            return [];
        }

        if (typeof positiveSpeechThreshold !== "number") {
            console.warn(
                "generateSpeechRegionsFromProbs: `positiveSpeechThreshold` is not a number.",
                {positiveSpeechThreshold}
            );
            return [];
        }

        if (typeof negativeSpeechThreshold !== "number") {
            console.warn(
                "generateSpeechRegionsFromProbs: `negativeSpeechThreshold` is not a number.",
                {negativeSpeechThreshold}
            );
            return [];
        }

        if (typeof redemptionFrames !== "number") {
            console.warn(
                "generateSpeechRegionsFromProbs: `redemptionFrames` is not a number.",
                {redemptionFrames}
            );
            return [];
        }

        // 4. New timing-related options
        if (typeof minSpeechDurationMs !== "number") {
            console.warn(
                "generateSpeechRegionsFromProbs: `minSpeechDurationMs` is not a number.",
                {minSpeechDurationMs}
            );
            return [];
        }

        if (typeof speechPadMs !== "number") {
            console.warn(
                "generateSpeechRegionsFromProbs: `speechPadMs` is not a number.",
                {speechPadMs}
            );
            return [];
        }

        if (probabilities.length === 0) {
            return [];
        }

        // Optional: Keep a safety check if options.sampleRate should align with a global constant,
        // but this makes the function less pure if Constants is from global scope.
        // For now, we trust options.sampleRate.
        // if (sampleRate !== Constants.VAD.SAMPLE_RATE) {
        //     console.warn(`App.generateSpeechRegionsFromProbs: Processing with sample rate ${sampleRate}. Ensure this is intended.`);
        // }

        const newRegions = [];
        let inSpeech = false;
        let regionStart = 0.0;
        let redemptionCounter = 0;
        let lastPositiveFrameIndex = -1;

        for (let i = 0; i < probabilities.length; i++) {
            const probability = probabilities[i];
            const frameStartTime = (i * frameSamples) / sampleRate;

            if (probability >= positiveSpeechThreshold) {
                if (!inSpeech) {
                    inSpeech = true;
                    regionStart = frameStartTime;
                }
                redemptionCounter = 0;
                lastPositiveFrameIndex = i;
            } else if (inSpeech) {
                if (probability < negativeSpeechThreshold) {
                    redemptionCounter++;
                    if (redemptionCounter >= redemptionFrames) {
                        const firstBadFrameIndex = i - redemptionFrames + 1;
                        const actualEnd = (firstBadFrameIndex * frameSamples) / sampleRate;
                        newRegions.push({start: regionStart, end: Math.max(regionStart, actualEnd)});
                        inSpeech = false;
                        redemptionCounter = 0;
                        lastPositiveFrameIndex = -1;
                    }
                } else {
                    redemptionCounter = 0;
                }
            }
        }

        if (inSpeech) {
            const endFrameIndexPlusOne = (lastPositiveFrameIndex !== -1 && lastPositiveFrameIndex < probabilities.length) ? lastPositiveFrameIndex + 1 : probabilities.length;
            const finalEnd = (endFrameIndexPlusOne * frameSamples) / sampleRate;
            newRegions.push({start: regionStart, end: Math.max(regionStart, finalEnd)});
        }

        const minSpeechDuration = minSpeechDurationMs / 1000.0; // Use from options
        const speechPad = speechPadMs / 1000.0;               // Use from options

        const paddedAndFilteredRegions = [];
        for (const region of newRegions) {
            const start = Math.max(0, region.start - speechPad);
            const end = region.end + speechPad;

            if ((end - start) >= minSpeechDuration) {
                paddedAndFilteredRegions.push({start: start, end: end});
            }
        }

        if (paddedAndFilteredRegions.length === 0) {
            return [];
        }

        const mergedRegions = [];
        let currentRegion = {...paddedAndFilteredRegions[0]};

        for (let i = 1; i < paddedAndFilteredRegions.length; i++) {
            const nextRegion = paddedAndFilteredRegions[i];
            if (nextRegion.start < currentRegion.end) {
                currentRegion.end = Math.max(currentRegion.end, nextRegion.end);
            } else {
                mergedRegions.push(currentRegion);
                currentRegion = {...nextRegion};
            }
        }
        mergedRegions.push(currentRegion);

        const maxProbTime = (probabilities.length * frameSamples) / sampleRate;
        return mergedRegions.map(region => ({
            start: region.start,
            end: Math.min(region.end, maxProbTime)
        }));
    }

    // --- REFACTORED: Attach init function to the passed-in 'app' object ---
    app.init = init;

    // For testing purposes only
    if (typeof process !== 'undefined' && process.env && process.env.NODE_ENV === 'test') {
        app.testExports = {
            generateSpeechRegionsFromProbs
        };
    }

})(AudioApp); // Immediately execute, passing the global AudioApp object.
// --- /vibe-player/js/app.js ---
````
--- End of File: vibe-player/js/app.js ---
--- File: vibe-player/js/goertzel.js ---
````javascript
// --- goertzel.js ---
// Pure JavaScript Goertzel Algorithm Implementation for Vibe Player
// Attaches GoertzelFilter to AudioApp.

/** @namespace AudioApp */
var AudioApp = AudioApp || {}; // Ensure AudioApp namespace exists

/**
 * @module GoertzelModule
 * @description Provides GoertzelFilter, DTMFParser, CallProgressToneParser classes and related constants.
 */
const GoertzelModule = (function () {
    'use strict';

    // --- DTMF Constants ---
    /** @type {number} Standard sample rate for DTMF processing (Hz). */
    const DTMF_SAMPLE_RATE = 16000;
    /** @type {number} Common block size for 16kHz sample rate (samples). */
    const DTMF_BLOCK_SIZE = 410;
    /** @type {number} Relative magnitude threshold factor: dominant tone must be X times stronger than others in its group. */
    const DTMF_RELATIVE_THRESHOLD_FACTOR = 2.0;
    /** @type {number} Absolute magnitude threshold: minimum energy for a tone to be considered. */
    const DTMF_ABSOLUTE_MAGNITUDE_THRESHOLD = 4e2;

    /** @type {number[]} Low frequency group for DTMF (Hz). */
    const DTMF_FREQUENCIES_LOW = [697, 770, 852, 941];
    /** @type {number[]} High frequency group for DTMF (Hz), including A,B,C,D. */
    const DTMF_FREQUENCIES_HIGH = [1209, 1336, 1477, 1633];

    /** @type {Object<string, string>} Maps DTMF frequency pairs to characters. Key: "lowFreq,highFreq". */
    const DTMF_CHARACTERS = {
        "697,1209": "1", "697,1336": "2", "697,1477": "3", "697,1633": "A",
        "770,1209": "4", "770,1336": "5", "770,1477": "6", "770,1633": "B",
        "852,1209": "7", "852,1336": "8", "852,1477": "9", "852,1633": "C",
        "941,1209": "*", "941,1336": "0", "941,1477": "#", "941,1633": "D"
    };

    // --- Call Progress Tone Frequencies (Hz) ---
    /** @type {number[]} Frequencies for Dial Tone. */
    const CPT_FREQ_DIAL_TONE = [350, 440];
    /** @type {number[]} Frequencies for Busy Signal. */
    const CPT_FREQ_BUSY_SIGNAL = [480, 620];
    /** @type {number[]} Frequencies for Reorder Tone (same as Busy). */
    const CPT_FREQ_REORDER_TONE = [480, 620];
    /** @type {number[]} Frequencies for Ringback Tone. */
    const CPT_FREQ_RINGBACK_TONE = [440, 480];
    /** @type {number[]} Frequencies for Off-Hook Warning Tone. */
    const CPT_FREQ_OFF_HOOK_WARNING = [1400, 2060, 2450, 2600];
    /** @type {number[]} Frequencies for Call Waiting Tone. */
    const CPT_FREQ_CALL_WAITING_TONE = [440];

    // --- Call Progress Tone Cadences (ms ON, ms OFF) ---
    /** @typedef {{on: number, off: number}} CadenceSpec */
    /** @type {CadenceSpec} Cadence for Busy Signal. */
    const CPT_CADENCE_BUSY_SIGNAL = {on: 500, off: 500};
    /** @type {CadenceSpec} Cadence for Reorder Tone. */
    const CPT_CADENCE_REORDER_TONE = {on: 250, off: 250};
    /** @type {CadenceSpec} Cadence for Ringback Tone. */
    const CPT_CADENCE_RINGBACK_TONE = {on: 2000, off: 4000};
    /** @type {CadenceSpec} Cadence for Call Waiting Tone. */
    const CPT_CADENCE_CALL_WAITING_TONE = {on: 300, off: 9700}; // Approximate

    // --- Call Progress Tone Parser Constants ---
    /** @type {number} Default sample rate for CPT parser (Hz). */
    const CPT_DEFAULT_SAMPLE_RATE = DTMF_SAMPLE_RATE;
    /** @type {number} Default block size for CPT parser (samples). */
    const CPT_DEFAULT_BLOCK_SIZE = DTMF_BLOCK_SIZE;
    /** @type {number} Default absolute magnitude threshold for CPT parser. */
    const CPT_DEFAULT_ABSOLUTE_MAGNITUDE_THRESHOLD = 2e2;
    /** @type {number} Default relative magnitude threshold factor for CPT parser. */
    const CPT_DEFAULT_RELATIVE_THRESHOLD_FACTOR = 1.5;
    /** @type {number} Tolerance (percentage) for CPT cadence timing. */
    const CPT_CADENCE_TOLERANCE_PERCENT = 0.25;
    /** @type {number} Minimum number of cycles for confirming a cadenced CPT. */
    const CPT_MIN_CYCLE_CONFIRMATION = 1.5;


    /**
     * @class GoertzelFilter
     * @memberof AudioApp
     * @description Implements the Goertzel algorithm to detect the magnitude of a specific frequency
     * in a block of audio samples.
     */
    class GoertzelFilter {
        /**
         * Creates an instance of GoertzelFilter.
         * @param {number} targetFrequency - The specific frequency (in Hz) this filter will detect.
         * @param {number} sampleRate - The sample rate (in Hz) of the audio signal.
         * @param {number} N - The block size (number of samples) for one analysis window.
         *                   Coefficients are calculated based on this N, and for the most
         *                   straightforward interpretation of getMagnitudeSquared(), exactly
         *                   N samples should be processed after a reset.
         */
        constructor(targetFrequency, sampleRate, N) {
            if (N <= 0) {
                throw new Error("GoertzelFilter: Block size N must be positive.");
            }
            if (sampleRate <= 0) {
                throw new Error("GoertzelFilter: Sample rate must be positive.");
            }
            if (targetFrequency <= 0 || targetFrequency >= sampleRate / 2) {
                // Technically can work, but typically target is < Nyquist
                console.warn("GoertzelFilter: Target frequency is very low or near/above Nyquist frequency. Results may be suboptimal.");
            }

            /** @type {number} The target frequency for this filter instance. */
            this.targetFrequency = targetFrequency;
            /** @type {number} The sample rate assumed by this filter instance. */
            this.sampleRate = sampleRate;
            /** @type {number} The block size (N) used for coefficient calculation. */
            this.N = N;

            // Precompute coefficients
            /** @private @type {number} Normalized frequency (DFT bin index). */
            const k = Math.floor(0.5 + (this.N * this.targetFrequency) / this.sampleRate);
            /** @private @type {number} Angular frequency. */
            this.omega = (2 * Math.PI * k) / this.N;
            /** @private @type {number} Cosine of omega. */
            this.cosine = Math.cos(this.omega);
            /** @private @type {number} Sine of omega. */
            this.sine = Math.sin(this.omega);
            /** @private @type {number} Filter coefficient (2 * cos(omega)). */
            this.coeff = 2 * this.cosine;

            /** @private @type {number} Represents s[n-1] state variable. */
            this.q1 = 0;
            /** @private @type {number} Represents s[n-2] state variable. */
            this.q2 = 0;
        }

        /**
         * Resets the internal state of the filter (q1 and q2).
         * Call this before processing a new independent block of N samples.
         * @public
         */
        reset() {
            this.q1 = 0;
            this.q2 = 0;
        }

        /**
         * Processes a single audio sample through the filter.
         * This updates the internal state variables q1 and q2.
         * @public
         * @param {number} sample - The audio sample value.
         */
        processSample(sample) {
            const q0 = sample + this.coeff * this.q1 - this.q2;
            this.q2 = this.q1;
            this.q1 = q0;
        }

        /**
         * Processes a block (array or Float32Array) of audio samples.
         * Each sample in the block is run through processSample.
         * @public
         * @param {number[] | Float32Array} samples - The block of audio samples.
         */
        processBlock(samples) {
            for (let i = 0; i < samples.length; i++) {
                // Inline processSample for minor optimization in a loop
                const q0 = samples[i] + this.coeff * this.q1 - this.q2;
                this.q2 = this.q1;
                this.q1 = q0;
            }
        }

        /**
         * Calculates the squared magnitude of the target frequency component.
         * This value is proportional to the power of the signal at the target frequency.
         * It does not reset the filter's internal state.
         * @public
         * @returns {number} The squared magnitude.
         */
        getMagnitudeSquared() {
            const realPart = this.q1 - this.q2 * this.cosine;
            const imagPart = this.q2 * this.sine;
            return realPart * realPart + imagPart * imagPart;
        }
    }

    /**
     * @class DTMFParser
     * @memberof AudioApp
     * @description Parses DTMF tones from audio blocks using Goertzel filters.
     * Note: This parser can be quite robust and may detect tones even if the provided
     * audioBlock is somewhat shorter than the configured blockSize, provided enough
     * characteristic signal is present.
     */
    class DTMFParser {
        /**
         * Creates an instance of DTMFParser.
         * @param {number} [sampleRate=DTMF_SAMPLE_RATE] - Sample rate of the audio.
         * @param {number} [blockSize=DTMF_BLOCK_SIZE] - Size of audio blocks to process.
         * @param {number} [threshold=DTMF_ABSOLUTE_MAGNITUDE_THRESHOLD] - Absolute magnitude threshold for tone detection.
         * @param {number} [relativeThresholdFactor=DTMF_RELATIVE_THRESHOLD_FACTOR] - Relative threshold factor for distinguishing tones.
         */
        constructor(sampleRate = DTMF_SAMPLE_RATE, blockSize = DTMF_BLOCK_SIZE, threshold = DTMF_ABSOLUTE_MAGNITUDE_THRESHOLD, relativeThresholdFactor = DTMF_RELATIVE_THRESHOLD_FACTOR) {
            /** @type {number} Sample rate in Hz. */
            this.sampleRate = sampleRate;
            /** @type {number} Block size in samples. */
            this.blockSize = blockSize;
            /** @type {number} Absolute magnitude detection threshold. */
            this.threshold = threshold;
            /** @type {number} Relative magnitude threshold factor. */
            this.relativeThresholdFactor = relativeThresholdFactor;

            /** @private @type {AudioApp.GoertzelFilter[]} Filters for low DTMF frequencies. */
            this.lowGroupFilters = DTMF_FREQUENCIES_LOW.map(freq =>
                new GoertzelFilter(freq, this.sampleRate, this.blockSize) // Changed: Use GoertzelFilter directly
            );
            /** @private @type {AudioApp.GoertzelFilter[]} Filters for high DTMF frequencies. */
            this.highGroupFilters = DTMF_FREQUENCIES_HIGH.map(freq =>
                new GoertzelFilter(freq, this.sampleRate, this.blockSize) // Changed: Use GoertzelFilter directly
            );
            /** @private @type {number} Counter for processed blocks (for debugging/logging). */
            this.processedBlocksCounter = 0;
        }

        /**
         * Processes a block of audio data to detect a DTMF tone.
         * @public
         * @param {Float32Array | number[]} audioBlock - The audio data to process. Must match blockSize.
         * @returns {string | null} The detected DTMF character ('0'-'9', '*', '#', 'A'-'D'), or null if no tone is detected.
         */
        processAudioBlock(audioBlock) {
            this.processedBlocksCounter++;
            if (audioBlock.length !== this.blockSize) {
                // console.warn(`DTMFParser: Audio block length (${audioBlock.length}) does not match expected block size (${this.blockSize}). Results may be inaccurate.`);
            }

            /** @type {number} */ let maxLowMag = -1;
            /** @type {number} */ let detectedLowFreq = -1;
            /** @type {Object<number, number>} */ const lowMagnitudes = {};

            this.lowGroupFilters.forEach(filter => {
                filter.reset();
                filter.processBlock(audioBlock);
                const magSq = filter.getMagnitudeSquared();
                lowMagnitudes[filter.targetFrequency] = magSq;
                if (magSq > maxLowMag) {
                    maxLowMag = magSq;
                    detectedLowFreq = filter.targetFrequency;
                }
            });

            /** @type {number} */ let maxHighMag = -1;
            /** @type {number} */ let detectedHighFreq = -1;
            /** @type {Object<number, number>} */ const highMagnitudes = {};

            this.highGroupFilters.forEach(filter => {
                filter.reset();
                filter.processBlock(audioBlock);
                const magSq = filter.getMagnitudeSquared();
                highMagnitudes[filter.targetFrequency] = magSq;
                if (magSq > maxHighMag) {
                    maxHighMag = magSq;
                    detectedHighFreq = filter.targetFrequency;
                }
            });

            if (maxLowMag < this.threshold || maxHighMag < this.threshold) {
                return null;
            }

            for (const freqStr in lowMagnitudes) {
                const freq = parseInt(freqStr);
                if (freq !== detectedLowFreq) {
                    if (lowMagnitudes[freq] * this.relativeThresholdFactor > maxLowMag) {
                        return null;
                    }
                }
            }

            for (const freqStr in highMagnitudes) {
                const freq = parseInt(freqStr);
                if (freq !== detectedHighFreq) {
                    if (highMagnitudes[freq] * this.relativeThresholdFactor > maxHighMag) {
                        return null;
                    }
                }
            }

            const dtmfKey = `${detectedLowFreq},${detectedHighFreq}`;
            const detectedChar = DTMF_CHARACTERS[dtmfKey];

            return detectedChar || null;
        }
    }

    /**
     * @typedef {Object} CadenceState
     * @property {CadenceSpec} spec - The ON/OFF duration specification.
     * @property {number[]} frequencies - The frequencies that constitute the tone.
     * @property {'ON' | 'OFF'} phase - Current phase of the cadence ('ON' or 'OFF').
     * @property {number} timerBlocks - Number of blocks spent in the current phase.
     * @property {number} cyclesDetected - Number of full ON/OFF cycles detected.
     * @property {any[]} history - Optional history for complex pattern matching.
     * @property {number} onBlocksTarget - Target number of blocks for the ON phase.
     * @property {number} offBlocksTarget - Target number of blocks for the OFF phase.
     */

    /**
     * @typedef {Object} ContinuousToneState
     * @property {number[]} requiredFreqs - Frequencies that must be present.
     * @property {number} presentBlocks - Number of consecutive blocks the tone has been present.
     * @property {number} neededBlocks - Number of consecutive blocks needed to confirm the tone.
     */

    /**
     * @class CallProgressToneParser
     * @memberof AudioApp
     * @description Parses call progress tones (e.g., busy, ringback) from audio blocks.
     */
    class CallProgressToneParser {
        /**
         * Creates an instance of CallProgressToneParser.
         * @param {number} [sampleRate=CPT_DEFAULT_SAMPLE_RATE] - Sample rate of the audio.
         * @param {number} [blockSize=CPT_DEFAULT_BLOCK_SIZE] - Size of audio blocks to process.
         * @param {number} [absoluteMagnitudeThreshold=CPT_DEFAULT_ABSOLUTE_MAGNITUDE_THRESHOLD] - Absolute magnitude threshold.
         * @param {number} [relativeThresholdFactor=CPT_DEFAULT_RELATIVE_THRESHOLD_FACTOR] - Relative threshold factor.
         */
        constructor(
            sampleRate = CPT_DEFAULT_SAMPLE_RATE,
            blockSize = CPT_DEFAULT_BLOCK_SIZE,
            absoluteMagnitudeThreshold = CPT_DEFAULT_ABSOLUTE_MAGNITUDE_THRESHOLD,
            relativeThresholdFactor = CPT_DEFAULT_RELATIVE_THRESHOLD_FACTOR
        ) {
            /** @type {number} Sample rate in Hz. */
            this.sampleRate = sampleRate;
            /** @type {number} Block size in samples. */
            this.blockSize = blockSize;
            /** @type {number} Absolute magnitude detection threshold. */
            this.absoluteMagnitudeThreshold = absoluteMagnitudeThreshold;
            /** @type {number} Relative magnitude threshold factor for multi-frequency tones. */
            this.relativeThresholdFactor = relativeThresholdFactor;

            /** @type {number} Duration of one audio block in milliseconds. */
            this.blockDurationMs = (this.blockSize / this.sampleRate) * 1000;

            /** @private @type {Set<number>} Unique frequencies used by CPTs. */
            const allCptFrequencies = new Set([
                ...CPT_FREQ_DIAL_TONE, ...CPT_FREQ_BUSY_SIGNAL,
                ...CPT_FREQ_RINGBACK_TONE, ...CPT_FREQ_OFF_HOOK_WARNING,
                ...CPT_FREQ_CALL_WAITING_TONE
            ]);

            /** @private @type {Object<number, AudioApp.GoertzelFilter>} Goertzel filters for each CPT frequency. */
            this.filters = {};
            allCptFrequencies.forEach(freq => {
                this.filters[freq] = new GoertzelFilter(freq, this.sampleRate, this.blockSize); // Changed: Use GoertzelFilter directly
            });

            /**
             * @private
             * @type {Object<string, CadenceState>} State for cadenced tones.
             */
            this.cadenceStates = {
                Busy: this._initCadenceState(CPT_CADENCE_BUSY_SIGNAL, CPT_FREQ_BUSY_SIGNAL),
                Reorder: this._initCadenceState(CPT_CADENCE_REORDER_TONE, CPT_FREQ_REORDER_TONE),
                Ringback: this._initCadenceState(CPT_CADENCE_RINGBACK_TONE, CPT_FREQ_RINGBACK_TONE),
                CallWaiting: this._initCadenceState(CPT_CADENCE_CALL_WAITING_TONE, CPT_FREQ_CALL_WAITING_TONE),
            };

            /**
             * @private
             * @type {Object<string, ContinuousToneState>} State for continuous tones.
             */
            this.continuousToneStates = {
                DialTone: {requiredFreqs: CPT_FREQ_DIAL_TONE, presentBlocks: 0, neededBlocks: 2},
                OffHookWarning: {requiredFreqs: CPT_FREQ_OFF_HOOK_WARNING, presentBlocks: 0, neededBlocks: 2}
            };
        }

        /**
         * Initializes the state object for a cadenced tone.
         * @private
         * @param {CadenceSpec} cadenceSpec - The ON/OFF duration specification.
         * @param {number[]} frequencies - The frequencies that constitute the tone.
         * @returns {CadenceState} The initialized state object.
         */
        _initCadenceState(cadenceSpec, frequencies) {
            return {
                spec: cadenceSpec,
                frequencies: frequencies,
                phase: 'OFF',
                timerBlocks: 0,
                cyclesDetected: 0,
                history: [],
                onBlocksTarget: Math.round(cadenceSpec.on / this.blockDurationMs),
                offBlocksTarget: Math.round(cadenceSpec.off / this.blockDurationMs),
            };
        }

        /**
         * Checks if a single frequency is present based on its magnitude.
         * @private
         * @param {number} freq - The frequency to check.
         * @param {Object<number, number>} magnitudes - Object mapping frequencies to their magnitudes.
         * @returns {boolean} True if the frequency is considered present.
         */
        _checkFrequencyPresence(freq, magnitudes) {
            return magnitudes[freq] >= this.absoluteMagnitudeThreshold;
        }

        /**
         * Checks if multiple required frequencies are present.
         * @private
         * @param {number[]} requiredFreqs - Array of frequencies that should be present.
         * @param {Object<number, number>} magnitudes - Object mapping frequencies to their magnitudes.
         * @param {boolean} [allowSingleComponent=false] - If true, allows detection if at least one component of a multi-frequency tone is present.
         * @returns {boolean} True if the required frequencies are considered present according to the criteria.
         */
        _checkMultiFrequencyPresence(requiredFreqs, magnitudes, allowSingleComponent = false) {
            let detectedCount = 0;
            for (const freq of requiredFreqs) {
                if (magnitudes[freq] && magnitudes[freq] >= this.absoluteMagnitudeThreshold) {
                    detectedCount++;
                } else {
                    if (!allowSingleComponent && requiredFreqs.length > 1) return false;
                }
            }
            if (requiredFreqs.length === 1) return detectedCount === 1;
            return allowSingleComponent ? detectedCount > 0 : detectedCount === requiredFreqs.length;
        }

        /**
         * Updates the cadence state for a given tone based on current activity.
         * @private
         * @param {string} toneName - The name of the tone (key in this.cadenceStates).
         * @param {boolean} isToneActiveNow - Whether the tone's frequencies are currently detected.
         * @returns {boolean} True if the cadence for this tone is confirmed.
         */
        _updateCadenceState(toneName, isToneActiveNow) {
            const state = this.cadenceStates[toneName];
            const toleranceOn = Math.ceil(state.onBlocksTarget * CPT_CADENCE_TOLERANCE_PERCENT);
            const toleranceOff = Math.ceil(state.offBlocksTarget * CPT_CADENCE_TOLERANCE_PERCENT);

            if (isToneActiveNow) {
                if (state.phase === 'OFF') {
                    if (state.timerBlocks >= state.offBlocksTarget - toleranceOff || state.cyclesDetected === 0) {
                        state.cyclesDetected += 0.5;
                    } else {
                        state.cyclesDetected = 0;
                    }
                    state.phase = 'ON';
                    state.timerBlocks = 0;
                }
                state.timerBlocks++;
            } else {
                if (state.phase === 'ON') {
                    if (state.timerBlocks >= state.onBlocksTarget - toleranceOn) {
                        state.cyclesDetected += 0.5;
                    } else {
                        state.cyclesDetected = 0;
                    }
                    state.phase = 'OFF';
                    state.timerBlocks = 0;
                }
                state.timerBlocks++;
                if (state.timerBlocks > state.offBlocksTarget + toleranceOff && state.cyclesDetected < CPT_MIN_CYCLE_CONFIRMATION) {
                    state.cyclesDetected = 0;
                }
            }
            return state.cyclesDetected >= CPT_MIN_CYCLE_CONFIRMATION;
        }

        /**
         * Processes a block of audio data to detect call progress tones.
         * @public
         * @param {Float32Array | number[]} audioBlock - The audio data to process. Must match blockSize.
         * @returns {string | null} The name of the detected CPT (e.g., "Dial Tone", "Busy Signal"), or null if no tone is confirmed.
         */
        processAudioBlock(audioBlock) {
            if (audioBlock.length !== this.blockSize) {
                console.warn(`CallProgressToneParser: Audio block length (${audioBlock.length}) does not match expected block size (${this.blockSize}).`);
                return null;
            }

            /** @type {Object<number, number>} */ const magnitudes = {};
            for (const freq in this.filters) {
                this.filters[freq].reset();
                this.filters[freq].processBlock(audioBlock);
                magnitudes[freq] = this.filters[freq].getMagnitudeSquared();
            }

            const dialTonePresent = this._checkMultiFrequencyPresence(CPT_FREQ_DIAL_TONE, magnitudes);
            if (dialTonePresent) {
                this.continuousToneStates.DialTone.presentBlocks++;
                if (this.continuousToneStates.DialTone.presentBlocks >= this.continuousToneStates.DialTone.neededBlocks) {
                    for (const tone in this.cadenceStates) this.cadenceStates[tone].cyclesDetected = 0;
                    return "Dial Tone";
                }
            } else {
                this.continuousToneStates.DialTone.presentBlocks = 0;
            }

            const offHookPresent = this._checkMultiFrequencyPresence(CPT_FREQ_OFF_HOOK_WARNING, magnitudes);
            if (offHookPresent) {
                this.continuousToneStates.OffHookWarning.presentBlocks++;
                if (this.continuousToneStates.OffHookWarning.presentBlocks >= this.continuousToneStates.OffHookWarning.neededBlocks) {
                    for (const tone in this.cadenceStates) this.cadenceStates[tone].cyclesDetected = 0;
                    return "Off-Hook Warning";
                }
            } else {
                this.continuousToneStates.OffHookWarning.presentBlocks = 0;
            }

            if (this.continuousToneStates.DialTone.presentBlocks >= this.continuousToneStates.DialTone.neededBlocks ||
                this.continuousToneStates.OffHookWarning.presentBlocks >= this.continuousToneStates.OffHookWarning.neededBlocks) {
                // Return early if a continuous tone is confirmed
            }

            const busyToneActive = this._checkMultiFrequencyPresence(CPT_FREQ_BUSY_SIGNAL, magnitudes);
            if (this._updateCadenceState('Busy', busyToneActive)) {
                return "Busy Signal";
            }

            const reorderToneActive = this._checkMultiFrequencyPresence(CPT_FREQ_REORDER_TONE, magnitudes);
            if (this._updateCadenceState('Reorder', reorderToneActive)) {
                return "Fast Busy / Reorder Tone";
            }

            const ringbackToneActive = this._checkMultiFrequencyPresence(CPT_FREQ_RINGBACK_TONE, magnitudes);
            if (this._updateCadenceState('Ringback', ringbackToneActive)) {
                return "Ringback Tone";
            }

            const callWaitingToneActive = this._checkMultiFrequencyPresence(CPT_FREQ_CALL_WAITING_TONE, magnitudes, true);
            if (this._updateCadenceState('CallWaiting', callWaitingToneActive)) {
                return "Call Waiting Tone";
            }

            return null;
        }
    }

    /**
     * @typedef {Object} GoertzelModuleReturn
     * @property {typeof GoertzelFilter} GoertzelFilter
     * @property {typeof DTMFParser} DTMFParser
     * @property {typeof CallProgressToneParser} CallProgressToneParser
     * @property {number} DTMF_SAMPLE_RATE
     * @property {number} DTMF_BLOCK_SIZE
     * @property {number[]} CPT_FREQ_DIAL_TONE
     * @property {number[]} CPT_FREQ_BUSY_SIGNAL
     * @property {number[]} CPT_FREQ_REORDER_TONE
     * @property {number[]} CPT_FREQ_RINGBACK_TONE
     * @property {number[]} CPT_FREQ_OFF_HOOK_WARNING
     * @property {number[]} CPT_FREQ_CALL_WAITING_TONE
     * @property {CadenceSpec} CPT_CADENCE_BUSY_SIGNAL
     * @property {CadenceSpec} CPT_CADENCE_REORDER_TONE
     * @property {CadenceSpec} CPT_CADENCE_RINGBACK_TONE
     * @property {CadenceSpec} CPT_CADENCE_CALL_WAITING_TONE
     * @property {number} CPT_DEFAULT_SAMPLE_RATE
     * @property {number} CPT_DEFAULT_BLOCK_SIZE
     * @property {number} CPT_DEFAULT_ABSOLUTE_MAGNITUDE_THRESHOLD
     * @property {number} CPT_DEFAULT_RELATIVE_THRESHOLD_FACTOR
     * @property {number} CPT_CADENCE_TOLERANCE_PERCENT
     * @property {number} CPT_MIN_CYCLE_CONFIRMATION
     */

    /** @type {GoertzelModuleReturn} */
    return {
        GoertzelFilter: GoertzelFilter,
        DTMFParser: DTMFParser,
        CallProgressToneParser: CallProgressToneParser,
        DTMF_SAMPLE_RATE: DTMF_SAMPLE_RATE,
        DTMF_BLOCK_SIZE: DTMF_BLOCK_SIZE,

        CPT_FREQ_DIAL_TONE: CPT_FREQ_DIAL_TONE,
        CPT_FREQ_BUSY_SIGNAL: CPT_FREQ_BUSY_SIGNAL,
        CPT_FREQ_REORDER_TONE: CPT_FREQ_REORDER_TONE,
        CPT_FREQ_RINGBACK_TONE: CPT_FREQ_RINGBACK_TONE,
        CPT_FREQ_OFF_HOOK_WARNING: CPT_FREQ_OFF_HOOK_WARNING,
        CPT_FREQ_CALL_WAITING_TONE: CPT_FREQ_CALL_WAITING_TONE,
        CPT_CADENCE_BUSY_SIGNAL: CPT_CADENCE_BUSY_SIGNAL,
        CPT_CADENCE_REORDER_TONE: CPT_CADENCE_REORDER_TONE,
        CPT_CADENCE_RINGBACK_TONE: CPT_CADENCE_RINGBACK_TONE,
        CPT_CADENCE_CALL_WAITING_TONE: CPT_CADENCE_CALL_WAITING_TONE,

        CPT_DEFAULT_SAMPLE_RATE: CPT_DEFAULT_SAMPLE_RATE,
        CPT_DEFAULT_BLOCK_SIZE: CPT_DEFAULT_BLOCK_SIZE,
        CPT_DEFAULT_ABSOLUTE_MAGNITUDE_THRESHOLD: CPT_DEFAULT_ABSOLUTE_MAGNITUDE_THRESHOLD,
        CPT_DEFAULT_RELATIVE_THRESHOLD_FACTOR: CPT_DEFAULT_RELATIVE_THRESHOLD_FACTOR,
        CPT_CADENCE_TOLERANCE_PERCENT: CPT_CADENCE_TOLERANCE_PERCENT,
        CPT_MIN_CYCLE_CONFIRMATION: CPT_MIN_CYCLE_CONFIRMATION
    };
})();

/** @type {typeof GoertzelModule.GoertzelFilter} */
AudioApp.GoertzelFilter = GoertzelModule.GoertzelFilter;
/** @type {typeof GoertzelModule.DTMFParser} */
AudioApp.DTMFParser = GoertzelModule.DTMFParser;
/** @type {typeof GoertzelModule.CallProgressToneParser} */
AudioApp.CallProgressToneParser = GoertzelModule.CallProgressToneParser;

/** @type {number} Standard sample rate for DTMF processing (Hz). */
AudioApp.DTMFParser.DTMF_SAMPLE_RATE = GoertzelModule.DTMF_SAMPLE_RATE;
/** @type {number} Common block size for DTMF processing (samples). */
AudioApp.DTMFParser.DTMF_BLOCK_SIZE = GoertzelModule.DTMF_BLOCK_SIZE;

/**
 * @namespace AudioApp.CPT_CONSTANTS
 * @description Constants related to Call Progress Tones.
 * @property {number[]} CPT_FREQ_DIAL_TONE
 * @property {number[]} CPT_FREQ_BUSY_SIGNAL
 * @property {number[]} CPT_FREQ_REORDER_TONE
 * @property {number[]} CPT_FREQ_RINGBACK_TONE
 * @property {number[]} CPT_FREQ_OFF_HOOK_WARNING
 * @property {number[]} CPT_FREQ_CALL_WAITING_TONE
 * @property {CadenceSpec} CPT_CADENCE_BUSY_SIGNAL
 * @property {CadenceSpec} CPT_CADENCE_REORDER_TONE
 * @property {CadenceSpec} CPT_CADENCE_RINGBACK_TONE
 * @property {CadenceSpec} CPT_CADENCE_CALL_WAITING_TONE
 * @property {number} CPT_DEFAULT_SAMPLE_RATE
 * @property {number} CPT_DEFAULT_BLOCK_SIZE
 * @property {number} CPT_DEFAULT_ABSOLUTE_MAGNITUDE_THRESHOLD
 * @property {number} CPT_DEFAULT_RELATIVE_THRESHOLD_FACTOR
 * @property {number} CPT_CADENCE_TOLERANCE_PERCENT
 * @property {number} CPT_MIN_CYCLE_CONFIRMATION
 */
AudioApp.CPT_CONSTANTS = {
    CPT_FREQ_DIAL_TONE: GoertzelModule.CPT_FREQ_DIAL_TONE,
    CPT_FREQ_BUSY_SIGNAL: GoertzelModule.CPT_FREQ_BUSY_SIGNAL,
    CPT_FREQ_REORDER_TONE: GoertzelModule.CPT_FREQ_REORDER_TONE,
    CPT_FREQ_RINGBACK_TONE: GoertzelModule.CPT_FREQ_RINGBACK_TONE,
    CPT_FREQ_OFF_HOOK_WARNING: GoertzelModule.CPT_FREQ_OFF_HOOK_WARNING,
    CPT_FREQ_CALL_WAITING_TONE: GoertzelModule.CPT_FREQ_CALL_WAITING_TONE,
    CPT_CADENCE_BUSY_SIGNAL: GoertzelModule.CPT_CADENCE_BUSY_SIGNAL,
    CPT_CADENCE_REORDER_TONE: GoertzelModule.CPT_CADENCE_REORDER_TONE,
    CPT_CADENCE_RINGBACK_TONE: GoertzelModule.CPT_CADENCE_RINGBACK_TONE,
    CPT_CADENCE_CALL_WAITING_TONE: GoertzelModule.CPT_CADENCE_CALL_WAITING_TONE,

    CPT_DEFAULT_SAMPLE_RATE: GoertzelModule.CPT_DEFAULT_SAMPLE_RATE,
    CPT_DEFAULT_BLOCK_SIZE: GoertzelModule.CPT_DEFAULT_BLOCK_SIZE,
    CPT_DEFAULT_ABSOLUTE_MAGNITUDE_THRESHOLD: GoertzelModule.CPT_DEFAULT_ABSOLUTE_MAGNITUDE_THRESHOLD,
    CPT_DEFAULT_RELATIVE_THRESHOLD_FACTOR: GoertzelModule.CPT_DEFAULT_RELATIVE_THRESHOLD_FACTOR,
    CPT_CADENCE_TOLERANCE_PERCENT: GoertzelModule.CPT_CADENCE_TOLERANCE_PERCENT,
    CPT_MIN_CYCLE_CONFIRMATION: GoertzelModule.CPT_MIN_CYCLE_CONFIRMATION
};

// Example Usage (for testing or a DTMF detector module):
/*
if (typeof AudioApp.GoertzelFilter !== 'undefined') {
    const SAMPLE_RATE = 8000; // Example
    const N_SAMPLES_PER_BLOCK = 205; // Common for DTMF at 8kHz

    // DTMF Frequencies
    const dtmfLowFreqs = [697, 770, 852, 941];
    const dtmfHighFreqs = [1209, 1336, 1477]; // Excluding 1633 for A,B,C,D for now

    const lowGroupFilters = dtmfLowFreqs.map(freq =>
        new AudioApp.GoertzelFilter(freq, SAMPLE_RATE, N_SAMPLES_PER_BLOCK)
    );
    const highGroupFilters = dtmfHighFreqs.map(freq =>
        new AudioApp.GoertzelFilter(freq, SAMPLE_RATE, N_SAMPLES_PER_BLOCK)
    );

    // Assume `audioBlock` is a Float32Array of N_SAMPLES_PER_BLOCK audio data
    function detectDTMF(audioBlock) {
        if (audioBlock.length !== N_SAMPLES_PER_BLOCK) {
            console.warn("Audio block length does not match N_SAMPLES_PER_BLOCK for Goertzel filters.");
            // Handle this case: either pad/truncate, or re-initialize filters with audioBlock.length
            // For simplicity here, we'll assume it matches.
        }

        let maxLowMag = -1, detectedLowFreq = -1;
        lowGroupFilters.forEach(filter => {
            filter.reset();
            filter.processBlock(audioBlock);
            const magSq = filter.getMagnitudeSquared();
            if (magSq > maxLowMag) {
                maxLowMag = magSq;
                detectedLowFreq = filter.targetFrequency;
            }
        });

        let maxHighMag = -1, detectedHighFreq = -1;
        highGroupFilters.forEach(filter => {
            filter.reset();
            filter.processBlock(audioBlock);
            const magSq = filter.getMagnitudeSquared();
            if (magSq > maxHighMag) {
                maxHighMag = magSq;
                detectedHighFreq = filter.targetFrequency;
            }
        });

        // Example thresholds (these need careful tuning!)
        const dtmfThreshold = 1e5; // Arbitrary, depends on N, input signal level, etc.
        const relativeThresholdFactor = 5; // Dominant tone should be X times stronger

        // Basic check if dominant tones are strong enough
        if (maxLowMag > dtmfThreshold && maxHighMag > dtmfThreshold) {
            // Add more checks: e.g., ensure the detected freqs are significantly stronger
            // than other freqs in their group.
            // For now, just log:
            console.log(`Potential DTMF: Low Freq ${detectedLowFreq} (MagSq ${maxLowMag.toExponential(2)}), High Freq ${detectedHighFreq} (MagSq ${maxHighMag.toExponential(2)})`);
            // Map (detectedLowFreq, detectedHighFreq) to a digit here
            return { low: detectedLowFreq, high: detectedHighFreq };
        }
        return null;
    }

    // To test:
    // const testSignal = new Float32Array(N_SAMPLES_PER_BLOCK);
    // // Fill testSignal with, e.g., sin(2*pi*697*t/8000) + sin(2*pi*1209*t/8000)
    // // detectDTMF(testSignal);
}
*/
````
--- End of File: vibe-player/js/goertzel.js ---
--- File: vibe-player/js/player/audioEngine.js ---
````javascript
// --- /vibe-player/js/player/audioEngine.js --- // Updated Path
// Manages Web Audio API, AudioWorklet loading/communication, decoding, resampling, and playback control.
// Uses Rubberband WASM via an AudioWorkletProcessor for time-stretching and pitch/formant shifting.

/** @namespace AudioApp */
var AudioApp = AudioApp || {};

/**
 * @namespace AudioApp.audioEngine
 * @description Manages Web Audio API, AudioWorklet loading/communication,
 * decoding, resampling, and playback control.
 */
AudioApp.audioEngine = (function () {
    'use strict';

    // --- Web Audio API & Worklet State ---
    /** @type {AudioContext|null} The main AudioContext. */
    let audioCtx = null;
    /** @type {GainNode|null} Master gain node for volume control. */
    let gainNode = null;
    /** @type {AudioWorkletNode|null} The node hosting the Rubberband processor. */
    let workletNode = null;
    /** @type {AudioBuffer|null} The currently loaded and decoded audio buffer. */
    let currentDecodedBuffer = null;

    /** @type {boolean} Tracks the desired playback state (play/pause) sent to the worklet. */
    let isPlaying = false;
    /** @type {boolean} Indicates if the AudioWorklet processor is ready. */
    let workletReady = false;
    /** @type {number} Current playback time in seconds within the source audio, as tracked by the worklet or seek commands. */
    let currentWorkletTime = 0.0;
    /** @type {number} Current playback speed factor. */
    let currentPlaybackSpeed = 1.0;
    /** @type {number} Current pitch shift scale. */
    let currentPitchScale = 1.0;
    /** @type {number} Current formant shift scale. */
    let currentFormantScale = 1.0;

    // --- WASM Resources ---
    /** @type {ArrayBuffer|null} Stores the fetched WASM binary for Rubberband. */
    let wasmBinary = null;
    /** @type {string|null} Stores the text of the WASM loader script. */
    let loaderScriptText = null;


    /**
     * Initializes the Audio Engine: sets up AudioContext and pre-fetches WASM resources.
     * @public
     * @async
     * @returns {Promise<void>}
     */
    async function init() {
        console.log("AudioEngine: Initializing...");
        setupAudioContext();
        await preFetchWorkletResources();

        if (AudioApp.state) {
            AudioApp.state.subscribe('param:speed:changed', (newSpeed) => {
                AudioApp.audioEngine.setSpeed(newSpeed);
            });
            AudioApp.state.subscribe('param:pitch:changed', (newPitch) => {
                AudioApp.audioEngine.setPitch(newPitch);
            });
            AudioApp.state.subscribe('param:gain:changed', (newGain) => {
                AudioApp.audioEngine.setGain(newGain);
            });
            AudioApp.state.subscribe('status:isActuallyPlaying:changed', (nowPlaying) => {
                // Compare with internal isPlaying state to avoid redundant toggles if possible
                // This assumes 'this.isPlaying' refers to the local 'isPlaying' variable in this IIFE's scope.
                // If AudioApp.audioEngine.isPlaying() getter were available, it would be better.
                // For now, directly call togglePlayPause if the AppState differs from the engine's last known command state.
                // The togglePlayPause method itself handles the internal 'isPlaying' state.
                // This also means if something else (e.g. worklet event) changes internal 'isPlaying',
                // AppState might toggle it back if it's not in sync. This needs careful handling.
                // A simple approach: if AppState says "play" and engine isn't, play. If AppState says "pause" and engine is, pause.

                // Get current internal state (assuming isPlaying variable in this scope reflects it)
                const internalIsPlaying = isPlaying;
                if (internalIsPlaying !== nowPlaying) {
                    AudioApp.audioEngine.togglePlayPause(); // This will flip internal 'isPlaying' and command worklet
                }
            });
            console.log("AudioEngine: Subscribed to AppState changes.");
        } else {
            console.warn("AudioEngine: AppState not available for subscriptions during init.");
        }

        console.log("AudioEngine: Initialized.");
    }


    /**
     * Creates or resets the AudioContext and main GainNode.
     * @private
     * @returns {boolean} True if the AudioContext is ready, false otherwise.
     */
    function setupAudioContext() {
        if (audioCtx && audioCtx.state !== 'closed') {
            return true;
        }
        try {
            if (audioCtx && audioCtx.state === 'closed') {
                console.log("AudioEngine: Recreating closed AudioContext.");
            }
            audioCtx = new (window.AudioContext || window.webkitAudioContext)();
            gainNode = audioCtx.createGain();
            gainNode.gain.value = 1.0; // Default gain
            gainNode.connect(audioCtx.destination);
            workletNode = null; // Reset worklet node on context recreation
            workletReady = false;
            console.log(`AudioEngine: AudioContext created/reset (state: ${audioCtx.state}). Sample Rate: ${audioCtx.sampleRate}Hz`);
            if (audioCtx.state === 'suspended') {
                console.warn("AudioEngine: AudioContext is suspended. User interaction (e.g., click) is needed to resume audio playback.");
            }
            return true;
        } catch (e) {
            console.error("AudioEngine: Failed to create AudioContext.", e);
            audioCtx = null;
            gainNode = null;
            workletNode = null;
            workletReady = false;
            dispatchEngineEvent('audioapp:engineError', {
                type: 'context',
                error: new Error("Web Audio API not supported or context creation failed.")
            });
            return false;
        }
    }

    /**
     * Pre-fetches WASM binary and loader script for the AudioWorklet.
     * Uses paths from `AudioApp.Constants`.
     * @private
     * @async
     * @returns {Promise<void>}
     */
    async function preFetchWorkletResources() {
        console.log("AudioEngine: Pre-fetching WASM resources...");
        try {
            if (typeof Constants === 'undefined') {
                throw new Error("Constants class not found. Cannot fetch resources.");
            }
            const wasmResponse = await fetch(Constants.AudioEngine.WASM_BINARY_URL);
            if (!wasmResponse.ok) throw new Error(`Fetch failed (${wasmResponse.status}) for WASM binary: ${Constants.AudioEngine.WASM_BINARY_URL}`);
            wasmBinary = await wasmResponse.arrayBuffer();

            const loaderResponse = await fetch(Constants.AudioEngine.LOADER_SCRIPT_URL);
            if (!loaderResponse.ok) throw new Error(`Fetch failed (${loaderResponse.status}) for Loader script: ${Constants.AudioEngine.LOADER_SCRIPT_URL}`);
            loaderScriptText = await loaderResponse.text();
            console.log("AudioEngine: WASM resources fetched successfully.");
        } catch (fetchError) {
            console.error("AudioEngine: Failed to fetch WASM/Loader resources:", fetchError);
            wasmBinary = null;
            loaderScriptText = null; // Ensure resources are null on error
            dispatchEngineEvent('audioapp:engineError', {type: 'resource', error: fetchError});
        }
    }


    /**
     * Loads an audio file, decodes it, and sets up the AudioWorklet for playback.
     * @public
     * @async
     * @param {File} file - The audio file to load.
     * @returns {Promise<void>} Resolves when setup is complete.
     * @throws {Error} If any critical step fails (e.g., context creation, decoding, worklet setup).
     */
    async function loadAndProcessFile(file) {
        if (!audioCtx || audioCtx.state === 'closed') {
            if (!setupAudioContext()) {
                throw new Error("AudioContext could not be created/reset for loading file.");
            }
        }
        // if (audioCtx.state === 'suspended') { // Attempt to resume context if suspended
        //     await audioCtx.resume().catch(e => console.warn("AudioEngine: Context resume failed during load.", e));
        //     if (audioCtx.state !== 'running') {
        //         throw new Error(`AudioContext could not be resumed (state: ${audioCtx.state}). User interaction might be required.`);
        //     }
        // }

        await cleanupCurrentWorklet(); // Clean up any existing worklet instance
        currentDecodedBuffer = null;
        isPlaying = false;
        currentWorkletTime = 0.0;
        currentFormantScale = 1.0;

        try {
            const arrayBuffer = await file.arrayBuffer();
            currentDecodedBuffer = await audioCtx.decodeAudioData(arrayBuffer);
            dispatchEngineEvent('audioapp:audioLoaded', {audioBuffer: currentDecodedBuffer});

            if (!wasmBinary || !loaderScriptText) {
                throw new Error("Cannot setup Worklet: WASM/Loader resources are missing. Ensure preFetchWorkletResources succeeded.");
            }
            await setupAndStartWorklet(currentDecodedBuffer);
        } catch (error) {
            console.error("AudioEngine: Error during load/decode/worklet setup:", error);
            currentDecodedBuffer = null;
            const errorType = error.message.includes("decodeAudioData") ? 'decodingError'
                : error.message.includes("Worklet") ? 'workletError'
                    : 'loadError';
            dispatchEngineEvent(`audioapp:${errorType}`, {error: error});
            throw error; // Re-throw for the caller (app.js) to handle UI state
        }
    }

    /**
     * Resamples an AudioBuffer to 16kHz mono Float32Array using OfflineAudioContext.
     * @private
     * @param {AudioBuffer} audioBuffer - The original decoded audio buffer.
     * @returns {Promise<Float32Array>} A promise resolving to the resampled PCM data.
     */
    function convertAudioBufferTo16kHzMonoFloat32(audioBuffer) {
        if (typeof Constants === 'undefined') return Promise.reject(new Error("Constants class not found for resampling."));
        const targetSampleRate = Constants.VAD.SAMPLE_RATE;
        const targetLength = Math.ceil(audioBuffer.duration * targetSampleRate);

        if (!targetLength || targetLength <= 0) return Promise.resolve(new Float32Array(0));

        try {
            const offlineCtx = new OfflineAudioContext(1, targetLength, targetSampleRate);
            const src = offlineCtx.createBufferSource();
            src.buffer = audioBuffer;
            src.connect(offlineCtx.destination);
            src.start();
            return offlineCtx.startRendering().then(renderedBuffer => renderedBuffer.getChannelData(0))
                .catch(err => {
                    throw new Error(`Audio resampling rendering failed: ${err.message}`);
                });
        } catch (offlineCtxError) {
            return Promise.reject(new Error(`OfflineContext creation failed: ${offlineCtxError.message}`));
        }
    }

    /**
     * Public wrapper to resample an AudioBuffer to 16kHz mono Float32Array.
     * @public
     * @async
     * @param {AudioBuffer} audioBuffer - The original decoded audio buffer.
     * @returns {Promise<Float32Array>} A promise resolving to the resampled PCM data.
     */
    async function resampleTo16kMono(audioBuffer) {
        console.log("AudioEngine: Resampling audio to 16kHz mono...");
        try {
            const pcm16k = await convertAudioBufferTo16kHzMonoFloat32(audioBuffer);
            console.log(`AudioEngine: Resampled to ${pcm16k.length} samples @ 16kHz.`);
            return pcm16k;
        } catch (error) {
            console.error("AudioEngine: Error during public resampling call:", error);
            dispatchEngineEvent('audioapp:resamplingError', {error: error});
            throw error;
        }
    }


    /**
     * Cleans up the current AudioWorkletNode: sends a 'cleanup' message,
     * removes listeners, and disconnects the node.
     * @private
     * @async
     * @returns {Promise<void>}
     */
    async function cleanupCurrentWorklet() {
        workletReady = false;
        if (workletNode) {
            console.log("[AudioEngine] Cleaning up previous worklet node...");
            try {
                postWorkletMessage({type: 'cleanup'});
                await new Promise(resolve => setTimeout(resolve, 50)); // Brief delay for message processing

                if (workletNode.port) { // Check if port still exists
                    workletNode.port.onmessage = null;
                }
                workletNode.onprocessorerror = null;
                workletNode.disconnect();
            } catch (e) {
                console.warn("[AudioEngine] Error during worklet cleanup:", e);
            } finally {
                workletNode = null;
            }
        }
    }

    /**
     * Sets up the AudioWorklet processor: adds the module, creates the node,
     * connects it, and sends initial configuration and audio data.
     * @private
     * @async
     * @param {AudioBuffer} decodedBuffer - The audio buffer to process.
     * @returns {Promise<void>}
     * @throws {Error} If prerequisites are missing or setup fails.
     */
    async function setupAndStartWorklet(decodedBuffer) {
        if (!audioCtx || !decodedBuffer || !wasmBinary || !loaderScriptText || !gainNode || typeof Constants === 'undefined') {
            throw new Error("Cannot setup worklet - prerequisites missing.");
        }
        await cleanupCurrentWorklet(); // Ensure previous instance is cleared

        try {
            await audioCtx.audioWorklet.addModule(Constants.AudioEngine.PROCESSOR_SCRIPT_URL);
            const wasmBinaryTransfer = wasmBinary.slice(0); // Create a transferable copy
            const processorOpts = {
                sampleRate: audioCtx.sampleRate,
                numberOfChannels: decodedBuffer.numberOfChannels,
                wasmBinary: wasmBinaryTransfer,
                loaderScriptText: loaderScriptText
            };

            workletNode = new AudioWorkletNode(audioCtx, Constants.AudioEngine.PROCESSOR_NAME, {
                numberOfInputs: 0, numberOfOutputs: 1,
                outputChannelCount: [decodedBuffer.numberOfChannels],
                processorOptions: processorOpts
            });

            setupWorkletMessageHandler();
            workletNode.onprocessorerror = (event) => {
                console.error(`[AudioEngine] Critical Processor Error:`, event);
                dispatchEngineEvent('audioapp:engineError', {
                    type: 'workletProcessor',
                    error: new Error("Processor crashed or encountered a critical error.")
                });
                cleanupCurrentWorklet();
                workletReady = false;
                isPlaying = false;
                dispatchEngineEvent('audioapp:playbackStateChanged', {isPlaying: false});
            };

            workletNode.connect(gainNode);

            const channelData = [];
            const transferListAudio = [];
            for (let i = 0; i < decodedBuffer.numberOfChannels; i++) {
                const dataArray = decodedBuffer.getChannelData(i);
                const bufferCopy = dataArray.buffer.slice(dataArray.byteOffset, dataArray.byteOffset + dataArray.byteLength);
                channelData.push(bufferCopy);
                transferListAudio.push(bufferCopy);
            }
            postWorkletMessage({type: 'load-audio', channelData: channelData}, transferListAudio);
        } catch (error) {
            console.error("[AudioEngine] Error setting up Worklet Node:", error);
            await cleanupCurrentWorklet();
            throw error;
        }
    }

    /**
     * Sets up the message handler for communication from the AudioWorkletProcessor.
     * @private
     */
    function setupWorkletMessageHandler() {
        if (!workletNode?.port) return;
        workletNode.port.onmessage = (event) => {
            const data = event.data;
            switch (data.type) {
                case 'status':
                    console.log(`[WorkletStatus] ${data.message}`);
                    if (data.message === 'processor-ready') {
                        workletReady = true;
                        dispatchEngineEvent('audioapp:workletReady');
                    } else if (data.message === 'Playback ended') {
                        dispatchEngineEvent('audioapp:playbackEnded');
                    } else if (data.message === 'Processor cleaned up') {
                        workletReady = false;
                        isPlaying = false;
                    }
                    break;
                case 'error':
                    console.error(`[WorkletError] ${data.message}`);
                    dispatchEngineEvent('audioapp:engineError', {
                        type: 'workletRuntime',
                        error: new Error(data.message)
                    });
                    workletReady = false;
                    isPlaying = false;
                    dispatchEngineEvent('audioapp:playbackStateChanged', {isPlaying: false});
                    break;
                case 'playback-state':
                    dispatchEngineEvent('audioapp:playbackStateChanged', {isPlaying: data.isPlaying});
                    break;
                case 'time-update':
                    if (typeof data.currentTime === 'number' && currentDecodedBuffer) {
                        currentWorkletTime = data.currentTime;
                    }
                    break;
                default:
                    console.warn("[AudioEngine] Unhandled message from worklet:", data.type, data);
            }
        };
    }

    /**
     * Safely posts a message to the AudioWorkletProcessor.
     * @private
     * @param {object} message - The message object.
     * @param {Transferable[]} [transferList=[]] - Optional array of transferable objects.
     */
    function postWorkletMessage(message, transferList = []) {
        if (workletNode?.port) {
            try {
                workletNode.port.postMessage(message, transferList);
            } catch (error) {
                console.error("[AudioEngine] Error posting message to worklet:", error, "Message type:", message.type);
                if (message.type !== 'cleanup') { // Avoid error loops on cleanup
                    dispatchEngineEvent('audioapp:engineError', {type: 'workletComm', error: error});
                }
                cleanupCurrentWorklet();
                workletReady = false;
                isPlaying = false;
                dispatchEngineEvent('audioapp:playbackStateChanged', {isPlaying: false});
            }
        } else {
            if (workletReady || message.type !== 'cleanup') { // Don't warn if not ready and trying to cleanup
                console.warn(`[AudioEngine] Cannot post message (${message.type}): Worklet node or port not available.`);
            }
        }
    }


    /**
     * Toggles the playback state (play/pause).
     * @public
     * @async
     * @returns {Promise<void>}
     */
    async function togglePlayPause() {
        if (!workletReady || !audioCtx) {
            console.warn("AudioEngine: Cannot toggle play/pause - Worklet or AudioContext not ready.");
            return;
        }
        if (audioCtx.state === 'suspended') {
            try {
                await audioCtx.resume();
            } catch (err) {
                dispatchEngineEvent('audioapp:engineError', {type: 'contextResume', error: err});
                return;
            }
        }
        if (audioCtx.state !== 'running') {
            console.error(`AudioEngine: AudioContext not running (state: ${audioCtx.state}). Cannot toggle playback.`);
            return;
        }
        const targetIsPlaying = !isPlaying;
        postWorkletMessage({type: targetIsPlaying ? 'play' : 'pause'});
        isPlaying = targetIsPlaying; // Update desired state
    }

    /**
     * Jumps playback position relative to the current source time.
     * @public
     * @param {number} seconds - Seconds to jump (positive or negative).
     */
    function jumpBy(seconds) {
        if (!workletReady || !currentDecodedBuffer) return;
        seek(currentWorkletTime + seconds);
    }

    /**
     * Seeks playback to an absolute time in seconds within the source audio.
     * @public
     * @param {number} time - The target time in seconds.
     */
    function seek(time) {
        if (!workletReady || !currentDecodedBuffer || isNaN(currentDecodedBuffer.duration)) return;
        const targetTime = Math.max(0, Math.min(time, currentDecodedBuffer.duration));
        postWorkletMessage({type: 'seek', positionSeconds: targetTime});
        currentWorkletTime = targetTime; // Update internal time immediately
    }

    /**
     * Sets the playback speed (rate).
     * @public
     * @param {number} speed - Desired playback speed (e.g., 1.0 for normal).
     */
    function setSpeed(speed) {
        const rate = Math.max(0.25, Math.min(parseFloat(String(speed)) || 1.0, 2.0));
        if (currentPlaybackSpeed !== rate) {
            currentPlaybackSpeed = rate;
            if (workletReady) postWorkletMessage({type: 'set-speed', value: rate});
            dispatchEngineEvent('audioapp:internalSpeedChanged', {speed: rate});
        }
    }

    /**
     * Sets the pitch shift scale.
     * @public
     * @param {number} pitch - Desired pitch scale (e.g., 1.0 for normal).
     */
    function setPitch(pitch) {
        const scale = Math.max(0.25, Math.min(parseFloat(String(pitch)) || 1.0, 2.0));
        if (currentPitchScale !== scale) {
            currentPitchScale = scale;
            if (workletReady) postWorkletMessage({type: 'set-pitch', value: scale});
        }
    }

    /**
     * Sets the formant shift scale.
     * @public
     * @param {number} formant - Desired formant scale (e.g., 1.0 for normal).
     */
    function setFormant(formant) {
        const scale = Math.max(0.5, Math.min(parseFloat(String(formant)) || 1.0, 2.0));
        if (currentFormantScale !== scale) {
            currentFormantScale = scale;
            if (workletReady) postWorkletMessage({type: 'set-formant', value: scale});
        }
    }

    /**
     * Sets the master gain (volume) level.
     * @public
     * @param {number} gain - Desired gain level (0.0 to 5.0, 1.0 is normal).
     */
    function setGain(gain) {
        if (!gainNode || !audioCtx || audioCtx.state === 'closed') return;
        const value = Math.max(0.0, Math.min(parseFloat(String(gain)) || 1.0, 5.0));
        gainNode.gain.setTargetAtTime(value, audioCtx.currentTime, 0.015); // Smooth transition
    }

    /**
     * Gets the current playback time (source time) and total duration.
     * @public
     * @returns {{currentTime: number, duration: number}}
     */
    function getCurrentTime() {
        return {
            currentTime: currentWorkletTime,
            duration: currentDecodedBuffer?.duration || 0
        };
    }

    /**
     * Returns the active AudioContext instance.
     * @public
     * @returns {AudioContext|null}
     */
    function getAudioContext() {
        return audioCtx;
    }


    /**
     * Cleans up all audio resources.
     * @public
     */
    function cleanup() {
        console.log("AudioEngine: Cleaning up resources...");
        cleanupCurrentWorklet().finally(() => {
            if (audioCtx && audioCtx.state !== 'closed') {
                audioCtx.close().then(() => console.log("AudioEngine: AudioContext closed."))
                    .catch(e => console.warn("AudioEngine: Error closing AudioContext:", e));
            }
            audioCtx = null;
            gainNode = null;
            workletNode = null;
            currentDecodedBuffer = null;
            wasmBinary = null;
            loaderScriptText = null;
            workletReady = false;
            isPlaying = false;
            currentWorkletTime = 0.0;
            currentPlaybackSpeed = 1.0;
            currentPitchScale = 1.0;
            currentFormantScale = 1.0;
        });
    }


    /**
     * Dispatches a custom event on the document.
     * @private
     * @param {string} eventName - The name of the event.
     * @param {Object<string, any>} [detail={}] - Data to pass with the event.
     */
    function dispatchEngineEvent(eventName, detail = {}) {
        document.dispatchEvent(new CustomEvent(eventName, {detail: detail}));
    }

    /**
     * @typedef {Object} AudioEnginePublicInterface
     * @property {function(): Promise<void>} init
     * @property {function(File): Promise<void>} loadAndProcessFile
     * @property {function(AudioBuffer): Promise<Float32Array>} resampleTo16kMono
     * @property {function(): Promise<void>} togglePlayPause
     * @property {function(number): void} jumpBy
     * @property {function(number): void} seek
     * @property {function(number): void} setSpeed
     * @property {function(number): void} setPitch
     * @property {function(number): void} setFormant
     * @property {function(number): void} setGain
     * @property {function(): {currentTime: number, duration: number}} getCurrentTime
     * @property {function(): (AudioContext|null)} getAudioContext
     * @property {function(): void} cleanup
     */

    /** @type {AudioEnginePublicInterface} */
    return {
        init: init,
        loadAndProcessFile: loadAndProcessFile,
        resampleTo16kMono: resampleTo16kMono,
        togglePlayPause: togglePlayPause,
        jumpBy: jumpBy,
        seek: seek,
        setSpeed: setSpeed,
        setPitch: setPitch,
        setFormant: setFormant,
        setGain: setGain,
        getCurrentTime: getCurrentTime,
        getAudioContext: getAudioContext,
        cleanup: cleanup
    };
})();
// --- /vibe-player/js/player/audioEngine.js --- // Updated Path

````
--- End of File: vibe-player/js/player/audioEngine.js ---
--- File: vibe-player/js/player/rubberbandProcessor.js ---
````javascript
// --- /vibe-player/js/player/rubberbandProcessor.js --- // Updated Path
// AudioWorkletProcessor for real-time time-stretching using Rubberband WASM.

// Constants cannot be accessed here directly, but name is needed for registration.
/** @const {string} Name of the AudioWorkletProcessor. */
const PROCESSOR_NAME = 'rubberband-processor';

/**
 * @class RubberbandProcessor
 * @extends AudioWorkletProcessor
 * @description Processes audio using the Rubberband library compiled to WASM.
 * Handles loading Rubberband WASM, managing its state, processing audio frames
 * for time-stretching and pitch-shifting, and communicating with the main thread.
 * Runs within an AudioWorkletGlobalScope.
 */
class RubberbandProcessor extends AudioWorkletProcessor {

    /**
     * Initializes the processor instance. Sets up initial state and message handling.
     * WASM/Rubberband initialization happens asynchronously via message handler or first process call.
     * @constructor
     * @param {AudioWorkletNodeOptions} options - Options passed from the AudioWorkletNode constructor.
     * @param {object} options.processorOptions - Custom options.
     * @param {number} options.processorOptions.sampleRate - The sample rate of the audio context.
     * @param {number} options.processorOptions.numberOfChannels - The number of channels in the input audio.
     * @param {ArrayBuffer} options.processorOptions.wasmBinary - The pre-fetched WASM binary of Rubberband.
     * @param {string} options.processorOptions.loaderScriptText - The text of the Rubberband WASM loader script.
     */
    constructor(options) {
        super(options); // Pass options to base constructor
        console.log("[Worklet] RubberbandProcessor created.");

        // --- State Initialization ---
        /** @private @type {object} Options passed from the main thread. */
        this.processorOpts = options.processorOptions || {};
        /** @private @type {number} Sample rate of the audio context. */
        this.sampleRate = this.processorOpts.sampleRate || sampleRate; // sampleRate is global in AudioWorkletGlobalScope
        /** @private @type {number} Number of audio channels. */
        this.numberOfChannels = this.processorOpts.numberOfChannels || 0;
        /** @private @type {ArrayBuffer|null} The WASM binary. */
        this.wasmBinary = this.processorOpts.wasmBinary;
        /** @private @type {string|null} The WASM loader script text. */
        this.loaderScriptText = this.processorOpts.loaderScriptText;

        /** @private @type {object|null} Exported functions from the WASM module. */
        this.wasmModule = null;
        /** @private @type {boolean} Flag indicating if WASM and Rubberband are initialized. */
        this.wasmReady = false;
        /** @private @type {number} Pointer to the RubberbandStretcher instance in WASM memory. */
        this.rubberbandStretcher = 0; // Using 'number' as it's an opaque pointer (integer).

        /** @private @type {boolean} Current playback state. */
        this.isPlaying = false;
        /** @private @type {number} Target speed ratio for time-stretching. */
        this.currentTargetSpeed = 1.0;
        /** @private @type {number} Target pitch scale. */
        this.currentTargetPitchScale = 1.0;
        /** @private @type {number} Target formant scale. */
        this.currentTargetFormantScale = 1.0;
        /** @private @type {number} Last applied stretch ratio to Rubberband. */
        this.lastAppliedStretchRatio = 1.0;
        /** @private @type {number} Last applied pitch scale to Rubberband. */
        this.lastAppliedPitchScale = 1.0;
        /** @private @type {number} Last applied formant scale to Rubberband. */
        this.lastAppliedFormantScale = 1.0;

        /** @private @type {boolean} Flag indicating if Rubberband state needs reset (e.g., after seek). */
        this.resetNeeded = true;
        /** @private @type {boolean} Flag indicating if the end of the source audio has been processed. */
        this.streamEnded = false;
        /** @private @type {boolean} Flag indicating if the final block has been sent to `rubberband_process`. */
        this.finalBlockSent = false;
        /** @private @type {number} Current playback position in the source audio, in seconds. */
        this.playbackPositionInSeconds = 0.0;

        /** @private @type {number} Pointer to the array of input channel buffer pointers in WASM memory. */
        this.inputPtrs = 0;
        /** @private @type {number} Pointer to the array of output channel buffer pointers in WASM memory. */
        this.outputPtrs = 0;
        /** @private @type {number[]} Array of pointers to individual input channel buffers in WASM memory. */
        this.inputChannelBuffers = [];
        /** @private @type {number[]} Array of pointers to individual output channel buffers in WASM memory. */
        this.outputChannelBuffers = [];
        /** @private @type {number} Fixed block size for WASM memory buffers (in frames). */
        this.blockSizeWasm = 1024;

        /** @private @type {Float32Array[]|null} Array of Float32Arrays holding the original audio data for each channel. */
        this.originalChannels = null;
        /** @private @type {boolean} Flag indicating if audio data has been loaded into the processor. */
        this.audioLoaded = false;
        /** @private @type {number} Duration of the loaded audio in seconds. */
        this.sourceDurationSeconds = 0;

        if (this.port) {
            this.port.onmessage = this.handleMessage.bind(this);
        } else {
            console.error("[Worklet] CONSTRUCTOR: Message port is not available! Cannot receive messages.");
        }

        if (!this.wasmBinary) this.postErrorAndStop("WASM binary missing in processorOptions.");
        if (!this.loaderScriptText) this.postErrorAndStop("Loader script text missing in processorOptions.");
        if (!this.sampleRate || this.sampleRate <= 0) this.postErrorAndStop(`Invalid SampleRate provided: ${this.sampleRate}`);
        if (!this.numberOfChannels || this.numberOfChannels <= 0) this.postErrorAndStop(`Invalid NumberOfChannels provided: ${this.numberOfChannels}`);

        console.log("[Worklet] RubberbandProcessor instance constructed. Waiting for audio data or commands.");
    }

    /**
     * Initializes the WASM module and the RubberbandStretcher instance.
     * This involves evaluating a loader script and using a custom `instantiateWasm` hook.
     * It also allocates memory within the WASM heap for audio buffers.
     * @private
     * @async
     * @returns {Promise<void>} Resolves when initialization is complete, or rejects on error.
     */
    async initializeWasmAndRubberband() {
        if (this.wasmReady) return; // Avoid re-initialization
        if (!this.wasmBinary || !this.loaderScriptText) {
            this.postErrorAndStop("Cannot initialize WASM: Resources missing.");
            return;
        }
        this.postStatus("Initializing WASM & Rubberband...");
        try {
            /** @type {function(WebAssembly.Imports, function(WebAssembly.Instance, WebAssembly.Module): void): object} */
            const instantiateWasm = (imports, successCallback) => {
                WebAssembly.instantiate(this.wasmBinary, imports)
                    .then(output => successCallback(output.instance, output.module))
                    .catch(error => this.postError(`WASM Hook Instantiate Error: ${error.message}`));
                return {}; // Emscripten convention
            };

            /** @type {function(object): Promise<object>} */
            let loaderFunc;
            try { // Security Note: Using Function constructor can be risky if loaderScriptText is from untrusted source.
                const getLoaderFactory = new Function('moduleArg', `${this.loaderScriptText}; return Rubberband;`);
                loaderFunc = getLoaderFactory();
                if (typeof loaderFunc !== 'function') throw new Error("Loader script did not return an async function.");
            } catch (e) {
                throw new Error(`Loader script evaluation error: ${e.message}`);
            }

            this.wasmModule = await loaderFunc({instantiateWasm: instantiateWasm});
            if (!this.wasmModule || typeof this.wasmModule._rubberband_new !== 'function') {
                throw new Error("WASM module loaded, but essential Rubberband exports not found.");
            }

            const RBOptions = this.wasmModule.RubberBandOptionFlag || {};
            const options = (RBOptions.ProcessRealTime ?? 0x01) | (RBOptions.PitchHighQuality ?? 0x02000000) | (RBOptions.PhaseIndependent ?? 0x2000);
            this.rubberbandStretcher = this.wasmModule._rubberband_new(this.sampleRate, this.numberOfChannels, options, 1.0, 1.0);
            if (!this.rubberbandStretcher) throw new Error("_rubberband_new failed to create stretcher instance.");

            const pointerSize = 4;
            const frameSize = 4; // Assuming 32-bit floats and pointers
            this.inputPtrs = this.wasmModule._malloc(this.numberOfChannels * pointerSize);
            this.outputPtrs = this.wasmModule._malloc(this.numberOfChannels * pointerSize);
            if (!this.inputPtrs || !this.outputPtrs) throw new Error("Failed to allocate memory for channel pointer arrays.");

            for (let i = 0; i < this.numberOfChannels; ++i) {
                const bufferSizeBytes = this.blockSizeWasm * frameSize;
                const inputBuf = this.wasmModule._malloc(bufferSizeBytes);
                const outputBuf = this.wasmModule._malloc(bufferSizeBytes);
                if (!inputBuf || !outputBuf) {
                    this.cleanupWasmMemory();
                    throw new Error(`Buffer malloc failed for Channel ${i}.`);
                }
                this.inputChannelBuffers.push(inputBuf);
                this.outputChannelBuffers.push(outputBuf);
                this.wasmModule.HEAPU32[(this.inputPtrs / pointerSize) + i] = inputBuf;
                this.wasmModule.HEAPU32[(this.outputPtrs / pointerSize) + i] = outputBuf;
            }
            this.wasmReady = true;
            this.postStatus('processor-ready');
        } catch (error) {
            console.error(`[Worklet] WASM/Rubberband Init Error: ${error.message}`, error.stack);
            this.postError(`Init Error: ${error.message}`);
            this.wasmReady = false;
            this.rubberbandStretcher = 0;
            this.cleanupWasmMemory();
        }
    }

    /**
     * Handles messages received from the main AudioEngine via the processor's port.
     * @private
     * @param {MessageEvent<object>} event - The event containing the message data.
     * @param {string} event.data.type - Message type (e.g., 'load-audio', 'play', 'seek').
     * @param {*} [event.data.value] - Optional value associated with the message.
     * @param {ArrayBuffer[]} [event.data.channelData] - Audio data for 'load-audio'.
     * @param {number} [event.data.positionSeconds] - Seek position for 'seek'.
     */
    handleMessage(event) {
        const data = event.data;
        try {
            switch (data.type) {
                case 'load-audio':
                    this.playbackPositionInSeconds = 0;
                    this.resetNeeded = true;
                    this.streamEnded = false;
                    this.finalBlockSent = false;
                    this.currentTargetSpeed = 1.0;
                    this.lastAppliedStretchRatio = 1.0;
                    this.currentTargetPitchScale = 1.0;
                    this.lastAppliedPitchScale = 1.0;
                    this.currentTargetFormantScale = 1.0;
                    this.lastAppliedFormantScale = 1.0;
                    this.audioLoaded = false;
                    this.originalChannels = null;
                    this.sourceDurationSeconds = 0;

                    if (data.channelData && Array.isArray(data.channelData) && data.channelData.length === this.numberOfChannels) {
                        this.originalChannels = data.channelData.map(buffer => new Float32Array(buffer));
                        this.audioLoaded = true;
                        this.sourceDurationSeconds = (this.originalChannels[0]?.length || 0) / this.sampleRate;
                        if (!this.wasmReady) {
                            this.initializeWasmAndRubberband();
                        } else {
                            this.postStatus('processor-ready');
                        }
                    } else {
                        this.postError('Invalid audio data received for loading.');
                    }
                    break;
                case 'play':
                    if (this.wasmReady && this.audioLoaded) {
                        if (!this.isPlaying) {
                            if (this.streamEnded || this.playbackPositionInSeconds >= this.sourceDurationSeconds) {
                                this.playbackPositionInSeconds = 0;
                                this.resetNeeded = true;
                                this.streamEnded = false;
                                this.finalBlockSent = false;
                            }
                            this.isPlaying = true;
                            this.port?.postMessage({type: 'playback-state', isPlaying: true});
                        }
                    } else {
                        this.postError(`Cannot play: ${!this.wasmReady ? 'WASM not ready' : 'Audio not loaded'}.`);
                        this.port?.postMessage({type: 'playback-state', isPlaying: false});
                    }
                    break;
                case 'pause':
                    if (this.isPlaying) {
                        this.isPlaying = false;
                        this.port?.postMessage({type: 'playback-state', isPlaying: false});
                    }
                    break;
                case 'set-speed':
                    if (this.wasmReady && typeof data.value === 'number') this.currentTargetSpeed = Math.max(0.01, data.value);
                    break;
                case 'set-pitch':
                    if (this.wasmReady && typeof data.value === 'number') this.currentTargetPitchScale = Math.max(0.1, data.value);
                    break;
                case 'set-formant':
                    if (this.wasmReady && typeof data.value === 'number') this.currentTargetFormantScale = Math.max(0.1, data.value);
                    break;
                case 'seek':
                    if (this.wasmReady && this.audioLoaded && typeof data.positionSeconds === 'number') {
                        this.playbackPositionInSeconds = Math.max(0, Math.min(data.positionSeconds, this.sourceDurationSeconds));
                        this.resetNeeded = true;
                        this.streamEnded = false;
                        this.finalBlockSent = false;
                    }
                    break;
                case 'cleanup':
                    this.cleanup();
                    break;
                default:
                    console.warn("[Worklet] Received unknown message type:", data.type);
            }
        } catch (error) {
            this.postError(`Error in handleMessage ('${data.type}'): ${error.message}`);
            this.isPlaying = false;
            this.port?.postMessage({type: 'playback-state', isPlaying: false});
        }
    }

    /**
     * Core audio processing method. Called by the AudioWorklet system at regular intervals.
     * Manages audio data flow to/from Rubberband WASM, applies parameter changes, and handles playback state.
     * @param {Float32Array[][]} inputs - Input audio buffers (not used by this processor as it's a source).
     * @param {Float32Array[][]} outputs - Output audio buffers to be filled by this processor.
     *                                     Structure: `outputs[0][channelIndex][sampleIndex]`
     * @param {Record<string, Float32Array>} parameters - Real-time audio parameters (not used by this processor).
     * @returns {boolean} Returns `true` to keep the processor alive, `false` to terminate it.
     */
    process(inputs, outputs, parameters) {
        if (!this.wasmReady || !this.audioLoaded || !this.rubberbandStretcher || !this.wasmModule) {
            this.outputSilence(outputs);
            return true;
        }
        if (!this.isPlaying) {
            this.outputSilence(outputs);
            return true;
        }

        const outputBuffer = outputs[0];
        if (!outputBuffer || outputBuffer.length !== this.numberOfChannels || !outputBuffer[0]) {
            this.outputSilence(outputs);
            return true; // Should not happen if configured correctly
        }
        const outputBlockSize = outputBuffer[0].length; // e.g., 128 frames
        if (outputBlockSize === 0) return true;

        if (this.streamEnded) { // If stream previously ended, check if Rubberband has any remaining buffered samples
            const availableInRb = this.wasmModule._rubberband_available?.(this.rubberbandStretcher) ?? 0;
            if (Math.max(0, availableInRb) <= 0) {
                this.outputSilence(outputs);
                return true;
            }
        }

        try {
            const sourceChannels = /** @type {Float32Array[]} */ (this.originalChannels); // Assert type as it's checked by audioLoaded
            const targetStretchRatio = 1.0 / Math.max(0.01, this.currentTargetSpeed);
            const safeStretchRatio = Math.max(0.05, Math.min(20.0, targetStretchRatio));
            const safeTargetPitch = Math.max(0.1, this.currentTargetPitchScale);
            const safeTargetFormant = Math.max(0.1, this.currentTargetFormantScale);

            const ratioChanged = Math.abs(safeStretchRatio - this.lastAppliedStretchRatio) > 1e-6;
            const pitchChanged = Math.abs(safeTargetPitch - this.lastAppliedPitchScale) > 1e-6;
            const formantChanged = Math.abs(safeTargetFormant - this.lastAppliedFormantScale) > 1e-6;

            if (this.resetNeeded) {
                this.wasmModule._rubberband_reset(this.rubberbandStretcher);
                this.wasmModule._rubberband_set_time_ratio(this.rubberbandStretcher, safeStretchRatio);
                this.wasmModule._rubberband_set_pitch_scale(this.rubberbandStretcher, safeTargetPitch);
                this.wasmModule._rubberband_set_formant_scale(this.rubberbandStretcher, safeTargetFormant);
                this.lastAppliedStretchRatio = safeStretchRatio;
                this.lastAppliedPitchScale = safeTargetPitch;
                this.lastAppliedFormantScale = safeTargetFormant;
                this.resetNeeded = false;
                this.finalBlockSent = false;
                this.streamEnded = false;
            } else {
                if (ratioChanged) {
                    this.wasmModule._rubberband_set_time_ratio(this.rubberbandStretcher, safeStretchRatio);
                    this.lastAppliedStretchRatio = safeStretchRatio;
                }
                if (pitchChanged) {
                    this.wasmModule._rubberband_set_pitch_scale(this.rubberbandStretcher, safeTargetPitch);
                    this.lastAppliedPitchScale = safeTargetPitch;
                }
                if (formantChanged) {
                    this.wasmModule._rubberband_set_formant_scale(this.rubberbandStretcher, safeTargetFormant);
                    this.lastAppliedFormantScale = safeTargetFormant;
                }
            }

            let inputFramesNeeded = Math.ceil(outputBlockSize / safeStretchRatio) + 4; // Recommended buffer
            inputFramesNeeded = Math.max(1, inputFramesNeeded);
            let readPosInSourceSamples = Math.round(this.playbackPositionInSeconds * this.sampleRate);
            readPosInSourceSamples = Math.max(0, Math.min(readPosInSourceSamples, sourceChannels[0].length));
            let actualInputProvided = Math.min(inputFramesNeeded, sourceChannels[0].length - readPosInSourceSamples);
            actualInputProvided = Math.max(0, actualInputProvided); // Ensure non-negative

            const isFinalDataBlock = (readPosInSourceSamples + actualInputProvided) >= sourceChannels[0].length;
            const sendFinalFlag = isFinalDataBlock && !this.finalBlockSent;

            if (actualInputProvided > 0 || sendFinalFlag) {
                for (let i = 0; i < this.numberOfChannels; i++) {
                    const wasmInputBufferView = new Float32Array(this.wasmModule.HEAPF32.buffer, this.inputChannelBuffers[i], this.blockSizeWasm);
                    if (actualInputProvided > 0) {
                        const inputSlice = sourceChannels[i].subarray(readPosInSourceSamples, readPosInSourceSamples + actualInputProvided);
                        wasmInputBufferView.set(inputSlice.subarray(0, Math.min(inputSlice.length, this.blockSizeWasm)));
                        if (inputSlice.length < this.blockSizeWasm) wasmInputBufferView.fill(0.0, inputSlice.length);
                    } else {
                        wasmInputBufferView.fill(0.0);
                    }
                }
                this.wasmModule._rubberband_process(this.rubberbandStretcher, this.inputPtrs, actualInputProvided, sendFinalFlag ? 1 : 0);
                this.playbackPositionInSeconds += (actualInputProvided / this.sampleRate);
                this.playbackPositionInSeconds = Math.min(this.playbackPositionInSeconds, this.sourceDurationSeconds);

                let correctedTime = this.playbackPositionInSeconds;
                try {
                    const latencySamples = this.wasmModule._rubberband_get_latency?.(this.rubberbandStretcher) ?? 0;
                    if (latencySamples >= 0 && this.sampleRate > 0) {
                        const totalLatencySeconds = (latencySamples / this.sampleRate) + (outputBlockSize / this.sampleRate);
                        correctedTime = Math.max(0, this.playbackPositionInSeconds - totalLatencySeconds);
                    }
                } catch (e) { /* ignore latency error */
                }
                this.port?.postMessage({type: 'time-update', currentTime: correctedTime});
                if (sendFinalFlag) this.finalBlockSent = true;
            }

            let totalRetrieved = 0;
            const tempOutputBuffers = Array.from({length: this.numberOfChannels}, () => new Float32Array(outputBlockSize));
            let availableInRb;
            do {
                availableInRb = this.wasmModule._rubberband_available?.(this.rubberbandStretcher) ?? 0;
                availableInRb = Math.max(0, availableInRb);
                if (availableInRb <= 0) break;
                const neededNow = outputBlockSize - totalRetrieved;
                if (neededNow <= 0) break;
                const framesToRetrieve = Math.min(availableInRb, neededNow, this.blockSizeWasm);
                if (framesToRetrieve <= 0) break;
                const retrieved = this.wasmModule._rubberband_retrieve?.(this.rubberbandStretcher, this.outputPtrs, framesToRetrieve) ?? -1;
                if (retrieved > 0) {
                    for (let i = 0; i < this.numberOfChannels; i++) {
                        const wasmOutputBufferView = new Float32Array(this.wasmModule.HEAPF32.buffer, this.outputChannelBuffers[i], retrieved);
                        tempOutputBuffers[i].set(wasmOutputBufferView.subarray(0, Math.min(retrieved, tempOutputBuffers[i].length - totalRetrieved)), totalRetrieved);
                    }
                    totalRetrieved += retrieved;
                } else {
                    availableInRb = 0;
                    break;
                }
            } while (totalRetrieved < outputBlockSize);

            for (let i = 0; i < this.numberOfChannels; ++i) {
                if (outputBuffer[i]) {
                    outputBuffer[i].set(tempOutputBuffers[i].subarray(0, Math.min(totalRetrieved, outputBlockSize)));
                    if (totalRetrieved < outputBlockSize) outputBuffer[i].fill(0.0, totalRetrieved);
                }
            }

            if (this.finalBlockSent && availableInRb <= 0 && totalRetrieved < outputBlockSize) {
                if (!this.streamEnded) {
                    this.streamEnded = true;
                    this.isPlaying = false;
                    this.postStatus('Playback ended');
                    this.port?.postMessage({type: 'playback-state', isPlaying: false});
                }
            }
        } catch (error) {
            console.error(`[Worklet] Processing Error: ${error.message}`, error.stack);
            this.postError(`Processing Error: ${error.message}`);
            this.isPlaying = false;
            this.streamEnded = true;
            this.outputSilence(outputs);
            this.port?.postMessage({type: 'playback-state', isPlaying: false});
        }
        return true;
    }

    /**
     * Fills the output audio buffers with silence (zeros).
     * @private
     * @param {Float32Array[][]} outputs - The output buffers from the `process` method.
     */
    outputSilence(outputs) {
        if (!outputs?.[0]?.[0]) return; // Ensure valid structure
        for (let channel = 0; channel < outputs[0].length; ++channel) {
            outputs[0][channel]?.fill(0.0); // Fill each channel buffer with 0.0
        }
    }

    /**
     * Posts a status message to the main thread.
     * @private
     * @param {string} message - The status message.
     */
    postStatus(message) {
        try {
            this.port?.postMessage({type: 'status', message});
        } catch (e) {
            console.error(`[Worklet] FAILED to post status '${message}':`, e.message);
        }
    }

    /**
     * Posts an error message to the main thread.
     * @private
     * @param {string} message - The error message.
     */
    postError(message) {
        try {
            this.port?.postMessage({type: 'error', message});
        } catch (e) {
            console.error(`[Worklet] FAILED to post error '${message}':`, e.message);
        }
    }

    /**
     * Posts an error message and initiates cleanup of the processor.
     * @private
     * @param {string} message - The error message.
     */
    postErrorAndStop(message) {
        this.postError(message);
        this.cleanup();
    }

    /**
     * Frees WASM memory allocated for input/output channel buffers and pointer arrays.
     * @private
     */
    cleanupWasmMemory() {
        if (this.wasmModule?._free) {
            try {
                this.inputChannelBuffers.forEach(ptr => {
                    if (ptr) this.wasmModule._free(ptr);
                });
                this.outputChannelBuffers.forEach(ptr => {
                    if (ptr) this.wasmModule._free(ptr);
                });
                if (this.inputPtrs) this.wasmModule._free(this.inputPtrs);
                if (this.outputPtrs) this.wasmModule._free(this.outputPtrs);
            } catch (e) {
                console.error("[Worklet] Error during explicit WASM memory cleanup:", e.message);
            }
        }
        this.inputPtrs = 0;
        this.outputPtrs = 0;
        this.inputChannelBuffers = [];
        this.outputChannelBuffers = [];
    }

    /**
     * Cleans up all resources used by the processor, including the Rubberband instance and WASM memory.
     * Resets the processor's state.
     * @private
     */
    cleanup() {
        console.log("[Worklet] Cleanup initiated.");
        this.isPlaying = false;
        if (this.wasmReady && this.rubberbandStretcher !== 0 && this.wasmModule?._rubberband_delete) {
            try {
                this.wasmModule._rubberband_delete(this.rubberbandStretcher);
            } catch (e) {
                console.error("[Worklet] Error deleting Rubberband instance:", e.message);
            }
        }
        this.rubberbandStretcher = 0;
        this.cleanupWasmMemory();
        this.wasmReady = false;
        this.audioLoaded = false;
        this.originalChannels = null;
        this.wasmModule = null;
        // Keep wasmBinary & loaderScriptText if re-init is possible without new options.
        // For full cleanup, these would be nulled too:
        // this.wasmBinary = null; this.loaderScriptText = null;
        this.playbackPositionInSeconds = 0;
        this.streamEnded = true;
        this.finalBlockSent = false;
        this.resetNeeded = true;
        this.postStatus("Processor cleaned up");
    }
}

try {
    if (typeof registerProcessor === 'function' && typeof sampleRate !== 'undefined') { // `sampleRate` is global in AudioWorkletGlobalScope
        registerProcessor(PROCESSOR_NAME, RubberbandProcessor);
    } else {
        console.error("[Worklet] `registerProcessor` or global `sampleRate` is not defined. Cannot register RubberbandProcessor.");
        // Attempt to notify main thread about this critical failure if postMessage is available
        if (typeof self !== 'undefined' && self.postMessage) {
            self.postMessage({
                type: 'error',
                message: 'Worklet environment error: registerProcessor or sampleRate undefined.'
            });
        }
    }
} catch (error) {
    console.error(`[Worklet] CRITICAL: Failed to register processor '${PROCESSOR_NAME}'. Error: ${error.message}`, error.stack);
    if (typeof self !== 'undefined' && self.postMessage) {
        self.postMessage({type: 'error', message: `Failed to register processor ${PROCESSOR_NAME}: ${error.message}`});
    }
}
// --- /vibe-player/js/player/rubberbandProcessor.js --- // Updated Path

````
--- End of File: vibe-player/js/player/rubberbandProcessor.js ---
--- File: vibe-player/js/sparkles.js ---
````javascript
// ─────────────────────────────────────────────────────────────────────────────
//  sparkles.js
//  A self-contained sparkle/dot effect that you can turn on/off by calling
//    sparkle(true)  or  sparkle(false)  or  sparkle() to toggle.
//  No external CSS or other files needed.
// ─────────────────────────────────────────────────────────────────────────────

(function () {
    'use strict';
    // ───────────────────────────────────────────────────────────────────────────
    //  CONFIGURATION CONSTANTS
    // ───────────────────────────────────────────────────────────────────────────
    /** @const {number} Maximum number of concurrent sparkles. */
    const MAX_SPARKLES = 1000;
    /** @const {number} Base lifetime for sparkles (in animation ticks). Stars live 2x this, then dots live 2x this. */
    const SPARKLE_LIFETIME = 40;
    /** @const {number} Controls spawn density along mouse path; smaller means more sparkles. */
    const SPARKLE_DISTANCE = 10;

    // ───────────────────────────────────────────────────────────────────────────
    //  INTERNAL STATE
    // ───────────────────────────────────────────────────────────────────────────
    /** @type {HTMLCanvasElement|null} The canvas element for drawing sparkles. */
    let canvas = null;
    /** @type {CanvasRenderingContext2D|null} The 2D rendering context of the canvas. */
    let ctx = null;
    /** @type {number} Current width of the document viewport. */
    let docW = 0;
    /** @type {number} Current height of the document viewport. */
    let docH = 0;

    /** @type {boolean} Flag indicating if the sparkle system has been initialized. */
    let isInitialized = false;
    /** @type {boolean} Flag indicating if sparkles are currently enabled. */
    let sparklesEnabled = false;
    /** @type {boolean} Flag indicating if the animation loop is currently running. */
    let animationRunning = false;
    /** @type {number} Timestamp of the last sparkle spawn attempt. */
    let lastSpawnTime = 0;

    /**
     * @typedef {Object} SparkleParticle
     * @property {boolean} active - Whether the particle is currently active and should be drawn/updated.
     * @property {number} x - The x-coordinate of the particle.
     * @property {number} y - The y-coordinate of the particle.
     * @property {number} ticksLeft - Remaining lifetime of the particle in animation ticks.
     * @property {string} color - The color of the particle (CSS color string).
     */

    /** @type {SparkleParticle[]} Pool for star particles. */
    const stars = [];
    /** @type {SparkleParticle[]} Pool for tiny dot particles. */
    const tinnies = [];

    for (let i = 0; i < MAX_SPARKLES; i++) {
        stars.push({active: false, x: 0, y: 0, ticksLeft: 0, color: ""});
        tinnies.push({active: false, x: 0, y: 0, ticksLeft: 0, color: ""});
    }

    /** @type {string[]} Precomputed pool of random RGB color strings for sparkles. */
    const COLOR_POOL = [];
    (function buildColorPool() {
        for (let i = 0; i < 512; i++) {
            const c1 = 255;
            const c2 = Math.floor(Math.random() * 256);
            const c3 = Math.floor(Math.random() * (256 - c2 / 2));
            const arr = [c1, c2, c3];
            arr.sort(() => 0.5 - Math.random()); // Shuffle to vary which component is dominant
            COLOR_POOL.push(`rgb(${arr[0]}, ${arr[1]}, ${arr[2]})`);
        }
    })();

    // ───────────────────────────────────────────────────────────────────────────
    //  INITIALIZATION (runs once when DOMContentLoaded fires)
    // ───────────────────────────────────────────────────────────────────────────
    /**
     * Initializes the sparkle system: creates canvas, sets up listeners.
     * This function is called once when the DOM is ready.
     * @private
     */
    function initialize() {
        if (isInitialized) return;
        isInitialized = true;

        canvas = document.createElement("canvas");
        canvas.style.position = "fixed";
        canvas.style.top = "0";
        canvas.style.left = "0";
        canvas.style.width = "100%";
        canvas.style.height = "100%";
        canvas.style.pointerEvents = "none"; // Canvas doesn't intercept mouse events
        canvas.style.zIndex = "999"; // Ensure it's on top (adjust if needed)
        document.body.appendChild(canvas);
        ctx = canvas.getContext("2d");

        handleResize();
        window.addEventListener("resize", handleResize);
        document.addEventListener("mousemove", onMouseMove);

        if (sparklesEnabled && !animationRunning) {
            animationRunning = true;
            requestAnimationFrame(animate);
        }
    }

    /**
     * Handles window resize events by updating canvas dimensions to match the viewport.
     * @private
     */
    function handleResize() {
        if (!canvas) return;
        docW = window.innerWidth;
        docH = window.innerHeight;
        canvas.width = docW;
        canvas.height = docH;
    }

    // ───────────────────────────────────────────────────────────────────────────
    //  SPAWNING LOGIC: place a “star” in the pool (or convert an old one to a dot)
    // ───────────────────────────────────────────────────────────────────────────
    /**
     * Spawns a new star particle at the given coordinates.
     * If all star slots are active, it may replace the oldest star, converting it to a dot.
     * @private
     * @param {number} x - The x-coordinate for the new star.
     * @param {number} y - The y-coordinate for the new star.
     */
    function spawnStar(x, y) {
        if (!ctx || x + 5 >= docW || y + 5 >= docH || x < 0 || y < 0) return;

        let chosenIdx = -1;
        let minTicks = SPARKLE_LIFETIME * 2 + 1; // Sentinel for oldest active star

        for (let i = 0; i < MAX_SPARKLES; i++) {
            const s = stars[i];
            if (!s.active) { // Found an inactive slot
                chosenIdx = i;
                minTicks = null; // Mark that we found a truly free slot
                break;
            } else if (s.ticksLeft < minTicks) { // Found an active star older than current minTicks
                minTicks = s.ticksLeft;
                chosenIdx = i;
            }
        }

        // If minTicks is not null here, it means all slots were active,
        // and chosenIdx points to the star with the least ticksLeft (oldest).
        if (minTicks !== null && chosenIdx !== -1) {
            const oldStar = stars[chosenIdx];
            // Convert the old star to a "tinny" dot
            const tinny = tinnies[chosenIdx];
            tinny.active = true;
            tinny.x = oldStar.x;
            tinny.y = oldStar.y;
            tinny.ticksLeft = SPARKLE_LIFETIME * 2;
            tinny.color = oldStar.color;
        }

        // Initialize the chosen slot (either inactive or oldest) as a new star
        if (chosenIdx !== -1) {
            const newStar = stars[chosenIdx];
            const col = COLOR_POOL[Math.floor(Math.random() * COLOR_POOL.length)];
            newStar.active = true;
            newStar.x = x;
            newStar.y = y;
            newStar.ticksLeft = SPARKLE_LIFETIME * 2;
            newStar.color = col;
        }
    }

    // ───────────────────────────────────────────────────────────────────────────
    //  ANIMATION LOOP: update and draw all active stars and dots each frame
    // ───────────────────────────────────────────────────────────────────────────
    /**
     * The main animation loop. Updates and draws all active particles.
     * Requests the next frame if particles are active or sparkles are enabled.
     * @private
     * @param {DOMHighResTimeStamp} timestamp - The current time provided by requestAnimationFrame.
     */
    function animate(timestamp) {
        if (!ctx) return;
        ctx.clearRect(0, 0, docW, docH);
        let anyAlive = false;

        // --- 1) Update & draw “stars” ---
        for (let i = 0; i < MAX_SPARKLES; i++) {
            const s = stars[i];
            if (!s.active) continue;

            s.ticksLeft--;
            if (s.ticksLeft <= 0) {
                // Convert to a “tiny” dot
                const tinny = tinnies[i];
                tinny.active = true;
                tinny.x = s.x;
                tinny.y = s.y;
                tinny.ticksLeft = SPARKLE_LIFETIME * 2;
                tinny.color = s.color;
                s.active = false;
                // anyAlive = true; // Dot is now alive
                continue; // Star is done
            }

            s.y += 1 + 3 * Math.random(); // Move downwards with some variance
            s.x += (i % 5 - 2) / 5; // Slight horizontal drift based on index

            if (s.y + 5 < docH && s.x + 5 < docW && s.x > -5 && s.y > -5) {
                const halfLife = SPARKLE_LIFETIME;
                ctx.strokeStyle = s.color;
                ctx.lineWidth = 1;
                if (s.ticksLeft > halfLife) { // First half of life: 5x5 cross
                    const cx = s.x + 2;
                    const cy = s.y + 2;
                    ctx.beginPath();
                    ctx.moveTo(s.x, cy);
                    ctx.lineTo(s.x + 5, cy);
                    ctx.moveTo(cx, s.y);
                    ctx.lineTo(cx, s.y + 5);
                    ctx.stroke();
                } else { // Second half of life: 3x3 cross
                    const cx = s.x + 1;
                    const cy = s.y + 1;
                    ctx.beginPath();
                    ctx.moveTo(s.x, cy);
                    ctx.lineTo(s.x + 3, cy);
                    ctx.moveTo(cx, s.y);
                    ctx.lineTo(cx, s.y + 3);
                    ctx.stroke();
                }
                anyAlive = true;
            } else {
                s.active = false; // Out of bounds
            }
        }

        // --- 2) Update & draw “tinnies” (dots) ---
        for (let i = 0; i < MAX_SPARKLES; i++) {
            const t = tinnies[i];
            if (!t.active) continue;

            t.ticksLeft--;
            if (t.ticksLeft <= 0) {
                t.active = false;
                continue;
            }

            t.y += 1 + 2 * Math.random(); // Move downwards
            t.x += (i % 4 - 2) / 4; // Slight horizontal drift

            if (t.y + 3 < docH && t.x + 3 < docW && t.x > -3 && t.y > -3) {
                const halfLife = SPARKLE_LIFETIME;
                ctx.fillStyle = t.color;
                if (t.ticksLeft > halfLife) { // First half: 2x2 square
                    ctx.fillRect(t.x, t.y, 2, 2);
                } else { // Second half: 1x1 pixel
                    ctx.fillRect(t.x + 0.5, t.y + 0.5, 1, 1);
                }
                anyAlive = true;
            } else {
                t.active = false; // Out of bounds
            }
        }

        if (anyAlive || sparklesEnabled) { // Continue if particles exist or feature is on
            animationRunning = true;
            requestAnimationFrame(animate);
        } else {
            animationRunning = false;
            if (ctx) ctx.clearRect(0, 0, docW, docH); // Final clear
        }
    }

    // ───────────────────────────────────────────────────────────────────────────
    //  MOUSEMOVE HANDLER: throttle to ≈60fps, spawn stars along the path
    // ───────────────────────────────────────────────────────────────────────────
    /**
     * Handles mouse move events to spawn sparkles.
     * Throttled to approximately 60 FPS. Spawns particles along the mouse path.
     * @private
     * @param {MouseEvent} e - The mouse event.
     */
    function onMouseMove(e) {
        if (!sparklesEnabled) return;

        const now = performance.now();
        if (now - lastSpawnTime < 16) return; // Throttle to ~60fps
        lastSpawnTime = now;

        const dx = e.movementX;
        const dy = e.movementY;
        const dist = Math.hypot(dx, dy);
        if (dist < 0.5) return; // Minimal movement

        let mx = e.clientX; // Viewport-relative X
        let my = e.clientY; // Viewport-relative Y

        const prob = dist / SPARKLE_DISTANCE; // Probability of spawning a star
        let cum = 0;
        // Calculate step to move back along the mouse path for distributed spawning
        const stepX = (dx * SPARKLE_DISTANCE * 2) / dist;
        const stepY = (dy * SPARKLE_DISTANCE * 2) / dist;

        // Iterate back along the path, spawning stars probabilistically
        // Note: original logic used Math.abs(cum) < Math.abs(dx), which might be problematic if dx is small or zero.
        // A more robust approach might be to iterate based on distance or number of steps.
        // For now, keeping it similar to original while noting potential improvement.
        let pathTraversed = 0;
        const totalPathLength = dist; // Use the actual distance for path traversal limit

        while (pathTraversed < totalPathLength) {
            if (Math.random() < prob) {
                spawnStar(mx, my);
            }
            const frac = Math.random(); // Random fraction of a step
            const dmx = stepX * frac;
            const dmy = stepY * frac;
            mx -= dmx;
            my -= dmy;
            pathTraversed += Math.hypot(dmx, dmy); // Accumulate distance traversed
        }


        if (!animationRunning && isInitialized) {
            animationRunning = true;
            requestAnimationFrame(animate);
        }
    }

    // ───────────────────────────────────────────────────────────────────────────
    //  PUBLIC API: window.sparkle(enable)
    //    - sparkle(true)  → turn ON sparkles
    //    - sparkle(false) → turn OFF immediately (clears all alive particles)
    //    - sparkle()      → toggle on/off
    // ───────────────────────────────────────────────────────────────────────────
    const globalRef = typeof window !== 'undefined' ? window : global;
    /**
     * @global
     * @function sparkle
     * @description Controls the sparkle effect.
     * Call with `true` to enable, `false` to disable, or no argument to toggle.
     * @param {boolean} [enable=null] - True to enable, false to disable. Toggles if null.
     */
    globalRef.sparkle = function (enable = null) {
        if (enable === null) {
            sparklesEnabled = !sparklesEnabled;
        } else {
            sparklesEnabled = !!enable; // Coerce to boolean
        }

        if (!sparklesEnabled && isInitialized) { // If turning off
            for (let i = 0; i < MAX_SPARKLES; i++) {
                stars[i].active = false;
                tinnies[i].active = false;
            }
            // Animation loop will stop itself if no particles are alive and sparklesEnabled is false
        }

        if (sparklesEnabled && isInitialized && !animationRunning) {
            animationRunning = true;
            requestAnimationFrame(animate);
        }
    };

    // ───────────────────────────────────────────────────────────────────────────
    //  WAIT FOR DOM TO BE READY, THEN INITIALIZE
    // ───────────────────────────────────────────────────────────────────────────
    if (document.readyState === "complete" || document.readyState === "interactive") {
        initialize();
    } else {
        document.addEventListener("DOMContentLoaded", initialize);
    }

})();
````
--- End of File: vibe-player/js/sparkles.js ---
--- File: vibe-player/js/state/appState.js ---
````javascript
// In vibe-player/js/state/appState.js
class AppState {
    constructor() {
        // --- State Categories ---
        this.params = {
            speed: 1.0,
            pitch: 1.0,
            gain: 1.0,
            vadPositive: typeof Constants !== 'undefined' ? Constants.VAD.DEFAULT_POSITIVE_THRESHOLD : 0.5,
            vadNegative: typeof Constants !== 'undefined' ? Constants.VAD.DEFAULT_NEGATIVE_THRESHOLD : 0.35,
            audioUrl: "", // Default to empty string for consistency
            jumpTime: 5,
            initialSeekTime: null // Added for deserializing time parameter
        };
        this.runtime = {
            currentAudioBuffer: null,
            currentVadResults: null,
            currentFile: null,
            // For playback time tracking (might be simplified later)
            playbackStartTimeContext: null,
            playbackStartSourceTime: 0.0,
            currentSpeedForUpdate: 1.0 // Tracks speed for UI time calculation
        };
        this.status = {
            isActuallyPlaying: false,
            vadModelReady: false,       // Assuming VAD model readiness is tracked
            workletPlaybackReady: false,
            isVadProcessing: false,
            playbackNaturallyEnded: false,
            urlInputStyle: 'default', // For uiManager.setUrlInputStyle
            fileInfoMessage: "No file selected.", // For uiManager.setFileInfo
            urlLoadingErrorMessage: "" // For uiManager.setUrlLoadingError
        };

        // --- Pub/Sub ---
        this._subscribers = {}; // Example: { "param:speed:changed": [callback1, callback2] }
    }

    // --- Public Methods ---
    updateParam(param, value) {
        if (this.params.hasOwnProperty(param)) {
            if (this.params[param] !== value) {
                this.params[param] = value;
                this._notify('param:' + param + ':changed', value);
                this._notify('param:changed', {param: param, value: value}); // Generic notification
            }
        } else {
            console.warn(`AppState: Attempted to update unknown param "${param}"`);
        }
    }

    updateRuntime(property, value) {
        if (this.runtime.hasOwnProperty(property)) {
            // For objects like currentAudioBuffer or currentVadResults, a shallow inequality check is often sufficient,
            // but for deep changes within these objects, the caller might need to ensure a new object reference is passed
            // or this method might need a more sophisticated deep comparison if granular notifications are not used.
            if (this.runtime[property] !== value) {
                this.runtime[property] = value;
                this._notify('runtime:' + property + ':changed', value);
            }
        } else {
            console.warn(`AppState: Attempted to update unknown runtime property "${property}"`);
        }
    }

    updateStatus(flag, value) {
        if (this.status.hasOwnProperty(flag)) {
            if (this.status[flag] !== value) {
                this.status[flag] = value;
                this._notify('status:' + flag + ':changed', value);
            }
        } else {
            console.warn(`AppState: Attempted to update unknown status flag "${flag}"`);
        }
    }

    subscribe(event, callback) {
        if (typeof callback !== 'function') {
            console.error(`AppState: Attempted to subscribe with non-function callback for event "${event}"`);
            return;
        }
        if (!this._subscribers[event]) {
            this._subscribers[event] = [];
        }
        if (!this._subscribers[event].includes(callback)) {
            this._subscribers[event].push(callback);
        }
    }

    unsubscribe(event, callback) {
        if (this._subscribers[event]) {
            this._subscribers[event] = this._subscribers[event].filter(cb => cb !== callback);
            if (this._subscribers[event].length === 0) {
                delete this._subscribers[event];
            }
        }
    }

    _notify(event, data) {
        if (this._subscribers[event]) {
            this._subscribers[event].forEach(callback => {
                try {
                    callback(data);
                } catch (error) {
                    console.error(`Error in subscriber for event "${event}":`, error);
                }
            });
        }
    }

    // --- Serialization / Deserialization ---
    deserialize(hashString) {
        if (!hashString) {
            return;
        }
        // Ensure Constants and its nested properties are available
        if (typeof Constants === 'undefined' || !Constants.URLHashKeys) {
            console.error("AppState.deserialize: Constants or Constants.URLHashKeys are not defined. Cannot deserialize.");
            return;
        }
        const searchParams = new URLSearchParams(hashString);
        const C_URL_KEYS = Constants.URLHashKeys; // Alias

        const speedStr = searchParams.get(C_URL_KEYS.SPEED);
        if (speedStr) {
            const speed = parseFloat(speedStr);
            if (!isNaN(speed)) this.updateParam('speed', speed);
        }

        const pitchStr = searchParams.get(C_URL_KEYS.PITCH);
        if (pitchStr) {
            const pitch = parseFloat(pitchStr);
            if (!isNaN(pitch)) this.updateParam('pitch', pitch);
        }

        const gainStr = searchParams.get(C_URL_KEYS.GAIN);
        if (gainStr) {
            const gain = parseFloat(gainStr);
            if (!isNaN(gain)) this.updateParam('gain', gain);
        }

        const vadPositiveStr = searchParams.get(C_URL_KEYS.VAD_POSITIVE);
        if (vadPositiveStr) {
            const vadPositive = parseFloat(vadPositiveStr);
            if (!isNaN(vadPositive)) this.updateParam('vadPositive', vadPositive);
        }

        const vadNegativeStr = searchParams.get(C_URL_KEYS.VAD_NEGATIVE);
        if (vadNegativeStr) {
            const vadNegative = parseFloat(vadNegativeStr);
            if (!isNaN(vadNegative)) this.updateParam('vadNegative', vadNegative);
        }

        const audioUrl = searchParams.get(C_URL_KEYS.AUDIO_URL);
        if (audioUrl) { // No parsing needed for string
            this.updateParam('audioUrl', audioUrl);
        }

        const timeStr = searchParams.get(C_URL_KEYS.TIME);
        if (timeStr) {
            const time = parseFloat(timeStr);
            if (!isNaN(time) && time >= 0) { // Allow t=0
                this.updateParam('initialSeekTime', time);
            }
        }
        // console.log("AppState.deserialize: Processed hash string.");
    }

    serialize(currentPosition) {
        const searchParams = new URLSearchParams();

        // Ensure Constants and its nested properties are available
        if (typeof Constants === 'undefined' || !Constants.URLHashKeys || !Constants.VAD) {
            console.error("AppState.serialize: Constants or required sub-properties (URLHashKeys, VAD) are not defined. Cannot serialize.");
            return ""; // Return empty string or handle error as appropriate
        }

        const C_URL_KEYS = Constants.URLHashKeys;
        const C_VAD_DEFAULTS = Constants.VAD;

        if (this.params.speed !== 1.0) {
            searchParams.set(C_URL_KEYS.SPEED, this.params.speed.toFixed(2));
        }
        if (this.params.pitch !== 1.0) {
            searchParams.set(C_URL_KEYS.PITCH, this.params.pitch.toFixed(2));
        }
        if (this.params.gain !== 1.0) {
            searchParams.set(C_URL_KEYS.GAIN, this.params.gain.toFixed(2));
        }
        // Check against undefined for VAD defaults in case Constants was loaded but VAD part is missing (defensive)
        if (C_VAD_DEFAULTS.DEFAULT_POSITIVE_THRESHOLD !== undefined && this.params.vadPositive !== C_VAD_DEFAULTS.DEFAULT_POSITIVE_THRESHOLD) {
            searchParams.set(C_URL_KEYS.VAD_POSITIVE, this.params.vadPositive.toFixed(2));
        }
        if (C_VAD_DEFAULTS.DEFAULT_NEGATIVE_THRESHOLD !== undefined && this.params.vadNegative !== C_VAD_DEFAULTS.DEFAULT_NEGATIVE_THRESHOLD) {
            searchParams.set(C_URL_KEYS.VAD_NEGATIVE, this.params.vadNegative.toFixed(2));
        }
        if (this.params.audioUrl) { // Check for truthiness (not null or empty string)
            searchParams.set(C_URL_KEYS.AUDIO_URL, this.params.audioUrl);
        }
        // Using a small threshold like 0.1s to avoid writing 't=0.00' for very start.
        if (typeof currentPosition === 'number' && currentPosition > 0.1) {
            searchParams.set(C_URL_KEYS.TIME, currentPosition.toFixed(2));
        }
        // console.log("AppState.serialize: generated hash params:", searchParams.toString());
        return searchParams.toString();
    }
}

// Export for Node.js/CommonJS for testing, or attach to window/global for browser/other environments
if (typeof module !== 'undefined' && module.exports) {
    module.exports = AppState;
} else if (typeof window !== 'undefined') {
    window.AppState = AppState;
} else if (typeof global !== 'undefined') {
    // Fallback for environments like Jest's JSDOM where 'global' is the window-like object
    global.AppState = AppState;
}

````
--- End of File: vibe-player/js/state/appState.js ---
--- File: vibe-player/js/state/constants.js ---
````javascript
// vibe-player/js/state/constants.js
class Constants {
    static get AudioEngine() {
        return {
            PROCESSOR_SCRIPT_URL: 'js/player/rubberbandProcessor.js',
            PROCESSOR_NAME: 'rubberband-processor',
            WASM_BINARY_URL: 'lib/rubberband.wasm',
            LOADER_SCRIPT_URL: 'lib/rubberband-loader.js'
        };
    }

    static get VAD() {
        return {
            SAMPLE_RATE: 16000,
            DEFAULT_FRAME_SAMPLES: 1536,
            PROGRESS_REPORT_INTERVAL: 20,
            YIELD_INTERVAL: 5,
            // Default thresholds (can be overridden by AppState or UI)
            DEFAULT_POSITIVE_THRESHOLD: 0.5,
            DEFAULT_NEGATIVE_THRESHOLD: 0.35,
            // these were missing
            MIN_SPEECH_DURATION_MS: 200,
            SPEECH_PAD_MS: 50,
            REDEMPTION_FRAMES: 3
        };
    }

    static get UI() {
        return {
            // Example:
            // DEFAULT_JUMP_TIME_S: 5,
            // MAX_GAIN_VALUE: 5.0
            DEBOUNCE_HASH_UPDATE_MS: 500,
            SYNC_DEBOUNCE_WAIT_MS: 300
        };
    }

    static get Visualizer() {
        return {
            WAVEFORM_HEIGHT_SCALE: 0.8,
            WAVEFORM_COLOR_LOADING: '#888888',
            WAVEFORM_COLOR_DEFAULT: '#26828E',
            WAVEFORM_COLOR_SPEECH: '#FDE725',
            SPEC_NORMAL_FFT_SIZE: 8192,
            SPEC_SHORT_FFT_SIZE: 2048,
            SPEC_SHORT_FILE_FFT_THRESHOLD_S: 10.0,
            SPEC_MAX_FREQS: [5000, 16000],
            SPEC_DEFAULT_MAX_FREQ_INDEX: 0,
            SPEC_FIXED_WIDTH: 2048,
            SPEC_SHORT_FILE_HOP_THRESHOLD_S: 5.0,
            SPEC_NORMAL_HOP_DIVISOR: 4,
            SPEC_SHORT_HOP_DIVISOR: 8,
            SPEC_CENTER_WINDOWS: true
        };
    }

    static get URLHashKeys() {
        return {
            // Old keys for reference during transition if needed, though new ones are primary
            // OLD_SPEED: 's',
            // OLD_PITCH: 'p',
            // ...
            // New keys
            SPEED: 'speed',
            PITCH: 'pitch',
            GAIN: 'gain', // Assuming 'v' (volume) becomes 'gain'
            VAD_POSITIVE: 'vadPositive',
            VAD_NEGATIVE: 'vadNegative',
            AUDIO_URL: 'url',
            TIME: 'time' // For playback position
        };
    }

    static get DTMF() {
        return {
            SAMPLE_RATE: 16000, // Or whatever AudioApp.DTMFParser.DTMF_SAMPLE_RATE was
            BLOCK_SIZE: 410     // Or whatever AudioApp.DTMFParser.DTMF_BLOCK_SIZE was
        };
    }
}

// Export for Node.js/CommonJS for testing, or attach to window/global for browser/other environments
if (typeof module !== 'undefined' && module.exports) {
    module.exports = Constants;
} else if (typeof self !== 'undefined' && (typeof self.importScripts === 'function' || typeof self.postMessage === 'function')) {
    // ADDED: Explicit check for a Worker-like environment ('self' exists and has worker functions).
    // This will make the Constants class available globally inside the worker.
    self.Constants = Constants;
} else if (typeof window !== 'undefined') {
    window.Constants = Constants;
} else if (typeof global !== 'undefined') {
    // Fallback for environments like Jest's JSDOM where 'global' is the window-like object
    global.Constants = Constants;
}

````
--- End of File: vibe-player/js/state/constants.js ---
--- File: vibe-player/js/uiManager.js ---
````javascript
// --- /vibe-player/js/uiManager.js ---
// Handles DOM manipulation, UI event listeners, and dispatches UI events.

/** @namespace AudioApp */
var AudioApp = AudioApp || {}; // Ensure namespace exists

/**
 * @namespace AudioApp.uiManager
 * @description Manages UI elements, interactions, and events for the Vibe Player.
 */
AudioApp.uiManager = (function () {
    'use strict';

    // === Module Dependencies ===
    /**
     * @private
     * @type {AudioApp.Utils} Reference to the Utils module.
     */
    const Utils = AudioApp.Utils;

    // --- DOM Element References ---
    // File/Info
    /** @type {HTMLButtonElement|null} Button to trigger file selection. */
    let chooseFileButton = null;
    /** @type {HTMLInputElement|null} Hidden input element for file selection. */
    let hiddenAudioFile = null;
    /** @type {HTMLInputElement|null} Input element for audio URL. */
    let audioUrlInput = null;
    /** @type {HTMLButtonElement|null} Button to load audio from URL. */
    let loadUrlButton = null;
    /** @type {HTMLSpanElement|null} Span to display URL loading errors. */
    let urlLoadingErrorDisplay = null;
    /** @type {HTMLSpanElement|null} Span to display the current file name. */
    let fileNameDisplay = null;
    /** @type {HTMLParagraphElement|null} Paragraph to display file information or status messages. */
    let fileInfo = null;
    /** @type {HTMLDivElement|null} Container for the VAD progress bar. */
    let vadProgressContainer = null;
    /** @type {HTMLSpanElement|null} The VAD progress bar element itself. */
    let vadProgressBar = null;
    /** @type {HTMLDivElement|null} Div to display detected DTMF tones. */
    let dtmfDisplay = null;
    /** @type {HTMLDivElement|null} Div to display detected Call Progress Tones. */
    let cptDisplayElement = null;

    // Drop Zone
    /** @type {HTMLDivElement|null} Overlay for drag-and-drop functionality. */
    let dropZoneOverlay = null;
    /** @type {HTMLDivElement|null} Message displayed within the drop zone. */
    let dropZoneMessage = null;

    // Buttons
    /** @type {HTMLButtonElement|null} Button to play or pause audio. */
    let playPauseButton = null;
    /** @type {HTMLButtonElement|null} Button to jump backward in audio. */
    let jumpBackButton = null;
    /** @type {HTMLButtonElement|null} Button to jump forward in audio. */
    let jumpForwardButton = null;
    /** @type {HTMLInputElement|null} Input for specifying jump time in seconds. */
    let jumpTimeInput = null;

    // Time & Seek
    /** @type {HTMLDivElement|null} Div to display current time and duration. */
    let timeDisplay = null;
    /** @type {HTMLInputElement|null} Seek bar (slider) for audio playback. */
    let seekBar = null;

    // Sliders & Displays & Markers
    /** @type {HTMLInputElement|null} Slider for playback speed control. */
    let playbackSpeedControl = null;
    /** @type {HTMLSpanElement|null} Span to display current playback speed value. */
    let speedValueDisplay = null;
    /** @type {HTMLDivElement|null} Container for speed slider markers. */
    let speedMarkers = null;
    /** @type {HTMLInputElement|null} Slider for pitch control. */
    let pitchControl = null;
    /** @type {HTMLSpanElement|null} Span to display current pitch value. */
    let pitchValueDisplay = null;
    /** @type {HTMLDivElement|null} Container for pitch slider markers. */
    let pitchMarkers = null;
    // Formant controls are referenced but not actively used in current logic, kept for potential future use.
    /** @type {HTMLInputElement|null} */ let formantControl = null;
    /** @type {HTMLSpanElement|null} */ let formantValueDisplay = null;
    /** @type {HTMLDivElement|null} */ let formantMarkers = null;
    /** @type {HTMLInputElement|null} Slider for gain (volume) control. */
    let gainControl = null;
    /** @type {HTMLSpanElement|null} Span to display current gain value. */
    let gainValueDisplay = null;
    /** @type {HTMLDivElement|null} Container for gain slider markers. */
    let gainMarkers = null;
    /** @type {HTMLInputElement|null} Slider for VAD positive threshold. */
    let vadThresholdSlider = null;
    /** @type {HTMLSpanElement|null} Span to display current VAD positive threshold value. */
    let vadThresholdValueDisplay = null;
    /** @type {HTMLInputElement|null} Slider for VAD negative threshold. */
    let vadNegativeThresholdSlider = null;
    /** @type {HTMLSpanElement|null} Span to display current VAD negative threshold value. */
    let vadNegativeThresholdValueDisplay = null;

    // VAD Output
    /** @type {HTMLPreElement|null} Element to display detected speech regions. */
    let speechRegionsDisplay = null;

    /**
     * Initializes the UI Manager. Assigns DOM elements, sets up event listeners, and resets the UI.
     * @public
     */
    function init() {
        console.log("UIManager: Initializing...");
        if (!Utils || typeof AudioApp === 'undefined' || !AudioApp.state || typeof Constants === 'undefined') {
            console.error("UIManager: CRITICAL - Missing dependencies (Utils, AudioApp.state, or Constants)! UI might not function correctly.");
            return;
        }
        assignDOMElements();
        initializeSliderMarkers();
        setupEventListeners();
        // Initial UI setup based on AppState defaults, before subscriptions might override them
        resetUI();

        // Subscribe to AppState changes
        AudioApp.state.subscribe('param:speed:changed', (newSpeed) => {
            setPlaybackSpeedValue(newSpeed);
        });
        AudioApp.state.subscribe('param:pitch:changed', (newPitch) => {
            setPitchValue(newPitch);
        });
        AudioApp.state.subscribe('param:gain:changed', (newGain) => {
            setGainValue(newGain);
        });
        AudioApp.state.subscribe('param:vadPositive:changed', (newThreshold) => {
            setVadPositiveThresholdValue(newThreshold);
        });
        AudioApp.state.subscribe('param:vadNegative:changed', (newThreshold) => {
            setVadNegativeThresholdValue(newThreshold);
        });
        AudioApp.state.subscribe('param:audioUrl:changed', (newUrl) => {
            if (getAudioUrlInputValue() !== newUrl) {
                setAudioUrlInputValue(newUrl);
            }
        });
        AudioApp.state.subscribe('param:jumpTime:changed', (newJumpTime) => {
            setJumpTimeValue(newJumpTime);
        });

        AudioApp.state.subscribe('runtime:currentAudioBuffer:changed', (audioBuffer) => {
            // Update duration part of timeDisplay
            const duration = audioBuffer ? audioBuffer.duration : 0;
            const currentTime = seekBar ? parseFloat(seekBar.value) * duration : 0; // Maintain current time if possible
            updateTimeDisplay(currentTime, duration); // Will update both current time and duration
            enableSeekBar(!!audioBuffer);
        });
        AudioApp.state.subscribe('runtime:currentVadResults:changed', (vadResults) => {
            const regions = vadResults ? vadResults.regions || [] : [];
            setSpeechRegionsText(regions);
            // Waveform highlight will be handled by waveformVisualizer subscribing separately
        });

        AudioApp.state.subscribe('status:isActuallyPlaying:changed', (isPlaying) => {
            setPlayButtonState(isPlaying);
        });
        AudioApp.state.subscribe('status:workletPlaybackReady:changed', (isReady) => {
            enablePlaybackControls(isReady);
            if (!isReady) {
                enableSeekBar(false);
            } // Also disable seekbar if worklet not ready
        });
        AudioApp.state.subscribe('status:urlInputStyle:changed', (style) => {
            setUrlInputStyle(style);
        });
        AudioApp.state.subscribe('status:fileInfoMessage:changed', (message) => {
            setFileInfo(message);
        });
        AudioApp.state.subscribe('status:urlLoadingErrorMessage:changed', (message) => {
            setUrlLoadingError(message);
        });
        AudioApp.state.subscribe('status:isVadProcessing:changed', (isProcessing) => {
            showVadProgress(isProcessing);
            if (!isProcessing) {
                // Check if VAD results are present to determine if progress should be 100% or reset
                const vadResults = AudioApp.state.runtime.currentVadResults;
                updateVadProgress(vadResults ? 100 : 0);
            } else {
                updateVadProgress(0);
            }
        });

        console.log("UIManager: Initialized and subscribed to AppState.");
    }

    /**
     * @private
     * @const {Object<string, string>}
     * @description Conceptual mapping of functional names to DOM element IDs.
     */
    const DOM_ELEMENT_IDS = {
        DTMF_DISPLAY: 'dtmfDisplay',
        CPT_DISPLAY: 'cpt-display-content'
    };

    /**
     * Assigns DOM elements to module-level variables.
     * @private
     */
    function assignDOMElements() {
        chooseFileButton = /** @type {HTMLButtonElement|null} */ (document.getElementById('chooseFileButton'));
        hiddenAudioFile = /** @type {HTMLInputElement|null} */ (document.getElementById('hiddenAudioFile'));
        audioUrlInput = /** @type {HTMLInputElement|null} */ (document.getElementById('audioUrlInput'));
        loadUrlButton = /** @type {HTMLButtonElement|null} */ (document.getElementById('loadUrlButton'));
        urlLoadingErrorDisplay = /** @type {HTMLSpanElement|null} */ (document.getElementById('urlLoadingErrorDisplay'));
        fileNameDisplay = /** @type {HTMLSpanElement|null} */ (document.getElementById('fileNameDisplay'));
        fileInfo = /** @type {HTMLParagraphElement|null} */ (document.getElementById('fileInfo'));
        vadProgressContainer = /** @type {HTMLDivElement|null} */ (document.getElementById('vadProgressContainer'));
        vadProgressBar = /** @type {HTMLSpanElement|null} */ (document.getElementById('vadProgressBar'));

        dropZoneOverlay = /** @type {HTMLDivElement|null} */ (document.getElementById('dropZoneOverlay'));
        dropZoneMessage = /** @type {HTMLDivElement|null} */ (document.getElementById('dropZoneMessage'));

        playPauseButton = /** @type {HTMLButtonElement|null} */ (document.getElementById('playPause'));
        jumpBackButton = /** @type {HTMLButtonElement|null} */ (document.getElementById('jumpBack'));
        jumpForwardButton = /** @type {HTMLButtonElement|null} */ (document.getElementById('jumpForward'));
        jumpTimeInput = /** @type {HTMLInputElement|null} */ (document.getElementById('jumpTime'));

        seekBar = /** @type {HTMLInputElement|null} */ (document.getElementById('seekBar'));
        timeDisplay = /** @type {HTMLDivElement|null} */ (document.getElementById('timeDisplay'));

        playbackSpeedControl = /** @type {HTMLInputElement|null} */ (document.getElementById('playbackSpeed'));
        speedValueDisplay = /** @type {HTMLSpanElement|null} */ (document.getElementById('speedValue'));
        speedMarkers = /** @type {HTMLDivElement|null} */ (document.getElementById('speedMarkers'));
        pitchControl = /** @type {HTMLInputElement|null} */ (document.getElementById('pitchControl'));
        pitchValueDisplay = /** @type {HTMLSpanElement|null} */ (document.getElementById('pitchValue'));
        pitchMarkers = /** @type {HTMLDivElement|null} */ (document.getElementById('pitchMarkers'));
        gainControl = /** @type {HTMLInputElement|null} */ (document.getElementById('gainControl'));
        gainValueDisplay = /** @type {HTMLSpanElement|null} */ (document.getElementById('gainValue'));
        gainMarkers = /** @type {HTMLDivElement|null} */ (document.getElementById('gainMarkers'));

        vadThresholdSlider = /** @type {HTMLInputElement|null} */ (document.getElementById('vadThreshold'));
        vadThresholdValueDisplay = /** @type {HTMLSpanElement|null} */ (document.getElementById('vadThresholdValue'));
        vadNegativeThresholdSlider = /** @type {HTMLInputElement|null} */ (document.getElementById('vadNegativeThreshold'));
        vadNegativeThresholdValueDisplay = /** @type {HTMLSpanElement|null} */ (document.getElementById('vadNegativeThresholdValue'));

        speechRegionsDisplay = /** @type {HTMLPreElement|null} */ (document.getElementById('speechRegionsDisplay'));
        dtmfDisplay = /** @type {HTMLDivElement|null} */ (document.getElementById(DOM_ELEMENT_IDS.DTMF_DISPLAY));
        cptDisplayElement = /** @type {HTMLDivElement|null} */ (document.getElementById(DOM_ELEMENT_IDS.CPT_DISPLAY));

        // Basic checks for critical elements
        if (!chooseFileButton || !playPauseButton || !seekBar) {
            console.warn("UIManager: Some critical UI elements (chooseFile, playPause, seekBar) not found.");
        }
        if (!dtmfDisplay) console.warn("UIManager: DTMF display element not found.");
        if (!cptDisplayElement) console.warn(`UIManager: CPT display element (ID: ${DOM_ELEMENT_IDS.CPT_DISPLAY}) not found.`);
    }

    /**
     * Initializes positions of markers (like 0.5x, 1x, 2x) for sliders.
     * @private
     */
    function initializeSliderMarkers() {
        /** @type {Array<{slider: HTMLInputElement|null, markersDiv: HTMLDivElement|null}>} */
        const markerConfigs = [
            {slider: playbackSpeedControl, markersDiv: speedMarkers},
            {slider: pitchControl, markersDiv: pitchMarkers},
            {slider: gainControl, markersDiv: gainMarkers}
        ];
        markerConfigs.forEach(config => {
            const {slider, markersDiv} = config;
            if (!slider || !markersDiv) return;
            const min = parseFloat(slider.min);
            const max = parseFloat(slider.max);
            const range = max - min;
            if (range <= 0) return; // Avoid division by zero or negative range
            /** @type {NodeListOf<HTMLSpanElement>} */
            const markers = markersDiv.querySelectorAll('span[data-value]');
            markers.forEach(span => {
                const value = parseFloat(span.dataset.value || "");
                if (!isNaN(value)) {
                    const percent = ((value - min) / range) * 100;
                    span.style.left = `${percent}%`;
                }
            });
        });
    }

    /**
     * Sets up all general UI event listeners.
     * @private
     */
    function setupEventListeners() {
        chooseFileButton?.addEventListener('click', () => {
            hiddenAudioFile?.click();
        });
        hiddenAudioFile?.addEventListener('change', (e) => {
            const target = /** @type {HTMLInputElement} */ (e.target);
            const file = target.files?.[0];
            if (file) {
                updateFileName(file.name);
                dispatchUIEvent('audioapp:fileSelected', {file: file});
            } else {
                updateFileName("");
            }
        });

        loadUrlButton?.addEventListener('click', () => {
            const audioUrl = audioUrlInput?.value.trim();
            if (audioUrl) {
                dispatchUIEvent('audioapp:urlSelected', {url: audioUrl});
            } else {
                console.warn("UIManager: Load URL button clicked, but URL is empty.");
                if (audioUrlInput) {
                    audioUrlInput.focus();
                    setUrlInputStyle('error');
                }
            }
        });

        audioUrlInput?.addEventListener('keypress', (event) => {
            if (event.key === 'Enter') {
                event.preventDefault();
                const audioUrl = audioUrlInput?.value.trim();
                if (audioUrl) {
                    dispatchUIEvent('audioapp:urlSelected', {url: audioUrl});
                } else {
                    console.warn("UIManager: Enter pressed in URL input, but URL is empty.");
                    if (audioUrlInput) {
                        audioUrlInput.focus();
                        setUrlInputStyle('error');
                    }
                }
            }
        });

        audioUrlInput?.addEventListener('keydown', (event) => {
            if (event.key === 'Escape') {
                event.preventDefault();
                unfocusUrlInput();
            }
        });

        audioUrlInput?.addEventListener('input', () => {
            if (!audioUrlInput) return;
            const currentStyles = audioUrlInput.classList;
            if (currentStyles.contains('url-style-success') || currentStyles.contains('url-style-file')) {
                setUrlInputStyle('modified');
            } else if (currentStyles.contains('url-style-error')) {
                setUrlInputStyle('default');
            } else if (currentStyles.contains('url-style-default')) {
                setUrlInputStyle('modified');
            }
        });

        seekBar?.addEventListener('input', (e) => {
            const target = /** @type {HTMLInputElement} */ (e.target);
            const fraction = parseFloat(target.value);
            if (!isNaN(fraction)) {
                dispatchUIEvent('audioapp:seekBarInput', {fraction: fraction});
            }
        });
        playPauseButton?.addEventListener('click', () => dispatchUIEvent('audioapp:playPauseClicked'));
        jumpBackButton?.addEventListener('click', () => dispatchUIEvent('audioapp:jumpClicked', { direction: -1 }));
        jumpForwardButton?.addEventListener('click', () => dispatchUIEvent('audioapp:jumpClicked', { direction: 1 }));

        jumpTimeInput?.addEventListener('input', (e) => {
          const inputElement = /** @type {HTMLInputElement} */ (e.target);
          let value = parseFloat(inputElement.value);
          if (isNaN(value) || value <= 0) {
            value = Math.max(1, value || 1); // Ensure jump time is at least 1
            // Optionally, update the input field visually to reflect the corrected value
            // inputElement.value = String(value);
          }
          dispatchUIEvent('audioapp:jumpTimeChanged', { value: value });
        });

        setupSliderListeners(playbackSpeedControl, speedValueDisplay, 'audioapp:speedChanged', 'speed', 'x');
        setupSliderListeners(pitchControl, pitchValueDisplay, 'audioapp:pitchChanged', 'pitch', 'x');
        setupSliderListeners(gainControl, gainValueDisplay, 'audioapp:gainChanged', 'gain', 'x');

        speedMarkers?.addEventListener('click', (e) => handleMarkerClick(/** @type {MouseEvent} */ (e), playbackSpeedControl));
        pitchMarkers?.addEventListener('click', (e) => handleMarkerClick(/** @type {MouseEvent} */ (e), pitchControl));
        gainMarkers?.addEventListener('click', (e) => handleMarkerClick(/** @type {MouseEvent} */ (e), gainControl));

        vadThresholdSlider?.addEventListener('input', handleVadSliderInput);
        vadNegativeThresholdSlider?.addEventListener('input', handleVadSliderInput);

        document.addEventListener('keydown', handleKeyDown);
    }

    /**
     * Sets up an event listener for a slider control.
     * @private
     * @param {HTMLInputElement|null} slider - The slider element.
     * @param {HTMLSpanElement|null} valueDisplay - The element to display the slider's value.
     * @param {string} eventName - The name of the custom event to dispatch.
     * @param {string} detailKey - The key for the value in the event detail object.
     * @param {string} [suffix=''] - Suffix to append to the displayed value.
     */
    function setupSliderListeners(slider, valueDisplay, eventName, detailKey, suffix = '') {
        if (!slider || !valueDisplay) return;
        slider.addEventListener('input', () => {
            const value = parseFloat(slider.value);
            valueDisplay.textContent = value.toFixed(2) + suffix;
            dispatchUIEvent(eventName, {[detailKey]: value});
        });
    }

    /**
     * Handles keydown events for global shortcuts.
     * @private
     * @param {KeyboardEvent} e - The keyboard event.
     */
    function handleKeyDown(e) {
        const target = /** @type {HTMLElement} */ (e.target);
        // Ignore key events if the target is an input field where typing is expected.
        const isTextInput = target instanceof HTMLInputElement && ['text', 'number', 'search', 'email', 'password', 'url'].includes(target.type);
        const isTextArea = target instanceof HTMLTextAreaElement;
        if (isTextInput || isTextArea) return;

        let handled = false;
        /** @type {string|null} */ let eventKey = null; // To track if 'Space' was pressed for the specific event
        switch (e.code) {
            case 'Space':
                eventKey = 'Space'; // Specifically track Space for audioapp:keyPressed
                handled = true;
                break;
            case 'ArrowLeft':
                dispatchUIEvent('audioapp:jumpClicked', { direction: -1 });
                handled = true;
                break;
            case 'ArrowRight':
                dispatchUIEvent('audioapp:jumpClicked', { direction: 1 });
                handled = true;
                break;
        }
        // Dispatch keyPressed only for Space, JumpClicked is handled directly for arrows
        if (eventKey && eventKey === 'Space') {
            dispatchUIEvent('audioapp:keyPressed', { key: eventKey });
        }
        if (handled) {
            e.preventDefault();
        } // Prevent default browser action (e.g., scrolling on space)
    }

    /**
     * Updates the DTMF display box with detected tones.
     * @public
     * @param {string | string[]} tones - The detected DTMF tone(s). Can be a single string or an array of strings.
     */
    function updateDtmfDisplay(tones) {
        if (!dtmfDisplay) return;
        if (Array.isArray(tones) && tones.length > 0) {
            dtmfDisplay.textContent = tones.join(', ');
        } else if (typeof tones === 'string' && tones.length > 0 && tones.trim() !== "") {
            dtmfDisplay.textContent = tones;
        } else if (Array.isArray(tones) && tones.length === 0) {
            dtmfDisplay.textContent = "No DTMF detected.";
        } else {
            dtmfDisplay.textContent = "N/A";
        }
    }

    /**
     * Updates the Call Progress Tones display box.
     * @public
     * @param {string[]} tones - An array of detected CPT names.
     */
    function updateCallProgressTonesDisplay(tones) {
        if (!cptDisplayElement) {
            console.error("UIManager: CPT display element not found.");
            return;
        }
        if (Array.isArray(tones) && tones.length > 0) {
            cptDisplayElement.textContent = tones.join(', ');
        } else if (Array.isArray(tones) && tones.length === 0) {
            cptDisplayElement.textContent = "No ringtone detected.";
        } else {
            cptDisplayElement.textContent = "N/A";
        }
    }

    /**
     * Handles input events from VAD threshold sliders.
     * @private
     * @param {Event} e - The input event.
     */
    function handleVadSliderInput(e) {
        const slider = /** @type {HTMLInputElement} */ (e.target);
        const value = parseFloat(slider.value);
        /** @type {string|null} */ let type = null;
        if (slider === vadThresholdSlider && vadThresholdValueDisplay) {
            vadThresholdValueDisplay.textContent = value.toFixed(2);
            type = 'positive';
        } else if (slider === vadNegativeThresholdSlider && vadNegativeThresholdValueDisplay) {
            vadNegativeThresholdValueDisplay.textContent = value.toFixed(2);
            type = 'negative';
        }
        if (type) {
            dispatchUIEvent('audioapp:thresholdChanged', {type: type, value: value});
        }
    }

    /**
     * Handles clicks on slider markers to set the slider value.
     * @private
     * @param {MouseEvent} event - The click event.
     * @param {HTMLInputElement|null} sliderElement - The slider element associated with the markers.
     */
    function handleMarkerClick(event, sliderElement) {
        if (!sliderElement || sliderElement.disabled) return;
        const target = /** @type {HTMLElement} */ (event.target);
        if (target.tagName === 'SPAN' && target.dataset.value) {
            const value = parseFloat(target.dataset.value);
            if (!isNaN(value)) {
                sliderElement.value = String(value);
                // Dispatch 'input' event to trigger associated listeners (e.g., value display update, app logic)
                sliderElement.dispatchEvent(new Event('input', {bubbles: true}));
            }
        }
    }

    /**
     * Gets the current gain value from the gain control slider.
     * @public
     * @returns {number} The current gain value (default is 1.0).
     */
    function getGainValue() {
        return gainControl ? parseFloat(gainControl.value) : 1.0;
    }

    /**
     * Sets the gain value on the UI slider and display.
     * @public
     * @param {number} value - The gain value to set.
     */
    function setGainValue(value) {
        if (gainControl) {
            gainControl.value = String(value);
        }
        if (gainValueDisplay) {
            const numericValue = parseFloat(String(value)); // Ensure it's a number
            gainValueDisplay.textContent = numericValue.toFixed(2) + 'x';
        }
    }

    /**
     * Gets the current value of the audio URL input field.
     * @public
     * @returns {string} The current value of the audio URL input.
     */
    function getAudioUrlInputValue() {
        return audioUrlInput ? audioUrlInput.value : "";
    }

    /**
     * Sets the value of the audio URL input field.
     * @public
     * @param {string} text The text to set as the value.
     */
    function setAudioUrlInputValue(text) {
        if (audioUrlInput) {
            audioUrlInput.value = text;
        }
    }

    /**
     * Sets the value of the jump time input field.
     * @public
     * @param {number|string} value The jump time value to set.
     */
    function setJumpTimeValue(value) {
        const inputElement = jumpTimeInput;
        if (inputElement) {
            const currentValue = parseFloat(inputElement.value);
            const newValue = parseFloat(String(value)); // Convert value to string first for robustness
            if (currentValue !== newValue && !isNaN(newValue)) {
                inputElement.value = String(newValue);
            }
        }
    }

    /**
     * Removes focus from the audio URL input field.
     * @public
     */
    function unfocusUrlInput() {
        if (audioUrlInput) {
            audioUrlInput.blur();
        }
    }

    /**
     * Dispatches a custom UI event.
     * @private
     * @param {string} eventName - The name of the event.
     * @param {Object<string, any>} [detail={}] - The detail object for the event.
     */
    function dispatchUIEvent(eventName, detail = {}) {
        document.dispatchEvent(new CustomEvent(eventName, {detail: detail}));
    }

    // --- Public Methods for Updating UI ---
    /**
     * Sets the error message for URL loading.
     * @public
     * @param {string} message - The error message to display.
     */
    function setUrlLoadingError(message) {
        if (urlLoadingErrorDisplay) {
            urlLoadingErrorDisplay.textContent = message;
        }
    }

    /**
     * Sets the visual style of the URL input field.
     * @public
     * @param {'success' | 'error' | 'file' | 'default' | 'modified'} styleType - The style to apply.
     */
    function setUrlInputStyle(styleType) {
        if (!audioUrlInput) return;
        audioUrlInput.classList.remove('url-style-success', 'url-style-error', 'url-style-file', 'url-style-default', 'url-style-modified');
        audioUrlInput.classList.add(`url-style-${styleType}`);
    }

    /**
     * Resets the entire UI to its initial state.
     * @public
     */
    function resetUI() {
        console.log("UIManager: Resetting UI");
        updateFileName("");
        setFileInfo("No file selected.");
        setPlayButtonState(false);
        updateTimeDisplay(0, 0);
        updateSeekBar(0);
        setSpeechRegionsText("None");
        updateVadDisplay(Constants.VAD.DEFAULT_POSITIVE_THRESHOLD, Constants.VAD.DEFAULT_NEGATIVE_THRESHOLD, true); // Reset VAD sliders and mark as N/A
        showVadProgress(false);
        updateVadProgress(0);
        if (dtmfDisplay) dtmfDisplay.textContent = "N/A";
        if (cptDisplayElement) cptDisplayElement.textContent = "N/A";
        if (urlLoadingErrorDisplay) urlLoadingErrorDisplay.textContent = "";
        setAudioUrlInputValue("");
        setUrlInputStyle('default');

        if (playbackSpeedControl && speedValueDisplay) {
            playbackSpeedControl.value = "1.0";
            speedValueDisplay.textContent = "1.00x";
        }
        if (pitchControl && pitchValueDisplay) {
            pitchControl.value = "1.0";
            pitchValueDisplay.textContent = "1.00x";
        }
        if (gainControl && gainValueDisplay) {
            gainControl.value = "1.0";
            gainValueDisplay.textContent = "1.00x";
        }
        if (jumpTimeInput) jumpTimeInput.value = "5";

        enableSeekBar(false);
        // Playback controls are typically enabled/disabled based on worklet readiness, not full reset.
    }

    /**
     * Updates the displayed file name.
     * @public
     * @param {string} text - The file name to display.
     */
    function updateFileName(text) {
        if (fileNameDisplay) {
            fileNameDisplay.textContent = text;
            fileNameDisplay.title = text;
        }
    }

    /**
     * Sets the general file information/status message.
     * @public
     * @param {string} text - The message to display.
     */
    function setFileInfo(text) {
        if (fileInfo) {
            fileInfo.textContent = text;
            fileInfo.title = text;
        }
    }

    /**
     * Sets the state of the play/pause button.
     * @public
     * @param {boolean} isPlaying - True if audio is playing, false otherwise.
     */
    function setPlayButtonState(isPlaying) {
        if (playPauseButton) playPauseButton.textContent = isPlaying ? 'Pause' : 'Play';
    }

    /**
     * Updates the time display (current time / duration).
     * @public
     * @param {number} currentTime - The current playback time in seconds.
     * @param {number} duration - The total duration of the audio in seconds.
     */
    function updateTimeDisplay(currentTime, duration) {
        if (timeDisplay && Utils) {
            timeDisplay.textContent = `${Utils.formatTime(currentTime)} / ${Utils.formatTime(duration)}`;
        } else if (timeDisplay) {
            timeDisplay.textContent = `Err / Err`; // Fallback if Utils is not available
        }
    }

    /**
     * Updates the position of the seek bar.
     * @public
     * @param {number} fraction - The progress fraction (0 to 1).
     */
    function updateSeekBar(fraction) {
        if (seekBar) {
            const clampedFraction = Math.max(0, Math.min(1, fraction));
            // Only update if significantly different to avoid fighting with user input
            if (Math.abs(parseFloat(seekBar.value) - clampedFraction) > 1e-6) {
                seekBar.value = String(clampedFraction);
            }
        }
    }

    /**
     * Sets the text content for the speech regions display.
     * @public
     * @param {string | Array<{start: number, end: number}>} regionsOrText - Either a string message or an array of speech region objects.
     */
    function setSpeechRegionsText(regionsOrText) {
        if (!speechRegionsDisplay) return;
        if (typeof regionsOrText === 'string') {
            speechRegionsDisplay.textContent = regionsOrText;
        } else if (Array.isArray(regionsOrText)) {
            if (regionsOrText.length > 0) {
                speechRegionsDisplay.textContent = regionsOrText.map(r => `Start: ${r.start.toFixed(2)}s, End: ${r.end.toFixed(2)}s`).join('\n');
            } else {
                speechRegionsDisplay.textContent = "No speech detected.";
            }
        } else {
            speechRegionsDisplay.textContent = "None"; // Default fallback
        }
    }

    /**
     * Updates the VAD threshold sliders and their value displays.
     * @public
     * @param {number} positive - The positive VAD threshold value.
     * @param {number} negative - The negative VAD threshold value.
     * @param {boolean} [isNA=false] - If true, sets displays to "N/A" and resets sliders to default.
     */
    function updateVadDisplay(positive, negative, isNA = false) {
        if (isNA) {
            if (vadThresholdValueDisplay) vadThresholdValueDisplay.textContent = "N/A";
            if (vadNegativeThresholdValueDisplay) vadNegativeThresholdValueDisplay.textContent = "N/A";
            if (vadThresholdSlider) vadThresholdSlider.value = String(Constants.VAD.DEFAULT_POSITIVE_THRESHOLD); // Default value
            if (vadNegativeThresholdSlider) vadNegativeThresholdSlider.value = String(Constants.VAD.DEFAULT_NEGATIVE_THRESHOLD); // Default value
        } else {
            if (vadThresholdSlider) vadThresholdSlider.value = String(positive);
            if (vadThresholdValueDisplay) vadThresholdValueDisplay.textContent = positive.toFixed(2);
            if (vadNegativeThresholdSlider) vadNegativeThresholdSlider.value = String(negative);
            if (vadNegativeThresholdValueDisplay) vadNegativeThresholdValueDisplay.textContent = negative.toFixed(2);
        }
    }

    /**
     * Enables or disables main playback controls.
     * @public
     * @param {boolean} enable - True to enable, false to disable.
     */
    function enablePlaybackControls(enable) {
        if (playPauseButton) playPauseButton.disabled = !enable;
        if (jumpBackButton) jumpBackButton.disabled = !enable;
        if (jumpForwardButton) jumpForwardButton.disabled = !enable;
        if (playbackSpeedControl) playbackSpeedControl.disabled = !enable;
        if (pitchControl) pitchControl.disabled = !enable;
        // Note: Gain control is typically always enabled.
    }

    /**
     * Enables or disables the seek bar.
     * @public
     * @param {boolean} enable - True to enable, false to disable.
     */
    function enableSeekBar(enable) {
        if (seekBar) seekBar.disabled = !enable;
    }

    /**
     * Enables or disables VAD threshold controls.
     * @public
     * @param {boolean} enable - True to enable, false to disable.
     */
    function enableVadControls(enable) {
        if (vadThresholdSlider) vadThresholdSlider.disabled = !enable;
        if (vadNegativeThresholdSlider) vadNegativeThresholdSlider.disabled = !enable;
        if (!enable) {
            updateVadDisplay(Constants.VAD.DEFAULT_POSITIVE_THRESHOLD, Constants.VAD.DEFAULT_NEGATIVE_THRESHOLD, true); // Reset display values to N/A and sliders to default if disabling
        }
    }

    /**
     * Updates the VAD progress bar percentage.
     * @public
     * @param {number} percentage - The progress percentage (0 to 100).
     */
    function updateVadProgress(percentage) {
        if (!vadProgressBar) return;
        const clampedPercentage = Math.max(0, Math.min(100, percentage));
        vadProgressBar.style.width = `${clampedPercentage}%`;
    }

    /**
     * Shows or hides the VAD progress bar container.
     * @public
     * @param {boolean} show - True to show, false to hide.
     */
    function showVadProgress(show) {
        if (!vadProgressContainer) return;
        vadProgressContainer.style.display = show ? 'block' : 'none';
    }

    /**
     * Shows the drop zone overlay with file information.
     * @public
     * @param {File} file The file being dragged over.
     */
    function showDropZone(file) {
        if (dropZoneOverlay && dropZoneMessage) {
            dropZoneOverlay.style.display = 'flex';
            // Assuming Utils.formatBytes is not available or moved, displaying size in bytes.
            dropZoneMessage.textContent = `File: ${file.name}, Size: ${file.size} bytes`;
            document.body.classList.add('blurred-background');
        }
    }

    /**
     * Hides the drop zone overlay.
     * @public
     */
    function hideDropZone() {
        if (dropZoneOverlay && dropZoneMessage) {
            dropZoneOverlay.style.display = 'none';
            dropZoneMessage.textContent = '';
            document.body.classList.remove('blurred-background');
        }
    }

    /**
     * Gets the current playback speed value.
     * @public
     * @returns {number} The current playback speed.
     */
    function getPlaybackSpeedValue() {
        return playbackSpeedControl ? parseFloat(playbackSpeedControl.value) : 1.0;
    }

    /**
     * Sets the playback speed value on the UI.
     * @public
     * @param {number} value - The playback speed to set.
     */
    function setPlaybackSpeedValue(value) {
        if (playbackSpeedControl) {
            playbackSpeedControl.value = String(value);
        }
        if (speedValueDisplay) {
            speedValueDisplay.textContent = parseFloat(String(value)).toFixed(2) + 'x';
        }
    }

    /**
     * Gets the current pitch value.
     * @public
     * @returns {number} The current pitch value.
     */
    function getPitchValue() {
        return pitchControl ? parseFloat(pitchControl.value) : 1.0;
    }

    /**
     * Sets the pitch value on the UI.
     * @public
     * @param {number} value - The pitch value to set.
     */
    function setPitchValue(value) {
        if (pitchControl) {
            pitchControl.value = String(value);
        }
        if (pitchValueDisplay) {
            pitchValueDisplay.textContent = parseFloat(String(value)).toFixed(2) + 'x';
        }
    }

    /**
     * Gets the current VAD positive threshold value.
     * @public
     * @returns {number} The current VAD positive threshold.
     */
    function getVadPositiveThresholdValue() {
        return vadThresholdSlider ? parseFloat(vadThresholdSlider.value) : Constants.VAD.DEFAULT_POSITIVE_THRESHOLD; // Default based on HTML
    }

    /**
     * Sets the VAD positive threshold value on the UI.
     * @public
     * @param {number} value - The VAD positive threshold to set.
     */
    function setVadPositiveThresholdValue(value) {
        if (vadThresholdSlider) {
            vadThresholdSlider.value = String(value);
        }
        if (vadThresholdValueDisplay) {
            vadThresholdValueDisplay.textContent = parseFloat(String(value)).toFixed(2);
        }
    }

    /**
     * Gets the current VAD negative threshold value.
     * @public
     * @returns {number} The current VAD negative threshold.
     */
    function getVadNegativeThresholdValue() {
        return vadNegativeThresholdSlider ? parseFloat(vadNegativeThresholdSlider.value) : Constants.VAD.DEFAULT_NEGATIVE_THRESHOLD; // Default based on HTML
    }

    /**
     * Sets the VAD negative threshold value on the UI.
     * @public
     * @param {number} value - The VAD negative threshold to set.
     */
    function setVadNegativeThresholdValue(value) {
        if (vadNegativeThresholdSlider) {
            vadNegativeThresholdSlider.value = String(value);
        }
        if (vadNegativeThresholdValueDisplay) {
            vadNegativeThresholdValueDisplay.textContent = parseFloat(String(value)).toFixed(2);
        }
    }

    /**
     * @typedef {Object} UIManagerPublicInterface
     * @property {function(): void} init
     * @property {function(): void} resetUI
     * @property {function(string): void} setFileInfo
     * @property {function(string): void} updateFileName
     * @property {function(boolean): void} setPlayButtonState
     * @property {function(number, number): void} updateTimeDisplay
     * @property {function(string|string[]): void} updateDtmfDisplay
     * @property {function(string[]): void} updateCallProgressTonesDisplay
     * @property {function(number): void} updateSeekBar
     * @property {function(string|Array<{start: number, end: number}>): void} setSpeechRegionsText
     * @property {function(number, number, boolean=): void} updateVadDisplay
     * @property {function(boolean): void} enablePlaybackControls
     * @property {function(boolean): void} enableSeekBar
     * @property {function(boolean): void} enableVadControls
     * @property {function(): number} getJumpTime
     * @property {function(number): void} updateVadProgress
     * @property {function(boolean): void} showVadProgress
     * @property {function(string): void} setUrlLoadingError
     * @property {function('success'|'error'|'file'|'default'|'modified'): void} setUrlInputStyle
     * @property {function(): void} unfocusUrlInput
     * @property {function(string): void} setAudioUrlInputValue
     * @property {function(): string} getAudioUrlInputValue
     * @property {function(number|string): void} setJumpTimeValue
     * @property {function(File): void} showDropZone
     * @property {function(): void} hideDropZone
     * @property {function(): number} getPlaybackSpeedValue
     * @property {function(): number} getPitchValue
     * @property {function(): number} getVadPositiveThresholdValue
     * @property {function(): number} getVadNegativeThresholdValue
     * @property {function(): number} getGainValue
     * @property {function(number): void} setPlaybackSpeedValue
     * @property {function(number): void} setPitchValue
     * @property {function(number): void} setVadPositiveThresholdValue
     * @property {function(number): void} setVadNegativeThresholdValue
     * @property {function(number): void} setGainValue
     */

    /** @type {UIManagerPublicInterface} */
    return {
        init: init,
        resetUI: resetUI,
        setFileInfo: setFileInfo,
        updateFileName: updateFileName,
        setPlayButtonState: setPlayButtonState,
        updateTimeDisplay: updateTimeDisplay,
        updateDtmfDisplay: updateDtmfDisplay,
        updateCallProgressTonesDisplay: updateCallProgressTonesDisplay,
        updateSeekBar: updateSeekBar,
        setSpeechRegionsText: setSpeechRegionsText,
        updateVadDisplay: updateVadDisplay,
        enablePlaybackControls: enablePlaybackControls,
        enableSeekBar: enableSeekBar,
        enableVadControls: enableVadControls,
        updateVadProgress: updateVadProgress,
        showVadProgress: showVadProgress,
        setUrlLoadingError: setUrlLoadingError,
        setUrlInputStyle: setUrlInputStyle,
        unfocusUrlInput: unfocusUrlInput,
        setAudioUrlInputValue: setAudioUrlInputValue,
        getAudioUrlInputValue: getAudioUrlInputValue,
        setJumpTimeValue: setJumpTimeValue,
        showDropZone: showDropZone,
        hideDropZone: hideDropZone,
        // New Getters
        getPlaybackSpeedValue: getPlaybackSpeedValue,
        getPitchValue: getPitchValue,
        getVadPositiveThresholdValue: getVadPositiveThresholdValue,
        getVadNegativeThresholdValue: getVadNegativeThresholdValue,
        getGainValue: getGainValue,
        // New Setters
        setPlaybackSpeedValue: setPlaybackSpeedValue,
        setPitchValue: setPitchValue,
        setVadPositiveThresholdValue: setVadPositiveThresholdValue,
        setVadNegativeThresholdValue: setVadNegativeThresholdValue,
        setGainValue: setGainValue
    };
})();
// --- /vibe-player/js/uiManager.js ---

````
--- End of File: vibe-player/js/uiManager.js ---
--- File: vibe-player/js/utils.js ---
````javascript
// --- /vibe-player/js/utils.js ---
// General utility functions for the Vibe Player application.

/** @namespace AudioApp */
var AudioApp = AudioApp || {}; // Ensure main namespace exists

/**
 * @namespace AudioApp.Utils
 * @description Provides utility functions for the Vibe Player application.
 */
AudioApp.Utils = (function () {
    'use strict';

    /**
     * Formats time in seconds to a mm:ss string.
     * @param {number} sec - Time in seconds.
     * @returns {string} Formatted time string (e.g., "0:00", "1:23").
     */
    function formatTime(sec) {
        if (isNaN(sec) || sec < 0) sec = 0;
        const minutes = Math.floor(sec / 60);
        const seconds = Math.floor(sec % 60);
        return `${minutes}:${seconds < 10 ? '0' + seconds : seconds}`;
    }

    /**
     * Helper function to yield control back to the main event loop.
     * Uses `setTimeout(resolve, 0)` inside a Promise.
     * @async
     * @returns {Promise<void>} Resolves on the next tick, allowing other microtasks/macrotasks to run.
     */
    async function yieldToMainThread() {
        return new Promise(resolve => setTimeout(resolve, 0));
    }

    /**
     * Generates a Hann window array for FFT.
     * The Hann window is a taper function used to reduce spectral leakage in FFT processing.
     * @param {number} length - The desired window length (number of samples). Must be a positive integer.
     * @returns {number[]|null} The Hann window array of the specified length, or null if length is invalid.
     * Each element is a float between 0 and 1.
     */
    function hannWindow(length) {
        if (length <= 0 || !Number.isInteger(length)) {
            console.error("Utils.hannWindow: Length must be a positive integer.");
            return null;
        }
        /** @type {number[]} */
        let windowArr = new Array(length);
        if (length === 1) {
            windowArr[0] = 1; // Single point window is 1
            return windowArr;
        }
        const denom = length - 1; // Denominator for the cosine argument
        for (let i = 0; i < length; i++) {
            windowArr[i] = 0.5 * (1 - Math.cos((2 * Math.PI * i) / denom));
        }
        return windowArr;
    }

    /**
     * Viridis colormap function. Maps a normalized value (0 to 1) to an RGB color.
     * The Viridis colormap is designed to be perceptually uniform.
     * @param {number} t - Normalized value (0 to 1). Values outside this range will be clamped.
     * @returns {number[]} Array containing [r, g, b] values (each 0-255).
     */
    function viridisColor(t) {
        /** @type {Array<Array<number>>} Colormap definition: [value, r, g, b] */
        const colors = [ // [normalized_value, R, G, B]
            [0.0, 68, 1, 84], [0.1, 72, 40, 120], [0.2, 62, 74, 137], [0.3, 49, 104, 142],
            [0.4, 38, 130, 142], [0.5, 31, 155, 137], [0.6, 53, 178, 126], [0.7, 109, 199, 104],
            [0.8, 170, 217, 70], [0.9, 235, 231, 35], [1.0, 253, 231, 37] // Last point
        ];
        t = Math.max(0, Math.min(1, t)); // Clamp t to [0, 1]

        /** @type {Array<number>} */ let c1 = colors[0];
        /** @type {Array<number>} */ let c2 = colors[colors.length - 1];

        for (let i = 0; i < colors.length - 1; i++) {
            if (t >= colors[i][0] && t <= colors[i + 1][0]) {
                c1 = colors[i];
                c2 = colors[i + 1];
                break;
            }
        }

        const range = c2[0] - c1[0];
        const ratio = (range === 0) ? 0 : (t - c1[0]) / range; // Avoid division by zero

        const r = Math.round(c1[1] + ratio * (c2[1] - c1[1]));
        const g = Math.round(c1[2] + ratio * (c2[2] - c1[2]));
        const b = Math.round(c1[3] + ratio * (c2[3] - c1[3]));
        return [r, g, b];
    }


    /**
     * Returns a function, that, as long as it continues to be invoked, will not
     * be triggered. The function will be called after it stops being called for
     * N milliseconds. If `immediate` is passed, trigger the function on the
     * leading edge, instead of the trailing.
     *
     * @template {Function} F
     * @param {F} func - The function to debounce.
     * @param {number} wait - The number of milliseconds to delay before invoking the function.
     * @param {boolean} [immediate=false] - If true, trigger the function on the leading edge instead of the trailing.
     * @returns {(...args: Parameters<F>) => void} The new debounced function.
     */
    function debounce(func, wait, immediate = false) {
        /** @type {number | undefined | null} */
        let timeout;
        // Using 'function' syntax for 'this' and 'arguments'
        return function executedFunction() {
            // @ts-ignore
            const context = this;
            const args = arguments; // arguments is not typed with ...args in JSDoc well

            const later = function () {
                timeout = null;
                if (!immediate) {
                    func.apply(context, args);
                }
            };

            const callNow = immediate && !timeout;
            clearTimeout(timeout);
            timeout = setTimeout(later, wait);

            if (callNow) {
                func.apply(context, args);
            }
        };
    }

    /**
     * @typedef {Object} UtilsPublicInterface
     * @property {function(number): string} formatTime - Formats time in seconds to mm:ss.
     * @property {function(): Promise<void>} yieldToMainThread - Yields control to the main event loop.
     * @property {function(number): (number[]|null)} hannWindow - Generates a Hann window array.
     * @property {function(number): number[]} viridisColor - Viridis colormap function.
     * @property {function(Function, number, boolean=): Function} debounce - Debounces a function.
     */

    /** @type {UtilsPublicInterface} */
    return {
        formatTime,
        yieldToMainThread,
        hannWindow,
        viridisColor,
        debounce
    };

})(); // End of AudioApp.Utils IIFE
// --- /vibe-player/js/utils.js ---

````
--- End of File: vibe-player/js/utils.js ---
--- File: vibe-player/js/vad/LocalWorkerStrategy.js ---
````javascript
// --- /vibe-player/js/vad/LocalWorkerStrategy.js ---
// This strategy handles VAD processing locally using a Web Worker.

/** @namespace AudioApp */
var AudioApp = AudioApp || {};

AudioApp.LocalWorkerStrategy = class {
    constructor() {
        this.worker = null;
        // Add a "ready" promise that resolves when the worker confirms model is loaded
        this.readyPromise = new Promise((resolve, reject) => {
            this._resolveReady = resolve;
            this._rejectReady = reject;
        });
    }

    init() {
        // Terminate any old worker to ensure a clean state.
        if (this.worker) {
            this.worker.terminate();
            // Re-create the promise for the new worker instance
            this.readyPromise = new Promise((resolve, reject) => {
                this._resolveReady = resolve;
                this._rejectReady = reject;
            });
        }

        // --- Step 1: Define the entire worker's code as a single string ---
        // This is the magic that makes it reliable. No more relative paths in importScripts!
        const workerScript = `
            // This code runs inside the worker.
            self.onmessage = async (event) => {
                const { type, payload } = event.data;

                if (type === 'init_and_load_scripts') {
                    // Use the absolute paths sent from the main thread.
                    const { basePath, onnxWasmPath, modelPath } = payload;
                    try {
                        // The 'basePath' ensures all these scripts load correctly.
                        importScripts(
                            basePath + 'js/state/constants.js', // Updated path
                            basePath + 'js/utils.js',
                            basePath + 'lib/ort.min.js', // Load ONNX runtime inside worker
                            basePath + 'js/vad/sileroWrapper.js',
                            basePath + 'js/vad/sileroProcessor.js'
                        );

                        // IMPORTANT: Tell the ONNX runtime where its own .wasm files are.
                        self.ort.env.wasm.wasmPaths = onnxWasmPath;

                        // Now, initialize the VAD model using the correct path.
                        const modelReady = await AudioApp.sileroWrapper.create(Constants.VAD.SAMPLE_RATE, modelPath);

                        if (modelReady) {
                            self.postMessage({ type: 'model_ready' });
                        } else {
                            self.postMessage({ type: 'error', payload: { message: "Failed to create Silero VAD model in worker." } });
                            throw new Error("Failed to create Silero VAD model in worker.");
                        }
                    } catch (e) {
                        self.postMessage({ type: 'error', payload: { message: 'Worker script import or init failed: ' + e.message } });
                    }

                } else if (type === 'analyze') {
                    const { pcmData } = payload;

                    // This callback will post progress messages back to the main thread.
                    const progressCallback = (progress) => {
                        self.postMessage({ type: 'progress', payload: progress });
                    };

                    try {
                        const vadResult = await AudioApp.sileroProcessor.analyzeAudio(pcmData, { onProgress: progressCallback });
                        self.postMessage({ type: 'result', payload: vadResult });
                    } catch(e) {
                         self.postMessage({ type: 'error', payload: { message: 'VAD analysis failed: ' + e.message } });
                    }
                }
            };
        `;

        // --- Step 2: Create the worker from a Blob URL ---
        // This avoids needing a separate .js file on disk for the worker code.
        const blob = new Blob([workerScript], {type: 'application/javascript'});
        this.worker = new Worker(URL.createObjectURL(blob));

        // Set up the onmessage handler for the worker HERE, specifically to listen for the 'model_ready' signal
        this.worker.onmessage = (event) => {
            const {type, payload} = event.data;
            if (type === 'model_ready') {
                console.log("LocalWorkerStrategy: Worker reported model is ready.");
                this._resolveReady(true); // Resolve the ready promise
            } else if (type === 'error') {
                // If an error happens during initialization, reject the ready promise
                this._rejectReady(new Error(payload.message));
            }
            // After initialization, subsequent messages will be handled by the promise in `analyze`
        };

        this.worker.onerror = (err) => {
            this._rejectReady(new Error(`VAD Worker initialization error: ${err.message}`));
        };


        // --- Step 3: Immediately send it the correct paths for initialization ---
        // The main thread knows where everything is relative to index.html.
        const pageUrl = new URL('.', window.location.href);
        this.worker.postMessage({
            type: 'init_and_load_scripts',
            payload: {
                basePath: pageUrl.href,
                onnxWasmPath: new URL('lib/', pageUrl).href, // Full path to the lib folder
                modelPath: new URL('model/silero_vad.onnx', pageUrl).href // Full path to the model
            }
        });
    }

    async analyze(pcmData, options) {
        // First, AWAIT the ready promise. This ensures init is complete.
        await this.readyPromise;

        if (!this.worker) {
            return Promise.reject(new Error("VAD worker has not been initialized."));
        }

        // This returns a Promise that will resolve or reject when the worker sends back a final message.
        return new Promise((resolve, reject) => {
            // Set the message handler for this specific analysis task
            this.worker.onmessage = (event) => {
                const {type, payload} = event.data;
                if (type === 'result') {
                    resolve(payload); // Analysis was successful.
                } else if (type === 'progress') {
                    // Forward progress updates to the main app if a callback was provided.
                    if (options.onProgress) {
                        options.onProgress(payload);
                    }
                } else if (type === 'error') {
                    reject(new Error(payload.message)); // Analysis failed in the worker.
                }
            };

            this.worker.onerror = (err) => {
                reject(new Error(`VAD Worker Error: ${err.message}`));
            };

            // Send the audio data to the worker to start analysis.
            // The second argument `[pcmData.buffer]` is a Transferable object.
            // This is a very fast, zero-copy transfer of the data to the worker.
            this.worker.postMessage({
                type: 'analyze',
                payload: {pcmData}
            }, [pcmData.buffer]);
        });
    }

    terminate() {
        if (this.worker) {
            this.worker.terminate();
            this.worker = null;
            console.log("LocalWorkerStrategy: Worker terminated.");
        }
    }
};

````
--- End of File: vibe-player/js/vad/LocalWorkerStrategy.js ---
--- File: vibe-player/js/vad/RemoteApiStrategy.js ---
````javascript
// --- /vibe-player/js/vad/RemoteApiStrategy.js ---
// This strategy will handle VAD by calling an external API.
// It is currently a placeholder.

/** @namespace AudioApp */
var AudioApp = AudioApp || {};

AudioApp.RemoteApiStrategy = class {
    init() {
        console.log("Remote VAD API Strategy Initialized.");
        // In the future, you might initialize API keys or settings here.
    }

    async analyze(pcmData, options) {
        console.log("RemoteApiStrategy: analyze called.");
        // In the future, this is where you would use `fetch` to send pcmData to your API.
        // For now, we return an empty result so the app doesn't break if you test it.
        alert('VAD is configured to use the Remote API, which is not yet implemented.');
        return Promise.resolve({
            regions: [],
            probabilities: new Float32Array(),
            // ... and other properties to match the VadResult structure
        });
    }

    terminate() {
        // In the future, you could use an AbortController here to cancel a `fetch` request.
        console.log("Remote VAD API Strategy Terminated.");
    }
};

````
--- End of File: vibe-player/js/vad/RemoteApiStrategy.js ---
--- File: vibe-player/js/vad/sileroProcessor.js ---
````javascript
// --- /vibe-player/js/vad/sileroProcessor.js --- // Updated Path
// Performs VAD analysis frame-by-frame using the SileroWrapper.
// Encapsulates the logic for iterating through audio data and calculating speech regions.

/** @namespace AudioApp */
var AudioApp = AudioApp || {};

/**
 * @namespace AudioApp.sileroProcessor
 * @description Processes audio data using the Silero VAD model via a wrapper.
 * Provides functions to analyze audio for speech regions and recalculate them with different thresholds.
 * @param {AudioApp.sileroWrapper} wrapper - The Silero VAD wrapper module.
 */
AudioApp.sileroProcessor = (function (wrapper) {
    'use strict';

    /**
     * @private
     * @type {AudioApp.Constants} Reference to the Constants module.
     */
    // const Constants = AudioApp.Constants; // Constants is now a global class
    /**
     * @private
     * @type {AudioApp.Utils} Reference to the Utils module.
     */
    const Utils = AudioApp.Utils;

    if (!wrapper || typeof wrapper.isAvailable !== 'function' || !wrapper.isAvailable()) {
        console.error("SileroProcessor: CRITICAL - AudioApp.sileroWrapper is not available or not functional!");
        /** @type {SileroProcessorPublicInterface} */
        const nonFunctionalInterface = {
            analyzeAudio: () => Promise.reject(new Error("Silero VAD Wrapper not available")),
            recalculateSpeechRegions: () => {
                console.error("SileroProcessor: Cannot recalculate, VAD wrapper not available.");
                return [];
            }
        };
        return nonFunctionalInterface;
    }
    if (typeof Constants === 'undefined') {
        console.error("SileroProcessor: CRITICAL - Constants class not available!");
        /** @type {SileroProcessorPublicInterface} */
        const errorInterface = {
            analyzeAudio: () => Promise.reject(new Error("Constants class not available")),
            recalculateSpeechRegions: () => []
        };
        return errorInterface;
    }
    if (!Utils) {
        console.error("SileroProcessor: CRITICAL - AudioApp.Utils not available!");
        /** @type {SileroProcessorPublicInterface} */
        const errorInterface = {
            analyzeAudio: () => Promise.reject(new Error("Utils not available")),
            recalculateSpeechRegions: () => []
        };
        return errorInterface;
    }

    /**
     * @typedef {object} VadRegion
     * @property {number} start - Start time of the speech region in seconds.
     * @property {number} end - End time of the speech region in seconds.
     */

    /**
     * @typedef {object} VadAnalysisOptions
     * @property {number} [frameSamples=AudioApp.Constants.DEFAULT_VAD_FRAME_SAMPLES] - Number of samples per VAD frame.
     * @property {number} [positiveSpeechThreshold=0.5] - Probability threshold to start or continue a speech segment.
     * @property {number} [negativeSpeechThreshold] - Probability threshold to consider stopping speech. Defaults to `positiveSpeechThreshold - 0.15`.
     * @property {number} [redemptionFrames=7] - Number of consecutive frames below `negativeSpeechThreshold` needed to end a speech segment.
     * @property {string} [modelPath] - Path to the ONNX VAD model (typically handled by the wrapper).
     * @property {function({processedFrames: number, totalFrames: number}): void} [onProgress] - Optional callback for progress updates.
     */

    /**
     * @typedef {object} VadResult
     * @property {VadRegion[]} regions - Array of detected speech regions.
     * @property {Float32Array} probabilities - Raw probability for each processed frame.
     * @property {number} frameSamples - Frame size (in samples) used in the analysis.
     * @property {number} sampleRate - Sample rate of the audio data used (should be `AudioApp.Constants.VAD_SAMPLE_RATE`).
     * @property {number} initialPositiveThreshold - The positive speech threshold used for this result.
     * @property {number} initialNegativeThreshold - The negative speech threshold used for this result.
     * @property {number} redemptionFrames - The number of redemption frames used for this result.
     */

    /**
     * Analyzes 16kHz mono PCM audio data for speech regions using the Silero VAD model.
     * @public
     * @async
     * @param {Float32Array} pcmData - The 16kHz mono Float32Array audio data.
     * @param {VadAnalysisOptions} [options={}] - VAD parameters and callback.
     * @returns {Promise<VadResult>} A promise resolving to the VAD results.
     * @throws {Error} If analysis fails (e.g., wrapper error, invalid input data).
     */
    async function analyzeAudio(pcmData, options = {}) {
        if (!(pcmData instanceof Float32Array)) {
            console.warn("SileroProcessor: VAD input data is not Float32Array. Attempting conversion.");
            try {
                pcmData = new Float32Array(pcmData);
            } catch (e) {
                const err = /** @type {Error} */ (e);
                console.error("SileroProcessor: Failed to convert VAD input data to Float32Array.", err);
                throw new Error(`VAD input data must be a Float32Array or convertible: ${err.message}`);
            }
        }

        const frameSamples = options.frameSamples || Constants.VAD.DEFAULT_FRAME_SAMPLES;
        const positiveThreshold = options.positiveSpeechThreshold !== undefined ? options.positiveSpeechThreshold : 0.5;
        const negativeThreshold = options.negativeSpeechThreshold !== undefined ? options.negativeSpeechThreshold : Math.max(0.01, positiveThreshold - 0.15);
        const redemptionFrames = options.redemptionFrames !== undefined ? options.redemptionFrames : 7;
        const onProgress = typeof options.onProgress === 'function' ? options.onProgress : () => {
        };

        if (!pcmData || pcmData.length === 0 || frameSamples <= 0) {
            console.log("SileroProcessor: No audio data or invalid frame size for VAD analysis.");
            // Ensure onProgress is called even for empty data, to complete any UI state
            setTimeout(() => onProgress({processedFrames: 0, totalFrames: 0}), 0);
            /** @type {VadResult} */
            const emptyResult = {
                regions: [], probabilities: new Float32Array(),
                frameSamples: frameSamples, sampleRate: Constants.VAD.SAMPLE_RATE,
                initialPositiveThreshold: positiveThreshold, initialNegativeThreshold: negativeThreshold,
                redemptionFrames: redemptionFrames
            };
            return emptyResult;
        }

        try {
            wrapper.reset_state();
        } catch (e) {
            const err = /** @type {Error} */ (e);
            console.error("SileroProcessor: Error resetting VAD state via wrapper:", err);
            throw new Error(`Failed to reset Silero VAD state: ${err.message}`);
        }

        /** @type {number[]} */ const allProbabilities = [];
        const totalFrames = Math.floor(pcmData.length / frameSamples);
        let processedFrames = 0;
        const startTime = performance.now();

        try {
            for (let i = 0; (i + frameSamples) <= pcmData.length; i += frameSamples) {
                const frame = pcmData.slice(i, i + frameSamples);
                const probability = await wrapper.process(frame);
                allProbabilities.push(probability);
                processedFrames++;

                if (processedFrames === 1 || processedFrames === totalFrames || (processedFrames % Constants.VAD.PROGRESS_REPORT_INTERVAL === 0)) {
                    onProgress({processedFrames, totalFrames});
                }
                if (processedFrames % Constants.VAD.YIELD_INTERVAL === 0 && processedFrames < totalFrames) {
                    await Utils.yieldToMainThread();
                }
            }
        } catch (e) {
            const err = /** @type {Error} */ (e);
            console.error(`SileroProcessor: Error during VAD frame processing after ${((performance.now() - startTime) / 1000).toFixed(2)}s:`, err);
            setTimeout(() => onProgress({processedFrames, totalFrames}), 0); // Final progress update on error
            throw new Error(`VAD inference failed: ${err.message}`);
        }
        console.log(`SileroProcessor: VAD analysis of ${totalFrames} frames took ${((performance.now() - startTime) / 1000).toFixed(2)}s.`);
        setTimeout(() => onProgress({processedFrames, totalFrames}), 0); // Ensure final progress is reported

        const probabilities = new Float32Array(allProbabilities);
        const initialRegions = recalculateSpeechRegions(probabilities, {
            frameSamples, sampleRate: Constants.VAD.SAMPLE_RATE,
            positiveSpeechThreshold: positiveThreshold, negativeSpeechThreshold: negativeThreshold,
            redemptionFrames
        });
        console.log(`SileroProcessor: Initially detected ${initialRegions.length} speech regions.`);

        /** @type {VadResult} */
        const result = {
            regions: initialRegions, probabilities, frameSamples,
            sampleRate: Constants.VAD.SAMPLE_RATE,
            initialPositiveThreshold: positiveThreshold, initialNegativeThreshold: negativeThreshold,
            redemptionFrames
        };
        return result;
    }

    /**
     * @typedef {object} RecalculateOptions
     * @property {number} frameSamples - Samples per frame used during original analysis.
     * @property {number} sampleRate - Sample rate used (should be `AudioApp.Constants.VAD_SAMPLE_RATE`).
     * @property {number} positiveSpeechThreshold - Current positive threshold (e.g., from UI slider).
     * @property {number} negativeSpeechThreshold - Current negative threshold.
     * @property {number} redemptionFrames - Redemption frames value used.
     */

    /**
     * Recalculates speech regions from stored probabilities using potentially new thresholds.
     * Does not re-run the VAD model; operates only on the probability array.
     * @public
     * @param {Float32Array} probabilities - Probabilities for each frame from `analyzeAudio`.
     * @param {RecalculateOptions} options - Parameters for recalculation.
     * @returns {VadRegion[]} Newly calculated speech regions.
     */
    function recalculateSpeechRegions(probabilities, options) {
        const {frameSamples, sampleRate, positiveSpeechThreshold, negativeSpeechThreshold, redemptionFrames} = options;

        if (sampleRate !== Constants.VAD.SAMPLE_RATE) {
            console.warn(`SileroProcessor: Recalculating speech regions with sample rate ${sampleRate}, which differs from the expected VAD constant ${Constants.VAD.SAMPLE_RATE}. This may lead to incorrect timing if frameSamples is based on the original rate.`);
        }
        if (!probabilities || probabilities.length === 0 || !frameSamples || !sampleRate ||
            positiveSpeechThreshold === undefined || negativeSpeechThreshold === undefined || redemptionFrames === undefined) {
            console.warn("SileroProcessor: Invalid arguments for recalculateSpeechRegions. Returning empty array.", options);
            return [];
        }

        /** @type {VadRegion[]} */ const newRegions = [];
        let inSpeech = false;
        let regionStart = 0.0;
        let redemptionCounter = 0;

        for (let i = 0; i < probabilities.length; i++) {
            const probability = probabilities[i];
            const frameStartTime = (i * frameSamples) / sampleRate;

            if (probability >= positiveSpeechThreshold) {
                if (!inSpeech) {
                    inSpeech = true;
                    regionStart = frameStartTime;
                }
                redemptionCounter = 0; // Reset redemption if speech detected
            } else if (inSpeech) { // Only apply redemption logic if we were in speech
                if (probability < negativeSpeechThreshold) {
                    redemptionCounter++;
                    if (redemptionCounter >= redemptionFrames) {
                        // End of speech segment detected
                        const triggerFrameIndex = i - redemptionFrames + 1; // Frame that triggered end
                        const actualEnd = (triggerFrameIndex * frameSamples) / sampleRate;
                        const finalEnd = Math.max(regionStart, actualEnd); // Ensure end is not before start
                        newRegions.push({start: regionStart, end: finalEnd});
                        inSpeech = false;
                        redemptionCounter = 0;
                    }
                } else { // Probability is between negative and positive thresholds
                    redemptionCounter = 0; // Reset redemption if not strictly below negative threshold
                }
            }
        }
        if (inSpeech) { // If speech segment was active at the end of probabilities
            const finalEnd = (probabilities.length * frameSamples) / sampleRate;
            newRegions.push({start: regionStart, end: finalEnd});
        }
        return newRegions;
    }

    /**
     * @typedef {Object} SileroProcessorPublicInterface
     * @property {function(Float32Array, VadAnalysisOptions=): Promise<VadResult>} analyzeAudio
     * @property {function(Float32Array, RecalculateOptions): VadRegion[]} recalculateSpeechRegions
     */

    /** @type {SileroProcessorPublicInterface} */
    return {
        analyzeAudio: analyzeAudio,
        recalculateSpeechRegions: recalculateSpeechRegions
    };

})(AudioApp.sileroWrapper);
// --- /vibe-player/js/vad/sileroProcessor.js --- // Updated Path

````
--- End of File: vibe-player/js/vad/sileroProcessor.js ---
--- File: vibe-player/js/vad/sileroWrapper.js ---
````javascript
// --- /vibe-player/js/vad/sileroWrapper.js --- // Updated Path
// Wraps the ONNX Runtime session for the Silero VAD model.
// Manages ONNX session creation, state tensors, and inference calls.

/** @namespace AudioApp */
var AudioApp = AudioApp || {};

/**
 * @namespace AudioApp.sileroWrapper
 * @description Wraps the ONNX Runtime session for the Silero VAD (Voice Activity Detection) model.
 * This module handles the creation of an ONNX inference session, manages the model's
 * recurrent state tensors (h, c), and provides methods to process audio frames for VAD.
 * @param {object} globalOrt - The global ONNX Runtime object (typically `window.ort`).
 */
AudioApp.sileroWrapper = (function (globalOrt) {
    'use strict';

    if (!globalOrt) {
        console.error("SileroWrapper: CRITICAL - ONNX Runtime (ort) object not found globally!");
        /** @type {SileroWrapperPublicInterface} */
        const nonFunctionalInterface = {
            create: () => Promise.resolve(false),
            process: () => Promise.reject(new Error("ONNX Runtime not available")),
            reset_state: () => {
                console.error("SileroWrapper: ONNX Runtime not available, cannot reset state.");
            },
            isAvailable: () => false // Changed to a function
        };
        return nonFunctionalInterface;
    }

    /** @type {ort.InferenceSession|null} The ONNX inference session. */
    let session = null;
    /** @type {ort.Tensor|null} Tensor holding the sample rate (e.g., 16000), required as int64 by some models. */
    let sampleRateTensor = null;
    /** @type {ort.Tensor|null} Hidden state 'c' tensor for the VAD model's RNN. */
    let state_c = null;
    /** @type {ort.Tensor|null} Hidden state 'h' tensor for the VAD model's RNN. */
    let state_h = null;

    /**
     * @const
     * @private
     * @type {number[]} Standard Silero state tensor dimensions: [num_layers*num_directions, batch_size, hidden_size].
     * Example: [2*1, 1, 64] for a common configuration.
     */
    const stateDims = [2, 1, 64];
    /**
     * @const
     * @private
     * @type {number} Total number of elements in a state tensor (product of stateDims).
     */
    const stateSize = stateDims.reduce((a, b) => a * b, 1); // Calculate product of dimensions


    /**
     * Creates and loads the Silero VAD ONNX InferenceSession.
     * This function is idempotent; it will only create the session once.
     * It also initializes or resets the model's recurrent state tensors.
     * @public
     * @async
     * @param {number} sampleRate - The sample rate required by the model (e.g., 16000 Hz).
     * @param {string} [uri='./model/silero_vad.onnx'] - Path to the ONNX model file.
     * @returns {Promise<boolean>} True if the session is ready, false on failure.
     */
    async function create(sampleRate, uri = './model/silero_vad.onnx') {
        if (session) {
            console.log("SileroWrapper: Session already exists. Resetting state for potential new audio stream.");
            try {
                reset_state();
            } catch (e) {
                console.warn("SileroWrapper: Error resetting state for existing session:", e);
            }
            return true;
        }

        /** @type {ort.InferenceSession.SessionOptions} */
        const opt = {
            executionProviders: ["wasm"],
            logSeverityLevel: 3, // 0:Verbose, 1:Info, 2:Warning, 3:Error, 4:Fatal
            logVerbosityLevel: 3, // Corresponds to logSeverityLevel for most cases
            wasm: {
                wasmPaths: 'lib/' // Path to ort-wasm.wasm, ort-wasm-simd.wasm etc. relative to HTML
            }
        };

        try {
            console.log(`SileroWrapper: Creating ONNX InferenceSession from URI: ${uri} with options:`, JSON.stringify(opt));
            session = await globalOrt.InferenceSession.create(uri, opt);
            // Sample rate tensor needs to be int64 for some Silero models
            sampleRateTensor = new globalOrt.Tensor("int64", [BigInt(sampleRate)], [1]); // Shape [1] for scalar
            reset_state(); // Initialize state tensors
            console.log("SileroWrapper: ONNX session and initial states created successfully.");
            return true;
        } catch (e) {
            const err = /** @type {Error} */ (e);
            console.error("SileroWrapper: Failed to create ONNX InferenceSession:", err.message, err.stack);
            if (err.message.includes("WebAssembly") || err.message.includes(".wasm")) {
                console.error("SileroWrapper: Hint - Ensure ONNX WASM files (e.g., ort-wasm.wasm) are in the 'lib/' folder and served correctly by the web server.");
            }
            session = null; // Ensure session is null if creation fails
            return false;
        }
    }

    /**
     * Resets the hidden state tensors (h, c) of the VAD model to zero.
     * This should be called before processing a new independent audio stream.
     * @public
     * @throws {Error} If the ONNX Runtime `ort.Tensor` constructor is not available.
     */
    function reset_state() {
        if (!globalOrt?.Tensor) {
            console.error("SileroWrapper: Cannot reset state - ONNX Runtime (ort.Tensor) is not available.");
            state_c = null;
            state_h = null; // Prevent further errors if process is called
            throw new Error("ONNX Runtime Tensor constructor not available. Silero VAD cannot function.");
        }
        try {
            state_c = new globalOrt.Tensor("float32", new Float32Array(stateSize).fill(0.0), stateDims);
            state_h = new globalOrt.Tensor("float32", new Float32Array(stateSize).fill(0.0), stateDims);
        } catch (tensorError) {
            const err = /** @type {Error} */ (tensorError);
            console.error("SileroWrapper: Error creating zero-filled state tensors:", err.message, err.stack);
            state_c = null;
            state_h = null; // Invalidate state on error
            throw err; // Re-throw to indicate failure
        }
    }

    /**
     * Processes a single audio frame through the Silero VAD model.
     * `create()` must have been successfully called before using this method.
     * The internal recurrent state of the model is updated after each call.
     * @public
     * @async
     * @param {Float32Array} audioFrame - A Float32Array of audio samples for one frame (e.g., 1536 samples at 16kHz).
     * @returns {Promise<number>} The VAD probability score (0.0 to 1.0) for the frame.
     * @throws {Error} If the session is not initialized, state tensors are missing, input is invalid, or inference fails.
     */
    async function process(audioFrame) {
        if (!session || !state_c || !state_h || !sampleRateTensor) {
            throw new Error("SileroWrapper: VAD session or state not initialized. Call create() and ensure it succeeds before processing audio.");
        }
        if (!(audioFrame instanceof Float32Array)) {
            throw new Error(`SileroWrapper: Input audioFrame must be a Float32Array, but received type ${typeof audioFrame}.`);
        }

        try {
            const inputTensor = new globalOrt.Tensor("float32", audioFrame, [1, audioFrame.length]); // Shape: [batch_size=1, num_samples]
            /** @type {Record<string, ort.Tensor>} */
            const feeds = {
                input: inputTensor,
                h: state_h,
                c: state_c,
                sr: sampleRateTensor
            };

            const outputMap = await session.run(feeds);

            if (outputMap.hn && outputMap.cn) { // 'hn' and 'cn' are typical output names for new states
                state_h = outputMap.hn;
                state_c = outputMap.cn;
            } else {
                console.warn("SileroWrapper: Model outputs 'hn' and 'cn' for recurrent state update were not found. Subsequent VAD results may be incorrect.");
            }

            // The primary VAD probability is typically named 'output'
            if (outputMap.output?.data instanceof Float32Array && typeof outputMap.output.data[0] === 'number') {
                return outputMap.output.data[0];
            } else {
                console.error("SileroWrapper: Unexpected model output structure. 'output' tensor with numeric data not found. Actual output:", outputMap);
                throw new Error("SileroWrapper: Invalid model output structure for VAD probability.");
            }
        } catch (e) {
            const err = /** @type {Error} */ (e);
            console.error("SileroWrapper: ONNX session run (inference) failed:", err.message, err.stack);
            // Consider whether to reset state here or let the caller decide. For now, re-throw.
            throw err;
        }
    }

    /**
     * Checks if the Silero VAD wrapper is available and operational (ONNX Runtime loaded).
     * @public
     * @returns {boolean} True if available, false otherwise.
     */
    function isAvailable() {
        return !!globalOrt;
    }

    /**
     * @typedef {Object} SileroWrapperPublicInterface
     * @property {function(number, string=): Promise<boolean>} create - Creates the ONNX session.
     * @property {function(Float32Array): Promise<number>} process - Processes an audio frame.
     * @property {function(): void} reset_state - Resets the model's recurrent state.
     * @property {function(): boolean} isAvailable - Checks if the ONNX runtime is available.
     */

    /** @type {SileroWrapperPublicInterface} */
    return {
        create: create,
        process: process,
        reset_state: reset_state,
        isAvailable: isAvailable // Changed to a function
    };

})(self.ort);
// --- /vibe-player/js/vad/sileroWrapper.js --- // Updated Path

````
--- End of File: vibe-player/js/vad/sileroWrapper.js ---
--- File: vibe-player/js/vad/vadAnalyzer.js ---
````javascript
// --- /vibe-player/js/vad/vadAnalyzer.js --- (REFACTORED)
// Manages the VAD strategy. The rest of the app talks to this module.

/** @namespace AudioApp */
var AudioApp = AudioApp || {};

AudioApp.vadAnalyzer = (function () {
    'use strict';

    // --- CONFIGURATION ---
    // To switch to the API, you will only have to change this line to 'api'.
    const VAD_MODE = 'local';

    let currentStrategy = null;

    // Initializes the chosen VAD strategy.
    function init() {
        if (currentStrategy?.terminate) {
            currentStrategy.terminate();
        }

        console.log(`VadAnalyzer: Initializing VAD with '${VAD_MODE}' strategy.`);
        if (VAD_MODE === 'local') {
            currentStrategy = new AudioApp.LocalWorkerStrategy();
        } else if (VAD_MODE === 'api') {
            currentStrategy = new AudioApp.RemoteApiStrategy();
        } else {
            console.error(`Unknown VAD_MODE: ${VAD_MODE}`);
            return;
        }
        currentStrategy.init();
    }

    // Delegates the analysis call to whatever strategy is active.
    async function analyze(pcmData, options = {}) {
        if (!currentStrategy) {
            throw new Error("VAD Analyzer not initialized. Call init() first.");
        }
        return currentStrategy.analyze(pcmData, options);
    }

    // The rest of the public methods have been removed for simplicity, as they were
    // tied to the old, stateful implementation. The `app.js` logic will be updated
    // to handle results directly from the `analyze` promise.

    return {
        init: init,
        analyze: analyze
    };
})();

````
--- End of File: vibe-player/js/vad/vadAnalyzer.js ---
--- File: vibe-player/js/visualizers/spectrogram.worker.js ---
````javascript
// --- /vibe-player/js/visualizers/spectrogram.worker.js ---
// This worker handles the computationally intensive task of calculating the spectrogram.

// 1. Import Dependencies
try {
    // These paths are relative to this worker file's location.
    importScripts('../../lib/fft.js', '../state/constants.js', '../utils.js'); // Updated path for constants
} catch (e) {
    console.error("Spectrogram Worker: Failed to import scripts.", e);
    self.postMessage({type: 'error', detail: 'Worker script import failed.'});
}

// 2. Listen for Messages
self.onmessage = (event) => {
    // Verify that dependencies loaded correctly before proceeding.
    // Check for global Constants class directly on self
    if (typeof self.FFT === 'undefined' || typeof self.Constants === 'undefined' || typeof self.AudioApp?.Utils === 'undefined') {
        let missing = [];
        if (typeof self.FFT === 'undefined') missing.push('FFT');
        if (typeof self.Constants === 'undefined') missing.push('Constants');
        if (typeof self.AudioApp?.Utils === 'undefined') missing.push('AudioApp.Utils');
        self.postMessage({type: 'error', detail: `Worker dependencies are missing: ${missing.join(', ')}.`});
        return;
    }

    const {type, payload} = event.data;

    if (type === 'compute') {
        try {
            const {channelData, sampleRate, duration, fftSize, targetSlices} = payload;

            // Access the globally loaded scripts via the 'self' scope.
            // Constants is now directly on self.
            const Utils = self.AudioApp.Utils; // Utils is still under AudioApp namespace for now
            const FFT = self.FFT;

            // 3. Run Computation
            const spectrogramData = computeSpectrogram(channelData, sampleRate, duration, fftSize, targetSlices, FFT, self.Constants, Utils);

            // 4. Post Result Back (with Transferable objects for performance)
            if (spectrogramData) {
                const transferable = spectrogramData.map(arr => arr.buffer);
                self.postMessage({type: 'result', payload: {spectrogramData}}, transferable);
            } else {
                self.postMessage({type: 'result', payload: {spectrogramData: []}}); // Send empty result
            }
        } catch (e) {
            console.error('Spectrogram Worker: Error during computation.', e);
            self.postMessage({type: 'error', detail: e.message});
        }
    }
};

// THIS FUNCTION IS A DIRECT COPY FROM THE ORIGINAL spectrogramVisualizer.js
function computeSpectrogram(channelData, sampleRate, duration, actualFftSize, targetSlices, FFTConstructor, ConstantsGlobal, Utils) {
    if (!channelData) {
        console.error("Worker: Invalid channelData.");
        return null;
    }
    const totalSamples = channelData.length;
    const hopDivisor = duration < ConstantsGlobal.Visualizer.SPEC_SHORT_FILE_HOP_THRESHOLD_S ? ConstantsGlobal.Visualizer.SPEC_SHORT_HOP_DIVISOR : ConstantsGlobal.Visualizer.SPEC_NORMAL_HOP_DIVISOR;
    const hopSize = Math.max(1, Math.floor(actualFftSize / hopDivisor));
    const padding = ConstantsGlobal.Visualizer.SPEC_CENTER_WINDOWS ? Math.floor(actualFftSize / 2) : 0;
    const rawSliceCount = ConstantsGlobal.Visualizer.SPEC_CENTER_WINDOWS ? Math.ceil(totalSamples / hopSize)
        : (totalSamples < actualFftSize ? 0 : Math.floor((totalSamples - actualFftSize) / hopSize) + 1);

    if (rawSliceCount <= 0) {
        console.warn("Worker: Not enough audio samples for FFT.");
        return [];
    }

    const fftInstance = new FFTConstructor(actualFftSize, sampleRate);
    const complexBuffer = fftInstance.createComplexArray();
    const fftInput = new Array(actualFftSize);
    const windowFunc = Utils.hannWindow(actualFftSize);
    if (!windowFunc) {
        console.error("Worker: Failed to generate Hann window.");
        return null;
    }

    const rawSpec = [];
    for (let i = 0; i < rawSliceCount; i++) {
        const windowCenterSample = i * hopSize;
        const windowFetchStart = windowCenterSample - padding;
        for (let j = 0; j < actualFftSize; j++) {
            const sampleIndex = windowFetchStart + j;
            let sampleValue = 0.0;
            if (sampleIndex >= 0 && sampleIndex < totalSamples) {
                sampleValue = channelData[sampleIndex];
            } else if (sampleIndex < 0) {
                sampleValue = totalSamples > 0 ? channelData[0] : 0.0;
            } else {
                sampleValue = totalSamples > 0 ? channelData[totalSamples - 1] : 0.0;
            }
            fftInput[j] = sampleValue * windowFunc[j];
        }
        fftInstance.realTransform(complexBuffer, fftInput);
        const numBins = actualFftSize / 2;
        const magnitudes = new Float32Array(numBins);
        for (let k = 0; k < numBins; k++) {
            const re = complexBuffer[k * 2], im = complexBuffer[k * 2 + 1];
            magnitudes[k] = Math.sqrt(re * re + im * im);
        }
        rawSpec.push(magnitudes);
    }

    if (rawSpec.length === 0) return [];
    if (rawSpec.length === targetSlices) return rawSpec;

    const numFreqBins = rawSpec[0].length;
    const finalSpec = new Array(targetSlices);
    for (let i = 0; i < targetSlices; i++) {
        const rawPos = (rawSpec.length > 1) ? (i / (targetSlices - 1)) * (rawSpec.length - 1) : 0;
        const index1 = Math.floor(rawPos);
        const index2 = Math.min(rawSpec.length - 1, Math.ceil(rawPos));
        const factor = rawPos - index1;
        const magnitudes1 = rawSpec[index1], magnitudes2 = rawSpec[index2];
        finalSpec[i] = new Float32Array(numFreqBins);
        if (index1 === index2 || factor === 0) {
            finalSpec[i].set(magnitudes1);
        } else {
            for (let k = 0; k < numFreqBins; k++) {
                finalSpec[i][k] = magnitudes1[k] * (1.0 - factor) + magnitudes2[k] * factor;
            }
        }
    }
    return finalSpec;
}
````
--- End of File: vibe-player/js/visualizers/spectrogram.worker.js ---
--- File: vibe-player/js/visualizers/spectrogramVisualizer.js ---
````javascript
// --- /vibe-player/js/visualizers/spectrogramVisualizer.js --- (CORRECTED)
// Handles orchestrating the Spectrogram worker and rendering the results to a canvas.

AudioApp.spectrogramVisualizer = (function (globalFFT) {
    'use strict';

    // Constants is now a global class, AudioApp.Constants is no longer used.
    const Utils = AudioApp.Utils;

    // DOM Elements
    let spectrogramCanvas = null, spectrogramCtx = null, spectrogramSpinner = null,
        spectrogramProgressIndicator = null, cachedSpectrogramCanvas = null;

    let getSharedAudioBuffer = null;
    let currentMaxFreqIndex = Constants.Visualizer.SPEC_DEFAULT_MAX_FREQ_INDEX;
    let worker = null;
    let lastAudioBuffer = null; // Cache the audio buffer for the current job

    function init(getAudioBufferCallback) {
        console.log("SpectrogramVisualizer: Initializing...");
        assignDOMElements();
        getSharedAudioBuffer = getAudioBufferCallback;

        try {
            worker = new Worker('js/visualizers/spectrogram.worker.js');
            worker.onmessage = handleWorkerMessage;
            worker.onerror = handleWorkerError;
        } catch (e) {
            console.error("SpectrogramVisualizer: Failed to create Web Worker.", e);
            worker = null;
        }

        if (spectrogramCanvas) {
            spectrogramCanvas.addEventListener('click', handleCanvasClick);
            spectrogramCanvas.addEventListener('dblclick', handleCanvasDoubleClick);
        }
    }

    function handleWorkerError(e) {
        console.error("SpectrogramVisualizer: Received error from worker:", e);
        showSpinner(false);
        if (spectrogramCtx && spectrogramCanvas) {
            spectrogramCtx.fillStyle = '#D32F2F';
            spectrogramCtx.textAlign = 'center';
            spectrogramCtx.font = '14px sans-serif';
            spectrogramCtx.fillText(`Worker Error: ${e.message}`, spectrogramCanvas.width / 2, spectrogramCanvas.height / 2);
        }
    }

    function handleWorkerMessage(event) {
        const {type, payload, detail} = event.data;
        if (type === 'result') {
            const {spectrogramData} = payload;
            const audioBuffer = lastAudioBuffer;

            if (!audioBuffer) {
                console.warn("SpectrogramVisualizer: Worker returned a result, but there is no longer an active audio buffer. Ignoring.");
                showSpinner(false);
                return;
            }

            if (spectrogramData && spectrogramData.length > 0) {
                const actualFftSize = audioBuffer.duration < Constants.Visualizer.SPEC_SHORT_FILE_FFT_THRESHOLD_S ? Constants.Visualizer.SPEC_SHORT_FFT_SIZE : Constants.Visualizer.SPEC_NORMAL_FFT_SIZE;
                drawSpectrogramAsync(spectrogramData, spectrogramCanvas, audioBuffer.sampleRate, actualFftSize)
                    .catch(error => console.error("SpectrogramVisualizer: Error during async drawing.", error))
                    .finally(() => showSpinner(false));
            } else {
                console.warn("SpectrogramVisualizer: Worker returned empty or null data.");
                showSpinner(false);
            }
        } else if (type === 'error') {
            handleWorkerError({message: detail});
        }
    }

    async function computeAndDrawSpectrogram(audioBufferFromParam) {
        lastAudioBuffer = audioBufferFromParam || (getSharedAudioBuffer ? getSharedAudioBuffer() : null);

        if (!lastAudioBuffer) {
            console.warn("SpectrogramVisualizer: No AudioBuffer available.");
            return;
        }
        if (!spectrogramCtx || !spectrogramCanvas) {
            console.warn("SpectrogramVisualizer: Canvas context/element missing.");
            return;
        }
        if (!worker) {
            handleWorkerError({message: "Worker not available or failed to load."});
            return;
        }

        console.log("SpectrogramVisualizer: Offloading spectrogram computation to worker...");
        clearVisualsInternal();
        resizeCanvasInternal();
        cachedSpectrogramCanvas = null;
        showSpinner(true);

        const actualFftSize = lastAudioBuffer.duration < Constants.Visualizer.SPEC_SHORT_FILE_FFT_THRESHOLD_S ? Constants.Visualizer.SPEC_SHORT_FFT_SIZE : Constants.Visualizer.SPEC_NORMAL_FFT_SIZE;
        // IMPORTANT: We must copy the data for transfer, as the original buffer might be needed elsewhere (e.g., VAD)
        const channelData = lastAudioBuffer.getChannelData(0).slice();

        worker.postMessage({
            type: 'compute',
            payload: {
                channelData: channelData,
                sampleRate: lastAudioBuffer.sampleRate,
                duration: lastAudioBuffer.duration,
                fftSize: actualFftSize,
                targetSlices: Constants.Visualizer.SPEC_FIXED_WIDTH
            }
        }, [channelData.buffer]);
    }

    // --- HELPER FUNCTIONS THAT WERE MISSING ---

    function assignDOMElements() {
        spectrogramCanvas = document.getElementById('spectrogramCanvas');
        spectrogramSpinner = document.getElementById('spectrogramSpinner');
        spectrogramProgressIndicator = document.getElementById('spectrogramProgressIndicator');
        if (spectrogramCanvas) {
            spectrogramCtx = spectrogramCanvas.getContext('2d');
        } else {
            console.error("SpectrogramVisualizer: Could not find 'spectrogramCanvas' element.");
        }
    }

    function handleCanvasClick(e) {
        if (!spectrogramCanvas) return;
        const rect = spectrogramCanvas.getBoundingClientRect();
        if (!rect || rect.width <= 0) return;
        const clickXRelative = e.clientX - rect.left;
        const fraction = Math.max(0, Math.min(1, clickXRelative / rect.width));
        document.dispatchEvent(new CustomEvent('audioapp:seekRequested', {detail: {fraction: fraction}}));
    }

    function handleCanvasDoubleClick(e) {
        e.preventDefault();
        if (!spectrogramCanvas || !Constants.Visualizer.SPEC_MAX_FREQS?.length) return;

        currentMaxFreqIndex = (currentMaxFreqIndex + 1) % Constants.Visualizer.SPEC_MAX_FREQS.length;
        const audioBufferForRedraw = lastAudioBuffer || (getSharedAudioBuffer ? getSharedAudioBuffer() : null);
        if (audioBufferForRedraw) {
            computeAndDrawSpectrogram(audioBufferForRedraw);
        }
    }

    function drawSpectrogramAsync(spectrogramData, canvas, sampleRate, actualFftSize) {
        return new Promise((resolve, reject) => {
            if (!canvas || !spectrogramData?.[0] || typeof Constants === 'undefined' || !Utils) {
                return reject(new Error("SpectrogramVisualizer: Missing dependencies for async draw."));
            }
            const displayCtx = canvas.getContext('2d');
            if (!displayCtx) return reject(new Error("SpectrogramVisualizer: Could not get 2D context from display canvas."));

            displayCtx.clearRect(0, 0, canvas.width, canvas.height);
            displayCtx.fillStyle = '#000';
            displayCtx.fillRect(0, 0, canvas.width, canvas.height);

            const dataWidth = spectrogramData.length;
            const displayHeight = canvas.height;
            if (!cachedSpectrogramCanvas || cachedSpectrogramCanvas.width !== dataWidth || cachedSpectrogramCanvas.height !== displayHeight) {
                cachedSpectrogramCanvas = document.createElement('canvas');
                cachedSpectrogramCanvas.width = dataWidth;
                cachedSpectrogramCanvas.height = displayHeight;
            }
            const offCtx = cachedSpectrogramCanvas.getContext('2d');
            if (!offCtx) return reject(new Error("SpectrogramVisualizer: Could not get context from offscreen canvas."));

            const numBins = actualFftSize / 2;
            const nyquist = sampleRate / 2;
            const currentSpecMaxFreq = Constants.Visualizer.SPEC_MAX_FREQS[currentMaxFreqIndex];
            const maxBinIndex = Math.min(numBins - 1, Math.floor((currentSpecMaxFreq / nyquist) * (numBins - 1)));

            const dbThreshold = -60;
            let maxDb = -Infinity;
            const sliceStep = Math.max(1, Math.floor(dataWidth / 100));
            const binStep = Math.max(1, Math.floor(maxBinIndex / 50));
            for (let i = 0; i < dataWidth; i += sliceStep) {
                const magnitudes = spectrogramData[i];
                if (!magnitudes) continue;
                for (let j = 0; j <= maxBinIndex; j += binStep) {
                    if (j >= magnitudes.length) break;
                    const db = 20 * Math.log10(Math.max(1e-9, magnitudes[j]));
                    maxDb = Math.max(maxDb, Math.max(dbThreshold, db));
                }
            }
            maxDb = Math.max(maxDb, dbThreshold + 1);
            const minDb = dbThreshold;
            const dbRange = maxDb - minDb;

            const fullImageData = offCtx.createImageData(dataWidth, displayHeight);
            const imgData = fullImageData.data;
            let currentSlice = 0;
            const chunkSize = 32;

            function drawChunk() {
                try {
                    const startSlice = currentSlice;
                    const endSlice = Math.min(startSlice + chunkSize, dataWidth);
                    for (let i = startSlice; i < endSlice; i++) {
                        const magnitudes = spectrogramData[i];
                        if (!magnitudes) continue;
                        for (let y = 0; y < displayHeight; y++) {
                            const freqRatio = (displayHeight - 1 - y) / (displayHeight - 1);
                            const logFreqRatio = Math.pow(freqRatio, 2.0);
                            const binIndex = Math.min(maxBinIndex, Math.floor(logFreqRatio * maxBinIndex));
                            const magnitude = magnitudes[binIndex] || 0;
                            const db = 20 * Math.log10(Math.max(1e-9, magnitude));
                            const normValue = dbRange > 0 ? (Math.max(minDb, db) - minDb) / dbRange : 0;
                            const [r, g, b] = Utils.viridisColor(normValue);
                            const idx = (i + y * dataWidth) * 4;
                            imgData[idx] = r;
                            imgData[idx + 1] = g;
                            imgData[idx + 2] = b;
                            imgData[idx + 3] = 255;
                        }
                    }
                    offCtx.putImageData(fullImageData, 0, 0, startSlice, 0, endSlice - startSlice, displayHeight);
                    currentSlice = endSlice;
                    if (currentSlice < dataWidth) {
                        requestAnimationFrame(drawChunk);
                    } else {
                        displayCtx.drawImage(cachedSpectrogramCanvas, 0, 0, canvas.width, canvas.height);
                        resolve();
                    }
                } catch (error) {
                    reject(error);
                }
            }

            requestAnimationFrame(drawChunk);
        });
    }

    function updateProgressIndicator(currentTime, duration) {
        if (!spectrogramCanvas || !spectrogramProgressIndicator) return;
        if (isNaN(duration) || duration <= 0) {
            spectrogramProgressIndicator.style.left = "0px";
            return;
        }
        const fraction = Math.max(0, Math.min(1, currentTime / duration));
        spectrogramProgressIndicator.style.left = `${fraction * spectrogramCanvas.clientWidth}px`;
    }

    function clearVisualsInternal() {
        if (spectrogramCtx && spectrogramCanvas) {
            spectrogramCtx.clearRect(0, 0, spectrogramCanvas.width, spectrogramCanvas.height);
            spectrogramCtx.fillStyle = '#000';
            spectrogramCtx.fillRect(0, 0, spectrogramCanvas.width, spectrogramCanvas.height);
        }
        updateProgressIndicator(0, 1);
    }

    function clearVisuals() {
        clearVisualsInternal();
        cachedSpectrogramCanvas = null;
    }

    function showSpinner(show) {
        if (spectrogramSpinner) {
            spectrogramSpinner.style.display = show ? 'inline' : 'none';
        }
    }

    function resizeCanvasInternal() {
        if (!spectrogramCanvas) return false;
        const {width, height} = spectrogramCanvas.getBoundingClientRect();
        const roundedWidth = Math.round(width);
        const roundedHeight = Math.round(height);
        if (spectrogramCanvas.width !== roundedWidth || spectrogramCanvas.height !== roundedHeight) {
            spectrogramCanvas.width = roundedWidth;
            spectrogramCanvas.height = roundedHeight;
            if (spectrogramCtx) {
                spectrogramCtx.fillStyle = '#000';
                spectrogramCtx.fillRect(0, 0, roundedWidth, roundedHeight);
            }
            return true;
        }
        return false;
    }

    function resizeAndRedraw(audioBuffer) {
        const wasResized = resizeCanvasInternal();
        if (wasResized && cachedSpectrogramCanvas && spectrogramCtx && spectrogramCanvas) {
            spectrogramCtx.drawImage(cachedSpectrogramCanvas, 0, 0, spectrogramCanvas.width, spectrogramCanvas.height);
        }
        const {currentTime = 0, duration = 0} = AudioApp.audioEngine?.getCurrentTime() || {};
        updateProgressIndicator(currentTime, duration || (audioBuffer ? audioBuffer.duration : 0));
    }

    return {
        init: init,
        computeAndDrawSpectrogram: computeAndDrawSpectrogram,
        resizeAndRedraw: resizeAndRedraw,
        updateProgressIndicator: updateProgressIndicator,
        clearVisuals: clearVisuals,
        showSpinner: showSpinner
    };
})(window.FFT);

````
--- End of File: vibe-player/js/visualizers/spectrogramVisualizer.js ---
--- File: vibe-player/js/visualizers/waveformVisualizer.js ---
````javascript
// --- /vibe-player/js/visualizers/waveformVisualizer.js ---
// Handles drawing the Waveform visualization to a canvas element.

/** @namespace AudioApp */
var AudioApp = AudioApp || {};

/**
 * @namespace AudioApp.waveformVisualizer
 * @description Manages the rendering of the audio waveform, including highlighting speech regions
 * and displaying a playback progress indicator.
 */
AudioApp.waveformVisualizer = (function () {
    'use strict';

    /**
     * @private
     * @type {AudioApp.Constants} Reference to the Constants module.
     */
    // const Constants = AudioApp.Constants; // Constants is now a global class
    /**
     * @private
     * @type {AudioApp.Utils} Reference to the Utils module (not directly used in this snippet but assumed available if needed).
     */
    const Utils = AudioApp.Utils;

    /** @type {HTMLCanvasElement|null} The canvas element for the waveform. */
    let waveformCanvas = null;
    /** @type {CanvasRenderingContext2D|null} The 2D rendering context of the waveform canvas. */
    let waveformCtx = null;
    /** @type {HTMLDivElement|null} The element used to indicate playback progress on the waveform. */
    let waveformProgressIndicator = null;


    /**
     * Initializes the Waveform Visualizer.
     * Retrieves DOM elements and sets up event listeners.
     * @public
     */
    function init() {
        console.log("WaveformVisualizer: Initializing...");
        assignDOMElements();
        if (waveformCanvas) {
            waveformCanvas.addEventListener('click', handleCanvasClick);
        } else {
            console.warn("WaveformVisualizer: Waveform canvas element not found during init.");
        }
        console.log("WaveformVisualizer: Initialized.");
    }

    /**
     * Assigns DOM elements to module-level variables.
     * @private
     */
    function assignDOMElements() {
        waveformCanvas = /** @type {HTMLCanvasElement|null} */ (document.getElementById('waveformCanvas'));
        waveformProgressIndicator = /** @type {HTMLDivElement|null} */ (document.getElementById('waveformProgressIndicator'));
        if (waveformCanvas) {
            waveformCtx = waveformCanvas.getContext('2d');
        } else {
            console.error("WaveformVisualizer: Could not find 'waveformCanvas' element.");
        }
        if (!waveformProgressIndicator) {
            console.warn("WaveformVisualizer: Could not find 'waveformProgressIndicator' element.");
        }
    }


    /**
     * Handles click events on the waveform canvas, dispatching a seek request.
     * @private
     * @param {MouseEvent} e - The MouseEvent from the click.
     */
    function handleCanvasClick(e) {
        if (!waveformCanvas) return;
        const rect = waveformCanvas.getBoundingClientRect();
        if (!rect || rect.width <= 0) return; // Avoid division by zero if canvas has no width
        const clickXRelative = e.clientX - rect.left;
        const fraction = Math.max(0, Math.min(1, clickXRelative / rect.width)); // Clamp fraction to [0, 1]
        document.dispatchEvent(new CustomEvent('audioapp:seekRequested', {detail: {fraction: fraction}}));
    }


    /**
     * @typedef {object} SpeechRegion
     * @property {number} start - Start time of the speech region in seconds.
     * @property {number} end - End time of the speech region in seconds.
     */

    /**
     * Computes waveform data from an AudioBuffer and draws it on the canvas.
     * Highlights speech regions if provided.
     * @public
     * @async
     * @param {AudioBuffer} audioBuffer - The audio data to visualize.
     * @param {SpeechRegion[]|null|undefined} speechRegions - Optional array of speech regions to highlight.
     * If null or empty, the waveform is drawn with a loading/default color.
     * @returns {Promise<void>} Resolves when the waveform has been drawn.
     */
    async function computeAndDrawWaveform(audioBuffer, speechRegions) {
        if (!audioBuffer) {
            console.warn("WaveformVisualizer: computeAndDrawWaveform called with no AudioBuffer.");
            return;
        }
        if (!waveformCtx || !waveformCanvas) {
            console.warn("WaveformVisualizer: Canvas context/element missing for drawing.");
            return;
        }

        resizeCanvasInternal(); // Ensure canvas dimensions are up-to-date
        const width = waveformCanvas.width;

        const waveformData = computeWaveformData(audioBuffer, width);
        drawWaveform(waveformData, waveformCanvas, waveformCtx, speechRegions, audioBuffer.duration, width);
        updateProgressIndicator(0, audioBuffer.duration); // Reset progress indicator
    }

    /**
     * Redraws the waveform, primarily to update speech region highlighting.
     * Recomputes waveform data based on the current canvas size.
     * @public
     * @param {AudioBuffer|null} audioBuffer - The current audio buffer.
     * @param {SpeechRegion[]} speechRegions - The speech regions to highlight.
     */
    function redrawWaveformHighlight(audioBuffer, speechRegions) {
        if (!audioBuffer) {
            console.warn("WaveformVisualizer: Cannot redraw highlight, AudioBuffer missing.");
            return;
        }
        if (!waveformCanvas || !waveformCtx) {
            console.warn("WaveformVisualizer: Cannot redraw highlight, canvas/context missing.");
            return;
        }
        const width = waveformCanvas.width;
        if (width <= 0) {
            console.warn("WaveformVisualizer: Cannot redraw highlight, canvas width is zero or invalid.");
            return;
        }

        const waveformData = computeWaveformData(audioBuffer, width);
        drawWaveform(waveformData, waveformCanvas, waveformCtx, speechRegions, audioBuffer.duration, width);
    }


    /**
     * @typedef {object} WaveformMinMax
     * @property {number} min - Minimum sample value in the segment.
     * @property {number} max - Maximum sample value in the segment.
     */

    /**
     * Computes simplified waveform data (min/max pairs for each pixel column).
     * @private
     * @param {AudioBuffer} buffer - The audio buffer to process.
     * @param {number} targetWidth - The target width in pixels for the waveform display.
     * @returns {WaveformMinMax[]} An array of min/max objects, one for each pixel column.
     */
    function computeWaveformData(buffer, targetWidth) {
        if (!buffer?.getChannelData || targetWidth <= 0) return [];
        const channelCount = buffer.numberOfChannels;
        const bufferLength = buffer.length;
        if (bufferLength === 0) return [];

        /** @type {Float32Array} */
        let sourceData;
        if (channelCount === 1) {
            sourceData = buffer.getChannelData(0);
        } else { // Mix down to mono if multi-channel
            sourceData = new Float32Array(bufferLength);
            for (let ch = 0; ch < channelCount; ch++) {
                const chData = buffer.getChannelData(ch);
                for (let i = 0; i < bufferLength; i++) {
                    sourceData[i] += chData[i];
                }
            }
            for (let i = 0; i < bufferLength; i++) {
                sourceData[i] /= channelCount;
            }
        }

        const samplesPerPixel = Math.max(1, Math.floor(bufferLength / targetWidth));
        /** @type {WaveformMinMax[]} */
        const waveform = [];
        for (let i = 0; i < targetWidth; i++) {
            const start = Math.floor(i * samplesPerPixel);
            const end = Math.min(start + samplesPerPixel, bufferLength);
            if (start >= end) {
                waveform.push({min: 0, max: 0});
                continue;
            }

            let min = 1.0, max = -1.0;
            for (let j = start; j < end; j++) {
                const sample = sourceData[j];
                if (sample < min) min = sample;
                if (sample > max) max = sample;
            }
            waveform.push({min, max});
        }
        return waveform;
    }


    /**
     * Draws the computed waveform data onto the canvas.
     * Highlights speech regions using specific colors defined in `AudioApp.Constants`.
     * @private
     * @param {WaveformMinMax[]} waveformData - Array of min/max values per pixel column.
     * @param {HTMLCanvasElement} canvas - The canvas element to draw on.
     * @param {CanvasRenderingContext2D} ctx - The 2D rendering context of the canvas.
     * @param {SpeechRegion[]|null|undefined} speechRegions - Array of speech time regions to highlight.
     * @param {number} audioDuration - Total duration of the audio in seconds.
     * @param {number} width - The current width of the canvas.
     */
    function drawWaveform(waveformData, canvas, ctx, speechRegions, audioDuration, width) {
        if (!ctx || typeof Constants === 'undefined') {
            console.error("WaveformVisualizer: Missing context or Constants for drawing.");
            return;
        }

        const {height} = canvas;
        ctx.clearRect(0, 0, width, height);
        ctx.fillStyle = '#000';
        ctx.fillRect(0, 0, width, height); // Background

        if (!waveformData || waveformData.length === 0 || !audioDuration || audioDuration <= 0) {
            ctx.fillStyle = '#888';
            ctx.textAlign = 'center';
            ctx.font = '12px sans-serif';
            ctx.fillText("No waveform data available", width / 2, height / 2);
            return;
        }

        const dataLen = waveformData.length;
        const halfHeight = height / 2;
        const scale = halfHeight * Constants.Visualizer.WAVEFORM_HEIGHT_SCALE;
        const pixelsPerSecond = width / audioDuration;
        const initialDraw = !speechRegions || speechRegions.length === 0;
        const defaultColor = initialDraw ? Constants.Visualizer.WAVEFORM_COLOR_LOADING : Constants.Visualizer.WAVEFORM_COLOR_DEFAULT;
        const speechPixelRegions = initialDraw ? [] : (speechRegions || []).map(r => ({
            startPx: r.start * pixelsPerSecond, endPx: r.end * pixelsPerSecond
        }));
        const pixelWidth = width / dataLen; // Width of each bar in the waveform

        // Draw non-speech/loading parts
        ctx.fillStyle = defaultColor;
        ctx.beginPath();
        for (let i = 0; i < dataLen; i++) {
            const x = i * pixelWidth;
            const currentPixelEnd = x + pixelWidth;
            let isOutsideSpeech = true;
            if (!initialDraw) {
                for (const region of speechPixelRegions) {
                    if (x < region.endPx && currentPixelEnd > region.startPx) {
                        isOutsideSpeech = false;
                        break;
                    }
                }
            }
            if (isOutsideSpeech) {
                const {min, max} = waveformData[i];
                const y1 = halfHeight - (max * scale);
                const y2 = halfHeight - (min * scale);
                ctx.rect(x, y1, pixelWidth, Math.max(1, y2 - y1)); // Ensure rect has at least 1px height
            }
        }
        ctx.fill();

        // Draw speech highlights
        if (!initialDraw) {
            ctx.fillStyle = Constants.Visualizer.WAVEFORM_COLOR_SPEECH;
            ctx.beginPath();
            for (let i = 0; i < dataLen; i++) {
                const x = i * pixelWidth;
                const currentPixelEnd = x + pixelWidth;
                let isInsideSpeech = false;
                for (const region of speechPixelRegions) {
                    if (x < region.endPx && currentPixelEnd > region.startPx) {
                        isInsideSpeech = true;
                        break;
                    }
                }
                if (isInsideSpeech) {
                    const {min, max} = waveformData[i];
                    const y1 = halfHeight - (max * scale);
                    const y2 = halfHeight - (min * scale);
                    ctx.rect(x, y1, pixelWidth, Math.max(1, y2 - y1));
                }
            }
            ctx.fill();
        }
    }


    /**
     * Updates the position of the playback progress indicator on the waveform.
     * @public
     * @param {number} currentTime - The current playback time in seconds.
     * @param {number} duration - The total duration of the audio in seconds.
     */
    function updateProgressIndicator(currentTime, duration) {
        if (!waveformCanvas || !waveformProgressIndicator) return;
        if (isNaN(duration) || duration <= 0) {
            waveformProgressIndicator.style.left = "0px";
            return;
        }
        const fraction = Math.max(0, Math.min(1, currentTime / duration));
        const waveformWidth = waveformCanvas.clientWidth;
        waveformProgressIndicator.style.left = waveformWidth > 0 ? `${fraction * waveformWidth}px` : "0px";
    }

    /**
     * Clears the waveform canvas and resets the progress indicator.
     * @public
     */
    function clearVisuals() {
        console.log("WaveformVisualizer: Clearing visuals.");
        if (waveformCtx && waveformCanvas) {
            waveformCtx.clearRect(0, 0, waveformCanvas.width, waveformCanvas.height);
            waveformCtx.fillStyle = '#000'; // Explicitly set black background
            waveformCtx.fillRect(0, 0, waveformCanvas.width, waveformCanvas.height);
        }
        updateProgressIndicator(0, 1); // Reset progress indicator
    }

    /**
     * Resizes the canvas element to match its CSS-defined display size.
     * This is important for ensuring crisp rendering.
     * @private
     * @returns {boolean} True if the canvas was resized, false otherwise.
     */
    function resizeCanvasInternal() {
        if (!waveformCanvas) return false;
        const {width, height} = waveformCanvas.getBoundingClientRect();
        const roundedWidth = Math.max(10, Math.round(width)); // Ensure minimum size
        const roundedHeight = Math.max(10, Math.round(height));
        if (waveformCanvas.width !== roundedWidth || waveformCanvas.height !== roundedHeight) {
            waveformCanvas.width = roundedWidth;
            waveformCanvas.height = roundedHeight;
            if (waveformCtx) { // Redraw background if context exists
                waveformCtx.fillStyle = '#000';
                waveformCtx.fillRect(0, 0, roundedWidth, roundedHeight);
            }
            return true;
        }
        return false;
    }

    /**
     * Handles window resize events. Adjusts canvas dimensions and redraws the waveform
     * using the provided audio buffer and speech regions.
     * @public
     * @param {AudioBuffer|null} audioBuffer - The current audio buffer.
     * @param {SpeechRegion[]|null} speechRegions - Current speech regions to highlight.
     */
    function resizeAndRedraw(audioBuffer, speechRegions) {
        const wasResized = resizeCanvasInternal();
        if (wasResized && audioBuffer) {
            redrawWaveformHighlight(audioBuffer, speechRegions || []);
        } else if (wasResized) {
            clearVisuals(); // Clear if resized but no audio buffer to redraw
        }
        // Always update progress indicator, as its position depends on clientWidth
        const {currentTime = 0, duration = 0} = AudioApp.audioEngine?.getCurrentTime() || {};
        updateProgressIndicator(currentTime, duration || (audioBuffer ? audioBuffer.duration : 0));
    }

    /**
     * @typedef {Object} WaveformVisualizerPublicInterface
     * @property {function(): void} init
     * @property {function(AudioBuffer, SpeechRegion[]|null|undefined): Promise<void>} computeAndDrawWaveform
     * @property {function(AudioBuffer|null, SpeechRegion[]): void} redrawWaveformHighlight
     * @property {function(AudioBuffer|null, SpeechRegion[]|null): void} resizeAndRedraw
     * @property {function(number, number): void} updateProgressIndicator
     * @property {function(): void} clearVisuals
     */

    /** @type {WaveformVisualizerPublicInterface} */
    return {
        init: init,
        computeAndDrawWaveform: computeAndDrawWaveform,
        redrawWaveformHighlight: redrawWaveformHighlight,
        resizeAndRedraw: resizeAndRedraw,
        updateProgressIndicator: updateProgressIndicator,
        clearVisuals: clearVisuals
    };

})();
// --- /vibe-player/js/visualizers/waveformVisualizer.js ---
````
--- End of File: vibe-player/js/visualizers/waveformVisualizer.js ---
--- File: vibe-player/lib/fft.js ---
````javascript
// --- /vibe-player/lib/fft.js ---
// NOTE: This is 3rd party code (adapted). JSDoc annotations not added here.
'use strict';

// =============================================
// == Fast Fourier Transform (FFT) Library ==
// Based on https://github.com/indutny/fft.js
// Creates a global FFT constructor.
// =============================================

function FFT(size) {
    this.size = size | 0;
    if (this.size <= 1 || (this.size & (this.size - 1)) !== 0)
        throw new Error('FFT size must be a power of two and bigger than 1');

    this._csize = size << 1;

    var table = new Array(this.size * 2);
    for (var i = 0; i < table.length; i += 2) {
        const angle = Math.PI * i / this.size;
        table[i] = Math.cos(angle);
        table[i + 1] = -Math.sin(angle);
    }
    this.table = table;

    var power = 0;
    for (var t = 1; this.size > t; t <<= 1)
        power++;

    this._width = power % 2 === 0 ? power - 1 : power;

    this._bitrev = new Array(1 << this._width);
    for (var j = 0; j < this._bitrev.length; j++) {
        this._bitrev[j] = 0;
        for (var shift = 0; shift < this._width; shift += 2) {
            var revShift = this._width - shift - 2;
            this._bitrev[j] |= ((j >>> shift) & 3) << revShift;
        }
    }

    this._out = null;
    this._data = null;
    this._inv = 0;
}

FFT.prototype.fromComplexArray = function fromComplexArray(complex, storage) {
    var res = storage || new Array(complex.length >>> 1);
    for (var i = 0; i < complex.length; i += 2)
        res[i >>> 1] = complex[i];
    return res;
};

FFT.prototype.createComplexArray = function createComplexArray() {
    const res = new Array(this._csize);
    for (var i = 0; i < res.length; i++)
        res[i] = 0;
    return res;
};

FFT.prototype.toComplexArray = function toComplexArray(input, storage) {
    var res = storage || this.createComplexArray();
    for (var i = 0; i < res.length; i += 2) {
        res[i] = input[i >>> 1];
        res[i + 1] = 0;
    }
    return res;
};

FFT.prototype.completeSpectrum = function completeSpectrum(spectrum) {
    var size = this._csize;
    var half = size >>> 1;
    for (var i = 2; i < half; i += 2) {
        spectrum[size - i] = spectrum[i];
        spectrum[size - i + 1] = -spectrum[i + 1];
    }
};

FFT.prototype.transform = function transform(out, data) {
    if (out === data) throw new Error('Input and output buffers must be different');
    this._out = out;
    this._data = data;
    this._inv = 0;
    this._transform4();
    this._out = null;
    this._data = null;
};

FFT.prototype.realTransform = function realTransform(out, data) {
    if (out === data) throw new Error('Input and output buffers must be different');
    this._out = out;
    this._data = data;
    this._inv = 0;
    this._realTransform4();
    this._out = null;
    this._data = null;
};

FFT.prototype.inverseTransform = function inverseTransform(out, data) {
    if (out === data) throw new Error('Input and output buffers must be different');
    this._out = out;
    this._data = data;
    this._inv = 1;
    this._transform4();
    for (var i = 0; i < out.length; i++) out[i] /= this.size;
    this._out = null;
    this._data = null;
};

FFT.prototype._transform4 = function _transform4() {
    var out = this._out, size = this._csize, width = this._width;
    var step = 1 << width, len = (size / step) << 1, bitrev = this._bitrev;
    var outOff, t;
    if (len === 4) {
        for (outOff = 0, t = 0; outOff < size; outOff += len, t++) this._singleTransform2(outOff, bitrev[t], step);
    } else {
        for (outOff = 0, t = 0; outOff < size; outOff += len, t++) this._singleTransform4(outOff, bitrev[t], step);
    }
    var inv = this._inv ? -1 : 1, table = this.table;
    for (step >>= 2; step >= 2; step >>= 2) {
        len = (size / step) << 1;
        var quarterLen = len >>> 2;
        for (outOff = 0; outOff < size; outOff += len) {
            var limit = outOff + quarterLen;
            for (var i = outOff, k = 0; i < limit; i += 2, k += step) {
                const A = i, B = A + quarterLen, C = B + quarterLen, D = C + quarterLen;
                const Ar = out[A], Ai = out[A + 1], Br = out[B], Bi = out[B + 1], Cr = out[C], Ci = out[C + 1],
                    Dr = out[D], Di = out[D + 1];
                const MAr = Ar, MAi = Ai;
                const tableBr = table[k], tableBi = inv * table[k + 1];
                const MBr = Br * tableBr - Bi * tableBi, MBi = Br * tableBi + Bi * tableBr;
                const tableCr = table[2 * k], tableCi = inv * table[2 * k + 1];
                const MCr = Cr * tableCr - Ci * tableCi, MCi = Cr * tableCi + Ci * tableCr;
                const tableDr = table[3 * k], tableDi = inv * table[3 * k + 1];
                const MDr = Dr * tableDr - Di * tableDi, MDi = Dr * tableDi + Di * tableDr;
                const T0r = MAr + MCr, T0i = MAi + MCi, T1r = MAr - MCr, T1i = MAi - MCi;
                const T2r = MBr + MDr, T2i = MBi + MDi, T3r = inv * (MBr - MDr), T3i = inv * (MBi - MDi);
                const FAr = T0r + T2r, FAi = T0i + T2i, FCr = T0r - T2r, FCi = T0i - T2i;
                const FBr = T1r + T3i, FBi = T1i - T3r, FDr = T1r - T3i, FDi = T1i + T3r;
                out[A] = FAr;
                out[A + 1] = FAi;
                out[B] = FBr;
                out[B + 1] = FBi;
                out[C] = FCr;
                out[C + 1] = FCi;
                out[D] = FDr;
                out[D + 1] = FDi;
            }
        }
    }
};
FFT.prototype._singleTransform2 = function _singleTransform2(outOff, off, step) {
    const out = this._out, data = this._data;
    const evenR = data[off], evenI = data[off + 1];
    const oddR = data[off + step], oddI = data[off + step + 1];
    const leftR = evenR + oddR, leftI = evenI + oddI;
    const rightR = evenR - oddR, rightI = evenI - oddI;
    out[outOff] = leftR;
    out[outOff + 1] = leftI;
    out[outOff + 2] = rightR;
    out[outOff + 3] = rightI;
};
FFT.prototype._singleTransform4 = function _singleTransform4(outOff, off, step) {
    const out = this._out, data = this._data;
    const inv = this._inv ? -1 : 1;
    const step2 = step * 2, step3 = step * 3;
    const Ar = data[off], Ai = data[off + 1], Br = data[off + step], Bi = data[off + step + 1], Cr = data[off + step2],
        Ci = data[off + step2 + 1], Dr = data[off + step3], Di = data[off + step3 + 1];
    const T0r = Ar + Cr, T0i = Ai + Ci, T1r = Ar - Cr, T1i = Ai - Ci;
    const T2r = Br + Dr, T2i = Bi + Di, T3r = inv * (Br - Dr), T3i = inv * (Bi - Di);
    const FAr = T0r + T2r, FAi = T0i + T2i, FBr = T1r + T3i, FBi = T1i - T3r;
    const FCr = T0r - T2r, FCi = T0i - T2i, FDr = T1r - T3i, FDi = T1i + T3r;
    out[outOff] = FAr;
    out[outOff + 1] = FAi;
    out[outOff + 2] = FBr;
    out[outOff + 3] = FBi;
    out[outOff + 4] = FCr;
    out[outOff + 5] = FCi;
    out[outOff + 6] = FDr;
    out[outOff + 7] = FDi;
};
FFT.prototype._realTransform4 = function _realTransform4() {
    var out = this._out, size = this._csize, width = this._width;
    var step = 1 << width, len = (size / step) << 1, bitrev = this._bitrev;
    var outOff, t;
    if (len === 4) {
        for (outOff = 0, t = 0; outOff < size; outOff += len, t++) this._singleRealTransform2(outOff, bitrev[t] >>> 1, step >>> 1);
    } else {
        for (outOff = 0, t = 0; outOff < size; outOff += len, t++) this._singleRealTransform4(outOff, bitrev[t] >>> 1, step >>> 1);
    }
    var inv = this._inv ? -1 : 1, table = this.table;
    for (step >>= 2; step >= 2; step >>= 2) {
        len = (size / step) << 1;
        var halfLen = len >>> 1, quarterLen = halfLen >>> 1, hquarterLen = quarterLen >>> 1;
        for (outOff = 0; outOff < size; outOff += len) {
            for (var i = 0, k = 0; i <= hquarterLen; i += 2, k += step) {
                var A = outOff + i, B = A + quarterLen, C = B + quarterLen, D = C + quarterLen;
                var Ar = out[A], Ai = out[A + 1], Br = out[B], Bi = out[B + 1], Cr = out[C], Ci = out[C + 1],
                    Dr = out[D], Di = out[D + 1];
                var MAr = Ar, MAi = Ai;
                var tableBr = table[k], tableBi = inv * table[k + 1];
                var MBr = Br * tableBr - Bi * tableBi, MBi = Br * tableBi + Bi * tableBr;
                var tableCr = table[2 * k], tableCi = inv * table[2 * k + 1];
                var MCr = Cr * tableCr - Ci * tableCi, MCi = Cr * tableCi + Ci * tableCr;
                var tableDr = table[3 * k], tableDi = inv * table[3 * k + 1];
                var MDr = Dr * tableDr - Di * tableDi, MDi = Dr * tableDi + Di * tableDr;
                var T0r = MAr + MCr, T0i = MAi + MCi, T1r = MAr - MCr, T1i = MAi - MCi;
                var T2r = MBr + MDr, T2i = MBi + MDi, T3r = inv * (MBr - MDr), T3i = inv * (MBi - MDi);
                var FAr = T0r + T2r, FAi = T0i + T2i, FBr = T1r + T3i, FBi = T1i - T3r;
                out[A] = FAr;
                out[A + 1] = FAi;
                out[B] = FBr;
                out[B + 1] = FBi;
                if (i === 0) {
                    var FCr = T0r - T2r, FCi = T0i - T2i;
                    out[C] = FCr;
                    out[C + 1] = FCi;
                    continue;
                }
                if (i === hquarterLen) continue;
                var ST0r = T1r, ST0i = -T1i, ST1r = T0r, ST1i = -T0i;
                var ST2r = -inv * T3i, ST2i = -inv * T3r, ST3r = -inv * T2i, ST3i = -inv * T2r;
                var SFAr = ST0r + ST2r, SFAi = ST0i + ST2i, SFBr = ST1r + ST3i, SFBi = ST1i - ST3r;
                var SA = outOff + quarterLen - i, SB = outOff + halfLen - i;
                out[SA] = SFAr;
                out[SA + 1] = SFAi;
                out[SB] = SFBr;
                out[SB + 1] = SFBi;
            }
        }
    }
};
FFT.prototype._singleRealTransform2 = function _singleRealTransform2(outOff, off, step) {
    const out = this._out, data = this._data;
    const evenR = data[off], oddR = data[off + step];
    const leftR = evenR + oddR, rightR = evenR - oddR;
    out[outOff] = leftR;
    out[outOff + 1] = 0;
    out[outOff + 2] = rightR;
    out[outOff + 3] = 0;
};
FFT.prototype._singleRealTransform4 = function _singleRealTransform4(outOff, off, step) {
    const out = this._out, data = this._data;
    const inv = this._inv ? -1 : 1;
    const step2 = step * 2, step3 = step * 3;
    const Ar = data[off], Br = data[off + step], Cr = data[off + step2], Dr = data[off + step3];
    const T0r = Ar + Cr, T1r = Ar - Cr, T2r = Br + Dr, T3r = inv * (Br - Dr);
    const FAr = T0r + T2r, FBr = T1r, FBi = -T3r, FCr = T0r - T2r, FDr = T1r, FDi = T3r;
    out[outOff] = FAr;
    out[outOff + 1] = 0;
    out[outOff + 2] = FBr;
    out[outOff + 3] = FBi;
    out[outOff + 4] = FCr;
    out[outOff + 5] = 0;
    out[outOff + 6] = FDr;
    out[outOff + 7] = FDi;
};

````
--- End of File: vibe-player/lib/fft.js ---
--- File: vibe-player/lib/rubberband-loader.js ---
````javascript
// --- START OF FILE rubberband.js (Self-Contained Loader + Options) ---

// ** MODIFIED Emscripten Loader for AudioWorklet **
// Original source: Emscripten-generated loader for Rubberband library (@echogarden)
// Modifications:
// - Removed Node.js support, file loading, script path detection.
// - Executes via new Function(), expects WASM binary via moduleArg.wasmBinary.
// - Expects instantiation hook via moduleArg.instantiateWasm.
// - Includes RubberBandOptionFlag constants directly on the resolved Module object.
// - Removed 'export default'.
// - Structure adjusted to return the async loader function, not invoke it immediately.

var Rubberband = (() => { // Outer IIFE defines Rubberband scope

    // This async function is what the outer IIFE will return
    return (
        async function (moduleArg = {}) { // Accepts { wasmBinary, instantiateWasm, ... }
            var Module = moduleArg; // Use the provided argument object directly
            var moduleRtn;

            // --- Promise for readiness ---
            var readyPromiseResolve, readyPromiseReject;
            var readyPromise = new Promise((resolve, reject) => {
                readyPromiseResolve = resolve;
                readyPromiseReject = reject;
            });

            // --- Basic Environment (Assume Worker/Worklet like) ---
            var out = Module["print"] || console.log.bind(console);
            var err = Module["printErr"] || console.error.bind(console);

            // --- State ---
            var wasmMemory;
            var ABORT = false;
            var runtimeInitialized = false;
            var HEAP8, HEAPU8, HEAP16, HEAPU16, HEAP32, HEAPU32, HEAPF32, HEAPF64;

            function updateMemoryViews() {
                if (!wasmMemory) return; // Prevent errors if called too early
                var b = wasmMemory.buffer;
                Module["HEAP8"] = HEAP8 = new Int8Array(b);
                Module["HEAP16"] = HEAP16 = new Int16Array(b);
                Module["HEAPU8"] = HEAPU8 = new Uint8Array(b);
                Module["HEAPU16"] = HEAPU16 = new Uint16Array(b);
                Module["HEAP32"] = HEAP32 = new Int32Array(b);
                Module["HEAPU32"] = HEAPU32 = new Uint32Array(b);
                Module["HEAPF32"] = HEAPF32 = new Float32Array(b);
                Module["HEAPF64"] = HEAPF64 = new Float64Array(b);
            }

            // --- Lifecycle Callbacks ---
            var __ATINIT__ = [];
            var __ATPOSTRUN__ = [];

            function addOnInit(cb) {
                __ATINIT__.unshift(cb)
            }

            function addOnPostRun(cb) {
                __ATPOSTRUN__.unshift(cb)
            }

            function callRuntimeCallbacks(callbacks) {
                callbacks.forEach(f => f(Module))
            }

            // --- Dependency Tracking (Simplified) ---
            var runDependencies = 0;
            var dependenciesFulfilled = null;

            function addRunDependency(id) {
                runDependencies++;
            }

            function removeRunDependency(id) {
                runDependencies--;
                if (runDependencies == 0 && dependenciesFulfilled) {
                    var callback = dependenciesFulfilled;
                    dependenciesFulfilled = null;
                    callback();
                }
            }

            // --- Abort ---
            function abort(what) {
                Module["onAbort"]?.(what);
                what = "Aborted(" + what + ")";
                err(what);
                ABORT = true;
                var e = new WebAssembly.RuntimeError(what);
                readyPromiseReject(e);
                throw e;
            }

            // --- WASM Instantiation ---
            var wasmExports;

            function createWasm() {
                // NOTE: 'a' is the expected import object name, 'n' is memory, 'o' is init func.
                // These might change if rubberband.wasm is rebuilt with different settings.
                var info = {a: wasmImports};

                function receiveInstance(instance, module) {
                    wasmExports = instance.exports;
                    wasmMemory = wasmExports["n"]; // Hardcoded memory export name
                    updateMemoryViews();
                    addOnInit(wasmExports["o"]); // Hardcoded init function export name
                    removeRunDependency("wasm-instantiate");
                    return wasmExports;
                }

                addRunDependency("wasm-instantiate");

                if (Module["instantiateWasm"]) {
                    try {
                        var exports = Module["instantiateWasm"](info, receiveInstance);
                        // Handle potential sync return (less likely for WASM)
                        if (exports instanceof WebAssembly.Instance) {
                            receiveInstance(exports);
                        }
                    } catch (e) {
                        err(`Module.instantiateWasm callback failed with error: ${e}`);
                        readyPromiseReject(e);
                    }
                } else {
                    var missingHookError = new Error("Fatal error: 'instantiateWasm' hook not provided to the WASM loader module.");
                    err(missingHookError.message);
                    readyPromiseReject(missingHookError);
                    return {};
                }
                return {}; // Required for async preparation
            }

            // --- Minimal Stubs needed *before* assignExports/runtime ---
            // Need a *basic* UTF8ToString for error reporting during init
            const _UTF8ToString_stub = (ptr) => {
                if (!ptr || !HEAPU8) return "";
                let str = '';
                let i = ptr;
                while (HEAPU8[i] && i < ptr + 1024) { // Limit length for safety
                    str += String.fromCharCode(HEAPU8[i++]);
                }
                return str;
            };
            const ___assert_fail = (condition, filename, line, func) => {
                abort(`Assertion failed: ${_UTF8ToString_stub(condition)}`)
            };
            const ___cxa_throw = (ptr, type, destructor) => {
                abort(`Exception thrown from WASM: ptr=${ptr} type=${type}`)
            };
            const __abort_js = () => {
                abort("")
            };
            const __emscripten_memcpy_js = (dest, src, num) => HEAPU8?.copyWithin(dest, src, src + num); // Check HEAPU8 exists
            const _emscripten_date_now = () => Date.now();
            const _emscripten_resize_heap = requestedSize => {
                err("_emscripten_resize_heap called - Not implemented.");
                return false;
            };
            const _environ_get = (__environ, environ_buf) => 0;
            const _environ_sizes_get = (penviron_count, penviron_buf_size) => {
                HEAPU32[penviron_count >> 2] = 0;
                HEAPU32[penviron_buf_size >> 2] = 0;
                return 0;
            };
            const __tzset_js = () => {
            };
            const _fd_close = (fd) => 0;
            const _fd_read = (fd, iov, iovcnt, pnum) => {
                HEAPU32[pnum >> 2] = 0;
                return 0;
            };
            const _fd_seek = (fd, offset_low, offset_high, whence, newOffset) => {
                HEAP32[newOffset >> 2] = 0;
                HEAP32[newOffset + 4 >> 2] = 0;
                return 0;
            };
            const _fd_write = (fd, iov, iovcnt, pnum) => { // Basic logging stub
                let num = 0;
                try {
                    for (let i = 0; i < iovcnt; i++) {
                        let ptr = HEAPU32[iov >> 2];
                        let len = HEAPU32[iov + 4 >> 2];
                        iov += 8;
                        let str = _UTF8ToString_stub(ptr); /* Basic ASCII ok for debug */
                        if (fd === 1) out(str); else err(str);
                        num += len;
                    }
                    HEAPU32[pnum >> 2] = num;
                } catch (e) { /* ignore errors during logging */
                }
                return 0;
            };

            // --- Stack variables (will be assigned in assignExports) ---
            var stackSave, stackRestore, stackAlloc, __emscripten_stack_alloc, __emscripten_stack_restore,
                _emscripten_stack_get_current;

            // --- WASM Imports Object ---
            // These keys ('a', 'b', 'c'...) MUST match what rubberband.wasm expects.
            var wasmImports = {
                b: ___assert_fail, a: ___cxa_throw, j: __abort_js, i: __emscripten_memcpy_js,
                l: __tzset_js, h: _emscripten_date_now, e: _emscripten_resize_heap,
                m: _environ_get, d: _environ_sizes_get, f: _fd_close, g: _fd_read,
                k: _fd_seek, c: _fd_write,
                // Add other imports if rubberband.wasm requires them (check browser console errors)
            };

            // --- Runtime Initialization ---
            function initRuntime() {
                runtimeInitialized = true;
                callRuntimeCallbacks(__ATINIT__);
            }

            function postRun() {
                callRuntimeCallbacks(__ATPOSTRUN__);
            }

            // --- Main Execution Logic ---
            var calledRun;
            dependenciesFulfilled = function runCaller() {
                if (!calledRun) run();
                if (!calledRun) dependenciesFulfilled = runCaller;
            };

            function run() {
                if (runDependencies > 0) return; // Wait for WASM etc.
                // No preRun needed unless user adds callbacks
                if (calledRun) return;
                calledRun = true;
                Module["calledRun"] = true;
                if (ABORT) return;
                initRuntime(); // Calls __ATINIT__ (which includes assignExports)
                readyPromiseResolve(Module); // Resolve the main promise HERE
                Module["onRuntimeInitialized"]?.();
                postRun();
            }

            // --- assignExports Function (Called via __ATINIT__) ---
            function assignExports() {
                if (!wasmExports) {
                    console.error("WASM Exports not available during assignExports!");
                    abort("WASM exports missing");
                    return;
                }

                // Define helpers *locally* within this scope
                updateMemoryViews(); // Ensure HEAP views are ready

                const getValue = (ptr, type = "i8") => { /* ... as in previous correct version ... */
                    if (!HEAPU8) return 0;
                    if (type.endsWith("*")) type = "*";
                    switch (type) {
                        case"i1":
                            return HEAP8[ptr];
                        case"i8":
                            return HEAP8[ptr];
                        case"i16":
                            return HEAP16[ptr >> 1];
                        case"i32":
                            return HEAP32[ptr >> 2];
                        case"i64":
                            abort("getValue(i64)");
                            return 0;
                        case"float":
                            return HEAPF32[ptr >> 2];
                        case"double":
                            return HEAPF64[ptr >> 3];
                        case"*":
                            return HEAPU32[ptr >> 2];
                        default:
                            abort(`invalid type for getValue: ${type}`);
                            return 0;
                    }
                };
                const setValue = (ptr, value, type = "i8") => { /* ... as in previous correct version ... */
                    if (!HEAPU8) return;
                    if (type.endsWith("*")) type = "*";
                    switch (type) {
                        case"i1":
                            HEAP8[ptr] = value;
                            break;
                        case"i8":
                            HEAP8[ptr] = value;
                            break;
                        case"i16":
                            HEAP16[ptr >> 1] = value;
                            break;
                        case"i32":
                            HEAP32[ptr >> 2] = value;
                            break;
                        case"i64":
                            abort("setValue(i64)");
                            break;
                        case"float":
                            HEAPF32[ptr >> 2] = value;
                            break;
                        case"double":
                            HEAPF64[ptr >> 3] = value;
                            break;
                        case"*":
                            HEAPU32[ptr >> 2] = value;
                            break;
                        default:
                            abort(`invalid type for setValue: ${type}`);
                    }
                };
                const UTF8Decoder = typeof TextDecoder != "undefined" ? new TextDecoder('utf8') : undefined;
                const UTF8ArrayToString = (heapOrArray, idx = 0, maxBytesToRead = Infinity) => { /* ... as in previous correct version ... */
                    var endIdx = Math.min(idx + maxBytesToRead, heapOrArray.length);
                    var endPtr = idx;
                    while (heapOrArray[endPtr] && endPtr < endIdx) ++endPtr;
                    if (endPtr - idx > 16 && heapOrArray.buffer && UTF8Decoder) {
                        return UTF8Decoder.decode(heapOrArray.subarray(idx, endPtr));
                    } else {
                        var str = "";
                        while (idx < endPtr) {
                            var u0 = heapOrArray[idx++];
                            if (!(u0 & 128)) {
                                str += String.fromCharCode(u0);
                                continue
                            }
                            var u1 = heapOrArray[idx++] & 63;
                            if ((u0 & 224) == 192) {
                                str += String.fromCharCode((u0 & 31) << 6 | u1);
                                continue
                            }
                            var u2 = heapOrArray[idx++] & 63;
                            if ((u0 & 240) == 224) {
                                u0 = (u0 & 15) << 12 | u1 << 6 | u2
                            } else {
                                u0 = (u0 & 7) << 18 | u1 << 12 | u2 << 6 | heapOrArray[idx++] & 63
                            }
                            if (u0 < 0x10000) {
                                str += String.fromCharCode(u0)
                            } else {
                                var ch = u0 - 0x10000;
                                str += String.fromCharCode(0xD800 | (ch >> 10), 0xDC00 | (ch & 0x3FF))
                            }
                        }
                        return str;
                    }
                };
                const UTF8ToString = (ptr, maxBytesToRead) => ptr ? UTF8ArrayToString(HEAPU8, ptr, maxBytesToRead) : "";
                const stringToUTF8Array = (str, heap, outIdx, maxBytesToWrite) => { /* ... as in previous correct version ... */
                    if (!(maxBytesToWrite > 0)) return 0;
                    var startIdx = outIdx;
                    var endIdx = outIdx + maxBytesToWrite - 1;
                    for (var i = 0; i < str.length; ++i) {
                        var u = str.charCodeAt(i);
                        if (u >= 0xD800 && u <= 0xDFFF) {
                            var u1 = str.charCodeAt(++i);
                            u = 0x10000 + ((u & 0x3FF) << 10) | (u1 & 0x3FF)
                        }
                        if (u <= 0x7F) {
                            if (outIdx >= endIdx) break;
                            heap[outIdx++] = u
                        } else if (u <= 0x7FF) {
                            if (outIdx + 1 >= endIdx) break;
                            heap[outIdx++] = 0xC0 | (u >> 6);
                            heap[outIdx++] = 0x80 | (u & 63)
                        } else if (u <= 0xFFFF) {
                            if (outIdx + 2 >= endIdx) break;
                            heap[outIdx++] = 0xE0 | (u >> 12);
                            heap[outIdx++] = 0x80 | ((u >> 6) & 63);
                            heap[outIdx++] = 0x80 | (u & 63)
                        } else {
                            if (outIdx + 3 >= endIdx) break;
                            heap[outIdx++] = 0xF0 | (u >> 18);
                            heap[outIdx++] = 0x80 | ((u >> 12) & 63);
                            heap[outIdx++] = 0x80 | ((u >> 6) & 63);
                            heap[outIdx++] = 0x80 | (u & 63)
                        }
                    }
                    heap[outIdx] = 0;
                    return outIdx - startIdx;
                };
                const stringToUTF8 = (str, outPtr, maxBytesToWrite) => stringToUTF8Array(str, HEAPU8, outPtr, maxBytesToWrite);
                const lengthBytesUTF8 = str => { /* ... as in previous correct version ... */
                    let len = 0;
                    for (let i = 0; i < str.length; ++i) {
                        let c = str.charCodeAt(i);
                        if (c <= 0x7F) {
                            len++;
                        } else if (c <= 0x7FF) {
                            len += 2;
                        } else if (c >= 0xD800 && c <= 0xDFFF) {
                            len += 4;
                            ++i;
                        } else {
                            len += 3;
                        }
                    }
                    return len;
                };

                // Assign mapped WASM functions to Module object
                // Using the export names ('q', 'r', etc.) presumed from previous attempts
                Module["_free"] = wasmExports["q"];
                Module["_malloc"] = wasmExports["V"];
                Module["_rubberband_new"] = wasmExports["r"];
                Module["_rubberband_delete"] = wasmExports["s"];
                Module["_rubberband_reset"] = wasmExports["t"];
                Module["_rubberband_get_engine_version"] = wasmExports["u"];
                Module["_rubberband_set_time_ratio"] = wasmExports["v"];
                Module["_rubberband_set_pitch_scale"] = wasmExports["w"];
                Module["_rubberband_get_time_ratio"] = wasmExports["x"];
                Module["_rubberband_get_pitch_scale"] = wasmExports["y"];
                Module["_rubberband_set_formant_scale"] = wasmExports["z"];
                Module["_rubberband_get_formant_scale"] = wasmExports["A"];
                Module["_rubberband_get_preferred_start_pad"] = wasmExports["B"];
                Module["_rubberband_get_start_delay"] = wasmExports["C"];
                Module["_rubberband_get_latency"] = wasmExports["D"];
                Module["_rubberband_set_transients_option"] = wasmExports["E"];
                Module["_rubberband_set_detector_option"] = wasmExports["F"];
                Module["_rubberband_set_phase_option"] = wasmExports["G"];
                Module["_rubberband_set_formant_option"] = wasmExports["H"];
                Module["_rubberband_set_pitch_option"] = wasmExports["I"];
                Module["_rubberband_set_expected_input_duration"] = wasmExports["J"];
                Module["_rubberband_get_samples_required"] = wasmExports["K"];
                Module["_rubberband_set_max_process_size"] = wasmExports["L"];
                Module["_rubberband_set_key_frame_map"] = wasmExports["M"];
                Module["_rubberband_study"] = wasmExports["N"];
                Module["_rubberband_process"] = wasmExports["O"];
                Module["_rubberband_available"] = wasmExports["P"];
                Module["_rubberband_retrieve"] = wasmExports["Q"];
                Module["_rubberband_get_channel_count"] = wasmExports["R"];
                Module["_rubberband_calculate_stretch"] = wasmExports["S"];
                Module["_rubberband_set_debug_level"] = wasmExports["T"];
                Module["_rubberband_set_default_debug_level"] = wasmExports["U"];

                // Assign Stack functions (CRITICAL)
                __emscripten_stack_alloc = wasmExports["X"];
                __emscripten_stack_restore = wasmExports["W"];
                _emscripten_stack_get_current = wasmExports["Y"];
                stackSave = _emscripten_stack_get_current;
                stackRestore = __emscripten_stack_restore;
                stackAlloc = __emscripten_stack_alloc;
                Module["stackSave"] = stackSave;
                Module["stackRestore"] = stackRestore;
                Module["stackAlloc"] = stackAlloc;

                // Assign locally defined helpers to Module object
                Module["getValue"] = getValue;
                Module["setValue"] = setValue;
                Module["UTF8ToString"] = UTF8ToString;
                Module["stringToUTF8"] = stringToUTF8;
                Module["lengthBytesUTF8"] = lengthBytesUTF8;

                // *** ADD RUBBERBAND OPTIONS FLAGS ***
                Module.RubberBandOptionFlag = {
                    ProcessOffline: 0x00000000, ProcessRealTime: 0x00000001,
                    StretchElastic: 0x00000000, StretchPrecise: 0x00000010,
                    TransientsCrisp: 0x00000000, TransientsMixed: 0x00000100, TransientsSmooth: 0x00000200,
                    DetectorCompound: 0x00000000, DetectorPercussive: 0x00000400, DetectorSoft: 0x00000800,
                    PhaseLaminar: 0x00000000, PhaseIndependent: 0x00002000,
                    ThreadingAuto: 0x00000000, ThreadingNever: 0x00010000, ThreadingAlways: 0x00020000,
                    WindowStandard: 0x00000000, WindowShort: 0x00100000, WindowLong: 0x00200000,
                    SmoothingOff: 0x00000000, SmoothingOn: 0x00800000,
                    FormantShifted: 0x00000000, FormantPreserved: 0x01000000,
                    PitchHighSpeed: 0x00000000, PitchHighQuality: 0x02000000, PitchHighConsistency: 0x04000000,
                    ChannelsApart: 0x00000000, ChannelsTogether: 0x10000000,
                    EngineFaster: 0x00000000, EngineFiner: 0x20000000,
                    // Add presets too if desired
                    // DefaultOptions: 0x00000000, PercussiveOptions: 0x00102000,
                    // Convenience aliases from your example (might be slightly different from direct enum names)
                    EngineDefault: 0, // Alias for EngineFaster
                    // PitchHighQuality: 0x02000000, // Already defined above
                };
                // Make sure the specific options used in the processor are available
                // These are just copies/aliases for clarity if the names differ slightly.
                Module.RubberbandOptions = Module.RubberBandOptionFlag; // Alias the whole object

            } // End assignExports

            // --- Start the process ---
            addOnInit(assignExports); // Queue exports assignment
            createWasm(); // Start WASM loading (async)

            moduleRtn = readyPromise;
            return moduleRtn; // Return the promise that resolves with the Module object
        }
    ) // <--- Inner async function is RETURNED, not invoked here
})(); // Outer IIFE is invoked immediately

// NO export default
// --- END OF FILE rubberband.js ---

````
--- End of File: vibe-player/lib/rubberband-loader.js ---
--- File: vibe-player/README.md ---
````markdown
<!-- /vibe-player/README.md -->

# Vibe Player

A simple, browser-based audio player designed for analyzing and manipulating audio files, inspired by classic desktop
application aesthetics. It runs entirely client-side using static files.

## Features

* Load local audio files (common formats supported by browser `decodeAudioData`).
* Real-time playback control (Play, Pause, Seek).
* Adjust playback Speed (0.25x - 2.0x) using Rubberband WASM.
* Adjust playback Pitch (0.25x - 2.0x) using Rubberband WASM.
* Adjust playback Gain (Volume Boost up to 5x).
* Voice Activity Detection (VAD) using Silero VAD model (ONNX Runtime):
    * Displays VAD progress during analysis.
    * Highlights detected speech segments on the waveform.
    * Allows tuning VAD thresholds (Positive/Negative) after initial analysis.
* Visualizations:
    * Real-time Waveform display.
    * Spectrogram display.
* Keyboard shortcuts for common actions (visible in the application UI).

## Usage

1. Serve the project files using a simple static file server (e.g., `python -m http.server` or VS Code Live Server). The
   server should be run from the `vibe-player` directory.
2. Open `index.html` in your web browser (Chrome/Edge/Firefox recommended).
3. Click "Choose File..." and select an audio file.
4. Wait for the initial processing (decoding, visuals). The waveform and spectrogram will appear.
5. Playback controls (Play, Seek, Speed, Pitch, Gain) become active once the audio engine is ready.
6. VAD processing runs in the background. Its progress is shown, and waveform highlights appear upon completion. VAD
   tuning sliders become active then.
7. Use the controls or click on the waveform/spectrogram to interact.

## Controls

* **Choose File...:** Select a local audio file.
* **Speed Slider:** Adjust playback speed (0.25x - 2.0x).
* **Pitch Slider:** Adjust playback pitch scale (0.25x - 2.0x).
* **Gain Slider:** Adjust output volume boost (1x - 5x).
* **Play/Pause Button:** Toggle playback.
* **Back/Forward Buttons & Input:** Jump backward or forward by the specified number of seconds.
* **Seek Bar / Time Display:** Shows current position / total duration. Click or drag seek bar to jump.
* **Waveform/Spectrogram:** Click to seek to that position.
* **VAD Threshold Sliders:** (Enabled after VAD) Adjust positive/negative thresholds to re-evaluate speech segments
  based on the initial analysis probabilities.
* **(Keyboard Shortcuts are listed within the application UI)**

## Developer Notes

* **Static Environment:** This application is designed to run entirely client-side without any build steps or
  server-side logic. See `architecture.md` for details.
* **Dependencies:** Requires ONNX Runtime Web (`ort.min.js`), FFT.js, and Rubberband WASM (`rubberband.wasm`,
  `rubberband-loader.js`). These are included in the `/lib/` directory.
* **Code Structure:** Uses Vanilla JS (ES6) with an IIFE module pattern. See `architecture.md`.

## Contributing / LLM Collaboration

Development involving LLM assistance should follow the guidelines outlined in `CONTRIBUTING-LLM.md`. Please ensure this
file is loaded into the LLM's context before starting work. If the file is missing, please request it.
<!-- /vibe-player/README.md -->

````
--- End of File: vibe-player/README.md ---
--- File: vibe-player/TODO.md ---
````markdown
<!-- /vibe-player/TODO.md -->

# Vibe Player - TODO & Future Ideas

This file tracks potential improvements, features, and known issues requiring further investigation for the Vibe Player
project. The list is prioritized, with the most impactful and straightforward tasks at the top.

---

### Priority 1: High-Impact UI/UX Features

These are "quick win" features that directly improve usability and the user experience.

* **Implement UI Control Buttons:**
    * **Task:** Add "Back to Start" and "Reset Controls" buttons to the main interface.
    * **Details:** The "Back to Start" button should seek playback to `0:00`. The "Reset Controls" button should reset
      Speed, Pitch, Gain, and VAD thresholds to their default values. This provides essential, convenient user actions.

* **Complete `jumpTime` Data Flow:**
    * **Task:** Refactor the "Jump Time" input to use the centralized `AppState`.
    * **Details:** Currently, the jump value is read directly from the DOM. This should be updated to follow the
      unidirectional data flow pattern: the input field should update `AppState`, and the jump logic should read its
      value from `AppState`. This is a code quality improvement that completes the state refactor.

---

### Priority 2: Core Functionality & Bug Fixes

This addresses the most significant known issue with an audio processing feature.

* **[INVESTIGATE] Formant Shift Functionality:**
    * **Task:** The formant shift feature is implemented but has no audible effect. Investigate the cause and either fix
      it or remove the control.
    * **Details:** This requires deep-diving into the Rubberband WASM library's flags and documentation. If a fix is not
      feasible, the formant slider should be removed from the UI to avoid user confusion.

---

### Priority 3: Advanced Features & Visualizations

These are larger features that build on the stable foundation to provide more power to the user.

* **VAD Probability Graph:**
    * **Task:** Add a new visualization that shows the raw VAD probability scores over time.
    * **Details:** This graph should align with the waveform and spectrogram. Ideally, it would include draggable
      horizontal lines for the positive/negative thresholds, making VAD tuning highly intuitive. This requires modifying
      the VAD worker to send back the full probability array.

* **Advanced Player Controls & Keybinds:**
    * **Task:** Investigate and potentially implement more granular controls (e.g., frame-by-frame stepping).
    * **Details:** Also, consider making keyboard shortcuts customizable by the user, with settings saved to
      `localStorage`.

---

### Priority 4: Long-Term Code Health & Robustness

These are ongoing tasks to ensure the project remains maintainable and reliable.

* **Expand Automated Testing:**
    * **Task:** Increase test coverage with more unit and integration tests.
    * **Details:** Now that the architecture is more modular, modules like `audioEngine` and `uiManager` can be more
      easily tested. This is crucial for preventing regressions as new features are added.

* **Continue `app.js` Refactoring:**
    * **Task:** Reduce the complexity of `app.js` by moving distinct responsibilities to more specialized modules.
    * **Details:** For example, the VAD and Tone analysis orchestration logic could be moved out of `app.js` into a
      dedicated `analysisOrchestrator.js` module. This improves separation of concerns and maintainability.

---

### Others

* **Improved Spectrogram Rendering:** Explore true progressive computation/rendering for the spectrogram, where slices
  are calculated and drawn incrementally, rather than computing all data upfront.
* Improve typing, docstrings, comment section headers, make the header and footer comment with the file path consistent 

---

### Done / Completed

* ~~**[DONE]** Refactor state management into a centralized `AppState` module.~~
* ~~**[DONE]** Move VAD processing to a Web Worker to prevent UI freezes.~~
* ~~**[DONE]** Offload Spectrogram FFT computation to a Web Worker.~~
* ~~**[DONE]** Fix critical script loading order and initialization bugs.~~
* ~~**[WON'T DO]** Implement Windows 98-style UI sounds for interactions

<!-- /vibe-player/TODO.md -->

````
--- End of File: vibe-player/TODO.md ---
--- File: vibe-player-v2/.gitignore ---
````.gitignore
node_modules

# Output
.output
.vercel
.netlify
.wrangler
/.svelte-kit
/build

# OS
.DS_Store
Thumbs.db

# Env
.env
.env.*
!.env.example
!.env.test

# Vite
vite.config.js.timestamp-*
vite.config.ts.timestamp-*

````
--- End of File: vibe-player-v2/.gitignore ---
--- File: vibe-player-v2/.npmrc ---
````.npmrc
engine-strict=true

````
--- End of File: vibe-player-v2/.npmrc ---
--- File: vibe-player-v2/.prettierrc ---
````.prettierrc
{
  "plugins": ["prettier-plugin-tailwindcss"]
}

````
--- End of File: vibe-player-v2/.prettierrc ---
--- File: vibe-player-v2/eslint.config.js ---
````javascript
// @ts-check

import eslint from "@eslint/js";
import sveltePlugin from "eslint-plugin-svelte";
import svelteParser from "svelte-eslint-parser";
import typescriptParser from "@typescript-eslint/parser";
import eslintConfigPrettier from "eslint-config-prettier";
import globals from "globals";

export default [
  {
    ignores: [
      ".svelte-kit/**", // Ignore SvelteKit's generated files
      "build/**", // Standard build output directory
      "dist/**", // Common distribution directory name
    ],
  },
  // eslint.configs.recommended, // Keep this commented out or remove rules like no-unused-vars from it
  ...sveltePlugin.configs["flat/recommended"],
  {
    rules: {
      "no-unused-vars": "off", // Turn off no-unused-vars for now
      // OR, more selectively for TypeScript if using @typescript-eslint/eslint-plugin
      // "@typescript-eslint/no-unused-vars": "off",
    },
  },
  {
    files: ["**/*.js", "**/*.ts", "**/*.svelte"],
    languageOptions: {
      globals: {
        ...globals.browser,
        ...globals.node, // For things like 'module' in rubberband-loader.js if needed, or setTimeout etc.
        // Add any other specific globals your project might use if not covered by browser/node
      },
    },
  },
  {
    files: ["src/lib/workers/**/*.js", "src/lib/workers/**/*.ts"],
    languageOptions: {
      globals: {
        ...globals.worker,
      },
    },
  },
  {
    files: ["**/*.js", "**/*.ts"],
    languageOptions: {
      parser: typescriptParser,
    },
  },
  {
    files: ["**/*.svelte"],
    languageOptions: {
      parser: svelteParser,
      parserOptions: {
        parser: typescriptParser,
      },
    },
    // rules: { // Rules specific to svelte files can go here if needed
    // },
  },
  eslintConfigPrettier,
];

````
--- End of File: vibe-player-v2/eslint.config.js ---
--- File: vibe-player-v2/playwright.config.ts ---
````typescript
// vibe-player-v2/playwright.config.ts

import { defineConfig, devices } from "@playwright/test";

// SvelteKit's default preview port is 4173.
const PORT = 4173;
const baseURL = `http://localhost:${PORT}`;

/**
 * See https://playwright.dev/docs/test-configuration.
 */
export default defineConfig({
  // The test directory is now relative to THIS config file.
  testDir: "./tests-e2e",

  // Output dir for reports is also relative.
  outputDir: "./tests-e2e/test-results",

  fullyParallel: true,
  forbidOnly: !!process.env.CI,
  retries: process.env.CI ? 2 : 0,
  workers: process.env.CI ? 1 : undefined,
  maxFailures: process.env.CI ? 1 : undefined,
  reporter: "html",

  use: {
    baseURL: baseURL,
    trace: "on-first-retry",
  },

  projects: [
    { name: "chromium", use: { ...devices["Desktop Chrome"] } },
    { name: "firefox", use: { ...devices["Desktop Firefox"] } },
    { name: "webkit", use: { ...devices["Desktop Safari"] } },
  ],

  // **THE KEY FIX IS HERE**
  // We now run the standard SvelteKit preview command from within this directory.
  // This command serves the production build of our app, which is the best
  // way to run end-to-end tests.
  webServer: {
    command: "npm run preview",
    url: baseURL,
    reuseExistingServer: !process.env.CI,
  },
});

````
--- End of File: vibe-player-v2/playwright.config.ts ---
--- File: vibe-player-v2/postcss.config.js ---
````javascript
export default {
  plugins: {
    tailwindcss: {},
    autoprefixer: {},
  },
};

````
--- End of File: vibe-player-v2/postcss.config.js ---
--- File: vibe-player-v2/README.md ---
````markdown
# sv

Everything you need to build a Svelte project, powered by [`sv`](https://github.com/sveltejs/cli).

## Creating a project

If you're seeing this, you've probably already done this step. Congrats!

```bash
# create a new project in the current directory
npx sv create

# create a new project in my-app
npx sv create my-app
```

## Developing

Once you've created a project and installed dependencies with `npm install` (or `pnpm install` or `yarn`), start a development server:

```bash
npm run dev

# or start the server and open the app in a new browser tab
npm run dev -- --open
```

## Building

To create a production version of your app:

```bash
npm run build
```

You can preview the production build with `npm run preview`.

> To deploy your app, you may need to install an [adapter](https://svelte.dev/docs/kit/adapters) for your target environment.

````
--- End of File: vibe-player-v2/README.md ---
--- File: vibe-player-v2/src/app.css ---
````css
@import "tailwindcss/base";
@import "tailwindcss/components";
@import "tailwindcss/utilities";

````
--- End of File: vibe-player-v2/src/app.css ---
--- File: vibe-player-v2/src/app.d.ts ---
````typescript
// See https://svelte.dev/docs/kit/types#app.d.ts
// for information about these interfaces
declare global {
  namespace App {
    // interface Error {}
    // interface Locals {}
    // interface PageData {}
    // interface PageState {}
    // interface Platform {}
  }
}

export {};

````
--- End of File: vibe-player-v2/src/app.d.ts ---
--- File: vibe-player-v2/src/app.html ---
````html
<!doctype html>
<html lang="en">
  <head>
    <meta charset="utf-8" />
    <link rel="icon" href="%sveltekit.assets%/favicon.png" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    %sveltekit.head%
  </head>
  <body data-sveltekit-preload-data="hover">
    <div style="display: contents">%sveltekit.body%</div>
  </body>
</html>

````
--- End of File: vibe-player-v2/src/app.html ---
--- File: vibe-player-v2/src/hooks.server.ts ---
````typescript
// vibe-player-v2/src/hooks.server.ts
import type { Handle } from "@sveltejs/kit";

/**
 * SvelteKit hook to add required security headers for SharedArrayBuffer support.
 * This is crucial for libraries like ONNX Runtime (ort-wasm-simd-threaded) and ensures
 * that both pages and static assets are served with the correct policies.
 * See: https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/SharedArrayBuffer/security_requirements
 */
export const handle: Handle = async ({ event, resolve }) => {
  // Apply the headers to all responses.
  const response = await resolve(event);

  // Required for SharedArrayBuffer
  response.headers.set("Cross-Origin-Opener-Policy", "same-origin");
  response.headers.set("Cross-Origin-Embedder-Policy", "require-corp");

  return response;
};

````
--- End of File: vibe-player-v2/src/hooks.server.ts ---
--- File: vibe-player-v2/src/lib/actions/sparkles.action.ts ---
````typescript
// vibe-player-v2/src/lib/actions/sparkles.action.ts
interface Sparkle {
  id: number;
  x: number;
  y: number;
  size: number;
  opacity: number;
  vx: number;
  vy: number;
  life: number; // Lifespan in frames
  element: HTMLElement;
}

let sparkleIdCounter = 0;

export function sparkles(
  node: HTMLElement,
  options?: { color?: string; count?: number; speed?: number },
) {
  const { color = "gold", count = 3, speed = 1 } = options || {};
  let animationFrameId: number;
  let sparkles: Sparkle[] = [];

  function createSparkle(x: number, y: number): Sparkle {
    const size = Math.random() * 5 + 2; // 2px to 7px
    const sparkleEl = document.createElement("div");
    sparkleEl.style.position = "absolute";
    sparkleEl.style.left = `${x}px`;
    sparkleEl.style.top = `${y}px`;
    sparkleEl.style.width = `${size}px`;
    sparkleEl.style.height = `${size}px`;
    sparkleEl.style.backgroundColor = color;
    sparkleEl.style.borderRadius = "50%";
    sparkleEl.style.pointerEvents = "none"; // Don't interfere with mouse events
    sparkleEl.style.opacity = "1";
    node.appendChild(sparkleEl);

    return {
      id: sparkleIdCounter++,
      x,
      y,
      size,
      opacity: 1,
      vx: (Math.random() - 0.5) * 2 * speed, // Random horizontal velocity
      vy: (Math.random() - 0.5) * 1 * speed - 1, // Upward drift
      life: Math.random() * 60 + 30, // 30 to 90 frames
      element: sparkleEl,
    };
  }

  function updateSparkles() {
    sparkles = sparkles.filter((s) => {
      s.x += s.vx;
      s.y += s.vy;
      s.opacity -= 0.02; // Fade out
      s.life--;

      if (s.opacity <= 0 || s.life <= 0) {
        s.element.remove();
        return false; // Remove sparkle
      }

      s.element.style.transform = `translate(${s.x - s.size / 2}px, ${s.y - s.size / 2}px)`;
      s.element.style.opacity = String(s.opacity);
      return true;
    });
    animationFrameId = requestAnimationFrame(updateSparkles);
  }

  function handleMouseMove(event: MouseEvent) {
    if (node.contains(event.target as Node) || event.target === node) {
      const rect = node.getBoundingClientRect();
      const x = event.clientX - rect.left;
      const y = event.clientY - rect.top;
      for (let i = 0; i < count; i++) {
        sparkles.push(createSparkle(x, y));
      }
    }
  }

  // Ensure node is relative for absolute positioning of sparkles
  if (getComputedStyle(node).position === "static") {
    node.style.position = "relative";
  }
  node.style.overflow = "hidden"; // Contain sparkles

  node.addEventListener("mousemove", handleMouseMove);
  animationFrameId = requestAnimationFrame(updateSparkles);

  return {
    destroy() {
      node.removeEventListener("mousemove", handleMouseMove);
      cancelAnimationFrame(animationFrameId);
      sparkles.forEach((s) => s.element.remove());
      sparkles = [];
    },
  };
}

````
--- End of File: vibe-player-v2/src/lib/actions/sparkles.action.ts ---
--- File: vibe-player-v2/src/lib/components/__mocks__/Button.svelte ---
````svelte
<script>
  // Mock Button
  export let color = 'primary'; // Example prop
  // Add any other props your component might expect to avoid runtime warnings/errors
</script>

<button class="mock-button btn variant-filled-{color}" on:click>
  <slot />
</button>

````
--- End of File: vibe-player-v2/src/lib/components/__mocks__/Button.svelte ---
--- File: vibe-player-v2/src/lib/components/__mocks__/Generic.svelte ---
````svelte
<script lang="ts">
  // Generic mock for any Skeleton component
  // It can accept any props via $$props
</script>

<div data-testid="generic-skeleton-mock" {...$$props}>
  <!-- Generic mock content -->
</div>

````
--- End of File: vibe-player-v2/src/lib/components/__mocks__/Generic.svelte ---
--- File: vibe-player-v2/src/lib/components/__mocks__/ProgressBar.svelte ---
````svelte
<script lang="ts">
  // Minimal mock for ProgressBar.svelte
  export let value: number | undefined = undefined;
  export let max: number = 100;
  // Add any other props that might be minimally required if type checking is strict
</script>

<div data-testid="mock-progress-bar" role="progressbar" aria-valuenow={value} aria-valuemax={max}>
  <!-- Mock content -->
</div>

````
--- End of File: vibe-player-v2/src/lib/components/__mocks__/ProgressBar.svelte ---
--- File: vibe-player-v2/src/lib/components/__mocks__/RangeSlider.svelte ---
````svelte
<script>
  // Mock RangeSlider
  export let value = 0;
  export let name = ''; // This will be used as the ID for the label's 'for' attribute
  export let min = 0;
  export let max = 100;
  export let step = 1;
  // Add any other props your component might expect
  // Use the 'name' prop also as 'id' to match <label for="...">
  const id = name;
</script>

<input type="range" class="mock-range-slider" {id} {name} bind:value {min} {max} {step} on:input on:change />

````
--- End of File: vibe-player-v2/src/lib/components/__mocks__/RangeSlider.svelte ---
--- File: vibe-player-v2/src/lib/components/Controls.svelte ---
````svelte
<!-- vibe-player-v2/src/lib/components/Controls.svelte -->
<script lang="ts">
    import { RangeSlider } from '@skeletonlabs/skeleton';
    import audioEngine from '$lib/services/audioEngine.service';
    import analysisService from '$lib/services/analysis.service';
    import { playerStore } from '$lib/stores/player.store';
    import { analysisStore } from '$lib/stores/analysis.store';

    let speed = $playerStore?.speed || 1.0;
    let pitch = $playerStore?.pitch || 0.0;
    let gain = $playerStore?.gain || 1.0;
    let vadPositive = $analysisStore?.vadPositiveThreshold || 0.5;
    let vadNegative = $analysisStore?.vadNegativeThreshold || 0.35;

    playerStore.subscribe(val => {
        if (val.speed !== undefined) speed = val.speed;
        if (val.pitch !== undefined) pitch = val.pitch;
        if (val.gain !== undefined) gain = val.gain;
    });
    analysisStore.subscribe(val => {
        if (val.vadPositiveThreshold !== undefined) vadPositive = val.vadPositiveThreshold;
        if (val.vadNegativeThreshold !== undefined) vadNegative = val.vadNegativeThreshold;
    });

    function handlePlayPause() {
        if ($playerStore.isPlaying) {
            audioEngine.pause();
        } else {
            audioEngine.play();
        }
    }
    function handleStop() {
        audioEngine.stop();
    }
    function updateSpeed() {
        audioEngine.setSpeed(speed);
    }
    function updatePitch() {
        audioEngine.setPitch(pitch);
    }
    function updateGain() {
        audioEngine.setGain(gain);
    }
    function updateVadThresholds() {
        console.log('VAD thresholds changed:', vadPositive, vadNegative);
        analysisStore.update(s => ({...s, vadPositiveThreshold: vadPositive, vadNegativeThreshold: vadNegative }));
    }
</script>

<div class="card p-4 space-y-4">
    <h3 class="h3">Controls</h3>
    <div class="flex space-x-2">
        <button type="button" class="btn" data-testid="play-button" on:click={handlePlayPause} disabled={!$playerStore.isPlayable}>
            {$playerStore.isPlaying ? 'Pause' : 'Play'}
        </button>
        <button type="button" class="btn" data-testid="stop-button" on:click={handleStop} disabled={!$playerStore.isPlayable}>Stop</button>
    </div>
    <div>
        <label for="speedSlider" class="label" data-testid="speed-value">Speed: {speed.toFixed(2)}x</label>
        <RangeSlider data-testid="speed-slider-input" name="speedSlider" bind:value={speed} min={0.5} max={2.0} step={0.01} on:input={updateSpeed} />
    </div>
    <div>
        <label for="pitchSlider" class="label" data-testid="pitch-value">Pitch: {pitch.toFixed(1)} semitones</label>
        <RangeSlider data-testid="pitch-slider-input" name="pitchSlider" bind:value={pitch} min={-12} max={12} step={0.1} on:input={updatePitch} />
    </div>
    <div>
        <label for="gainSlider" class="label" data-testid="gain-value">Gain: {gain.toFixed(2)}</label>
        <RangeSlider data-testid="gain-slider-input" name="gainSlider" bind:value={gain} min={0} max={2.0} step={0.01} on:input={updateGain} />
    </div>
    <div>
        <label for="vadPositiveSlider" class="label" data-testid="vad-positive-value">VAD Positive Threshold: {vadPositive.toFixed(2)}</label>
        <RangeSlider data-testid="vad-positive-slider-input" name="vadPositiveSlider" bind:value={vadPositive} min={0.05} max={0.95} step={0.01} on:input={updateVadThresholds} />
    </div>
    <div>
        <label for="vadNegativeSlider" class="label" data-testid="vad-negative-value">VAD Negative Threshold: {vadNegative.toFixed(2)}</label>
        <RangeSlider data-testid="vad-negative-slider-input" name="vadNegativeSlider" bind:value={vadNegative} min={0.05} max={0.95} step={0.01} on:input={updateVadThresholds} />
    </div>
</div>

````
--- End of File: vibe-player-v2/src/lib/components/Controls.svelte ---
--- File: vibe-player-v2/src/lib/components/Controls.test.ts ---
````typescript
// vibe-player-v2/src/lib/components/Controls.test.ts
import { render, fireEvent, screen, act } from "@testing-library/svelte";
import { describe, it, expect, vi, beforeEach, type Mocked } from "vitest";
import Controls from "./Controls.svelte";
import audioEngineService from "$lib/services/audioEngine.service";
import { playerStore } from "$lib/stores/player.store";
import { analysisStore } from "$lib/stores/analysis.store";
import { writable, type Writable, get } from "svelte/store";

// --- Hoisted Mocks ---
vi.mock("$lib/stores/player.store", () => ({
  playerStore: { subscribe: vi.fn(), update: vi.fn(), set: vi.fn() },
}));
vi.mock("$lib/stores/analysis.store", () => ({
  analysisStore: { subscribe: vi.fn(), update: vi.fn(), set: vi.fn() },
}));
vi.mock("$lib/services/audioEngine.service", () => ({
  default: {
    unlockAudio: vi.fn(),
    play: vi.fn(),
    pause: vi.fn(),
    stop: vi.fn(),
    setSpeed: vi.fn(),
    setPitch: vi.fn(),
    setGain: vi.fn(),
    initialize: vi.fn(),
    dispose: vi.fn(),
  },
}));

// --- Test State Setup ---
type PlayerStoreValues = ReturnType<typeof get<Writable<any>>>;
const initialMockPlayerStoreValues: PlayerStoreValues = {
  speed: 1.0,
  pitch: 0.0,
  gain: 1.0,
  isPlaying: false,
  isPlayable: false,
};
const initialMockAnalysisStoreValues = {
  vadPositiveThreshold: 0.5,
  vadNegativeThreshold: 0.35,
};
let mockPlayerStoreWritable: Writable<PlayerStoreValues>;
let mockAnalysisStoreWritable: Writable<any>;

describe("Controls.svelte", () => {
  beforeEach(async () => {
    mockPlayerStoreWritable = writable({ ...initialMockPlayerStoreValues });
    mockAnalysisStoreWritable = writable({ ...initialMockAnalysisStoreValues });

    const playerStoreMocks = await import("$lib/stores/player.store");
    vi.mocked(playerStoreMocks.playerStore.subscribe).mockImplementation(
      mockPlayerStoreWritable.subscribe,
    );
    vi.mocked(playerStoreMocks.playerStore.update).mockImplementation(
      mockPlayerStoreWritable.update,
    );

    const analysisStoreMocks = await import("$lib/stores/analysis.store");
    vi.mocked(analysisStoreMocks.analysisStore.subscribe).mockImplementation(
      mockAnalysisStoreWritable.subscribe,
    );
    vi.mocked(analysisStoreMocks.analysisStore.update).mockImplementation(
      mockAnalysisStoreWritable.update,
    );

    vi.clearAllMocks();

    vi.mocked(playerStoreMocks.playerStore.subscribe).mockImplementation(
      mockPlayerStoreWritable.subscribe,
    );
    vi.mocked(playerStoreMocks.playerStore.update).mockImplementation(
      mockPlayerStoreWritable.update,
    );
    vi.mocked(analysisStoreMocks.analysisStore.subscribe).mockImplementation(
      mockAnalysisStoreWritable.subscribe,
    );
    vi.mocked(analysisStoreMocks.analysisStore.update).mockImplementation(
      mockAnalysisStoreWritable.update,
    );
  });

  it("renders all control buttons and sliders", () => {
    render(Controls);
    expect(screen.getByRole("button", { name: /Play/i })).toBeInTheDocument();
    expect(screen.getByRole("button", { name: /Stop/i })).toBeInTheDocument();
    expect(screen.getByLabelText(/Speed/i)).toBeInTheDocument();
    expect(screen.getByLabelText(/Pitch/i)).toBeInTheDocument();
    expect(screen.getByLabelText(/Gain/i)).toBeInTheDocument();
    expect(
      screen.getByLabelText(/VAD Positive Threshold/i),
    ).toBeInTheDocument();
    expect(
      screen.getByLabelText(/VAD Negative Threshold/i),
    ).toBeInTheDocument();
  });

  it("calls audioEngine.play() when play button is clicked and not playing", async () => {
    render(Controls);
    act(() => {
      mockPlayerStoreWritable.update((s) => ({
        ...s,
        isPlayable: true,
        isPlaying: false,
      }));
    });
    const playButton = await screen.findByRole("button", { name: /Play/i });
    await fireEvent.click(playButton);
    expect(audioEngineService.play).toHaveBeenCalledTimes(1);
    expect(audioEngineService.pause).not.toHaveBeenCalled();
  });

  it("calls audioEngine.pause() when pause button is clicked and is playing", async () => {
    render(Controls);
    act(() => {
      mockPlayerStoreWritable.update((s) => ({
        ...s,
        isPlayable: true,
        isPlaying: true,
      }));
    });
    const pauseButton = await screen.findByRole("button", { name: /Pause/i });
    await fireEvent.click(pauseButton);
    expect(audioEngineService.pause).toHaveBeenCalledTimes(1);
    expect(audioEngineService.play).not.toHaveBeenCalled();
  });

  it("calls audioEngine.stop() on Stop button click", async () => {
    render(Controls);
    act(() => {
      mockPlayerStoreWritable.update((s) => ({ ...s, isPlayable: true }));
    });
    const stopButton = await screen.findByRole("button", { name: /Stop/i });
    await fireEvent.click(stopButton);
    expect(audioEngineService.stop).toHaveBeenCalledTimes(1);
  });

  // Slider tests remain the same but use async queries for safety
  it("calls audioEngine.setSpeed() when speed slider changes", async () => {
    render(Controls);
    const speedSlider = screen.getByLabelText<HTMLInputElement>(/Speed/i);
    await fireEvent.input(speedSlider, { target: { value: "1.5" } });
    expect(audioEngineService.setSpeed).toHaveBeenCalledWith(1.5);
    expect(await screen.findByLabelText(/Speed: 1.50x/i)).toBeInTheDocument();
  });

  it("calls audioEngine.setPitch() when pitch slider changes", async () => {
    render(Controls);
    const pitchSlider = screen.getByLabelText<HTMLInputElement>(/Pitch/i);
    await fireEvent.input(pitchSlider, { target: { value: "-5.0" } });
    expect(audioEngineService.setPitch).toHaveBeenCalledWith(-5.0);
    expect(
      await screen.findByLabelText(/Pitch: -5.0 semitones/i),
    ).toBeInTheDocument();
  });

  it("calls audioEngine.setGain() when gain slider changes", async () => {
    render(Controls);
    const gainSlider = screen.getByLabelText<HTMLInputElement>(/Gain/i);
    await fireEvent.input(gainSlider, { target: { value: "0.7" } });
    expect(audioEngineService.setGain).toHaveBeenCalledWith(0.7);
    expect(await screen.findByLabelText(/Gain: 0.70/i)).toBeInTheDocument();
  });

  it("slider values update if store changes externally", async () => {
    render(Controls);
    act(() => {
      mockPlayerStoreWritable.set({
        ...initialMockPlayerStoreValues,
        speed: 1.8,
        pitch: 3.0,
        gain: 0.5,
      });
    });
    await screen.findByLabelText(/Speed: 1.80x/i);
    expect(
      (await screen.findByLabelText<HTMLInputElement>(/Speed/i)).value,
    ).toBe("1.8");
  });
});

````
--- End of File: vibe-player-v2/src/lib/components/Controls.test.ts ---
--- File: vibe-player-v2/src/lib/components/FileLoader.svelte ---
````svelte
<!-- vibe-player-v2/src/lib/components/FileLoader.svelte -->

<script lang="ts">
    import audioEngine from '$lib/services/audioEngine.service';
    import { playerStore } from '$lib/stores/player.store'; // To show status or file name

    let currentFile: File | null = null;
    let isLoading = false;

    async function handleFileSelect(event: Event) {
        const input = event.target as HTMLInputElement;
        if (input.files && input.files.length > 0) {
            currentFile = input.files[0];
            playerStore.update(s => ({ ...s, fileName: currentFile?.name, error: null, status: 'File selected', isPlayable: false }));
            isLoading = true;

            try {
                await audioEngine.unlockAudio(); // Ensure AudioContext is ready

                const arrayBuffer = await currentFile.arrayBuffer();
                await audioEngine.loadFile(arrayBuffer, currentFile.name);
                // Status updates will now come from audioEngine via playerStore

            } catch (e: any) {
                console.error('Error processing file:', e);
                playerStore.update(s => ({ ...s, error: `Error processing file: ${e.message}`, isPlayable: false }));
            } finally {
                isLoading = false;
                // Clear the file input so the same file can be re-selected if needed after an error
                input.value = '';
            }
        }
    }
</script>

<div class="card p-4">
    <h3 class="h3 mb-2">Load Audio File</h3>
    <input type="file" id="fileInput" class="input" on:change={handleFileSelect} accept="audio/*" disabled={isLoading} />
    {#if currentFile}
        <p class="mt-2 text-sm">Selected: {currentFile.name} ({ (currentFile.size / 1024 / 1024).toFixed(2) } MB)</p>
    {/if}
    {#if isLoading}
        <p class="mt-2 text-sm">Loading...</p>
    {/if}
    <!-- Status messages from playerStore can be displayed here -->
    {#if $playerStore?.status}
        <p class="mt-2 text-sm text-gray-500">Status: {$playerStore.status}</p>
    {/if}
    {#if $playerStore?.error}
        <p class="mt-2 text-sm text-error-500">Error: {$playerStore.error}</p>
    {/if}
</div>

````
--- End of File: vibe-player-v2/src/lib/components/FileLoader.svelte ---
--- File: vibe-player-v2/src/lib/components/FileLoader.test.ts ---
````typescript
// vibe-player-v2/src/lib/components/FileLoader.test.ts
import { render, fireEvent, screen, act } from "@testing-library/svelte";
import { describe, it, expect, vi, beforeEach, type Mocked } from "vitest";
import FileLoader from "./FileLoader.svelte"; // Adjust path
import audioEngineService from "$lib/services/audioEngine.service";
import { playerStore } from "$lib/stores/player.store";
import { writable, type Writable } from "svelte/store";

// Hoisted Mocks for store structure
vi.mock("$lib/stores/player.store", () => ({
  playerStore: {
    subscribe: vi.fn(),
    update: vi.fn(),
    set: vi.fn(),
  },
}));

// Mock services
vi.mock("$lib/services/audioEngine.service", () => ({
  default: {
    unlockAudio: vi.fn(() => Promise.resolve()),
    loadFile: vi.fn(() => Promise.resolve()),
    initialize: vi.fn(),
    dispose: vi.fn(),
  },
}));

// Declare types for store values
type PlayerStoreValues = {
  fileName: string | null;
  error: string | null;
  status: string;
  isPlayable: boolean;
  isLoadingViaStore?: boolean;
};

// Original initial values
const initialMockPlayerStoreValues: PlayerStoreValues = {
  fileName: null,
  error: null,
  status: "Ready",
  isPlayable: false,
  isLoadingViaStore: false,
};

// This will hold the actual writable store instance, created in beforeEach
let mockPlayerStoreWritable: Writable<PlayerStoreValues>;

describe("FileLoader.svelte", () => {
  beforeEach(async () => {
    vi.useFakeTimers(); // Add fake timers
    // Polyfill/mock File.prototype.arrayBuffer if it doesn't exist in JSDOM
    if (!File.prototype.arrayBuffer) {
      File.prototype.arrayBuffer = vi
        .fn()
        .mockResolvedValue(new ArrayBuffer(10));
    }
    mockPlayerStoreWritable = writable(initialMockPlayerStoreValues);

    const playerStoreMocks = await import("$lib/stores/player.store");
    vi.mocked(playerStoreMocks.playerStore.subscribe).mockImplementation(
      mockPlayerStoreWritable.subscribe,
    );
    vi.mocked(playerStoreMocks.playerStore.update).mockImplementation(
      mockPlayerStoreWritable.update,
    );
    vi.mocked(playerStoreMocks.playerStore.set).mockImplementation(
      mockPlayerStoreWritable.set,
    );

    // Reset store state
    act(() => {
      mockPlayerStoreWritable.set(initialMockPlayerStoreValues);
    });

    vi.clearAllMocks(); // Clear service mocks etc.

    // Re-apply store mock implementations after vi.clearAllMocks()
    vi.mocked(playerStoreMocks.playerStore.subscribe).mockImplementation(
      mockPlayerStoreWritable.subscribe,
    );
    vi.mocked(playerStoreMocks.playerStore.update).mockImplementation(
      mockPlayerStoreWritable.update,
    );
    vi.mocked(playerStoreMocks.playerStore.set).mockImplementation(
      mockPlayerStoreWritable.set,
    );
  });

  it("renders the file input", () => {
    const { container } = render(FileLoader);
    const fileInput = container.querySelector("#fileInput");
    expect(fileInput).toBeInTheDocument();
  });

  it("calls audioEngine.unlockAudio and loadFile on file selection", async () => {
    const { container } = render(FileLoader);
    const fileInput = container.querySelector("#fileInput");
    if (!fileInput) throw new Error("File input with ID 'fileInput' not found");

    const mockFile = new File(["dummy content"], "test.mp3", {
      type: "audio/mpeg",
    });
    const mockArrayBuffer = new ArrayBuffer(10);
    // Spy on the potentially polyfilled/mocked arrayBuffer
    vi.spyOn(File.prototype, "arrayBuffer").mockResolvedValue(mockArrayBuffer);

    await fireEvent.change(fileInput, { target: { files: [mockFile] } });

    expect(audioEngineService.unlockAudio).toHaveBeenCalledTimes(1);
    // Wait for promises in handleFileSelect to resolve
    await act(() => Promise.resolve());
    expect(audioEngineService.loadFile).toHaveBeenCalledWith(
      mockArrayBuffer,
      mockFile.name,
    );
  });

  it("displays selected file name and size", async () => {
    const { container } = render(FileLoader);
    const fileInput = container.querySelector("#fileInput");
    if (!fileInput) throw new Error("File input with ID 'fileInput' not found");

    const mockFile = new File(["dummy content"], "example.wav", {
      type: "audio/wav",
      lastModified: Date.now(),
    });
    Object.defineProperty(mockFile, "size", { value: 1024 * 500 }); // 0.5 MB

    await fireEvent.change(fileInput, { target: { files: [mockFile] } });
    await act(() => Promise.resolve()); // allow store updates and component reactions

    expect(
      screen.getByText(`Selected: ${mockFile.name} (0.49 MB)`), // Corrected size
    ).toBeInTheDocument();
  });

  it("shows loading indicator text while isLoading is true (component internal state)", async () => {
    (audioEngineService.loadFile as Mocked<any>).mockImplementationOnce(
      () => new Promise((resolve) => setTimeout(resolve, 100)), // Simulate delay
    );
    const { container } = render(FileLoader);
    const fileInput = container.querySelector("#fileInput");
    if (!fileInput) throw new Error("File input with ID 'fileInput' not found");

    const mockFile = new File(["dummy"], "loading_test.mp3", {
      type: "audio/mpeg",
    });
    // Spy on the potentially polyfilled/mocked arrayBuffer
    vi.spyOn(File.prototype, "arrayBuffer").mockResolvedValue(
      new ArrayBuffer(8),
    );

    // Don't await this, to check intermediate loading state
    fireEvent.change(fileInput, { target: { files: [mockFile] } });

    await screen.findByText("Loading..."); // Component's internal isLoading state
    expect(screen.getByText("Loading...")).toBeInTheDocument();

    await act(() => vi.advanceTimersByTimeAsync(100)); // Resolve the loadFile promise
    expect(screen.queryByText("Loading...")).not.toBeInTheDocument();
  });

  it("disables file input when isLoading (component internal state) is true", async () => {
    (audioEngineService.loadFile as Mocked<any>).mockImplementationOnce(
      () => new Promise((resolve) => setTimeout(resolve, 100)),
    );
    const { container } = render(FileLoader);
    const fileInput = container.querySelector("#fileInput");
    if (!fileInput) throw new Error("File input with ID 'fileInput' not found");

    const mockFile = new File(["dummy"], "test.mp3", { type: "audio/mpeg" });
    // Spy on the potentially polyfilled/mocked arrayBuffer
    vi.spyOn(File.prototype, "arrayBuffer").mockResolvedValue(
      new ArrayBuffer(8),
    );

    fireEvent.change(fileInput, { target: { files: [mockFile] } });
    await screen.findByText("Loading..."); // Wait for loading state to be true
    expect(fileInput).toBeDisabled();

    await act(() => vi.advanceTimersByTimeAsync(100)); // Resolve promise
    expect(fileInput).not.toBeDisabled();
  });

  it("displays status and error messages from playerStore", async () => {
    render(FileLoader);

    act(() => {
      mockPlayerStoreWritable.update((s) => ({
        ...s,
        status: "Test Status Message",
      }));
    });
    // Use findByText to wait for potential DOM updates after store change
    expect(
      await screen.findByText("Status: Test Status Message"),
    ).toBeInTheDocument();

    act(() => {
      mockPlayerStoreWritable.update((s) => ({
        ...s,
        error: "Test Error Message",
      }));
    });
    expect(
      await screen.findByText("Error: Test Error Message"),
    ).toBeInTheDocument();
  });
});

````
--- End of File: vibe-player-v2/src/lib/components/FileLoader.test.ts ---
--- File: vibe-player-v2/src/lib/components/ToneDisplay.svelte ---
````svelte
<!-- vibe-player-v2/src/lib/components/ToneDisplay.svelte -->
<script lang="ts">
  import { dtmfStore } from '$lib/stores/dtmf.store';
</script>

<div class="card p-4 space-y-4">
  <h3 class="h3">Detected Tones</h3>
  <div>
    <h4 class="font-bold">DTMF (Dial Tones):</h4>
    {#if $dtmfStore.status === 'processing'}
      <p class="text-sm text-surface-500">Processing...</p>
    {:else if $dtmfStore.dtmf.length > 0}
  <!-- *** ADD data-testid HERE *** -->
  <p data-testid="dtmf-display" class="font-mono text-lg p-2 bg-surface-100 dark:bg-surface-800 rounded">
        {$dtmfStore.dtmf.join(' ')}
      </p>
    {:else}
      <p class="text-sm text-surface-500">None detected.</p>
    {/if}
  </div>
  <!-- You would add a similar block for CPTs here -->
</div>

````
--- End of File: vibe-player-v2/src/lib/components/ToneDisplay.svelte ---
--- File: vibe-player-v2/src/lib/components/visualizers/Spectrogram.svelte ---
````svelte
<!-- vibe-player-v2/src/lib/components/visualizers/Spectrogram.svelte -->

<script lang="ts">
    import { onMount, onDestroy } from 'svelte';
    import { get } from 'svelte/store';
    import { analysisStore } from '$lib/stores/analysis.store';
    import { viridisColor } from '$lib/utils/dsp'; // Assuming dsp.ts has viridisColor
    import { VISUALIZER_CONSTANTS } from '$lib/utils';

    let canvasElement: HTMLCanvasElement;
    let canvasCtx: CanvasRenderingContext2D | null = null;
    let spectrogramData: Float32Array[] | null = null;

    // Example: Trigger spectrogram processing after file is loaded via audioEngine
    // This is a bit indirect. A more robust system might have audioEngine emit an event
    // or update a store that analysisService listens to, to get the full audio buffer.
    // For now, this is a placeholder for how processing might be initiated.
    // playerStore.subscribe(value => {
    //     if (value.originalAudioBuffer && analysisService && get(analysisStore).spectrogramWorkerInitialized) {
    //          const pcmData = value.originalAudioBuffer.getChannelData(0); // Mono for spec for now
    //          analysisService.processAudioForSpectrogram(pcmData);
    //     }
    // });

    analysisStore.subscribe(value => {
        if (value.spectrogramData && value.spectrogramData.length > 0) {
            spectrogramData = value.spectrogramData;
            drawSpectrogram();
        } else if (spectrogramData && (!value.spectrogramData || value.spectrogramData.length === 0)) {
            spectrogramData = null;
            clearCanvas();
        }
    });

    function clearCanvas() {
        if (canvasCtx && canvasElement) {
            canvasCtx.clearRect(0, 0, canvasElement.width, canvasElement.height);
        }
    }

    function drawSpectrogram() {
        if (!canvasCtx || !canvasElement || !spectrogramData || spectrogramData.length === 0) {
            clearCanvas();
            return;
        }

        const numFrames = spectrogramData.length; // Time axis
        const numBins = spectrogramData[0].length; // Frequency axis (FFT_SIZE / 2 + 1)

        const width = canvasElement.width;
        const height = canvasElement.height;

        const cellWidth = width / numFrames;
        const cellHeight = height / numBins;

        canvasCtx.clearRect(0, 0, width, height);

        // Find global min/max magnitude for better color scaling (or use fixed range)
        let minMag = Infinity, maxMag = -Infinity;
        for (let t = 0; t < numFrames; t++) {
            for (let f = 0; f < numBins; f++) {
                const mag = spectrogramData[t][f];
                if (mag < minMag) minMag = mag;
                if (mag > maxMag) maxMag = mag;
            }
        }
        // Basic log scaling for magnitudes can improve visualization
        // const logMinMag = Math.log10(Math.max(1e-6, minMag)); // Avoid log(0)
        // const logMaxMag = Math.log10(Math.max(1e-6, maxMag));
        // const magRange = logMaxMag - logMinMag;

        // For linear scaling from 0 to maxMag (assuming magnitudes are positive)
        maxMag = Math.max(maxMag, 0.00001); // ensure maxMag is not zero for division

        for (let t = 0; t < numFrames; t++) { // Time
            for (let f = 0; f < numBins; f++) { // Frequency
                const magnitude = spectrogramData[t][f];

                // Normalize magnitude (0 to 1) - simple linear scaling
                let normalizedMag = magnitude / maxMag;
                // Or log scale:
                // if (magRange > 1e-6) {
                //    normalizedMag = (Math.log10(Math.max(1e-6, magnitude)) - logMinMag) / magRange;
                // } else {
                //    normalizedMag = 0;
                // }
                normalizedMag = Math.max(0, Math.min(1, normalizedMag)); // Clamp

                const [r, g, b] = viridisColor(normalizedMag);
                canvasCtx.fillStyle = `rgb(${r},${g},${b})`;

                // Draw from top (high freq) to bottom (low freq)
                canvasCtx.fillRect(t * cellWidth, height - (f + 1) * cellHeight, cellWidth, cellHeight);
            }
        }
    }

    onMount(() => {
        if (!canvasElement) return;
        canvasElement.width = canvasElement.offsetWidth;
        canvasElement.height = canvasElement.offsetHeight;
        canvasCtx = canvasElement.getContext('2d');

        const currentAnalysisData = get(analysisStore);
        if (currentAnalysisData.spectrogramData) {
            spectrogramData = currentAnalysisData.spectrogramData;
        }
        drawSpectrogram();
    });

</script>

<div class="card p-1 bg-surface-200-700-token aspect-[4/1] w-full h-full">
    <canvas bind:this={canvasElement} class="w-full h-full"></canvas>
</div>

````
--- End of File: vibe-player-v2/src/lib/components/visualizers/Spectrogram.svelte ---
--- File: vibe-player-v2/src/lib/components/visualizers/Waveform.svelte ---
````svelte
<!-- vibe-player-v2/src/lib/components/visualizers/Waveform.svelte -->

<script lang="ts">
    import { onMount, onDestroy } from 'svelte';
    import { playerStore } from '$lib/stores/player.store';
    import { VISUALIZER_CONSTANTS } from '$lib/utils/constants'; // For colors etc.
    import { get } from 'svelte/store'; // To read store value once if needed

    let canvasElement: HTMLCanvasElement;
    let canvasCtx: CanvasRenderingContext2D | null = null;
    let waveformData: number[][] = []; // Store current waveform data

    const WAVEFORM_COLOR_DEFAULT = VISUALIZER_CONSTANTS.WAVEFORM_COLOR_DEFAULT || '#26828E';
    const WAVEFORM_HEIGHT_SCALE = VISUALIZER_CONSTANTS.WAVEFORM_HEIGHT_SCALE || 0.8;


    playerStore.subscribe(value => {
        if (value.waveformData && value.waveformData.length > 0) {
            waveformData = value.waveformData;
            drawWaveform();
        } else if (waveformData.length > 0 && (!value.waveformData || value.waveformData.length === 0)) {
            // Clear canvas if waveform data is removed (e.g. new file loading, error)
            waveformData = [];
            clearCanvas();
        }
    });

    function clearCanvas() {
        if (canvasCtx && canvasElement) {
            canvasCtx.clearRect(0, 0, canvasElement.width, canvasElement.height);
        }
    }

    function drawWaveform() {
        if (!canvasCtx || !canvasElement || !waveformData || waveformData.length === 0) {
            clearCanvas();
            return;
        }

        const width = canvasElement.width;
        const height = canvasElement.height;
        const numChannels = waveformData.length;
        const channelHeight = height / numChannels;

        canvasCtx.clearRect(0, 0, width, height);
        canvasCtx.strokeStyle = WAVEFORM_COLOR_DEFAULT;
        canvasCtx.lineWidth = 1;

        for (let c = 0; c < numChannels; c++) {
            const channelData = waveformData[c];
            if (!channelData || channelData.length === 0) continue;

            const dataPoints = channelData.length;
            const stepX = width / dataPoints;
            const channelCenterY = (channelHeight * c) + (channelHeight / 2);

            canvasCtx.beginPath();
            canvasCtx.moveTo(0, channelCenterY - (channelData[0] * channelHeight / 2 * WAVEFORM_HEIGHT_SCALE));

            for (let i = 1; i < dataPoints; i++) {
                const x = i * stepX;
                const yValue = channelData[i] * channelHeight / 2 * WAVEFORM_HEIGHT_SCALE; // Scale amplitude to fit channel height
                canvasCtx.lineTo(x, channelCenterY - yValue);
            }
            canvasCtx.stroke();
        }
    }

    onMount(() => {
        if (!canvasElement) return;
        // Ensure canvas has a size for drawing, falling back to CSS size if not set directly
        // For responsive canvas, often done with ResizeObserver or binding width/height
        // Here, we'll use offsetWidth/Height for initial sizing.
        canvasElement.width = canvasElement.offsetWidth;
        canvasElement.height = canvasElement.offsetHeight;
        canvasCtx = canvasElement.getContext('2d');

        // Initial draw in case store already has data (e.g. page reload with URL state)
        const currentPlayerData = get(playerStore);
        if (currentPlayerData.waveformData) {
             waveformData = currentPlayerData.waveformData;
        }
        drawWaveform();

        // Optional: Handle window resize to redraw (more complex, involves debouncing)
        // window.addEventListener('resize', handleResize);
    });

    // function handleResize() { // Debounced resize handler
    //     if(canvasElement) {
    //         canvasElement.width = canvasElement.offsetWidth;
    //         canvasElement.height = canvasElement.offsetHeight;
    //         drawWaveform();
    //     }
    // }

    onDestroy(() => {
        // window.removeEventListener('resize', handleResize);
    });

</script>

<div class="card p-1 bg-surface-200-700-token aspect-[4/1] w-full h-full">
    <canvas bind:this={canvasElement} class="w-full h-full"></canvas>
</div>

````
--- End of File: vibe-player-v2/src/lib/components/visualizers/Waveform.svelte ---
--- File: vibe-player-v2/src/lib/index.ts ---
````typescript
// place files you want to import through the `$lib` alias in this folder.

````
--- End of File: vibe-player-v2/src/lib/index.ts ---
--- File: vibe-player-v2/src/lib/services/analysis.service.test.ts ---
````typescript
// vibe-player-v2/src/lib/services/analysis.service.test.ts

import { vi, describe, it, expect, beforeEach, afterEach } from "vitest";

// --- Mock Dependencies ---

// Define the mock worker instance here, so it's available for the mock factory.
const mockVadWorkerInstance = {
  postMessage: vi.fn(),
  terminate: vi.fn(),
  onmessage: null as ((event: MessageEvent) => void) | null,
  onerror: null as ((event: ErrorEvent) => void) | null,
  __IS_MOCK__: true, // Unique property
};

// Hoisted mocks must use the variables defined above.
vi.mock("$lib/stores/analysis.store", () => ({
  analysisStore: {
    subscribe: vi.fn(),
    set: vi.fn(),
    update: vi.fn(),
  },
}));

vi.mock("$lib/workers/sileroVad.worker?worker&inline", () => {
  const MockConstructor = vi.fn().mockImplementation(() => {
    return mockVadWorkerInstance; // mockVadWorkerInstance is from the outer (test file) scope
  });
  return { default: MockConstructor };
});

// --- Test Suite ---
// import analysisService from "./analysis.service"; // No longer imported at top level
import { VAD_CONSTANTS } from "$lib/utils";
import { VAD_WORKER_MSG_TYPE } from "$lib/types/worker.types"; // <-- ADD THIS IMPORT

describe("AnalysisService (VAD Only)", () => {
  let analysisService: typeof import("./analysis.service").default; // Type for the service

  beforeEach(async () => {
    vi.resetModules(); // Reset modules before each test

    // Dynamically import the service to get a fresh instance with fresh mocks
    const serviceModule = await import("./analysis.service");
    analysisService = serviceModule.default;

    // Spies on mockVadWorkerInstance will be new for each test if it were re-defined,
    // but it's from outer scope. clearAllMocks will handle its spies.
    vi.clearAllMocks(); // Still useful for clearing history on mockVadWorkerInstance's methods

    // Mock the global `fetch` API (needs to be re-applied after resetModules)
    vi.spyOn(global, "fetch").mockResolvedValue({
      ok: true,
      status: 200,
      arrayBuffer: () => Promise.resolve(new ArrayBuffer(8)),
    } as Response);

    // Dispose the freshly imported service instance to ensure clean state before test logic
    analysisService.dispose();
  });

  afterEach(() => {
    // Restore original implementations after each test.
    // vi.restoreAllMocks(); // restoreAllMocks might be too broad if fetch is spied globally
    // vi.resetAllMocks() could also be an option if preferred over clearAllMocks.
    // For now, beforeEach handles spy setup.
  });

  describe("initialize (VAD)", () => {
    // FIX: Correctly test the asynchronous flow.
    it("should successfully initialize the VAD worker", async () => {
      // Act: Start the initialization process.
      const initPromise = analysisService.initialize();

      // Give a chance for async operations within initialize() to proceed up to postMessage
      await new Promise((resolve) => setImmediate(resolve)); // Ensures any sync code in initialize runs

      // Directly check if postMessage spy was called
      expect(mockVadWorkerInstance.postMessage.mock.calls.length).toBe(1);
      expect(mockVadWorkerInstance.postMessage).toHaveBeenCalledWith(
        expect.objectContaining({ type: VAD_WORKER_MSG_TYPE.INIT }),
        expect.any(Array),
      );

      // Simulate: The worker sends a "success" message back.
      mockVadWorkerInstance.onmessage!({
        data: {
          type: VAD_WORKER_MSG_TYPE.INIT_SUCCESS,
          messageId: "vad_msg_0",
        },
      } as MessageEvent);

      // Assert: The main initialization promise should now resolve without errors.
      await expect(initPromise).resolves.toBeUndefined();

      // Assert (Final): Check that fetch was also called as expected.
      expect(global.fetch).toHaveBeenCalledWith(VAD_CONSTANTS.ONNX_MODEL_URL);
    });

    // FIX: Correctly test the rejection flow.
    it("should handle initialization failure from the worker", async () => {
      // Act: Start the initialization process.
      const initPromise = analysisService.initialize();

      // Give a chance for async operations within initialize() to proceed up to postMessage
      await new Promise((resolve) => setImmediate(resolve));

      // Directly check if postMessage spy was called (it should be, to register the promise)
      expect(mockVadWorkerInstance.postMessage.mock.calls.length).toBe(1);

      // Simulate: The worker responds with an error message.
      mockVadWorkerInstance.onmessage!({
        data: {
          type: VAD_WORKER_MSG_TYPE.INIT_ERROR,
          error: "Model load failed",
          messageId: "vad_msg_0",
        },
      } as MessageEvent);

      // Assert: The promise should reject with the worker's error.
      await expect(initPromise).rejects.toThrowError("Model load failed");
    });
  });

  // ... (dispose tests should now pass due to the beforeEach fix)
  describe("dispose", () => {
    it("should terminate the worker if it was initialized", async () => {
      // Arrange
      const initPromise = analysisService.initialize();

      // Give a chance for async operations within initialize() to proceed up to postMessage
      await new Promise((resolve) => setImmediate(resolve));

      // Check postMessage was called for initialization
      expect(mockVadWorkerInstance.postMessage.mock.calls.length).toBe(1);

      mockVadWorkerInstance.onmessage!({
        data: {
          type: VAD_WORKER_MSG_TYPE.INIT_SUCCESS,
          messageId: "vad_msg_0",
        },
      } as MessageEvent);
      await initPromise; // This should now resolve

      // Act
      analysisService.dispose();

      // Assert
      expect(mockVadWorkerInstance.terminate).toHaveBeenCalledTimes(1);
    });

    it("should not throw an error if called before initialization", () => {
      // Arrange: The beforeEach hook already ensures a clean state.

      // Act & Assert
      expect(() => analysisService.dispose()).not.toThrow();
      expect(mockVadWorkerInstance.terminate).not.toHaveBeenCalled();
    });
  });
});

````
--- End of File: vibe-player-v2/src/lib/services/analysis.service.test.ts ---
--- File: vibe-player-v2/src/lib/services/analysis.service.ts ---
````typescript
// vibe-player-v2/src/lib/services/analysis.service.ts
import { browser } from "$app/environment";
import { get } from "svelte/store";
import type {
  SileroVadInitPayload,
  SileroVadProcessPayload,
  SileroVadProcessResultPayload,
  WorkerMessage,
} from "$lib/types/worker.types";
import { VAD_WORKER_MSG_TYPE } from "$lib/types/worker.types";
import { VAD_CONSTANTS } from "$lib/utils";
import { analysisStore } from "$lib/stores/analysis.store";
import SileroVadWorker from "$lib/workers/sileroVad.worker?worker&inline";

interface PendingRequest {
  resolve: (value: unknown) => void;
  reject: (reason?: any) => void;
}

interface AnalysisServiceInitializeOptions {
  positiveThreshold?: number;
  negativeThreshold?: number;
}

class AnalysisService {
  private static instance: AnalysisService;
  private worker: Worker | null = null;
  private isInitialized = false;
  private isInitializing = false;
  private nextMessageId = 0;
  private pendingRequests = new Map<string, PendingRequest>();

  private constructor() {}

  public static getInstance(): AnalysisService {
    if (!AnalysisService.instance) {
      AnalysisService.instance = new AnalysisService();
    }
    return AnalysisService.instance;
  }

  private generateMessageId(): string {
    return `vad_msg_${this.nextMessageId++}`;
  }

  private postMessageToWorker<T>(
    message: WorkerMessage<T>,
    transferList?: Transferable[],
  ): Promise<unknown> {
    return new Promise((resolve, reject) => {
      if (!this.worker) {
        return reject(new Error("VAD Worker not initialized."));
      }
      const messageId = this.generateMessageId();
      this.pendingRequests.set(messageId, { resolve, reject });
      this.worker.postMessage({ ...message, messageId }, transferList || []);
    });
  }

  public async initialize(
    options?: AnalysisServiceInitializeOptions,
  ): Promise<void> {
    if (!browser) return;
    if (this.isInitialized || this.isInitializing) {
      return;
    }
    this.isInitializing = true;
    analysisStore.update((s) => ({
      ...s,
      vadStatus: "VAD service initializing...",
      vadInitialized: false,
      vadError: null,
    }));

    this.worker = new SileroVadWorker();

    this.worker.onmessage = (event: MessageEvent<WorkerMessage<unknown>>) => {
      const { type, payload, error, messageId } = event.data;
      const request = messageId
        ? this.pendingRequests.get(messageId)
        : undefined;

      if (error) {
        const errorMsg = error instanceof Error ? error.message : String(error);
        analysisStore.update((s) => ({
          ...s,
          vadError: `VAD Worker error: ${errorMsg}`,
        }));
        if (request) request.reject(new Error(errorMsg));
        if (type === VAD_WORKER_MSG_TYPE.INIT_ERROR) {
          this.isInitialized = false;
          this.isInitializing = false;
          analysisStore.update((s) => ({
            ...s,
            vadStatus: "Error initializing VAD service.",
            vadInitialized: false,
          }));
        }
      } else {
        switch (type) {
          case VAD_WORKER_MSG_TYPE.INIT_SUCCESS:
            this.isInitialized = true;
            this.isInitializing = false;
            analysisStore.update((s) => ({
              ...s,
              vadStatus: "VAD service initialized.",
              vadInitialized: true,
              vadError: null,
            }));
            if (request) request.resolve(payload);
            break;
          case VAD_WORKER_MSG_TYPE.PROCESS_RESULT:
            const resultPayload = payload as SileroVadProcessResultPayload;
            analysisStore.update((s) => ({
              ...s,
              lastVadResult: resultPayload,
              isSpeaking: resultPayload.isSpeech,
            }));
            if (request) request.resolve(resultPayload);
            break;
          case `${VAD_WORKER_MSG_TYPE.RESET}_SUCCESS`:
            analysisStore.update((s) => ({
              ...s,
              vadStateResetted: true,
              lastVadResult: null,
              isSpeaking: false,
            }));
            if (request) request.resolve(payload);
            break;
          default:
            if (request) request.resolve(payload);
        }
      }
      if (messageId && request) this.pendingRequests.delete(messageId);
    };

    this.worker.onerror = (err: Event | string) => {
      const errorMsg =
        typeof err === "string"
          ? err
          : err instanceof ErrorEvent
            ? err.message
            : "Unknown VAD worker error";
      analysisStore.update((s) => ({
        ...s,
        vadStatus: "Critical VAD worker error.",
        vadError: errorMsg,
        vadInitialized: false,
      }));
      this.pendingRequests.forEach((req) =>
        req.reject(new Error(`VAD Worker failed critically: ${errorMsg}`)),
      );
      this.pendingRequests.clear();
      this.isInitialized = false;
      this.isInitializing = false;
    };

    try {
      const modelResponse = await fetch(VAD_CONSTANTS.ONNX_MODEL_URL);
      if (!modelResponse.ok) {
        throw new Error(
          `Failed to fetch ONNX model: ${modelResponse.statusText}`,
        );
      }
      const modelBuffer = await modelResponse.arrayBuffer();

      const initPayload: SileroVadInitPayload = {
        origin: location.origin, // <-- ADDED
        modelBuffer,
        sampleRate: VAD_CONSTANTS.SAMPLE_RATE,
        frameSamples: VAD_CONSTANTS.DEFAULT_FRAME_SAMPLES,
        positiveThreshold:
          options?.positiveThreshold ||
          VAD_CONSTANTS.DEFAULT_POSITIVE_THRESHOLD,
        negativeThreshold:
          options?.negativeThreshold ||
          VAD_CONSTANTS.DEFAULT_NEGATIVE_THRESHOLD,
      };

      await this.postMessageToWorker<SileroVadInitPayload>(
        { type: VAD_WORKER_MSG_TYPE.INIT, payload: initPayload },
        [initPayload.modelBuffer],
      );
    } catch (err) {
      const errorMessage = err instanceof Error ? err.message : String(err);
      this.isInitialized = false;
      this.isInitializing = false;
      analysisStore.update((s) => ({
        ...s,
        vadStatus: "Error sending VAD init to worker.",
        vadError: errorMessage,
        vadInitialized: false,
      }));
      throw err;
    }
  }

  public async analyzeAudioFrame(
    audioFrame: Float32Array,
    timestamp?: number,
  ): Promise<SileroVadProcessResultPayload | null> {
    if (!this.worker || !this.isInitialized) {
      const errorMsg = "VAD Service not initialized or worker unavailable.";
      analysisStore.update((s) => ({ ...s, vadError: errorMsg }));
      throw new Error(errorMsg);
    }
    const payload: SileroVadProcessPayload = { audioFrame, timestamp };
    try {
      const result = await this.postMessageToWorker<SileroVadProcessPayload>(
        { type: VAD_WORKER_MSG_TYPE.PROCESS, payload },
        [payload.audioFrame.buffer],
      );
      return result as SileroVadProcessResultPayload;
    } catch (error) {
      const errorMessage =
        error instanceof Error ? error.message : String(error);
      analysisStore.update((s) => ({
        ...s,
        vadError: `Error processing VAD frame: ${errorMessage}`,
      }));
      return null;
    }
  }

  public dispose(): void {
    if (this.worker) {
      this.worker.terminate();
      this.worker = null;
    }
    this.pendingRequests.clear();
    this.nextMessageId = 0;
    this.isInitialized = false;
    this.isInitializing = false;
    analysisStore.update((s) => ({
      ...s,
      vadStatus: "VAD service disposed.",
      vadInitialized: false,
      lastVadResult: null,
      isSpeaking: undefined,
      vadError: null,
    }));
    console.log("AnalysisService disposed.");
  }
}

export default AnalysisService.getInstance();

````
--- End of File: vibe-player-v2/src/lib/services/analysis.service.ts ---
--- File: vibe-player-v2/src/lib/services/audioEngine.service.test.ts ---
````typescript
// vibe-player-v2/src/lib/services/audioEngine.service.test.ts

import { vi, describe, it, expect, beforeEach, afterEach } from "vitest";
import { writable, get } from "svelte/store";
import { playerStore } from "$lib/stores/player.store";
import audioEngineService from "./audioEngine.service";
import { RB_WORKER_MSG_TYPE } from "$lib/types/worker.types";
import RubberbandWorker from "$lib/workers/rubberband.worker?worker&inline";
// writable is imported dynamically below
// import { writable } from 'svelte/store';

// --- Mocks ---

// Mock playerStore with an actual writable store
vi.mock("$lib/stores/player.store", async () => {
  const { writable } = await import("svelte/store"); // Dynamically import writable
  const initialMockPlayerStateInsideFactory = {
    // Define state inside factory
    speed: 1.0,
    pitch: 0.0,
    isPlayable: false,
    error: null,
    fileName: "",
    status: "",
    duration: 0,
    audioBuffer: null,
    waveformData: [],
    currentTime: 0,
    gain: 1.0,
    sampleRate: 44100,
  };
  const mockPlayerStoreInstance = writable(initialMockPlayerStateInsideFactory);
  return {
    playerStore: mockPlayerStoreInstance,
  };
});

vi.mock("$lib/workers/rubberband.worker?worker&inline");

const mockWorkerInstance = {
  postMessage: vi.fn(),
  terminate: vi.fn(),
  onmessage: null as ((event: MessageEvent) => void) | null,
};

vi.mocked(RubberbandWorker).mockImplementation(
  () => mockWorkerInstance as unknown as Worker,
);

// Store the mock function so we can target it directly in tests
const mockDecodeAudioData = vi.fn();

global.AudioContext = vi.fn(() => ({
  decodeAudioData: mockDecodeAudioData, // Use the stored mock function
  createGain: vi.fn(() => ({
    connect: vi.fn(),
    gain: { setValueAtTime: vi.fn() },
  })),
  resume: vi.fn().mockResolvedValue(undefined),
  close: vi.fn().mockResolvedValue(undefined),
  state: "running",
  currentTime: 0,
  destination: {},
  sampleRate: 48000,
})) as any;

vi.spyOn(global, "fetch").mockImplementation((url) => {
  return Promise.resolve({
    ok: true,
    status: 200,
    arrayBuffer: () => Promise.resolve(new ArrayBuffer(8)),
    text: () => Promise.resolve("// Mock loader script"),
  } as Response);
});
// --- End Mocks ---

describe("AudioEngineService (Refactored)", () => {
  beforeEach(() => {
    vi.useFakeTimers(); // Use fake timers for RAF
    vi.clearAllMocks();
    // Reset the Svelte store to its initial state before each test
    // playerStore.set is not available directly on the vi.mocked import,
    // we need to import the actual instance if we want to .set() it here.
    // For now, the factory mock re-initializes it.
    // If tests need to modify then reset, we'd need direct access to mockPlayerStoreInstance.
    // Resetting the service's internal state
    audioEngineService.dispose();
  });

  afterEach(() => {
    vi.useRealTimers(); // Restore real timers
  });

  it("loadFile should initialize the worker with correct audio parameters", async () => {
    const mockArrayBuffer = new ArrayBuffer(8);
    const mockDecodedBuffer = {
      duration: 1.0,
      numberOfChannels: 1, // <-- Test with MONO
      sampleRate: 44100,
      getChannelData: vi.fn(() => new Float32Array(1)),
    };
    mockDecodeAudioData.mockResolvedValue(mockDecodedBuffer as any);

    // Act
    await audioEngineService.loadFile(mockArrayBuffer, "test-mono.wav");

    // Assert: Worker should have been created
    expect(RubberbandWorker).toHaveBeenCalledTimes(1);

    // Assert: INIT message was sent with the CORRECT parameters from the decoded buffer
    expect(mockWorkerInstance.postMessage).toHaveBeenCalledWith(
      expect.objectContaining({
        type: RB_WORKER_MSG_TYPE.INIT,
        payload: expect.objectContaining({
          channels: 1, // <-- Crucial check
          sampleRate: 44100, // <-- Crucial check
        }),
      }),
      expect.any(Array), // for the transferable wasmBinary
    );
  });

  it("play should only work after the worker confirms initialization", async () => {
    const mockArrayBuffer = new ArrayBuffer(8);
    const mockDecodedBuffer = {
      duration: 1.0,
      numberOfChannels: 1,
      sampleRate: 44100,
      getChannelData: vi.fn(() => new Float32Array(44100).fill(0.1)),
      length: 44100,
    };
    mockDecodeAudioData.mockResolvedValue(mockDecodedBuffer as any);

    // Act 1: Load the file, which sends the INIT message
    await audioEngineService.loadFile(mockArrayBuffer, "test.wav");

    // Assert 1: Playback is not yet possible because worker hasn't responded
    vi.spyOn(console, "warn").mockImplementation(() => {});
    await audioEngineService.play();
    expect(console.warn).toHaveBeenCalledWith(
      "AudioEngine: Play command ignored. Not ready or already playing.",
    );
    expect(mockWorkerInstance.postMessage).not.toHaveBeenCalledWith(
      expect.objectContaining({ type: RB_WORKER_MSG_TYPE.PROCESS }),
    );
    vi.mocked(console.warn).mockRestore();

    // Act 2: Simulate the worker responding that it's ready
    mockWorkerInstance.onmessage!({
      data: { type: RB_WORKER_MSG_TYPE.INIT_SUCCESS },
    } as MessageEvent);

    // Assert 2: The store should now be updated to be playable
    // To check this, we need to get the actual instance of the mock store used by the service.
    // This requires importing it if the mock factory is self-contained.
    // For now, we rely on the fact that playerStore.update was called.
    // A more robust check would be:
    // import { playerStore as actualPlayerStore } from '$lib/stores/player.store'; // Get the mocked instance
    // expect(get(actualPlayerStore).isPlayable).toBe(true);
    // This currently might fail if the test setup doesn't re-export playerStore correctly for direct import.
    // The mock setup above makes playerStore available.
    expect(get(playerStore).isPlayable).toBe(true);

    // Act 3: Now, play should work
    await audioEngineService.play();

    // vi.advanceTimersByTime(100); // This should no longer be needed due to synchronous first iteration.

    // Assert 3: A PROCESS message should have been sent
    expect(mockWorkerInstance.postMessage).toHaveBeenCalledWith(
      expect.objectContaining({ type: RB_WORKER_MSG_TYPE.PROCESS }),
      expect.any(Array),
    );
  });
});

````
--- End of File: vibe-player-v2/src/lib/services/audioEngine.service.test.ts ---
--- File: vibe-player-v2/src/lib/services/audioEngine.service.ts ---
````typescript
// vibe-player-v2/src/lib/services/audioEngine.service.ts

import { get } from "svelte/store";
import type {
  WorkerMessage,
  RubberbandInitPayload,
  RubberbandProcessPayload,
  RubberbandProcessResultPayload,
  WorkerErrorPayload,
} from "$lib/types/worker.types";
import { RB_WORKER_MSG_TYPE } from "$lib/types/worker.types";
import { playerStore } from "$lib/stores/player.store";
import RubberbandWorker from "$lib/workers/rubberband.worker?worker&inline";
import { assert, AUDIO_ENGINE_CONSTANTS } from "$lib/utils";
import { analysisStore } from "../stores/analysis.store";

class AudioEngineService {
  // ... (static instance and private properties remain the same) ...
  private static instance: AudioEngineService;
  private worker: Worker | null = null;
  private audioContext: AudioContext | null = null;
  private gainNode: GainNode | null = null;
  private originalBuffer: AudioBuffer | null = null;
  private isPlaying = false;
  private isWorkerInitialized = false;
  private isStopping = false;
  private sourcePlaybackOffset = 0;
  private nextChunkTime = 0;

  private constructor() {}

  public static getInstance(): AudioEngineService {
    if (!AudioEngineService.instance) {
      AudioEngineService.instance = new AudioEngineService();
    }
    return AudioEngineService.instance;
  }

  // --- REMOVED: The old `initialize` and `_initializeWorker` methods are gone. ---

  private _getAudioContext(): AudioContext {
    if (!this.audioContext || this.audioContext.state === "closed") {
      this.audioContext = new AudioContext();
      this.gainNode = this.audioContext.createGain();
      this.gainNode.connect(this.audioContext.destination);
    }
    return this.audioContext;
  }

  public async unlockAudio(): Promise<void> {
    // ... (this method is unchanged) ...
  }

  // --- REFACTORED: `loadFile` now handles worker initialization ---
  public async loadFile(
    audioFileBuffer: ArrayBuffer,
    fileName: string,
  ): Promise<void> {
    if (
      !audioFileBuffer ||
      !(audioFileBuffer instanceof ArrayBuffer) ||
      audioFileBuffer.byteLength === 0
    ) {
      const errorMsg = "loadFile received an invalid or empty ArrayBuffer.";
      console.error(`[AudioEngine] ${errorMsg}`);
      playerStore.update((s) => ({ ...s, error: errorMsg, isPlayable: false }));
      return;
    }

    await this.stop(); // Stop and reset any current playback
    const ctx = this._getAudioContext();
    playerStore.update((s) => ({
      ...s,
      status: `Decoding ${fileName}...`,
      error: null,
      fileName,
      isPlayable: false,
    }));

    try {
      this.originalBuffer = await ctx.decodeAudioData(audioFileBuffer);

      // --- START: NEW WORKER INITIALIZATION LOGIC ---
      // If worker doesn't exist, create it.
      if (!this.worker) {
        this.worker = new RubberbandWorker();
        this.worker.onmessage = this.handleWorkerMessage.bind(this);
      } else {
        // If it exists, ensure it's reset for the new file's properties.
        this.worker.postMessage({ type: RB_WORKER_MSG_TYPE.RESET });
      }

      this.isWorkerInitialized = false; // Mark as not ready until worker confirms.

      const wasmResponse = await fetch(AUDIO_ENGINE_CONSTANTS.WASM_BINARY_URL);
      const loaderResponse = await fetch(
        AUDIO_ENGINE_CONSTANTS.LOADER_SCRIPT_URL,
      );
      if (!wasmResponse.ok || !loaderResponse.ok)
        throw new Error("Failed to fetch worker dependencies.");
      const wasmBinary = await wasmResponse.arrayBuffer();
      const loaderScriptText = await loaderResponse.text();

      const initPayload: RubberbandInitPayload = {
        wasmBinary,
        loaderScriptText,
        origin: location.origin,
        sampleRate: this.originalBuffer.sampleRate, // <-- CORRECT: Use actual sample rate
        channels: this.originalBuffer.numberOfChannels, // <-- CORRECT: Use actual channel count
        initialSpeed: get(playerStore).speed,
        initialPitch: get(playerStore).pitch,
      };

      this.worker.postMessage(
        { type: RB_WORKER_MSG_TYPE.INIT, payload: initPayload },
        [wasmBinary],
      );
      // --- END: NEW WORKER INITIALIZATION LOGIC ---

      // The rest of this method (waveform generation, store updates) remains the same...
      const waveformDisplayData: number[][] = [];
      // ... (waveform code)
      playerStore.update((s) => ({
        ...s,
        status: `Initializing processor for ${fileName}...`, // New status
        duration: this.originalBuffer!.duration,
        audioBuffer: this.originalBuffer,
        waveformData: waveformDisplayData,
      }));
      analysisStore.set({});
    } catch (e) {
      const error = e as Error;
      playerStore.update((s) => ({
        ...s,
        status: `Error decoding`,
        error: error.message,
        isPlayable: false,
      }));
      throw error;
    }
  }

  public async play(): Promise<void> {
    // This check now correctly waits for worker confirmation.
    if (this.isPlaying || !this.originalBuffer || !this.isWorkerInitialized) {
      console.warn(
        "AudioEngine: Play command ignored. Not ready or already playing.",
      );
      return;
    }

    const audioCtx = this._getAudioContext();
    if (audioCtx.state === "suspended") {
      await audioCtx.resume();
    }

    this.isPlaying = true;
    playerStore.update((s) => ({
      ...s,
      isPlaying: true,
      status: `Playing: ${s.fileName}`,
    }));

    // If starting fresh or after a stop/seek, set nextChunkTime to current time.
    // The condition `this.nextChunkTime < audioCtx.currentTime` handles cases where context time might have advanced
    // significantly while paused (e.g. due to system sleep), ensuring we don't schedule in the past.
    if (this.nextChunkTime === 0 || this.nextChunkTime < audioCtx.currentTime) {
      this.nextChunkTime = audioCtx.currentTime;
    }

    // MODIFICATION FOR TESTING: Call one iteration synchronously for the first time
    this._performSingleProcessAndPlayIteration();

    // Then schedule the rest with RAF if still playing
    if (this.isPlaying) {
      requestAnimationFrame(this._recursiveProcessAndPlayLoop.bind(this));
    }
  }

  // Renamed original processAndPlayLoop and made it private for RAF recursion
  private _recursiveProcessAndPlayLoop(): void {
    if (
      !this.isPlaying ||
      !this.originalBuffer ||
      this.isStopping ||
      !this.audioContext
    ) {
      return;
    }
    this._performSingleProcessAndPlayIteration(); // Perform one iteration
    if (this.isPlaying) {
      // If still playing after one iteration, schedule next
      requestAnimationFrame(this._recursiveProcessAndPlayLoop.bind(this));
    }
  }

  // Contains the actual logic of one iteration of the processing loop
  private _performSingleProcessAndPlayIteration(): void {
    if (
      !this.isPlaying ||
      !this.originalBuffer ||
      this.isStopping ||
      !this.audioContext
    ) {
      // console.log("ProcessAndPlayLoop: Aborting - isPlaying:", this.isPlaying, "has buffer:", !!this.originalBuffer, "isStopping:", this.isStopping);
      return;
    }

    const now = this.audioContext.currentTime;
    const lookahead = AUDIO_ENGINE_CONSTANTS.PROCESS_LOOKAHEAD_TIME;

    // Check if it's time to request more data
    if (this.nextChunkTime < now + lookahead) {
      // Check if there's more audio data to process in the original buffer
      if (this.sourcePlaybackOffset < this.originalBuffer.duration) {
        const chunkDuration = AUDIO_ENGINE_CONSTANTS.TARGET_CHUNK_DURATION_S;
        // Calculate the actual duration of the next chunk to process
        let actualChunkDuration = Math.min(
          chunkDuration,
          this.originalBuffer.duration - this.sourcePlaybackOffset,
        );

        if (
          actualChunkDuration <= AUDIO_ENGINE_CONSTANTS.MIN_CHUNK_DURATION_S &&
          this.originalBuffer.duration - this.sourcePlaybackOffset >
            AUDIO_ENGINE_CONSTANTS.MIN_CHUNK_DURATION_S
        ) {
          actualChunkDuration = Math.min(
            this.originalBuffer.duration - this.sourcePlaybackOffset,
            AUDIO_ENGINE_CONSTANTS.TARGET_CHUNK_DURATION_S,
          );
        } else if (actualChunkDuration <= 0) {
          this.isPlaying = false;
          playerStore.update((s) => ({
            ...s,
            isPlaying: false,
            currentTime: this.originalBuffer!.duration,
            status: `Finished: ${s.fileName}`,
          }));
          return;
        }

        const startSample = Math.floor(
          this.sourcePlaybackOffset * this.originalBuffer.sampleRate,
        );
        const endSample = Math.floor(
          Math.min(
            this.sourcePlaybackOffset + actualChunkDuration,
            this.originalBuffer.duration,
          ) * this.originalBuffer.sampleRate,
        );

        if (startSample >= endSample) {
          this.isPlaying = false;
          playerStore.update((s) => ({
            ...s,
            isPlaying: false,
            currentTime: this.originalBuffer!.duration,
            status: `Finished: ${s.fileName}`,
          }));
          return;
        }

        const channelData = this.originalBuffer.getChannelData(0);
        const segment = channelData.slice(startSample, endSample);

        const processPayload: RubberbandProcessPayload = {
          inputBuffer: segment,
          isFinalChunk:
            this.sourcePlaybackOffset + actualChunkDuration >=
            this.originalBuffer.duration,
        };

        this.worker!.postMessage(
          { type: RB_WORKER_MSG_TYPE.PROCESS, payload: processPayload },
          [segment.buffer],
        );

        this.sourcePlaybackOffset += actualChunkDuration;
      } else {
        this.isPlaying = false;
        playerStore.update((s) => ({
          ...s,
          isPlaying: false,
          currentTime: this.originalBuffer.duration,
          status: `Finished: ${s.fileName}`,
        }));
        return;
      }
    }
    // Note: The recursive call via requestAnimationFrame is removed from here
    // and handled by _recursiveProcessAndPlayLoop or the initial call in play().
  }

  public async stop(): Promise<void> {
    this.isStopping = true;
    this.isPlaying = false;
    if (this.worker) {
      this.worker.postMessage({ type: RB_WORKER_MSG_TYPE.RESET });
    }
    this.sourcePlaybackOffset = 0;
    this.nextChunkTime = 0;
    playerStore.update((s) => ({
      ...s,
      currentTime: 0,
      isPlaying: false,
      status: `Stopped: ${s.fileName || ""}`,
    }));
    this.isStopping = false;
  }

  public pause(): void {
    if (!this.isPlaying) return;
    this.isPlaying = false;
    playerStore.update((s) => ({
      ...s,
      isPlaying: false,
      status: `Paused: ${s.fileName || ""}`,
    }));
  }

  public async seek(time: number): Promise<void> {
    if (
      !this.originalBuffer ||
      time < 0 ||
      time > this.originalBuffer.duration
    ) {
      console.warn("AudioEngine: Seek time is out of bounds.");
      return;
    }

    const wasPlaying = this.isPlaying;
    if (this.isPlaying) {
      this.pause();
    }

    this.sourcePlaybackOffset = time;
    this.nextChunkTime = this.audioContext ? this.audioContext.currentTime : 0;

    playerStore.update((s) => ({ ...s, currentTime: time }));

    if (this.worker) {
      this.worker.postMessage({ type: RB_WORKER_MSG_TYPE.RESET });
    }

    if (wasPlaying) {
      // Resume playback after seeking. Needs to ensure processAndPlayLoop is triggered.
      // The current play() method might be sufficient if it correctly starts the loop.
      // Adding a small delay for worker reset might be needed in practice.
      await this.play();
    }
  }

  public setSpeed(speed: number): void {
    if (this.worker && this.isWorkerInitialized) {
      this.worker.postMessage({
        type: RB_WORKER_MSG_TYPE.SET_SPEED,
        payload: { speed },
      });
    }
    playerStore.update((s) => ({ ...s, speed }));
  }

  public setPitch(pitch: number): void {
    if (this.worker && this.isWorkerInitialized) {
      this.worker.postMessage({
        type: RB_WORKER_MSG_TYPE.SET_PITCH,
        payload: { pitch },
      });
    }
    playerStore.update((s) => ({ ...s, pitch }));
  }

  public setGain(level: number): void {
    if (this.gainNode && this.audioContext) {
      const newGain = Math.max(0, Math.min(1, level)); // Clamp between 0 and 1
      this.gainNode.gain.setValueAtTime(newGain, this.audioContext.currentTime);
      playerStore.update((s) => ({ ...s, gain: newGain }));
    }
  }

  public dispose(): void {
    // this.stop(); // stop is async, dispose is sync. This can be an issue.
    // Forcing a synchronous stop for dispose lifecycle:
    this.isPlaying = false;
    this.isStopping = true; // Prevent processing loop
    if (this.worker) {
      this.worker.postMessage({ type: RB_WORKER_MSG_TYPE.RESET }); // Tell worker to clear state
    }
    this.sourcePlaybackOffset = 0;
    this.nextChunkTime = 0;
    // Not updating store from dispose to avoid potential issues during component teardown
    this.isStopping = false;

    // Proceed with termination and cleanup
    this.worker?.terminate();
    this.worker = null;
    this.isWorkerInitialized = false; // Reset flag on dispose
    this.audioContext?.close();
    this.audioContext = null;
  }

  // The original processAndPlayLoop is now _recursiveProcessAndPlayLoop
  // and its core logic is in _performSingleProcessAndPlayIteration.
  // This change effectively renames processAndPlayLoop to _recursiveProcessAndPlayLoop
  // and extracts its core into _performSingleProcessAndPlayIteration.
  // The line below is where the old processAndPlayLoop definition was.
  // We've inserted the new methods above it.

  private scheduleChunkPlayback(
    processedChunk: Float32Array,
    startTime: number,
  ): void {
    if (
      !this.audioContext ||
      !this.gainNode ||
      this.isStopping ||
      !this.originalBuffer
    ) {
      // console.log("ScheduleChunkPlayback: Aborting due to invalid state.");
      return;
    }

    const numberOfChannels = this.originalBuffer.numberOfChannels;
    // Ensure processedChunk length is a multiple of numberOfChannels
    // This basic check assumes interleaved data if multi-channel
    if (
      processedChunk.length === 0 ||
      processedChunk.length % numberOfChannels !== 0
    ) {
      console.error(
        "ScheduleChunkPlayback: Processed chunk length is invalid for channel count.",
        processedChunk.length,
        numberOfChannels,
      );
      return;
    }
    const frameCount = processedChunk.length / numberOfChannels;

    const audioBuffer = this.audioContext.createBuffer(
      numberOfChannels,
      frameCount,
      this.originalBuffer.sampleRate,
    );

    // De-interleave if necessary (example for stereo)
    if (numberOfChannels === 1) {
      audioBuffer.copyToChannel(processedChunk, 0);
    } else if (numberOfChannels === 2) {
      const left = new Float32Array(frameCount);
      const right = new Float32Array(frameCount);
      for (let i = 0; i < frameCount; i++) {
        left[i] = processedChunk[i * 2];
        right[i] = processedChunk[i * 2 + 1];
      }
      audioBuffer.copyToChannel(left, 0);
      audioBuffer.copyToChannel(right, 1);
    } else {
      // General case for >2 channels (assuming interleaved and copying to each channel)
      // This might need more sophisticated handling based on expected worker output.
      for (let i = 0; i < numberOfChannels; i++) {
        const channelData = new Float32Array(frameCount);
        for (let j = 0; j < frameCount; j++) {
          channelData[j] = processedChunk[j * numberOfChannels + i];
        }
        audioBuffer.copyToChannel(channelData, i);
      }
    }

    const bufferSource = this.audioContext.createBufferSource();
    bufferSource.buffer = audioBuffer;
    bufferSource.connect(this.gainNode);

    const actualStartTime = Math.max(this.audioContext.currentTime, startTime);
    // console.log(`ScheduleChunkPlayback: Scheduling chunk at ${actualStartTime}. Duration: ${audioBuffer.duration}`);
    bufferSource.start(actualStartTime);

    const chunkDuration = audioBuffer.duration;
    // Update nextChunkTime for the next iteration of processAndPlayLoop
    // Subtracting SCHEDULE_AHEAD_TIME_S helps ensure there's always some buffer
    this.nextChunkTime =
      actualStartTime +
      chunkDuration -
      AUDIO_ENGINE_CONSTANTS.SCHEDULE_AHEAD_TIME_S;

    bufferSource.onended = () => {
      // console.log("ScheduleChunkPlayback: BufferSource ended. Current offset:", this.sourcePlaybackOffset, "Total duration:", this.originalBuffer!.duration);
      if (
        this.sourcePlaybackOffset >= this.originalBuffer!.duration &&
        this.isPlaying
      ) {
        // This condition might be hit if the very last chunk finishes playing
        this.isPlaying = false;
        playerStore.update((s) => ({
          ...s,
          isPlaying: false,
          status: `Finished: ${s.fileName}`,
        }));
        // console.log("ScheduleChunkPlayback: Playback officially finished after buffer ended.");
      }
      bufferSource.disconnect(); // Clean up
    };
  }

  private handleWorkerMessage(
    event: MessageEvent<
      WorkerMessage<RubberbandProcessResultPayload | WorkerErrorPayload>
    >,
  ): void {
    const { type, payload } = event.data;

    if (type === RB_WORKER_MSG_TYPE.INIT_SUCCESS) {
      this.isWorkerInitialized = true;
      console.log("AudioEngine worker initialized successfully for new file.");
      playerStore.update((s) => ({
        ...s,
        isPlayable: true,
        status: `Ready: ${s.fileName}`,
      }));
    } else if (type === RB_WORKER_MSG_TYPE.ERROR) {
      const errorPayload = payload as WorkerErrorPayload;
      console.error("AudioEngine Worker Error:", errorPayload.message);
      playerStore.update((s) => ({
        ...s,
        error: errorPayload.message,
        isPlaying: false,
        isPlayable: false,
        status: "Error",
      }));
      this.isWorkerInitialized = false;
      // Potentially stop playback and reset if a critical error occurs
      if (this.isPlaying) {
        this.isPlaying = false; // Stop trying to play
      }
    } else if (type === RB_WORKER_MSG_TYPE.PROCESS_RESULT && payload) {
      const { outputBuffer } = payload as RubberbandProcessResultPayload;
      // console.log("AudioEngine: Received PROCESS_RESULT. Output buffer size:", outputBuffer?.length);
      if (outputBuffer && this.isPlaying && !this.isStopping) {
        this.scheduleChunkPlayback(outputBuffer, this.nextChunkTime);
        // The processAndPlayLoop is driven by requestAnimationFrame.
        // If it had paused waiting for nextChunkTime to advance (which it does after scheduling),
        // the next animation frame should pick up the new state and continue processing or wait if still too early.
      } else if (!this.isPlaying && !this.isStopping) {
        // console.log("AudioEngine: Worker processed a chunk, but playback is currently stopped/paused. Ignoring.");
      } else if (this.isStopping) {
        // console.log("AudioEngine: Worker processed a chunk, but we are in stopping phase. Ignoring.");
      }
    }
  }
}

export default AudioEngineService.getInstance();

````
--- End of File: vibe-player-v2/src/lib/services/audioEngine.service.ts ---
--- File: vibe-player-v2/src/lib/services/dtmf.service.test.ts ---
````typescript
// vibe-player-v2/src/lib/services/dtmf.service.test.ts
import {
  vi,
  describe,
  it,
  expect,
  beforeEach,
  afterEach,
  type Mocked,
} from "vitest";
import DtmfWorker from "$lib/workers/dtmf.worker?worker&inline";
import dtmfService from "./dtmf.service";
import { dtmfStore, type DtmfState } from "$lib/stores/dtmf.store";

// Mock Svelte stores
vi.mock("$lib/stores/dtmf.store", () => {
  const actual = vi.importActual("$lib/stores/dtmf.store");
  return {
    ...actual, // Import and retain actual DtmfState, initialState if needed by service
    dtmfStore: {
      subscribe: vi.fn(),
      set: vi.fn(),
      update: vi.fn(),
    },
  };
});

// Mock Web Workers
const mockDtmfWorkerInstance = {
  postMessage: vi.fn(),
  terminate: vi.fn(),
  onmessage: null as ((event: MessageEvent) => void) | null,
  onerror: null as ((event: ErrorEvent) => void) | null, // Though service uses onmessage for errors
};

vi.mock("$lib/workers/dtmf.worker?worker&inline", () => ({
  default: vi.fn().mockImplementation(() => mockDtmfWorkerInstance),
}));

// Mock OfflineAudioContext
const mockGetChannelData = vi.fn();
const mockStartRendering = vi.fn();
const mockOfflineAudioContext = vi.fn(() => ({
  createBufferSource: vi.fn(() => ({
    buffer: null,
    connect: vi.fn(),
    start: vi.fn(),
  })),
  startRendering: mockStartRendering,
}));
global.OfflineAudioContext = mockOfflineAudioContext as any;

// Create a mock AudioBuffer that is an instance of the globally mocked AudioBuffer
// and has a non-zero length.
const mockAudioBuffer = new global.AudioBuffer();
Object.defineProperty(mockAudioBuffer, "length", {
  value: 48000,
  writable: false,
  configurable: true,
});
Object.defineProperty(mockAudioBuffer, "sampleRate", {
  value: 48000,
  writable: false,
  configurable: true,
});
Object.defineProperty(mockAudioBuffer, "duration", {
  value: 1.0,
  writable: false,
  configurable: true,
});
Object.defineProperty(mockAudioBuffer, "numberOfChannels", {
  value: 1,
  writable: false,
  configurable: true,
});
(mockAudioBuffer as any).getChannelData = vi.fn(() => new Float32Array(48000));

const resampledAudioBuffer = {
  sampleRate: 16000,
  duration: 1.0,
  numberOfChannels: 1,
  getChannelData: mockGetChannelData,
} as unknown as AudioBuffer;

describe("DtmfService", () => {
  beforeEach(() => {
    vi.clearAllMocks();
    mockDtmfWorkerInstance.postMessage.mockClear();
    mockDtmfWorkerInstance.terminate.mockClear();
    mockDtmfWorkerInstance.onmessage = null;
    mockDtmfWorkerInstance.onerror = null;

    (dtmfStore.update as Mocked<any>).mockClear();
    (dtmfStore.set as Mocked<any>).mockClear();

    dtmfService.dispose(); // Clean up previous state
  });

  afterEach(() => {
    dtmfService.dispose(); // Clean up
  });

  describe("initialize", () => {
    it("should create DTMF worker, post INIT message, and update store on init_complete", () => {
      dtmfService.initialize(16000); // targetSampleRate for worker

      expect(DtmfWorker).toHaveBeenCalledTimes(1);
      expect(mockDtmfWorkerInstance.postMessage).toHaveBeenCalledWith({
        type: "init",
        payload: { sampleRate: 16000 },
      });

      // Simulate worker response for init_complete
      if (mockDtmfWorkerInstance.onmessage) {
        mockDtmfWorkerInstance.onmessage({
          data: { type: "init_complete" },
        } as MessageEvent);
      }

      expect(dtmfStore.update).toHaveBeenCalledTimes(1);
      const lastUpdateCall = (dtmfStore.update as Mocked<any>).mock.calls[0][0];
      const mockState: DtmfState = {
        status: "processing",
        dtmf: [],
        cpt: [],
        error: "old error",
      };
      const newState = lastUpdateCall(mockState);
      expect(newState.status).toBe("idle");
      expect(newState.error).toBeNull();
    });

    it("should update dtmfStore on 'error' message from worker during init", () => {
      dtmfService.initialize(16000);

      if (mockDtmfWorkerInstance.onmessage) {
        mockDtmfWorkerInstance.onmessage({
          data: { type: "error", payload: "Init failed" },
        } as MessageEvent);
      }

      expect(dtmfStore.update).toHaveBeenCalledTimes(1);
      const lastUpdateCall = (dtmfStore.update as Mocked<any>).mock.calls[0][0];
      const mockState: DtmfState = {
        status: "processing",
        dtmf: [],
        cpt: [],
        error: null,
      };
      const newState = lastUpdateCall(mockState);
      expect(newState.status).toBe("error");
      expect(newState.error).toBe("Init failed");
    });
  });

  describe("process", () => {
    beforeEach(() => {
      // Ensure service is initialized
      dtmfService.initialize(16000);
      if (mockDtmfWorkerInstance.onmessage) {
        mockDtmfWorkerInstance.onmessage({
          data: { type: "init_complete" },
        } as MessageEvent);
      }
      (dtmfStore.update as Mocked<any>).mockClear(); // Clear init updates

      // Setup resampling mock
      mockGetChannelData.mockReturnValue(new Float32Array(16000)); // Resampled data
      mockStartRendering.mockResolvedValue(resampledAudioBuffer);
    });

    it("should update store to 'processing', resample audio, and post 'process' message", async () => {
      await dtmfService.process(mockAudioBuffer);

      expect(dtmfStore.update).toHaveBeenCalledWith(expect.any(Function));
      const processingUpdateCall = (dtmfStore.update as Mocked<any>).mock
        .calls[0][0];
      const processingState = processingUpdateCall({
        status: "idle",
        dtmf: ["old"],
        cpt: ["old"],
        error: "yes",
      });
      expect(processingState.status).toBe("processing");
      expect(processingState.dtmf).toEqual([]);
      expect(processingState.cpt).toEqual([]);

      expect(mockOfflineAudioContext).toHaveBeenCalledWith(
        1,
        mockAudioBuffer.duration * 16000,
        16000,
      );
      expect(mockStartRendering).toHaveBeenCalled();

      // Wait for resampling to complete
      await mockStartRendering();

      expect(mockDtmfWorkerInstance.postMessage).toHaveBeenCalledWith(
        expect.objectContaining({
          type: "process",
          payload: { pcmData: new Float32Array(16000) },
        }),
      );
    });

    it("should update store with results on 'result' message from worker", async () => {
      const processPromise = dtmfService.process(mockAudioBuffer);

      // Simulate worker response for result
      if (mockDtmfWorkerInstance.onmessage) {
        mockDtmfWorkerInstance.onmessage({
          data: {
            type: "result",
            payload: { dtmf: ["1", "2"], cpt: ["busy"] },
          },
        } as MessageEvent);
      }
      await processPromise; // Ensure all async operations complete

      // The first update is 'processing', the second is the result
      const resultUpdateCall = (dtmfStore.update as Mocked<any>).mock
        .calls[1][0];
      const mockState: DtmfState = {
        status: "processing",
        dtmf: [],
        cpt: [],
        error: null,
      };
      const newState = resultUpdateCall(mockState);
      expect(newState.status).toBe("complete");
      expect(newState.dtmf).toEqual(["1", "2"]);
      expect(newState.cpt).toEqual(["busy"]);
    });

    it("should update store with error if worker not initialized", () => {
      dtmfService.dispose(); // Ensure worker is null
      (dtmfStore.update as Mocked<any>).mockClear();

      dtmfService.process(mockAudioBuffer);

      expect(dtmfStore.update).toHaveBeenCalledTimes(1);
      const errorUpdateCall = (dtmfStore.update as Mocked<any>).mock
        .calls[0][0];
      const newState = errorUpdateCall({
        status: "idle",
        dtmf: [],
        cpt: [],
        error: null,
      });
      expect(newState.status).toBe("error");
      expect(newState.error).toBe("DTMF Worker not initialized.");
    });

    it("should update store with error if resampling fails", async () => {
      // Arrange: Mock the resampling process to fail
      const resamplingError = new Error("Resampling failed");
      mockStartRendering.mockRejectedValueOnce(resamplingError);

      // Act: Call the process method and await its expected rejection
      await expect(dtmfService.process(mockAudioBuffer)).rejects.toThrow(
        resamplingError,
      );

      // Assert:
      // The store should be updated twice: once for 'processing', once for 'error'.
      expect(dtmfStore.update).toHaveBeenCalledTimes(2);

      // Get the second update call (the error one) and test its logic.
      const errorUpdateCall = (dtmfStore.update as Mocked<any>).mock
        .calls[1][0];
      const mockState: DtmfState = {
        status: "processing",
        dtmf: [],
        cpt: [],
        error: null,
      };
      const newState = errorUpdateCall(mockState);

      expect(newState.status).toBe("error");
      expect(newState.error).toContain("Resampling failed");
    });
  });

  describe("dispose", () => {
    it("should terminate worker", () => {
      dtmfService.initialize(16000); // Initialize first
      if (mockDtmfWorkerInstance.onmessage) {
        // Simulate init complete
        mockDtmfWorkerInstance.onmessage({
          data: { type: "init_complete" },
        } as MessageEvent);
      }
      (dtmfStore.update as Mocked<any>).mockClear();

      dtmfService.dispose();

      expect(mockDtmfWorkerInstance.terminate).toHaveBeenCalledTimes(1);
      // Check if worker is set to null (not directly testable for private prop, but terminate is a good indicator)
    });

    it("should do nothing if worker already null", () => {
      dtmfService.dispose(); // Call dispose once to ensure worker is null
      // Since the worker is mocked at the module level and dtmfService is a singleton,
      // the first dispose() call will set its internal worker to null.
      // The DtmfWorker constructor mock won't be called again unless initialize is called.
      // So, the first dispose makes the internal worker null.
      mockDtmfWorkerInstance.terminate.mockClear(); // Clear any calls from previous dispose if any test didn't clean up

      dtmfService.dispose(); // Call again

      expect(mockDtmfWorkerInstance.terminate).not.toHaveBeenCalled();
    });
  });
});

````
--- End of File: vibe-player-v2/src/lib/services/dtmf.service.test.ts ---
--- File: vibe-player-v2/src/lib/services/dtmf.service.ts ---
````typescript
// vibe-player-v2/src/lib/services/dtmf.service.ts
import { browser } from "$app/environment"; // <-- ADD THIS IMPORT
import DtmfWorker from "$lib/workers/dtmf.worker?worker&inline";
import { dtmfStore } from "$lib/stores/dtmf.store";

class DtmfService {
  private static instance: DtmfService;
  private worker: Worker | null = null;

  private constructor() {}

  public static getInstance(): DtmfService {
    if (!DtmfService.instance) {
      DtmfService.instance = new DtmfService();
    }
    return DtmfService.instance;
  }

  public initialize(sampleRate: number): void {
    if (!browser) return; // <-- ADD THIS GUARD

    if (this.worker) {
      this.worker.terminate();
    }

    this.worker = new DtmfWorker();

    this.worker.onmessage = (event) => {
      const { type, payload, error } = event.data;
      if (type === "init_complete") {
        dtmfStore.update((s) => ({ ...s, status: "idle", error: null }));
      } else if (type === "result") {
        dtmfStore.update((s) => ({
          ...s,
          status: "complete",
          dtmf: payload.dtmf,
          cpt: payload.cpt || [],
        }));
      } else if (type === "error") {
        dtmfStore.update((s) => ({ ...s, status: "error", error: payload }));
      }
    };

    this.worker.postMessage({ type: "init", payload: { sampleRate } });
  }

  public async process(audioBuffer: AudioBuffer): Promise<void> {
    // --- ADD THIS GUARD ---
    if (!this.worker) {
      dtmfStore.update((s) => ({
        ...s,
        status: "error",
        error: "DTMF Worker not initialized.",
      }));
      return;
    }
    if (
      !audioBuffer ||
      !(audioBuffer instanceof AudioBuffer) ||
      audioBuffer.length === 0
    ) {
      dtmfStore.update((s) => ({
        ...s,
        status: "error",
        error: "DTMF process called with invalid AudioBuffer.",
      }));
      return;
    }
    // --- END GUARD ---
    dtmfStore.update((s) => ({
      ...s,
      status: "processing",
      dtmf: [],
      cpt: [],
    }));

    // We need to resample the audio to 16kHz for the Goertzel algorithm
    const targetSampleRate = 16000;
    const offlineCtx = new OfflineAudioContext(
      1,
      audioBuffer.duration * targetSampleRate,
      targetSampleRate,
    );
    const source = offlineCtx.createBufferSource();
    source.buffer = audioBuffer;
    source.connect(offlineCtx.destination);
    source.start();

    try {
      const resampled = await offlineCtx.startRendering();
      const pcmData = resampled.getChannelData(0);
      this.worker?.postMessage({ type: "process", payload: { pcmData } });
    } catch (e) {
      const error = e as Error;
      dtmfStore.update((s) => ({
        ...s,
        status: "error",
        error: `Resampling failed: ${error.message}`,
      }));
      // Re-throw the error so the caller (like a test) can know it failed.
      throw error;
    }
  }

  public dispose(): void {
    if (this.worker) {
      this.worker.terminate();
      this.worker = null;
    }
    console.log("DtmfService disposed.");
  }
}

export default DtmfService.getInstance();

````
--- End of File: vibe-player-v2/src/lib/services/dtmf.service.ts ---
--- File: vibe-player-v2/src/lib/services/spectrogram.service.test.ts ---
````typescript
// vibe-player-v2/src/lib/services/spectrogram.service.test.ts
import {
  vi,
  describe,
  it,
  expect,
  beforeEach,
  afterEach,
  type Mocked,
} from "vitest";
import SpectrogramWorker from "$lib/workers/spectrogram.worker?worker&inline";
import spectrogramService from "./spectrogram.service";
import { analysisStore } from "$lib/stores/analysis.store";
import { VISUALIZER_CONSTANTS } from "$lib/utils/constants"; // For init payload
import { SPEC_WORKER_MSG_TYPE } from "$lib/types/worker.types";

// Mock Svelte stores
vi.mock("$lib/stores/analysis.store", () => ({
  analysisStore: {
    subscribe: vi.fn(),
    set: vi.fn(),
    update: vi.fn(),
  },
}));

// Mock Web Workers
const mockSpecWorkerInstance = {
  postMessage: vi.fn(),
  terminate: vi.fn(),
  onmessage: null as ((event: MessageEvent) => void) | null,
  onerror: null as ((event: ErrorEvent | Event | string) => void) | null, // Adjusted to match service
};

vi.mock("$lib/workers/spectrogram.worker?worker&inline", () => ({
  default: vi.fn().mockImplementation(() => mockSpecWorkerInstance),
}));

const mockAudioData = new Float32Array(16000); // Sample audio data

describe("SpectrogramService", () => {
  beforeEach(() => {
    vi.useFakeTimers();
    vi.clearAllMocks();

    // Mock global fetch
    vi.spyOn(global, "fetch").mockImplementation((url) => {
      if (String(url).includes("fft.js")) {
        return Promise.resolve({
          ok: true,
          status: 200,
          text: () => Promise.resolve("// Mock FFT script content"),
        } as Response);
      }
      return Promise.reject(new Error(`Unhandled fetch in test: ${url}`));
    });

    // Reset worker instance mocks
    mockSpecWorkerInstance.postMessage.mockClear();
    mockSpecWorkerInstance.terminate.mockClear();
    mockSpecWorkerInstance.onmessage = null;
    mockSpecWorkerInstance.onerror = null;

    // Reset store mocks
    (analysisStore.update as Mocked<any>).mockClear();
    (analysisStore.set as Mocked<any>).mockClear();

    // Ensure a fresh service instance for some tests if necessary, or reset its state.
    // For singleton, we might need a reset method or careful state management in tests.
    // For now, we rely on dispose and re-initialize logic.
    spectrogramService.dispose(); // Clean up previous state
  });

  afterEach(() => {
    spectrogramService.dispose(); // Clean up
    vi.useRealTimers();
  });

  describe("initialize", () => {
    it("should create Spectrogram worker, post INIT message, and update store", async () => {
      const initializePromise = spectrogramService.initialize({
        sampleRate: 16000,
      });

      // SpectrogramWorker constructor is called synchronously within initialize
      expect(SpectrogramWorker).toHaveBeenCalledTimes(1);
      // The first analysisStore.update for 'Initializing worker...' also happens synchronously or very early
      expect(analysisStore.update).toHaveBeenCalledWith(expect.any(Function));

      // Allow async operations within initialize (like fetch) to complete and postMessage to be called.
      await vi.runAllTimersAsync();

      // Now that timers have run, postMessage (INIT) should have been called.
      expect(mockSpecWorkerInstance.postMessage).toHaveBeenCalledWith(
        expect.objectContaining({ type: SPEC_WORKER_MSG_TYPE.INIT }),
      );

      // Ensure postMessage was called before trying to access its details
      if (mockSpecWorkerInstance.postMessage.mock.calls.length === 0) {
        throw new Error(
          "mockSpecWorkerInstance.postMessage was not called by initialize().",
        );
      }
      const initMessageId =
        mockSpecWorkerInstance.postMessage.mock.calls[0][0].messageId;

      // Simulate worker response for INIT_SUCCESS *before* awaiting initializePromise
      if (mockSpecWorkerInstance.onmessage) {
        mockSpecWorkerInstance.onmessage({
          data: {
            type: SPEC_WORKER_MSG_TYPE.INIT_SUCCESS,
            payload: {},
            messageId: initMessageId,
          },
        } as MessageEvent);
      } else {
        throw new Error(
          "mockSpecWorkerInstance.onmessage is not set up for INIT_SUCCESS simulation.",
        );
      }

      // Now await the promise. It should resolve as the worker has responded.
      await initializePromise;

      // Ensure promise queue is flushed after initializePromise resolves
      await Promise.resolve();

      // Check the final state update for success
      const updateCalls = (analysisStore.update as Mocked<any>).mock.calls;
      let initializedUpdateCall = null;
      // Iterate backwards as the successful 'Initialized' state is likely one of the last updates.
      for (let i = updateCalls.length - 1; i >= 0; i--) {
        const mockStatePreview = {
          spectrogramStatus: "",
          spectrogramInitialized: false,
          spectrogramError: "previous error",
        };
        // Execute the updater function to see the resulting state.
        const resultingState = updateCalls[i][0](mockStatePreview);
        if (
          resultingState.spectrogramStatus === "Initialized" &&
          resultingState.spectrogramInitialized === true
        ) {
          initializedUpdateCall = updateCalls[i][0]; // Store the updater function itself
          break;
        }
      }

      expect(initializedUpdateCall).not.toBeNull(
        "Could not find store update setting status to 'Initialized'.",
      );

      if (initializedUpdateCall) {
        const mockState = {
          spectrogramStatus: "Initializing",
          spectrogramInitialized: false,
          spectrogramError: "some error",
        };
        const newState = initializedUpdateCall(mockState); // Call the identified updater
        expect(newState.spectrogramStatus).toBe("Initialized");
        expect(newState.spectrogramInitialized).toBe(true);
        expect(newState.spectrogramError).toBeNull();
      }
    });

    it("should update analysisStore on INIT_ERROR from worker message", async () => {
      const initPromise = spectrogramService.initialize({ sampleRate: 16000 });

      // Allow async operations within initialize (like fetch) to complete and postMessage to be called.
      await vi.runAllTimersAsync();

      if (mockSpecWorkerInstance.postMessage.mock.calls.length === 0) {
        throw new Error(
          "mockSpecWorkerInstance.postMessage was not called. Cannot simulate INIT_ERROR.",
        );
      }
      const initMessageId =
        mockSpecWorkerInstance.postMessage.mock.calls[0][0].messageId;

      // Simulate worker response for INIT_ERROR *before* awaiting initPromise
      if (mockSpecWorkerInstance.onmessage) {
        mockSpecWorkerInstance.onmessage({
          data: {
            type: SPEC_WORKER_MSG_TYPE.INIT_ERROR,
            error: "Init failed in worker",
            messageId: initMessageId,
          },
        } as MessageEvent);
      } else {
        throw new Error(
          "mockSpecWorkerInstance.onmessage is not set up for INIT_ERROR simulation.",
        );
      }

      try {
        await initPromise;
      } catch (e) {
        // Expected to reject due to error
      }

      await Promise.resolve(); // Flush microtask queue

      const lastUpdateCall = (
        analysisStore.update as Mocked<any>
      ).mock.calls.pop();
      expect(lastUpdateCall).toBeDefined();
      const mockState = {
        spectrogramStatus: "",
        spectrogramInitialized: true,
        spectrogramError: null,
      };
      const newState = lastUpdateCall[0](mockState);
      expect(newState.spectrogramError).toContain("Init failed in worker");
      expect(newState.spectrogramInitialized).toBe(false);
    });

    it("should update analysisStore on worker onerror during initialize", async () => {
      mockSpecWorkerInstance.postMessage.mockImplementationOnce(() => {
        // Simulate error being thrown by postMessage or worker globally failing
        if (mockSpecWorkerInstance.onerror) {
          mockSpecWorkerInstance.onerror(
            new ErrorEvent("error", { message: "Critical worker failure" }),
          );
        }
        throw new Error("Simulated postMessage failure");
      });

      try {
        await spectrogramService.initialize({ sampleRate: 16000 });
      } catch (e) {
        // error expected
      }

      const lastUpdateCall = (
        analysisStore.update as Mocked<any>
      ).mock.calls.pop();
      const mockState = {
        spectrogramStatus: "",
        spectrogramInitialized: true,
        spectrogramError: null,
      };
      const newState = lastUpdateCall[0](mockState); // This might be the one from onerror or the catch block in initialize

      // Check for either "Simulated postMessage failure" or "Critical worker failure"
      expect(newState.spectrogramError).toBeDefined();
      expect(newState.spectrogramInitialized).toBe(false);
    });
  });

  describe("process", () => {
    beforeEach(async () => {
      const initPromise = spectrogramService.initialize({ sampleRate: 16000 });
      // Allow async operations within initialize (like fetch) to complete and postMessage to be called.
      await vi.runAllTimersAsync();

      if (mockSpecWorkerInstance.postMessage.mock.calls.length === 0) {
        throw new Error(
          "Spectrogram service initialization failed to call postMessage in beforeEach for 'process' tests. Cannot get initMessageId.",
        );
      }
      const initMessageId =
        mockSpecWorkerInstance.postMessage.mock.calls[0][0].messageId;

      // Simulate INIT_SUCCESS *before* awaiting initPromise
      if (mockSpecWorkerInstance.onmessage) {
        mockSpecWorkerInstance.onmessage({
          data: {
            type: SPEC_WORKER_MSG_TYPE.INIT_SUCCESS,
            payload: {},
            messageId: initMessageId,
          },
        } as MessageEvent);
      } else {
        throw new Error(
          "mockSpecWorkerInstance.onmessage is not set up for INIT_SUCCESS simulation in 'process' beforeEach.",
        );
      }

      await initPromise; // Now await the promise
      await Promise.resolve(); // Ensure store updates from onmessage are processed
      (analysisStore.update as Mocked<any>).mockClear();
    });

    it("should post PROCESS message and update store on success", async () => {
      // Initialize is done in beforeEach. Now call process.
      const processPromise = spectrogramService.process(mockAudioData);

      // Allow async operations within process (like postMessage) to execute.
      await vi.runAllTimersAsync();

      // Check that postMessage was called for PROCESS
      expect(mockSpecWorkerInstance.postMessage).toHaveBeenCalledWith(
        expect.objectContaining({
          type: SPEC_WORKER_MSG_TYPE.PROCESS,
          payload: { audioData: mockAudioData },
        }),
      );

      const processCall = mockSpecWorkerInstance.postMessage.mock.calls.find(
        (call) => call[0].type === SPEC_WORKER_MSG_TYPE.PROCESS,
      );
      if (!processCall)
        throw new Error("PROCESS message not found in postMessage calls");
      const processMessageId = processCall[0].messageId;

      // Simulate worker response for PROCESS_RESULT *before* awaiting processPromise
      const mockResultPayload = { magnitudes: new Float32Array([1, 2, 3]) };
      if (mockSpecWorkerInstance.onmessage) {
        mockSpecWorkerInstance.onmessage({
          data: {
            type: SPEC_WORKER_MSG_TYPE.PROCESS_RESULT,
            payload: mockResultPayload,
            messageId: processMessageId,
          },
        } as MessageEvent);
      } else {
        throw new Error(
          "mockSpecWorkerInstance.onmessage is not set up for PROCESS_RESULT simulation.",
        );
      }

      await processPromise; // Wait for the process method to complete
      await Promise.resolve(); // Flush microtasks

      const updateCalls = (analysisStore.update as Mocked<any>).mock.calls;
      // Update sequence: 'Processing audio...', data update, 'Processing complete.'
      expect(updateCalls.length).toBeGreaterThanOrEqual(3); // Based on current service logic

      const dataUpdateState = updateCalls[updateCalls.length - 2][0]({
        spectrogramData: null,
      });
      expect(dataUpdateState.spectrogramData).toEqual(
        mockResultPayload.magnitudes,
      );

      const statusUpdateState = updateCalls[updateCalls.length - 1][0]({});
      expect(statusUpdateState.spectrogramStatus).toBe("Processing complete.");
    });

    it("should update store on PROCESS_ERROR from worker", async () => {
      const processPromise = spectrogramService.process(mockAudioData);

      // Allow async operations within process (like postMessage) to execute.
      await vi.runAllTimersAsync();

      const processCall = mockSpecWorkerInstance.postMessage.mock.calls.find(
        (call) => call[0].type === SPEC_WORKER_MSG_TYPE.PROCESS,
      );
      if (!processCall)
        throw new Error(
          "PROCESS message not found in postMessage calls for error test.",
        );
      const processMessageId = processCall[0].messageId;

      // Simulate worker response for PROCESS_ERROR *before* awaiting processPromise
      if (mockSpecWorkerInstance.onmessage) {
        mockSpecWorkerInstance.onmessage({
          data: {
            type: SPEC_WORKER_MSG_TYPE.PROCESS_ERROR,
            error: "Processing failed in worker",
            messageId: processMessageId,
          },
        } as MessageEvent);
      } else {
        throw new Error(
          "mockSpecWorkerInstance.onmessage is not set up for PROCESS_ERROR simulation.",
        );
      }

      try {
        await processPromise;
      } catch (e) {
        // Expected to reject if service re-throws, or resolve if service handles and updates store
      }
      await Promise.resolve(); // Flush microtasks

      const lastUpdateCall = (
        analysisStore.update as Mocked<any>
      ).mock.calls.pop();
      expect(lastUpdateCall).toBeDefined();
      const mockState = { spectrogramStatus: "", spectrogramError: null };
      const newState = lastUpdateCall[0](mockState);
      expect(newState.spectrogramStatus).toBe("Processing failed.");
      expect(newState.spectrogramError).toContain(
        "Processing failed in worker",
      );
    });
  });

  describe("dispose", () => {
    it("should terminate worker, update store to disposed state, and clear pending promises", async () => {
      const initPromise = spectrogramService.initialize({ sampleRate: 16000 });
      // Allow async operations within initialize (like fetch) to complete and postMessage to be called.
      await vi.runAllTimersAsync();

      if (mockSpecWorkerInstance.postMessage.mock.calls.length === 0) {
        throw new Error(
          "Spectrogram service initialization failed to call postMessage in 'dispose' test. Cannot get initMessageId.",
        );
      }
      const initMessageId =
        mockSpecWorkerInstance.postMessage.mock.calls[0][0].messageId;

      // Simulate INIT_SUCCESS *before* awaiting initPromise
      if (mockSpecWorkerInstance.onmessage) {
        mockSpecWorkerInstance.onmessage({
          data: {
            type: SPEC_WORKER_MSG_TYPE.INIT_SUCCESS,
            payload: {},
            messageId: initMessageId,
          },
        } as MessageEvent);
      } else {
        throw new Error(
          "mockSpecWorkerInstance.onmessage is not set up for INIT_SUCCESS simulation in 'dispose' test.",
        );
      }

      await initPromise; // Now await the promise
      await Promise.resolve(); // Ensure store updates from onmessage are processed
      (analysisStore.update as Mocked<any>).mockClear();

      spectrogramService.dispose();

      // --- Assert ---
      // Worker termination
      expect(mockSpecWorkerInstance.terminate).toHaveBeenCalledTimes(1);
      expect(analysisStore.update).toHaveBeenCalledTimes(1);
      const storeUpdater = (analysisStore.update as Mocked<any>).mock
        .calls[0][0];
      const prevState = {
        /* ... provide a representative previous state ... */
      };
      const newState = storeUpdater(prevState);
      expect(newState.spectrogramStatus).toBe("Disposed");
      // ... other assertions for disposed state ...
    });

    // ... other tests for "dispose"
    it("should handle dispose being called multiple times without error", () => {
      spectrogramService.initialize({ sampleRate: 16000 }); // Ensure worker exists

      expect(() => {
        spectrogramService.dispose();
        spectrogramService.dispose(); // Call dispose again
      }).not.toThrow();

      expect(mockSpecWorkerInstance.terminate).toHaveBeenCalledTimes(1); // Still only terminates the first time
    });
  });
});

````
--- End of File: vibe-player-v2/src/lib/services/spectrogram.service.test.ts ---
--- File: vibe-player-v2/src/lib/services/spectrogram.service.ts ---
````typescript
// vibe-player-v2/src/lib/services/spectrogram.service.ts
import { browser } from "$app/environment"; // <-- ADD THIS IMPORT
import type {
  WorkerMessage,
  SpectrogramInitPayload,
  SpectrogramProcessPayload,
  SpectrogramResultPayload,
} from "$lib/types/worker.types";
import { SPEC_WORKER_MSG_TYPE } from "$lib/types/worker.types";
import { VISUALIZER_CONSTANTS } from "$lib/utils/constants";
import { analysisStore, type AnalysisState } from "$lib/stores/analysis.store";
import SpectrogramWorker from "$lib/workers/spectrogram.worker?worker&inline";

class SpectrogramService {
  private static instance: SpectrogramService;
  private worker: Worker | null = null;
  private isInitialized = false;
  private nextMessageId = 0;
  private pendingRequests = new Map<
    string,
    { resolve: (value: unknown) => void; reject: (reason?: any) => void }
  >();

  private constructor() {}

  public static getInstance(): SpectrogramService {
    if (!SpectrogramService.instance) {
      SpectrogramService.instance = new SpectrogramService();
    }
    return SpectrogramService.instance;
  }

  private generateMessageId(): string {
    return `spec_msg_${this.nextMessageId++}`;
  }

  private postMessageToWorker<T>(message: WorkerMessage<T>): Promise<unknown> {
    return new Promise((resolve, reject) => {
      if (!this.worker) {
        return reject(new Error("Spectrogram Worker not initialized."));
      }
      const messageId = this.generateMessageId();
      this.pendingRequests.set(messageId, { resolve, reject });
      this.worker.postMessage({ ...message, messageId });
    });
  }

  public async initialize(options: { sampleRate: number }): Promise<void> {
    if (!browser) return; // <-- ADD THIS GUARD

    if (this.isInitialized) {
      console.log(
        "SpectrogramService: Re-initializing. Disposing existing worker first.",
      );
      this.dispose();
    }

    analysisStore.update((s) => ({
      ...s,
      spectrogramStatus: "Initializing worker...",
      spectrogramInitialized: false,
    }));
    this.worker = new SpectrogramWorker();

    this.worker.onmessage = (event: MessageEvent<WorkerMessage<unknown>>) => {
      const { type, payload, error, messageId } = event.data;
      const request = messageId
        ? this.pendingRequests.get(messageId)
        : undefined;
      if (error) {
        const errorMsg =
          typeof error === "string" ? error : (error as Error).message;
        analysisStore.update((s) => ({
          ...s,
          spectrogramError: `Worker error: ${errorMsg}`,
          spectrogramInitialized: false,
        }));
        if (request) request.reject(errorMsg);
      } else {
        switch (type) {
          case SPEC_WORKER_MSG_TYPE.INIT_SUCCESS:
            this.isInitialized = true;
            analysisStore.update((s) => ({
              ...s,
              spectrogramStatus: "Initialized",
              spectrogramInitialized: true,
              spectrogramError: null,
            }));
            if (request) request.resolve(payload);
            break;
          case SPEC_WORKER_MSG_TYPE.PROCESS_RESULT:
            const specResult = payload as SpectrogramResultPayload;
            analysisStore.update((s) => ({
              ...s,
              spectrogramData: specResult.magnitudes,
            }));
            if (request) request.resolve(specResult);
            break;
          default:
            if (request) request.resolve(payload);
        }
      }
      if (messageId && request) this.pendingRequests.delete(messageId);
    };

    this.worker.onerror = (err: Event | string) => {
      const errorMsg =
        typeof err === "string"
          ? err
          : err instanceof ErrorEvent
            ? err.message
            : "Unknown error";
      analysisStore.update((s) => ({
        ...s,
        spectrogramError: `Worker onerror: ${errorMsg}`,
        spectrogramInitialized: false,
      }));
      this.pendingRequests.forEach((req) =>
        req.reject(
          new Error(`Spectrogram Worker failed critically: ${errorMsg}`),
        ),
      );
      this.pendingRequests.clear();
      this.isInitialized = false;
    };

    // Fetch the FFT script text
    let fftScriptText: string;
    try {
      const fftResponse = await fetch(
        VISUALIZER_CONSTANTS.FFT_WORKER_SCRIPT_URL,
      );
      if (!fftResponse.ok) {
        throw new Error(
          `Failed to fetch FFT script: ${fftResponse.status} ${fftResponse.statusText}`,
        );
      }
      fftScriptText = await fftResponse.text();
    } catch (e) {
      const errorMessage = e instanceof Error ? e.message : String(e);
      analysisStore.update((s) => ({
        ...s,
        spectrogramError: `FFT script fetch error: ${errorMessage}`,
        spectrogramInitialized: false,
      }));
      this.isInitialized = false;
      return; // Stop initialization if script fetch fails
    }

    const initPayload: SpectrogramInitPayload = {
      origin: location.origin,
      fftScriptText, // Pass the fetched script content
      sampleRate: options.sampleRate,
      fftSize: VISUALIZER_CONSTANTS.SPEC_NORMAL_FFT_SIZE,
      hopLength: Math.floor(VISUALIZER_CONSTANTS.SPEC_NORMAL_FFT_SIZE / 4),
    };

    try {
      await this.postMessageToWorker({
        type: SPEC_WORKER_MSG_TYPE.INIT,
        payload: initPayload,
      });
    } catch (e) {
      const errorMessage = e instanceof Error ? e.message : String(e);
      analysisStore.update((s) => ({
        ...s,
        spectrogramError: errorMessage,
        spectrogramInitialized: false,
      }));
      this.isInitialized = false;
    }
  }

  public async process(audioData: Float32Array): Promise<void> {
    if (!this.worker || !this.isInitialized) {
      throw new Error("Spectrogram worker not initialized or unavailable.");
    }
    analysisStore.update((s) => ({
      ...s,
      spectrogramStatus: "Processing audio for spectrogram...",
    }));
    try {
      await this.postMessageToWorker<SpectrogramProcessPayload>({
        type: SPEC_WORKER_MSG_TYPE.PROCESS,
        payload: { audioData },
      });
      analysisStore.update((s) => ({
        ...s,
        spectrogramStatus: "Processing complete.",
      }));
    } catch (e) {
      const errorMessage = e instanceof Error ? e.message : String(e);
      analysisStore.update((s) => ({
        ...s,
        spectrogramStatus: "Processing failed.",
        spectrogramError: errorMessage,
      }));
    }
  }

  public dispose(): void {
    if (this.worker) {
      this.worker.terminate();
      this.worker = null;
      this.isInitialized = false;
    }
    this.pendingRequests.clear();
    analysisStore.update((s) => ({
      ...s,
      spectrogramStatus: "Disposed",
      spectrogramData: null,
      spectrogramInitialized: false,
      spectrogramError: null,
    }));
    console.log("SpectrogramService disposed.");
  }
}

export default SpectrogramService.getInstance();

````
--- End of File: vibe-player-v2/src/lib/services/spectrogram.service.ts ---
--- File: vibe-player-v2/src/lib/stores/analysis.store.ts ---
````typescript
import { writable } from "svelte/store";
import type { AnalysisState } from "$lib/types/analysis.types";

const initialState: AnalysisState = {
  vadStatus: undefined,
  lastVadResult: null,
  isSpeaking: undefined,
  vadStateResetted: undefined,
  vadError: null,
  vadInitialized: false,

  spectrogramStatus: undefined,
  spectrogramError: null,
  spectrogramData: null,
  spectrogramInitialized: false,

  isLoading: false,
};

export const analysisStore = writable<AnalysisState>(initialState);

````
--- End of File: vibe-player-v2/src/lib/stores/analysis.store.ts ---
--- File: vibe-player-v2/src/lib/stores/derived.store.ts ---
````typescript
import { derived } from "svelte/store";
import { statusStore } from "./status.store";
export const exampleDerived = derived(statusStore, ($statusStore) => ({
  placeholder: true,
}));

````
--- End of File: vibe-player-v2/src/lib/stores/derived.store.ts ---
--- File: vibe-player-v2/src/lib/stores/dtmf.store.ts ---
````typescript
// vibe-player-v2/src/lib/stores/dtmf.store.ts

import { writable } from "svelte/store";

export interface DtmfState {
  status: "idle" | "processing" | "complete" | "error";
  dtmf: string[];
  cpt: string[]; // For Call Progress Tones
  error: string | null;
}

const initialState: DtmfState = {
  status: "idle",
  dtmf: [],
  cpt: [],
  error: null,
};

export const dtmfStore = writable<DtmfState>(initialState);

````
--- End of File: vibe-player-v2/src/lib/stores/dtmf.store.ts ---
--- File: vibe-player-v2/src/lib/stores/player.store.ts ---
````typescript
import { writable } from "svelte/store";
import type { PlayerState } from "$lib/types/player.types";

const initialState: PlayerState = {
  status: "idle",
  fileName: null,
  duration: 0,
  currentTime: 0,
  isPlaying: false,
  isPlayable: false,
  speed: 1.0,
  pitch: 0.0,
  gain: 1.0,
  waveformData: undefined,
  error: null,
  audioBuffer: undefined,
  audioContextResumed: false,
  channels: undefined,
  sampleRate: undefined,
  lastProcessedChunk: undefined,
};

export const playerStore = writable<PlayerState>(initialState);

````
--- End of File: vibe-player-v2/src/lib/stores/player.store.ts ---
--- File: vibe-player-v2/src/lib/stores/status.store.ts ---
````typescript
import { writable } from "svelte/store";
import type { StatusState } from "$lib/types/status.types";

const initialState: StatusState = {
  message: null,
  type: null,
  isLoading: false,
  details: null,
  progress: null,
};

export const statusStore = writable<StatusState>(initialState);

````
--- End of File: vibe-player-v2/src/lib/stores/status.store.ts ---
--- File: vibe-player-v2/src/lib/types/analysis.types.ts ---
````typescript
import type {
  SileroVadProcessResultPayload,
  SpectrogramResultPayload,
} from "$lib/types/worker.types";

export interface AnalysisState {
  // VAD related properties
  vadStatus?: string; // e.g., "VAD service initializing...", "VAD service initialized."
  lastVadResult?: SileroVadProcessResultPayload | null;
  isSpeaking?: boolean;
  vadStateResetted?: boolean;
  vadError?: string | null;
  vadInitialized?: boolean; // To track VAD worker initialization status

  // Spectrogram related properties
  spectrogramStatus?: string; // e.g., "Spectrogram worker initializing..."
  spectrogramError?: string | null;
  spectrogramData?: number[][] | null; // Assuming magnitudes from SpectrogramResultPayload are number[][]
  spectrogramInitialized?: boolean; // To track Spectrogram worker initialization

  // General analysis properties
  isLoading?: boolean; // For general loading states within the analysis domain
}

````
--- End of File: vibe-player-v2/src/lib/types/analysis.types.ts ---
--- File: vibe-player-v2/src/lib/types/player.types.ts ---
````typescript
export interface PlayerState {
  status: string;
  fileName: string | null;
  duration: number;
  currentTime: number;
  isPlaying: boolean;
  isPlayable: boolean;
  speed: number;
  pitch: number;
  gain: number;
  waveformData?: number[][];
  error: string | null;
  audioBuffer?: AudioBuffer;
  audioContextResumed?: boolean;
  channels?: number;
  sampleRate?: number;
  lastProcessedChunk?: any; // TODO: Refine this type later
}

````
--- End of File: vibe-player-v2/src/lib/types/player.types.ts ---
--- File: vibe-player-v2/src/lib/types/status.types.ts ---
````typescript
export type NotificationType = "info" | "error" | "success" | "warning";

export interface StatusState {
  message: string | null;
  type: NotificationType | null;
  isLoading: boolean; // General loading indicator for the app
  details?: string | null; // Optional field for more detailed messages or error info
  progress?: number | null; // For operations that have a progress, e.g. file loading
}

````
--- End of File: vibe-player-v2/src/lib/types/status.types.ts ---
--- File: vibe-player-v2/src/lib/types/worker.types.ts ---
````typescript
// vibe-player-v2/src/lib/types/worker.types.ts

// General message structure for worker communication
export interface WorkerMessage<T = unknown> {
  type: string;
  payload?: T;
  error?: string | Error; // Allow Error object
  messageId?: string;
}

// --- Rubberband Worker ---
export const RB_WORKER_MSG_TYPE = {
  INIT: "rb_init",
  PROCESS: "rb_process",
  FLUSH: "rb_flush",
  RESET: "rb_reset",
  SET_PITCH: "rb_set_pitch",
  SET_SPEED: "rb_set_speed",
  INIT_SUCCESS: "rb_init_success",
  INIT_ERROR: "rb_init_error",
  PROCESS_RESULT: "rb_process_result",
  PROCESS_ERROR: "rb_process_error",
  FLUSH_RESULT: "rb_flush_result",
  STATUS: "rb_status",
};

export interface RubberbandInitPayload {
  wasmBinary: ArrayBuffer; // CHANGED
  loaderScriptText: string; // CHANGED
  origin: string;
  sampleRate: number;
  channels: number;
  initialSpeed: number;
  initialPitch: number;
}

export interface RubberbandProcessPayload {
  inputBuffer: Float32Array[];
}

export interface RubberbandProcessResultPayload {
  outputBuffer: Float32Array[];
}

export interface RubberbandStatusPayload {
  message: string;
  progress?: number;
}

// --- Silero VAD Worker ---
export const VAD_WORKER_MSG_TYPE = {
  INIT: "vad_init",
  PROCESS: "vad_process",
  RESET: "vad_reset",
  INIT_SUCCESS: "vad_init_success",
  INIT_ERROR: "vad_init_error",
  PROCESS_RESULT: "vad_process_result",
  PROCESS_ERROR: "vad_process_error",
  STATUS: "vad_status",
};

export interface SileroVadInitPayload {
  origin: string; // <-- ADDED
  modelBuffer: ArrayBuffer;
  sampleRate: number;
  frameSamples: number;
  positiveThreshold?: number;
  negativeThreshold?: number;
}

export interface SileroVadProcessPayload {
  audioFrame: Float32Array;
  timestamp?: number;
}

export interface SileroVadProcessResultPayload {
  isSpeech: boolean;
  timestamp: number;
  score: number;
  audioFrame?: Float32Array;
}

export interface SileroVadStatusPayload {
  message: string;
}

// --- Spectrogram Worker ---
export const SPEC_WORKER_MSG_TYPE = {
  INIT: "spec_init",
  PROCESS: "spec_process",
  CONFIG_UPDATE: "spec_config_update",
  INIT_SUCCESS: "spec_init_success",
  INIT_ERROR: "spec_init_error",
  PROCESS_RESULT: "spec_process_result",
  PROCESS_ERROR: "spec_process_error",
};

export interface SpectrogramInitPayload {
  origin: string;
  fftScriptText: string;
  sampleRate: number;
  fftSize: number;
  hopLength: number;
}

export interface SpectrogramProcessPayload {
  audioData: Float32Array;
}

export interface SpectrogramResultPayload {
  magnitudes: Float32Array[];
}

````
--- End of File: vibe-player-v2/src/lib/types/worker.types.ts ---
--- File: vibe-player-v2/src/lib/utils/assert.ts ---
````typescript
// vibe-player-v2/src/lib/utils/assert.ts

/**
 * Asserts that a condition is true, throwing an error in development if it's not.
 * This function is stripped from production builds.
 *
 * This implementation uses `import.meta.env.DEV`, a Vite-provided variable,
 * making it safe to use in both the main app and in Web Workers.
 *
 * @param condition The condition to check.
 * @param message The error message to throw if the condition is false.
 */
export function assert(condition: unknown, message: string): asserts condition {
  // Vite will replace `import.meta.env.DEV` with `true` or `false` at build time.
  // The `if (false && ...)` block will be completely removed (tree-shaken)
  // in production builds, resulting in zero performance overhead.
  if (import.meta.env.DEV && !condition) {
    throw new Error(`[Assertion Failed] ${message}`);
  }
}

````
--- End of File: vibe-player-v2/src/lib/utils/assert.ts ---
--- File: vibe-player-v2/src/lib/utils/async.test.ts ---
````typescript
// vibe-player-v2/src/lib/utils/async.test.ts
import { describe, it, expect, vi, beforeEach, afterEach } from "vitest";
import { yieldToMainThread, debounce } from "./async";

describe("async utilities", () => {
  describe("yieldToMainThread", () => {
    beforeEach(() => {
      vi.useFakeTimers();
    });

    afterEach(() => {
      vi.restoreAllMocks();
    });

    it("should return a Promise", () => {
      expect(yieldToMainThread()).toBeInstanceOf(Promise);
    });

    it("should resolve after a timeout", async () => {
      const promise = yieldToMainThread();
      vi.runAllTimers(); // Or vi.advanceTimersByTime(0)
      await expect(promise).resolves.toBeUndefined();
    });
  });

  describe("debounce", () => {
    let mockFn: ReturnType<typeof vi.fn>;

    beforeEach(() => {
      vi.useFakeTimers();
      mockFn = vi.fn();
    });

    afterEach(() => {
      vi.restoreAllMocks(); // Clears mocks and timers
    });

    it("should call the function only once after multiple rapid calls", () => {
      const debouncedFn = debounce(mockFn, 100);
      debouncedFn();
      debouncedFn();
      debouncedFn();

      expect(mockFn).not.toHaveBeenCalled();
      vi.advanceTimersByTime(100);
      expect(mockFn).toHaveBeenCalledTimes(1);
    });

    it("should call the function after the specified wait time", () => {
      const debouncedFn = debounce(mockFn, 200);
      debouncedFn();

      vi.advanceTimersByTime(199);
      expect(mockFn).not.toHaveBeenCalled();

      vi.advanceTimersByTime(1);
      expect(mockFn).toHaveBeenCalledTimes(1);
    });

    it("should call the function immediately if immediate is true", () => {
      const debouncedFn = debounce(mockFn, 100, true);
      debouncedFn();
      expect(mockFn).toHaveBeenCalledTimes(1);

      // Should not call again after timeout
      vi.advanceTimersByTime(100);
      expect(mockFn).toHaveBeenCalledTimes(1);
    });

    it("should call the function again after wait time if immediate is true and called again after wait", () => {
      const debouncedFn = debounce(mockFn, 100, true);
      debouncedFn(); // immediate call
      expect(mockFn).toHaveBeenCalledTimes(1);

      vi.advanceTimersByTime(50);
      debouncedFn(); // this call should be ignored as it's within the wait period
      expect(mockFn).toHaveBeenCalledTimes(1);

      vi.advanceTimersByTime(50); // total 100ms passed
      debouncedFn(); // this should also be ignored as the timeout from the first call is still active
      expect(mockFn).toHaveBeenCalledTimes(1);

      vi.advanceTimersByTime(100); // total 200ms passed, timeout for first call ended
      debouncedFn(); // New immediate call
      expect(mockFn).toHaveBeenCalledTimes(2);
    });

    it("should pass arguments correctly to the debounced function", () => {
      const debouncedFn = debounce(mockFn, 100);
      const arg1 = "test";
      const arg2 = 123;
      debouncedFn(arg1, arg2);

      vi.advanceTimersByTime(100);
      expect(mockFn).toHaveBeenCalledWith(arg1, arg2);
    });

    it("should maintain `this` context for the debounced function", () => {
      const obj = { method: mockFn, name: "testObject" };
      const debouncedFn = debounce(obj.method, 100);

      // Call it in a way that sets the `this` context to `obj`
      debouncedFn.call(obj);

      vi.advanceTimersByTime(100);
      expect(mockFn).toHaveBeenCalledTimes(1);
      // Check that the context (`this`) inside the mock call was indeed `obj`
      expect(mockFn.mock.contexts[0]).toBe(obj);
    });
  });
});

````
--- End of File: vibe-player-v2/src/lib/utils/async.test.ts ---
--- File: vibe-player-v2/src/lib/utils/async.ts ---
````typescript
export async function yieldToMainThread(): Promise<void> {
  return new Promise((resolve) => setTimeout(resolve, 0));
}
export function debounce<T extends (...args: any[]) => any>(
  func: T,
  wait: number,
  immediate: boolean = false,
): (...args: Parameters<T>) => void {
  let timeout: ReturnType<typeof setTimeout> | null;
  return function executedFunction(...args: Parameters<T>) {
    const context = this;
    const later = () => {
      timeout = null;
      if (!immediate) {
        func.apply(context, args);
      }
    };
    const callNow = immediate && !timeout;
    if (timeout) clearTimeout(timeout);
    timeout = setTimeout(later, wait);
    if (callNow) {
      func.apply(context, args);
    }
  };
}

````
--- End of File: vibe-player-v2/src/lib/utils/async.ts ---
--- File: vibe-player-v2/src/lib/utils/constants.test.ts ---
````typescript
// vibe-player-v2/src/lib/utils/constants.test.ts
import { describe, it, expect } from "vitest";
import * as AllConstants from "./constants";

describe("Constants", () => {
  it("AUDIO_ENGINE_CONSTANTS should be defined and have expected properties", () => {
    expect(AllConstants.AUDIO_ENGINE_CONSTANTS).toBeDefined();
    expect(AllConstants.AUDIO_ENGINE_CONSTANTS.PROCESSOR_NAME).toBe(
      "rubberband-processor",
    );
    // UPDATED TEST: Check for the new, organized path
    expect(AllConstants.AUDIO_ENGINE_CONSTANTS.WASM_BINARY_URL).toBe(
      "/vendor/rubberband/rubberband.wasm",
    );
  });

  it("VAD_CONSTANTS should be defined and have expected properties", () => {
    expect(AllConstants.VAD_CONSTANTS).toBeDefined();
    expect(AllConstants.VAD_CONSTANTS.SAMPLE_RATE).toBe(16000);
    // UPDATED TEST: Check for the new, organized path
    expect(AllConstants.VAD_CONSTANTS.ONNX_MODEL_URL).toBe(
      "/models/silero_vad.onnx",
    );
  });

  it("UI_CONSTANTS should be defined and have expected properties", () => {
    expect(AllConstants.UI_CONSTANTS).toBeDefined();
    expect(AllConstants.UI_CONSTANTS.DEBOUNCE_HASH_UPDATE_MS).toBe(500);
  });

  it("VISUALIZER_CONSTANTS should be defined and have expected properties", () => {
    expect(AllConstants.VISUALIZER_CONSTANTS).toBeDefined();
    expect(AllConstants.VISUALIZER_CONSTANTS.WAVEFORM_COLOR_DEFAULT).toBe(
      "#26828E",
    );
    expect(AllConstants.VISUALIZER_CONSTANTS.SPEC_NORMAL_FFT_SIZE).toBe(8192);
    // UPDATED TEST: Check for the new, organized path
    expect(AllConstants.VISUALIZER_CONSTANTS.FFT_WORKER_SCRIPT_URL).toBe(
      "/vendor/fft.js",
    );
  });

  it("URL_HASH_KEYS should be defined and have expected properties", () => {
    expect(AllConstants.URL_HASH_KEYS).toBeDefined();
    expect(AllConstants.URL_HASH_KEYS.SPEED).toBe("speed");
  });

  it("DTMF_CONSTANTS should be defined and have expected properties", () => {
    expect(AllConstants.DTMF_CONSTANTS).toBeDefined();
    expect(AllConstants.DTMF_CONSTANTS.SAMPLE_RATE).toBe(16000);
  });
});

````
--- End of File: vibe-player-v2/src/lib/utils/constants.test.ts ---
--- File: vibe-player-v2/src/lib/utils/constants.ts ---
````typescript
// vibe-player-v2/src/lib/utils/constants.ts
export interface AudioEngineConstants {
  PROCESSOR_SCRIPT_URL: string;
  PROCESSOR_NAME: string;
  WASM_BINARY_URL: string;
  LOADER_SCRIPT_URL: string;
  // ADD THESE:
  PROCESS_LOOKAHEAD_TIME: number;
  TARGET_CHUNK_DURATION_S: number;
  MIN_CHUNK_DURATION_S: number;
  SCHEDULE_AHEAD_TIME_S: number;
}
export const AUDIO_ENGINE_CONSTANTS: AudioEngineConstants = {
  PROCESSOR_SCRIPT_URL: "js/player/rubberbandProcessor.js", // This is a source file, not static, path is correct.
  PROCESSOR_NAME: "rubberband-processor",
  WASM_BINARY_URL: "/vendor/rubberband/rubberband.wasm", // UPDATED
  LOADER_SCRIPT_URL: "/vendor/rubberband/rubberband-loader.js", // UPDATED
  // ADD THESE WITH VALUES:
  PROCESS_LOOKAHEAD_TIME: 0.1, // seconds
  TARGET_CHUNK_DURATION_S: 0.1, // seconds
  MIN_CHUNK_DURATION_S: 0.001, // seconds
  SCHEDULE_AHEAD_TIME_S: 0.05, // seconds
};
export interface VadConstants {
  SAMPLE_RATE: number;
  DEFAULT_FRAME_SAMPLES: number;
  PROGRESS_REPORT_INTERVAL: number;
  YIELD_INTERVAL: number;
  DEFAULT_POSITIVE_THRESHOLD: number;
  DEFAULT_NEGATIVE_THRESHOLD: number;
  ONNX_MODEL_URL: string;
}
export const VAD_CONSTANTS: VadConstants = {
  SAMPLE_RATE: 16000,
  DEFAULT_FRAME_SAMPLES: 1536,
  PROGRESS_REPORT_INTERVAL: 20,
  YIELD_INTERVAL: 5,
  DEFAULT_POSITIVE_THRESHOLD: 0.5,
  DEFAULT_NEGATIVE_THRESHOLD: 0.35,
  ONNX_MODEL_URL: "/models/silero_vad.onnx", // UPDATED
};
export interface UiConstants {
  DEBOUNCE_HASH_UPDATE_MS: number;
  SYNC_DEBOUNCE_WAIT_MS: number;
}
export const UI_CONSTANTS: UiConstants = {
  DEBOUNCE_HASH_UPDATE_MS: 500,
  SYNC_DEBOUNCE_WAIT_MS: 300,
};
export interface VisualizerConstants {
  WAVEFORM_HEIGHT_SCALE: number;
  WAVEFORM_COLOR_LOADING: string;
  WAVEFORM_COLOR_DEFAULT: string;
  WAVEFORM_COLOR_SPEECH: string;
  SPEC_NORMAL_FFT_SIZE: number;
  SPEC_SHORT_FFT_SIZE: number;
  SPEC_SHORT_FILE_FFT_THRESHOLD_S: number;
  SPEC_MAX_FREQS: number[];
  SPEC_DEFAULT_MAX_FREQ_INDEX: number;
  SPEC_FIXED_WIDTH: number;
  SPEC_SHORT_FILE_HOP_THRESHOLD_S: number;
  SPEC_NORMAL_HOP_DIVISOR: number;
  SPEC_SHORT_HOP_DIVISOR: number;
  SPEC_CENTER_WINDOWS: boolean;
  FFT_WORKER_SCRIPT_URL: string;
}
export const VISUALIZER_CONSTANTS: VisualizerConstants = {
  WAVEFORM_HEIGHT_SCALE: 0.8,
  WAVEFORM_COLOR_LOADING: "#888888",
  WAVEFORM_COLOR_DEFAULT: "#26828E",
  WAVEFORM_COLOR_SPEECH: "#FDE725",
  SPEC_NORMAL_FFT_SIZE: 8192,
  SPEC_SHORT_FFT_SIZE: 2048,
  SPEC_SHORT_FILE_FFT_THRESHOLD_S: 10.0,
  SPEC_MAX_FREQS: [5000, 16000],
  SPEC_DEFAULT_MAX_FREQ_INDEX: 0,
  SPEC_FIXED_WIDTH: 2048,
  SPEC_SHORT_FILE_HOP_THRESHOLD_S: 5.0,
  SPEC_NORMAL_HOP_DIVISOR: 4,
  SPEC_SHORT_HOP_DIVISOR: 8,
  SPEC_CENTER_WINDOWS: true,
  FFT_WORKER_SCRIPT_URL: "/vendor/fft.js", // UPDATED
};
export interface UrlHashKeys {
  SPEED: string;
  PITCH: string;
  GAIN: string;
  VAD_POSITIVE: string;
  VAD_NEGATIVE: string;
  AUDIO_URL: string;
  TIME: string;
}
export const URL_HASH_KEYS: UrlHashKeys = {
  SPEED: "speed",
  PITCH: "pitch",
  GAIN: "gain",
  VAD_POSITIVE: "vadPositive",
  VAD_NEGATIVE: "vadNegative",
  AUDIO_URL: "url",
  TIME: "time",
};
export interface DtmfConstants {
  SAMPLE_RATE: number;
  BLOCK_SIZE: number;
}
export const DTMF_CONSTANTS: DtmfConstants = {
  SAMPLE_RATE: 16000,
  BLOCK_SIZE: 410,
};

````
--- End of File: vibe-player-v2/src/lib/utils/constants.ts ---
--- File: vibe-player-v2/src/lib/utils/dsp.test.ts ---
````typescript
// vibe-player-v2/src/lib/utils/dsp.test.ts
import { describe, it, expect, vi } from "vitest";
import { hannWindow, viridisColor } from "./dsp";

describe("dsp utilities", () => {
  describe("hannWindow", () => {
    it("should return null for invalid lengths", () => {
      expect(hannWindow(0)).toBeNull();
      expect(hannWindow(-5)).toBeNull();
      expect(hannWindow(3.5)).toBeNull();
    });

    it("should return [1] for length 1", () => {
      expect(hannWindow(1)).toEqual([1]);
    });

    it("should generate a correct Hann window for length 4", () => {
      const window = hannWindow(4);
      expect(window).toBeInstanceOf(Array);
      expect(window?.length).toBe(4);
      if (!window) throw new Error("Window is null"); // Type guard
      // Expected values for Hann window of length 4:
      // w[0] = 0.5 * (1 - cos(0)) = 0
      // w[1] = 0.5 * (1 - cos(2*PI*1/3)) = 0.5 * (1 - (-0.5)) = 0.75
      // w[2] = 0.5 * (1 - cos(2*PI*2/3)) = 0.5 * (1 - (-0.5)) = 0.75
      // w[3] = 0.5 * (1 - cos(2*PI*3/3)) = 0.5 * (1 - 1) = 0
      expect(window[0]).toBeCloseTo(0);
      expect(window[1]).toBeCloseTo(0.75);
      expect(window[2]).toBeCloseTo(0.75);
      expect(window[3]).toBeCloseTo(0);
    });

    it("should generate a symmetric Hann window for length 5", () => {
      const window = hannWindow(5);
      expect(window).toBeInstanceOf(Array);
      expect(window?.length).toBe(5);
      if (!window) throw new Error("Window is null");
      // w[0] = 0.5 * (1 - cos(0)) = 0
      // w[1] = 0.5 * (1 - cos(2*PI*1/4)) = 0.5 * (1 - 0) = 0.5
      // w[2] = 0.5 * (1 - cos(2*PI*2/4)) = 0.5 * (1 - (-1)) = 1.0
      // w[3] = 0.5 * (1 - cos(2*PI*3/4)) = 0.5 * (1 - 0) = 0.5
      // w[4] = 0.5 * (1 - cos(2*PI*4/4)) = 0.5 * (1 - 1) = 0
      expect(window[0]).toBeCloseTo(0);
      expect(window[1]).toBeCloseTo(0.5);
      expect(window[2]).toBeCloseTo(1.0);
      expect(window[3]).toBeCloseTo(0.5);
      expect(window[4]).toBeCloseTo(0);
    });

    it("all window values should be between 0 and 1", () => {
      const window = hannWindow(128);
      if (!window) throw new Error("Window is null");
      for (const val of window) {
        expect(val).toBeGreaterThanOrEqual(0);
        expect(val).toBeLessThanOrEqual(1);
      }
    });
  });

  describe("viridisColor", () => {
    it("should return known color for t = 0 (first color in map)", () => {
      const color = viridisColor(0); // #440154
      expect(color).toEqual([68, 1, 84]);
    });

    it("should return known color for t = 1 (last color in map)", () => {
      const color = viridisColor(1); // #fde725
      expect(color).toEqual([253, 231, 37]);
    });

    it("should return a color for t = 0.5 (interpolated)", () => {
      const color = viridisColor(0.5); // #21918c
      // Exact value from map definition for t=0.5: [31, 155, 137]
      expect(color).toEqual([31, 155, 137]);
    });

    it("should clamp input t < 0 to 0", () => {
      const color = viridisColor(-0.5);
      expect(color).toEqual(viridisColor(0));
    });

    it("should clamp input t > 1 to 1", () => {
      const color = viridisColor(1.5);
      expect(color).toEqual(viridisColor(1));
    });

    it("should return an array of 3 numbers (RGB)", () => {
      const color = viridisColor(0.75);
      expect(color).toBeInstanceOf(Array);
      expect(color.length).toBe(3);
      color.forEach((val) => {
        expect(typeof val).toBe("number");
        expect(val).toBeGreaterThanOrEqual(0);
        expect(val).toBeLessThanOrEqual(255);
      });
    });
  });
});

````
--- End of File: vibe-player-v2/src/lib/utils/dsp.test.ts ---
--- File: vibe-player-v2/src/lib/utils/dsp.ts ---
````typescript
export function hannWindow(length: number): number[] | null {
  if (length <= 0 || !Number.isInteger(length)) {
    console.error("hannWindow: Length must be a positive integer.");
    return null;
  }
  const windowArr: number[] = new Array(length);
  if (length === 1) {
    windowArr[0] = 1;
    return windowArr;
  }
  const denom = length - 1;
  for (let i = 0; i < length; i++) {
    windowArr[i] = 0.5 * (1 - Math.cos((2 * Math.PI * i) / denom));
  }
  return windowArr;
}
export function viridisColor(t: number): [number, number, number] {
  const colors: Array<[number, number, number, number]> = [
    [0.0, 68, 1, 84],
    [0.1, 72, 40, 120],
    [0.2, 62, 74, 137],
    [0.3, 49, 104, 142],
    [0.4, 38, 130, 142],
    [0.5, 31, 155, 137],
    [0.6, 53, 178, 126],
    [0.7, 109, 199, 104],
    [0.8, 170, 217, 70],
    [0.9, 235, 231, 35],
    [1.0, 253, 231, 37],
  ];
  t = Math.max(0, Math.min(1, t));
  let c1: [number, number, number, number] = colors[0];
  let c2: [number, number, number, number] = colors[colors.length - 1];
  for (let i = 0; i < colors.length - 1; i++) {
    if (t >= colors[i][0] && t <= colors[i + 1][0]) {
      c1 = colors[i];
      c2 = colors[i + 1];
      break;
    }
  }
  const range = c2[0] - c1[0];
  const ratio = range === 0 ? 0 : (t - c1[0]) / range;
  const r = Math.round(c1[1] + ratio * (c2[1] - c1[1]));
  const g = Math.round(c1[2] + ratio * (c2[2] - c1[2]));
  const b = Math.round(c1[3] + ratio * (c2[3] - c1[3]));
  return [r, g, b];
}

````
--- End of File: vibe-player-v2/src/lib/utils/dsp.ts ---
--- File: vibe-player-v2/src/lib/utils/formatters.test.ts ---
````typescript
// vibe-player-v2/src/lib/utils/formatters.test.ts
import { describe, it, expect } from "vitest";
import { formatTime } from "./formatters";

describe("formatTime", () => {
  it("should format 0 seconds correctly", () => {
    expect(formatTime(0)).toBe("0:00");
  });

  it("should format less than 1 minute correctly", () => {
    expect(formatTime(30)).toBe("0:30");
    expect(formatTime(59)).toBe("0:59");
  });

  it("should format exactly 1 minute correctly", () => {
    expect(formatTime(60)).toBe("1:00");
  });

  it("should format more than 1 minute correctly", () => {
    expect(formatTime(61)).toBe("1:01");
    expect(formatTime(125)).toBe("2:05");
  });

  it("should format large numbers of seconds correctly", () => {
    expect(formatTime(3600)).toBe("60:00"); // 1 hour
    expect(formatTime(3661)).toBe("61:01");
  });

  it('should handle NaN by returning "0:00"', () => {
    expect(formatTime(NaN)).toBe("0:00");
  });

  it('should handle negative numbers by returning "0:00"', () => {
    expect(formatTime(-10)).toBe("0:00");
    expect(formatTime(-0.5)).toBe("0:00");
  });

  it("should handle decimal seconds by flooring them", () => {
    expect(formatTime(30.5)).toBe("0:30");
    expect(formatTime(59.999)).toBe("0:59");
    expect(formatTime(60.1)).toBe("1:00");
  });
});

````
--- End of File: vibe-player-v2/src/lib/utils/formatters.test.ts ---
--- File: vibe-player-v2/src/lib/utils/formatters.ts ---
````typescript
export function formatTime(sec: number): string {
  if (isNaN(sec) || sec < 0) sec = 0;
  const minutes = Math.floor(sec / 60);
  const seconds = Math.floor(sec % 60);
  return `${minutes}:${seconds < 10 ? "0" + seconds : seconds}`;
}

````
--- End of File: vibe-player-v2/src/lib/utils/formatters.ts ---
--- File: vibe-player-v2/src/lib/utils/index.ts ---
````typescript
export * from "./assert";
export * from "./constants";
export * from "./formatters";
export * from "./async";
export * from "./dsp";
export * from "./urlState";

````
--- End of File: vibe-player-v2/src/lib/utils/index.ts ---
--- File: vibe-player-v2/src/lib/utils/urlState.test.ts ---
````typescript
// vibe-player-v2/src/lib/utils/urlState.test.ts
import { describe, it, expect, vi, beforeEach, afterEach } from "vitest";
import {
  loadStateFromUrl,
  subscribeToStoresForUrlUpdate,
  _resetUrlStateInitializationFlagForTesting,
} from "./urlState";
import { page } from "$app/stores";
import { goto } from "$app/navigation";
import { playerStore } from "../stores/player.store";
import { analysisStore } from "../stores/analysis.store";
import { UI_CONSTANTS, URL_HASH_KEYS } from "./constants";
import type { Writable } from "svelte/store";
import { writable } from "svelte/store"; // Import writable

// Mocks
// Create a real writable store for the page mock
const mockPageData = {
  url: { searchParams: new URLSearchParams(), pathname: "/" },
  // Add other initial properties if your code uses them
};
const mockPageStoreInstance = writable(mockPageData);

vi.mock("$app/stores", () => ({
  get page() {
    // Use a getter to ensure the mock instance is used
    return mockPageStoreInstance;
  },
}));

vi.mock("$app/navigation", () => ({
  goto: vi.fn(),
}));

// Create actual writable stores for playerStore and analysisStore to be used in tests
const initialPlayerState = {
  speed: 1.0,
  pitch: 0,
  // Add other relevant player store properties with initial values
  // Ensure all properties accessed by buildUrlSearchParams are present
  currentTime: 0,
  duration: 0,
  isPlaying: false,
  isPlayable: false,
  fileName: null,
  error: null,
  gain: 1,
  waveformData: null,
  status: "Ready",
};
const mockPlayerStoreInstance = writable(initialPlayerState);

const initialAnalysisState = {
  vadPositiveThreshold: 0.5, // Example initial value
  vadNegativeThreshold: 0.35, // Example initial value
  // Add other relevant analysis store properties
  spectrogramData: null,
  isSpeaking: false,
  status: "Ready",
  spectrogramStatus: "Ready",
  error: null,
  spectrogramError: null,
  lastVadResult: null,
  vadStateResetted: false,
};
const mockAnalysisStoreInstance = writable(initialAnalysisState);

vi.mock("../stores/player.store", () => ({
  get playerStore() {
    return mockPlayerStoreInstance;
  },
}));

vi.mock("../stores/analysis.store", () => ({
  get analysisStore() {
    return mockAnalysisStoreInstance;
  },
}));

// Helper to update the mock Svelte's page store
async function updateMockPageStore(searchParams: URLSearchParams) {
  const newPageValue = {
    url: {
      searchParams,
      pathname: "/", // Default pathname
    },
    // Add other properties if your code uses them
  };
  mockPageStoreInstance.set(newPageValue); // Use the .set method of the writable store
}

describe("urlState utilities", () => {
  beforeEach(async () => {
    // Reset module state FIRST
    _resetUrlStateInitializationFlagForTesting();

    // Then setup timers
    vi.useFakeTimers();

    // Then clear any pending microtasks from previous tests that might have been queued *before* this beforeEach
    // This ensures that if a previous test did loadStateFromUrl(), its Promise.resolve().then() is flushed.
    vi.runAllTimers(); // This is crucial for the hasInitializedFromUrl flag

    // Reset the store to default for each test
    mockPageStoreInstance.set({
      url: { searchParams: new URLSearchParams(), pathname: "/" },
    });
    mockPlayerStoreInstance.set(initialPlayerState);
    mockAnalysisStoreInstance.set(initialAnalysisState);

    // Clear specific mocks if necessary, e.g., goto
    vi.mocked(goto).mockClear();

    // Re-spy on store methods as vi.restoreAllMocks() in afterEach clears them
    // (or if vi.clearAllMocks() was used above, which it is not currently)
    vi.spyOn(mockPlayerStoreInstance, "update");
    vi.spyOn(mockPlayerStoreInstance, "subscribe");
    vi.spyOn(mockPlayerStoreInstance, "set");
    vi.spyOn(mockAnalysisStoreInstance, "update");
    vi.spyOn(mockAnalysisStoreInstance, "subscribe");
    vi.spyOn(mockAnalysisStoreInstance, "set");
  });

  afterEach(() => {
    vi.restoreAllMocks();
  });

  describe("loadStateFromUrl", () => {
    it("should call playerStore.update with parsed speed from URL", async () => {
      const params = new URLSearchParams();
      params.set(URL_HASH_KEYS.SPEED, "1.75");
      await updateMockPageStore(params);

      loadStateFromUrl();

      expect(playerStore.update).toHaveBeenCalled();
      const lastCallArg = (playerStore.update as ReturnType<typeof vi.fn>).mock
        .calls[0][0];
      const newState = lastCallArg({}); // Call the updater function
      expect(newState.speed).toBe(1.75);
    });

    it("should call analysisStore.update with parsed VAD thresholds from URL", async () => {
      const params = new URLSearchParams();
      params.set(URL_HASH_KEYS.VAD_POSITIVE, "0.8");
      params.set(URL_HASH_KEYS.VAD_NEGATIVE, "0.2");
      await updateMockPageStore(params);

      loadStateFromUrl();

      expect(analysisStore.update).toHaveBeenCalled();
      const lastCallArg = (analysisStore.update as ReturnType<typeof vi.fn>)
        .mock.calls[0][0];
      const newState = lastCallArg({});
      expect(newState.vadPositiveThreshold).toBe(0.8);
      expect(newState.vadNegativeThreshold).toBe(0.2);
    });

    it("should use undefined for missing parameters for playerStore", async () => {
      await updateMockPageStore(new URLSearchParams()); // Empty params
      loadStateFromUrl();

      expect(playerStore.update).toHaveBeenCalled();
      const lastCallArg = (playerStore.update as ReturnType<typeof vi.fn>).mock
        .calls[0][0];
      const newState = lastCallArg({ speed: 1, pitch: 0 }); // Provide some initial state
      expect(newState.speed).toBeUndefined();
      expect(newState.pitch).toBeUndefined();
      // ensure others are also undefined
    });

    it("should set hasInitializedFromUrl to true after timeout", async () => {
      // This test requires a bit more setup to check the internal `hasInitializedFromUrl`
      // For now, we assume it works as intended based on its Promise.resolve().then(...)
      // A more complex test might involve spying on `subscribeToStoresForUrlUpdate` behavior
      // which depends on this flag.
      loadStateFromUrl();
      // console.log('hasInitializedFromUrl should be false initially or after this function call');
      vi.runAllTimers(); // Resolve the Promise.resolve().then()
      // console.log('hasInitializedFromUrl should be true after timers run');
      // This test doesn't directly assert hasInitializedFromUrl as it's not exposed.
      // We'd test its effect on subscribeToStoresForUrlUpdate.
      expect(true).toBe(true); // Placeholder
    });
  });

  describe("subscribeToStoresForUrlUpdate", () => {
    it("should subscribe to playerStore and analysisStore", () => {
      subscribeToStoresForUrlUpdate();
      expect(playerStore.subscribe).toHaveBeenCalled();
      expect(analysisStore.subscribe).toHaveBeenCalled();
    });

    it("debounced URL updater should call goto eventually after store change (if initialized)", async () => {
      // First, simulate initialization
      loadStateFromUrl();
      // Ensure the microtask from loadStateFromUrl (setting hasInitializedFromUrl = true) completes
      await vi.advanceTimersByTimeAsync(0);

      // let playerStoreSubscriber: (state: any) => void = () => {};
      // (playerStore.subscribe as ReturnType<typeof vi.fn>).mockImplementation( // Not needed with real store
      //   (cb) => {
      //     playerStoreSubscriber = cb;
      //     cb(get(mockPlayerStoreInstance)); // Call with current state
      //     return mockPlayerStoreInstance.subscribe(cb); // Use real subscribe for further updates
      //   },
      // );

      subscribeToStoresForUrlUpdate(); // This sets up the subscriptions

      // Simulate a store change by updating the actual store instance
      mockPlayerStoreInstance.update((s) => ({ ...s, speed: 1.5 }));
      // vi.runAllTimers(); // Ensure store update is processed if it involves async operations (it shouldn't here)

      // goto might be called once immediately upon subscription if hasInitializedFromUrl is true,
      // then again after the debounce from the explicit update.
      // Or, the debouncer might coalesce these. Let's check for at least one call after advancing timer.
      vi.advanceTimersByTime(UI_CONSTANTS.DEBOUNCE_HASH_UPDATE_MS);
      expect(goto).toHaveBeenCalled();
      // Check the last call for the correct URL params
      const lastCallIndex =
        (goto as ReturnType<typeof vi.fn>).mock.calls.length - 1;
      expect(
        (goto as ReturnType<typeof vi.fn>).mock.calls[lastCallIndex][0],
      ).toContain(`${URL_HASH_KEYS.SPEED}=1.5`);
      // If we need to be more precise about call count, it would require deeper analysis of debounce interaction.
    });

    it("debounced URL updater should NOT call goto if not initialized", () => {
      // DO NOT call loadStateFromUrl or run timers for hasInitializedFromUrl flag

      // (playerStore.subscribe as ReturnType<typeof vi.fn>).mockImplementation( // Not needed
      //   (cb) => {
      //     playerStoreSubscriber = cb;
      //     cb(get(mockPlayerStoreInstance));
      //     return mockPlayerStoreInstance.subscribe(cb);
      //   },
      // );

      subscribeToStoresForUrlUpdate();

      mockPlayerStoreInstance.update((s) => ({ ...s, speed: 1.5 }));
      // vi.runAllTimers();

      vi.advanceTimersByTime(UI_CONSTANTS.DEBOUNCE_HASH_UPDATE_MS);
      expect(goto).not.toHaveBeenCalled();
    });

    it("should return an unsubscribe function that calls store unsubscribers", () => {
      const mockPlayerUnsub = vi.fn();
      const mockAnalysisUnsub = vi.fn();
      // Now spy on the methods of the actual store instances
      vi.mocked(mockPlayerStoreInstance.subscribe).mockReturnValue(
        mockPlayerUnsub,
      );
      vi.mocked(mockAnalysisStoreInstance.subscribe).mockReturnValue(
        mockAnalysisUnsub,
      );

      const unsubscribeAll = subscribeToStoresForUrlUpdate();
      unsubscribeAll();

      expect(mockPlayerUnsub).toHaveBeenCalled();
      expect(mockAnalysisUnsub).toHaveBeenCalled();
    });
  });
});

````
--- End of File: vibe-player-v2/src/lib/utils/urlState.test.ts ---
--- File: vibe-player-v2/src/lib/utils/urlState.ts ---
````typescript
import { goto } from "$app/navigation";
import { page } from "$app/stores";
import { get } from "svelte/store"; // To get current value of page store

// Assuming placeholder stores for now. Actual structure might differ.
import { playerStore } from "../stores/player.store";
import { analysisStore } from "../stores/analysis.store";

import { debounce } from "./async";
import { URL_HASH_KEYS, UI_CONSTANTS } from "./constants";

// This flag prevents updating the URL when the stores are initially set from the URL parameters.
let hasInitializedFromUrl = false;

// Placeholder: Actual store structures are not yet defined.
// These interfaces are for conceptual clarity of what we expect.
interface PlayerState {
  speed?: number;
  pitch?: number;
  gain?: number;
  audioUrl?: string;
  currentTime?: number;
}

interface AnalysisState {
  vadPositiveThreshold?: number;
  vadNegativeThreshold?: number;
}

function buildUrlSearchParams(
  player: PlayerState,
  analysis: AnalysisState,
): URLSearchParams {
  const params = new URLSearchParams();
  if (player.speed !== undefined)
    params.set(URL_HASH_KEYS.SPEED, String(player.speed));
  if (player.pitch !== undefined)
    params.set(URL_HASH_KEYS.PITCH, String(player.pitch));
  if (player.gain !== undefined)
    params.set(URL_HASH_KEYS.GAIN, String(player.gain));
  if (player.audioUrl) params.set(URL_HASH_KEYS.AUDIO_URL, player.audioUrl);
  if (player.currentTime !== undefined)
    params.set(URL_HASH_KEYS.TIME, String(player.currentTime));
  if (analysis.vadPositiveThreshold !== undefined)
    params.set(
      URL_HASH_KEYS.VAD_POSITIVE,
      String(analysis.vadPositiveThreshold),
    );
  if (analysis.vadNegativeThreshold !== undefined)
    params.set(
      URL_HASH_KEYS.VAD_NEGATIVE,
      String(analysis.vadNegativeThreshold),
    );
  return params;
}

const updateUrlFromStateDebounced = debounce(() => {
  if (!hasInitializedFromUrl) return;

  // In a real scenario, you'd get current store values here
  // For now, we'll assume they are passed or accessible if this were part of a class/service
  // This function will be called by store subscribers that pass the latest state.
  // This is a simplified placeholder for the debounced function's body.
  // Actual state needs to be fetched from stores inside the debounced function or passed to it.

  // Placeholder: get current state from stores
  const currentPlayerState = get(playerStore) as PlayerState;
  const currentAnalysisState = get(analysisStore) as AnalysisState;

  const params = buildUrlSearchParams(currentPlayerState, currentAnalysisState);
  if (params.toString()) {
    goto(`?${params.toString()}`, {
      keepFocus: true,
      replaceState: true,
      noScroll: true,
    });
  } else {
    // If no params, go to base path to clear URL
    const currentPath = get(page).url.pathname;
    goto(currentPath, { keepFocus: true, replaceState: true, noScroll: true });
  }
}, UI_CONSTANTS.DEBOUNCE_HASH_UPDATE_MS);

export function loadStateFromUrl() {
  const currentParams = get(page).url.searchParams;

  const speedStr = currentParams.get(URL_HASH_KEYS.SPEED);
  const pitchStr = currentParams.get(URL_HASH_KEYS.PITCH);
  const gainStr = currentParams.get(URL_HASH_KEYS.GAIN);
  const audioUrl = currentParams.get(URL_HASH_KEYS.AUDIO_URL);
  const timeStr = currentParams.get(URL_HASH_KEYS.TIME);
  const vadPositiveStr = currentParams.get(URL_HASH_KEYS.VAD_POSITIVE);
  const vadNegativeStr = currentParams.get(URL_HASH_KEYS.VAD_NEGATIVE);

  playerStore.update((s) => ({
    ...s,
    speed: speedStr ? parseFloat(speedStr) : undefined, // Or default from constants/store
    pitch: pitchStr ? parseFloat(pitchStr) : undefined,
    gain: gainStr ? parseFloat(gainStr) : undefined,
    audioUrl: audioUrl || undefined,
    currentTime: timeStr ? parseFloat(timeStr) : undefined,
  }));

  analysisStore.update((s) => ({
    ...s,
    vadPositiveThreshold: vadPositiveStr
      ? parseFloat(vadPositiveStr)
      : undefined,
    vadNegativeThreshold: vadNegativeStr
      ? parseFloat(vadNegativeStr)
      : undefined,
  }));

  // Important: Set flag after attempting to load and update stores
  // to allow subscriptions to start updating the URL.
  // Use a microtask to ensure stores have propagated changes before enabling URL updates.
  Promise.resolve().then(() => {
    hasInitializedFromUrl = true;
  });
}

export function subscribeToStoresForUrlUpdate(): () => void {
  // Ensure this is called after initial loadStateFromUrl
  if (!hasInitializedFromUrl) {
    console.warn(
      "subscribeToStoresForUrlUpdate called before hasInitializedFromUrl is true. URL updates might be unexpected.",
    );
  }

  const unsubPlayer = playerStore.subscribe((state) => {
    if (hasInitializedFromUrl) {
      // Only update URL if initial load is done
      updateUrlFromStateDebounced(); // Debounced function will fetch latest store values
    }
  });

  const unsubAnalysis = analysisStore.subscribe((state) => {
    if (hasInitializedFromUrl) {
      updateUrlFromStateDebounced();
    }
  });

  return () => {
    unsubPlayer();
    unsubAnalysis();
  };
}

// THIS FUNCTION IS FOR TESTING PURPOSES ONLY
export function _resetUrlStateInitializationFlagForTesting() {
  hasInitializedFromUrl = false;
}

````
--- End of File: vibe-player-v2/src/lib/utils/urlState.ts ---
--- File: vibe-player-v2/src/lib/workers/dtmf.worker.ts ---
````typescript
// vibe-player-v2/src/lib/workers/dtmf.worker.ts

// --- Constants directly ported from V1's goertzel.js ---
const DTMF_SAMPLE_RATE = 16000;
const DTMF_BLOCK_SIZE = 410;
const DTMF_RELATIVE_THRESHOLD_FACTOR = 2.0;
const DTMF_ABSOLUTE_MAGNITUDE_THRESHOLD = 4e2;
const DTMF_FREQUENCIES_LOW = [697, 770, 852, 941];
const DTMF_FREQUENCIES_HIGH = [1209, 1336, 1477, 1633];
export const DTMF_CHARACTERS: { [key: string]: string } = {
  "697_1209": "1",
  "697_1336": "2",
  "697_1477": "3",
  "697_1633": "A",
  "770_1209": "4",
  "770_1336": "5",
  "770_1477": "6",
  "770_1633": "B",
  "852_1209": "7",
  "852_1336": "8",
  "852_1477": "9",
  "852_1633": "C",
  "941_1209": "*",
  "941_1336": "0",
  "941_1477": "#",
  "941_1633": "D",
};
// NOTE: CPT constants and classes would be ported here as well for a full implementation.
// For this step, we will focus on DTMF.

// --- Ported GoertzelFilter Class with TypeScript ---
class GoertzelFilter {
  private q1: number = 0;
  private q2: number = 0;
  private N: number;
  private cosine: number;
  private coeff: number;

  constructor(
    public targetFrequency: number,
    public sampleRate: number,
    N: number,
  ) {
    this.N = N;
    const k = Math.floor(
      0.5 + (this.N * this.targetFrequency) / this.sampleRate,
    );
    const omega = (2 * Math.PI * k) / this.N;
    this.cosine = Math.cos(omega);
    this.coeff = 2 * this.cosine;
  }

  public reset(): void {
    this.q1 = 0;
    this.q2 = 0;
  }

  public processBlock(samples: Float32Array): void {
    for (let i = 0; i < samples.length; i++) {
      const q0 = samples[i] + this.coeff * this.q1 - this.q2;
      this.q2 = this.q1;
      this.q1 = q0;
    }
  }

  public getMagnitudeSquared(): number {
    return (
      this.q1 * this.q1 + this.q2 * this.q2 - this.q1 * this.q2 * this.coeff
    );
  }
}

// --- Ported DTMFParser Class with TypeScript ---
class DTMFParser {
  private lowGroupFilters: GoertzelFilter[];
  private highGroupFilters: GoertzelFilter[];

  constructor(
    private sampleRate: number,
    private blockSize: number,
  ) {
    this.lowGroupFilters = DTMF_FREQUENCIES_LOW.map(
      (freq) => new GoertzelFilter(freq, this.sampleRate, this.blockSize),
    );
    this.highGroupFilters = DTMF_FREQUENCIES_HIGH.map(
      (freq) => new GoertzelFilter(freq, this.sampleRate, this.blockSize),
    );
  }

  public processAudioBlock(audioBlock: Float32Array): string | null {
    let maxLowMag = -1,
      detectedLowFreq = -1;
    const lowMagnitudes: { [key: number]: number } = {};
    this.lowGroupFilters.forEach((filter) => {
      filter.reset();
      filter.processBlock(audioBlock);
      const magSq = filter.getMagnitudeSquared();
      lowMagnitudes[filter.targetFrequency] = magSq;
      if (magSq > maxLowMag) {
        maxLowMag = magSq;
        detectedLowFreq = filter.targetFrequency;
      }
    });

    let maxHighMag = -1,
      detectedHighFreq = -1;
    const highMagnitudes: { [key: number]: number } = {};
    this.highGroupFilters.forEach((filter) => {
      filter.reset();
      filter.processBlock(audioBlock);
      const magSq = filter.getMagnitudeSquared();
      highMagnitudes[filter.targetFrequency] = magSq;
      if (magSq > maxHighMag) {
        maxHighMag = magSq;
        detectedHighFreq = filter.targetFrequency;
      }
    });

    if (
      maxLowMag < DTMF_ABSOLUTE_MAGNITUDE_THRESHOLD ||
      maxHighMag < DTMF_ABSOLUTE_MAGNITUDE_THRESHOLD
    ) {
      return null;
    }

    // Check relative threshold
    for (const freq in lowMagnitudes) {
      if (
        Number(freq) !== detectedLowFreq &&
        lowMagnitudes[freq] * DTMF_RELATIVE_THRESHOLD_FACTOR > maxLowMag
      )
        return null;
    }
    for (const freq in highMagnitudes) {
      if (
        Number(freq) !== detectedHighFreq &&
        highMagnitudes[freq] * DTMF_RELATIVE_THRESHOLD_FACTOR > maxHighMag
      )
        return null;
    }

    const dtmfKey = `${detectedLowFreq}_${detectedHighFreq}`;
    return (DTMF_CHARACTERS as Record<string, string>)[dtmfKey] || null;
  }
}

// --- Worker Logic ---
let dtmfParser: DTMFParser | null = null;

self.onmessage = (event: MessageEvent) => {
  const { type, payload } = event.data;

  try {
    if (type === "init") {
      dtmfParser = new DTMFParser(payload.sampleRate, DTMF_BLOCK_SIZE);
      self.postMessage({ type: "init_complete" });
    } else if (type === "process") {
      if (!dtmfParser) throw new Error("Worker not initialized.");

      const { pcmData } = payload;
      const detectedDtmf: string[] = [];
      let lastDetectedDtmf: string | null = null;

      // Ported processing loop from V1's app.js (simplified for DTMF only)
      for (
        let i = 0;
        i + DTMF_BLOCK_SIZE <= pcmData.length;
        i += DTMF_BLOCK_SIZE
      ) {
        const audioBlock = pcmData.subarray(i, i + DTMF_BLOCK_SIZE);
        const tone = dtmfParser.processAudioBlock(audioBlock);

        if (tone) {
          // A simple logic to avoid adding the same tone for every single block it's detected in
          if (lastDetectedDtmf !== tone) {
            detectedDtmf.push(tone);
          }
          lastDetectedDtmf = tone;
        } else {
          lastDetectedDtmf = null;
        }
      }

      self.postMessage({ type: "result", payload: { dtmf: detectedDtmf } });
    }
  } catch (e) {
    const error = e as Error;
    self.postMessage({ type: "error", payload: error.message });
  }
};

````
--- End of File: vibe-player-v2/src/lib/workers/dtmf.worker.ts ---
--- File: vibe-player-v2/src/lib/workers/rubberband.worker.ts ---
````typescript
// vibe-player-v2/src/lib/workers/rubberband.worker.ts
import type {
  RubberbandInitPayload,
  WorkerMessage,
  RubberbandProcessPayload,
  RubberbandProcessResultPayload,
} from "../types/worker.types";
import { RB_WORKER_MSG_TYPE } from "../types/worker.types";

// --- Type definitions for the Emscripten/WASM Module ---
interface RubberbandModule {
  _malloc: (size: number) => number;
  _free: (ptr: number) => void;
  _rubberband_new: (
    sampleRate: number,
    channels: number,
    options: number,
    timeRatio: number,
    pitchScale: number,
  ) => number;
  _rubberband_delete: (stretcher: number) => void;
  _rubberband_set_time_ratio: (stretcher: number, ratio: number) => void;
  _rubberband_set_pitch_scale: (stretcher: number, scale: number) => void;
  _rubberband_reset: (stretcher: number) => void;
  _rubberband_process: (
    stretcher: number,
    inputPtrs: number,
    samples: number,
    final: number,
  ) => void;
  _rubberband_available: (stretcher: number) => number;
  _rubberband_retrieve: (
    stretcher: number,
    outputPtrs: number,
    samples: number,
  ) => number;
  HEAPU32: Uint32Array;
  HEAPF32: Float32Array;
  RubberBandOptionFlag?: { [key: string]: number };
}

declare function Rubberband(moduleArg: {
  instantiateWasm: Function;
}): Promise<RubberbandModule>;

// --- Worker State ---
let wasmModule: RubberbandModule | null = null;
let stretcher: number = 0; // Opaque pointer to the C++ RubberbandStretcher object

// --- Main Worker Logic ---
self.onmessage = async (event: MessageEvent<WorkerMessage>) => {
  const { type, payload, messageId } = event.data;

  try {
    switch (type) {
      case RB_WORKER_MSG_TYPE.INIT:
        await handleInit(payload as RubberbandInitPayload);
        self.postMessage({ type: RB_WORKER_MSG_TYPE.INIT_SUCCESS, messageId });
        break;

      case RB_WORKER_MSG_TYPE.SET_SPEED:
        if (stretcher && wasmModule && payload?.speed) {
          wasmModule._rubberband_set_time_ratio(stretcher, 1.0 / payload.speed);
        }
        break;

      case RB_WORKER_MSG_TYPE.SET_PITCH:
        if (stretcher && wasmModule && payload?.pitch !== undefined) {
          const pitchScale = Math.pow(2, payload.pitch / 12.0);
          wasmModule._rubberband_set_pitch_scale(stretcher, pitchScale);
        }
        break;

      case RB_WORKER_MSG_TYPE.RESET:
        if (stretcher && wasmModule) {
          wasmModule._rubberband_reset(stretcher);
        }
        break;

      case RB_WORKER_MSG_TYPE.PROCESS:
        const result = handleProcess(payload as RubberbandProcessPayload);
        self.postMessage(
          {
            type: RB_WORKER_MSG_TYPE.PROCESS_RESULT,
            payload: result,
            messageId,
          },
          result.outputBuffer.map((b) => b.buffer),
        );
        break;

      case RB_WORKER_MSG_TYPE.FLUSH:
        // This would be used to get the last remaining samples from the stretcher.
        // For simplicity in this fix, we are not fully implementing a separate flush logic.
        // The main loop stops when it runs out of source samples.
        self.postMessage({
          type: RB_WORKER_MSG_TYPE.PROCESS_RESULT,
          payload: { outputBuffer: [] },
          messageId,
        });
        break;
    }
  } catch (e) {
    const error = e as Error;
    self.postMessage({
      type: `${type}_ERROR`,
      error: error.message,
      messageId,
    });
  }
};

async function handleInit(payload: RubberbandInitPayload) {
  if (stretcher && wasmModule) {
    wasmModule._rubberband_delete(stretcher);
  }

  // --- START of CHANGE ---
  const { wasmBinary, loaderScriptText } = payload;
  if (!wasmBinary || !loaderScriptText) {
    throw new Error(
      "Worker handleInit: Missing wasmBinary or loaderScriptText in payload.",
    );
  }

  // The loader script is designed to be executed to produce a factory function.
  // We use new Function() to safely evaluate the text we received and get the factory.
  const getRubberbandFactory = new Function(
    loaderScriptText + "\nreturn Rubberband;",
  )(); // MODIFIED LINE
  const Rubberband = getRubberbandFactory; // Ensure Rubberband is the factory itself
  // --- END of CHANGE ---

  // The loader script expects an `instantiateWasm` function to be provided.
  const instantiateWasm = (
    imports: WebAssembly.Imports,
    cb: (instance: WebAssembly.Instance) => void,
  ) => {
    WebAssembly.instantiate(wasmBinary, imports).then((output) =>
      cb(output.instance),
    );
    return {};
  };

  wasmModule = await Rubberband({ instantiateWasm });

  const RBOptions = wasmModule.RubberBandOptionFlag || {};
  const options =
    (RBOptions.ProcessRealTime ?? 0) | (RBOptions.PitchHighQuality ?? 0);

  stretcher = wasmModule._rubberband_new(
    payload.sampleRate,
    payload.channels,
    options,
    1.0 / payload.initialSpeed,
    Math.pow(2, payload.initialPitch / 12.0),
  );
  if (!stretcher)
    throw new Error("Failed to create Rubberband stretcher instance.");
}

function handleProcess(
  payload: RubberbandProcessPayload,
): RubberbandProcessResultPayload {
  if (!wasmModule || !stretcher)
    throw new Error("Worker not initialized for processing.");

  const { inputBuffer } = payload;
  const channels = inputBuffer.length;
  if (channels === 0) return { outputBuffer: [] };

  const frameCount = inputBuffer[0].length;
  if (frameCount === 0) {
    return { outputBuffer: [] };
  }

  // 1. Allocate memory in the WASM heap for an array of pointers (one for each channel).
  const inputPtrs = wasmModule._malloc(channels * 4);

  // 2. For each channel, allocate memory and copy the audio data into the WASM heap.
  //    Store the pointer to this memory in the pointers array.
  for (let i = 0; i < channels; i++) {
    const bufferPtr = wasmModule._malloc(frameCount * 4);
    wasmModule.HEAPF32.set(inputBuffer[i], bufferPtr / 4);
    wasmModule.HEAPU32[inputPtrs / 4 + i] = bufferPtr;
  }

  // 3. Call the C++ `rubberband_process` function.
  wasmModule._rubberband_process(stretcher, inputPtrs, frameCount, 0);

  // 4. Free the memory we allocated for the input buffers and the pointer array.
  for (let i = 0; i < channels; i++) {
    wasmModule._free(wasmModule.HEAPU32[inputPtrs / 4 + i]);
  }
  wasmModule._free(inputPtrs);

  // 5. Retrieve the processed audio from Rubberband's internal buffers.
  const available = wasmModule._rubberband_available(stretcher);
  const outputBuffer: Float32Array[] = [];
  if (available > 0) {
    const outputPtrs = wasmModule._malloc(channels * 4);
    const retrievedPtrs: number[] = [];
    for (let i = 0; i < channels; i++) {
      const bufferPtr = wasmModule._malloc(available * 4);
      wasmModule.HEAPU32[outputPtrs / 4 + i] = bufferPtr;
      retrievedPtrs.push(bufferPtr);
    }

    const retrievedCount = wasmModule._rubberband_retrieve(
      stretcher,
      outputPtrs,
      available,
    );

    for (let i = 0; i < channels; i++) {
      const channelData = new Float32Array(retrievedCount);
      channelData.set(
        wasmModule.HEAPF32.subarray(
          retrievedPtrs[i] / 4,
          retrievedPtrs[i] / 4 + retrievedCount,
        ),
      );
      outputBuffer.push(channelData);
      wasmModule._free(retrievedPtrs[i]);
    }
    wasmModule._free(outputPtrs);
  }

  return { outputBuffer };
}

````
--- End of File: vibe-player-v2/src/lib/workers/rubberband.worker.ts ---
--- File: vibe-player-v2/src/lib/workers/sileroVad.worker.ts ---
````typescript
// vibe-player-v2/src/lib/workers/sileroVad.worker.ts
import * as ort from "onnxruntime-web";
import type {
  WorkerMessage,
  SileroVadInitPayload,
  SileroVadProcessPayload,
  SileroVadProcessResultPayload,
} from "../types/worker.types";
import { VAD_WORKER_MSG_TYPE } from "../types/worker.types";
import { assert } from "../utils/assert";

let vadSession: ort.InferenceSession | null = null;
let sampleRate: number = 16000;
let frameSamples: number = 1536;
let positiveThreshold: number = 0.5;
let negativeThreshold: number = 0.35;
let _h: ort.Tensor | null = null;
let _c: ort.Tensor | null = null;
const srData = new Int32Array(1);
let srTensor: ort.Tensor | null = null;

self.onmessage = async (event: MessageEvent<WorkerMessage>) => {
  const { type, payload, messageId } = event.data;

  try {
    switch (type) {
      case VAD_WORKER_MSG_TYPE.INIT:
        const initPayload = payload as SileroVadInitPayload;

        // --- ADD THESE ASSERTIONS ---
        assert(
          initPayload && typeof initPayload === "object",
          "INIT payload is missing or not an object.",
        );
        assert(initPayload.origin, "INIT payload is missing `origin`.");
        assert(
          initPayload.modelBuffer &&
            initPayload.modelBuffer instanceof ArrayBuffer,
          "INIT payload is missing a valid `modelBuffer`.",
        );
        assert(
          typeof initPayload.sampleRate === "number",
          "INIT payload is missing `sampleRate`.",
        );
        // --- END ASSERTIONS ---

        sampleRate = initPayload.sampleRate;
        frameSamples = initPayload.frameSamples;
        positiveThreshold = initPayload.positiveThreshold || positiveThreshold;
        negativeThreshold = initPayload.negativeThreshold || negativeThreshold;

        // --- THE FIX ---
        if (!initPayload.origin) {
          throw new Error(
            "SileroVadWorker INIT: `origin` is missing in payload.",
          );
        }
        // Ensure the path has a trailing slash before ORT uses it.
        ort.env.wasm.wasmPaths = `${initPayload.origin}/`;
        // --- END FIX ---

        if (!initPayload.modelBuffer) {
          throw new Error(
            "SileroVadWorker INIT: modelBuffer is missing in payload",
          );
        }

        try {
          vadSession = await ort.InferenceSession.create(
            initPayload.modelBuffer,
            { executionProviders: ["wasm"] },
          );
        } catch (e) {
          const ortError = e as Error;
          throw new Error(
            `ONNX session creation failed: ${ortError.message}. Check WASM paths and model buffer.`,
          );
        }

        _h = new ort.Tensor(
          "float32",
          new Float32Array(2 * 1 * 64).fill(0),
          [2, 1, 64],
        );
        _c = new ort.Tensor(
          "float32",
          new Float32Array(2 * 1 * 64).fill(0),
          [2, 1, 64],
        );
        srData[0] = sampleRate;
        srTensor = new ort.Tensor("int32", srData, [1]);

        self.postMessage({ type: VAD_WORKER_MSG_TYPE.INIT_SUCCESS, messageId });
        break;

      case VAD_WORKER_MSG_TYPE.PROCESS:
        if (!vadSession || !_h || !_c || !srTensor) {
          throw new Error("VAD worker not initialized or tensors not ready.");
        }
        const processPayload = payload as SileroVadProcessPayload;

        // --- ADD THIS ASSERTION ---
        assert(
          processPayload.audioFrame &&
            processPayload.audioFrame instanceof Float32Array,
          "PROCESS payload is missing a valid `audioFrame`.",
        );
        // --- END ASSERTION ---

        const audioFrame = processPayload.audioFrame;

        if (audioFrame.length !== frameSamples) {
          throw new Error(
            `Input audio frame size ${audioFrame.length} does not match expected frameSamples ${frameSamples}`,
          );
        }

        const inputTensor = new ort.Tensor("float32", audioFrame, [
          1,
          audioFrame.length,
        ]);
        const feeds: Record<string, ort.Tensor> = {
          input: inputTensor,
          sr: srTensor,
          h: _h,
          c: _c,
        };

        const results = await vadSession.run(feeds);
        const outputScore = (results.output.data as Float32Array)[0];
        _h = results.hn;
        _c = results.cn;

        const isSpeech = outputScore >= positiveThreshold;

        const resultPayload: SileroVadProcessResultPayload = {
          isSpeech: isSpeech,
          timestamp: payload.timestamp || 0,
          score: outputScore,
        };
        self.postMessage({
          type: VAD_WORKER_MSG_TYPE.PROCESS_RESULT,
          payload: resultPayload,
          messageId,
        });
        break;

      case VAD_WORKER_MSG_TYPE.RESET:
        if (_h && _c) {
          _h.data.fill(0);
          _c.data.fill(0);
        }
        self.postMessage({
          type: `${VAD_WORKER_MSG_TYPE.RESET}_SUCCESS`,
          messageId,
        });
        break;

      default:
        self.postMessage({
          type: "unknown_message",
          error: `Unknown message type: ${type}`,
          messageId,
        });
    }
  } catch (error) {
    const errorMessage = error instanceof Error ? error.message : String(error);
    const errorStack = error instanceof Error ? error.stack : undefined;
    console.error(
      `Error in SileroVadWorker (type: ${type}):`,
      errorMessage,
      errorStack,
    );
    self.postMessage({
      type: `${type}_ERROR` as string,
      error: errorMessage,
      messageId,
    });
  }
};

````
--- End of File: vibe-player-v2/src/lib/workers/sileroVad.worker.ts ---
--- File: vibe-player-v2/src/lib/workers/spectrogram.worker.ts ---
````typescript
// vibe-player-v2/src/lib/workers/spectrogram.worker.ts
import type {
  SpectrogramInitPayload,
  SpectrogramProcessPayload,
  SpectrogramResultPayload,
  WorkerMessage,
} from "../types/worker.types";
import { SPEC_WORKER_MSG_TYPE } from "../types/worker.types";

interface FFTClass {
  new (size: number): FFTInstance;
}

interface FFTInstance {
  createComplexArray(): Float32Array;
  realTransform(output: Float32Array, input: Float32Array): void;
}

declare var FFT: FFTClass;

function generateHannWindow(length: number): number[] | null {
  if (length <= 0 || !Number.isInteger(length)) return null;
  const windowArr: number[] = new Array(length);
  if (length === 1) {
    windowArr[0] = 1;
    return windowArr;
  }
  const denom = length - 1;
  for (let i = 0; i < length; i++) {
    windowArr[i] = 0.5 * (1 - Math.cos((2 * Math.PI * i) / denom));
  }
  return windowArr;
}

let fftInstance: FFTInstance | null = null;
let sampleRate: number;
let fftSize: number;
let hopLength: number;
let hannWindow: number[] | null = null;

self.onmessage = async (event: MessageEvent<WorkerMessage>) => {
  const { type, payload, messageId } = event.data;

  try {
    switch (type) {
      case SPEC_WORKER_MSG_TYPE.INIT:
        const initPayload = payload as SpectrogramInitPayload;

        // --- MODIFIED: Direct assignment, no fallback logic needed ---
        // The service is responsible for providing these values.
        sampleRate = initPayload.sampleRate;
        fftSize = initPayload.fftSize;
        hopLength = initPayload.hopLength;

        // --- MODIFICATION START ---
        if (!initPayload.fftScriptText) {
          throw new Error(
            "SpectrogramWorker INIT: fftScriptText is missing in payload.",
          );
        }

        // Dynamically create the FFT class from the script text
        const getFftClass = new Function(
          initPayload.fftScriptText + "; return FFT;",
        );
        const FftClass = getFftClass() as FFTClass | undefined;

        if (typeof FftClass === "undefined") {
          throw new Error("Failed to define FFT class from fftScriptText.");
        }
        fftInstance = new FftClass(fftSize);
        // --- MODIFICATION END ---

        // --- BEGIN NEW: Generate Hann Window ---
        hannWindow = generateHannWindow(fftSize);
        if (!hannWindow) {
          console.warn(
            "SpectrogramWorker: Failed to generate Hann window, proceeding without windowing.",
          );
        }
        // --- END NEW: Generate Hann Window ---

        self.postMessage({
          type: SPEC_WORKER_MSG_TYPE.INIT_SUCCESS,
          messageId,
        });
        break;

      case SPEC_WORKER_MSG_TYPE.PROCESS:
        if (!fftInstance) {
          throw new Error("Spectrogram worker not initialized.");
        }
        const processPayload = payload as SpectrogramProcessPayload;
        const audioData = processPayload.audioData;
        const magnitudes: Float32Array[] = [];

        for (let i = 0; i + fftSize <= audioData.length; i += hopLength) {
          const frame = audioData.subarray(i, i + fftSize);
          let windowedFrame = new Float32Array(fftSize);

          // --- BEGIN NEW: Apply Hann Window ---
          if (hannWindow && hannWindow.length === fftSize) {
            for (let j = 0; j < fftSize; j++) {
              windowedFrame[j] = frame[j] * hannWindow[j];
            }
          } else {
            // If no window, copy frame directly
            windowedFrame.set(frame);
          }
          // --- END NEW: Apply Hann Window ---

          const complexSpectrum = fftInstance.createComplexArray();
          // Use windowedFrame for transform
          fftInstance.realTransform(complexSpectrum, windowedFrame);

          const frameMagnitudes = new Float32Array(fftSize / 2 + 1);
          for (let k = 0; k < frameMagnitudes.length; k++) {
            const real = complexSpectrum[k * 2];
            const imag = complexSpectrum[k * 2 + 1];
            frameMagnitudes[k] = Math.sqrt(real * real + imag * imag) / fftSize;
          }
          magnitudes.push(frameMagnitudes);
        }
        if (magnitudes.length > 0) {
          const resultPayload: SpectrogramResultPayload = { magnitudes };
          self.postMessage({
            type: SPEC_WORKER_MSG_TYPE.PROCESS_RESULT,
            payload: resultPayload,
            messageId,
          });
        } else {
          self.postMessage({
            type: SPEC_WORKER_MSG_TYPE.PROCESS_RESULT,
            payload: { magnitudes: [] },
            messageId,
          }); // Send empty if no frames
        }
        break;
      default:
        console.warn(`SpectrogramWorker: Unknown message type: ${type}`);
        self.postMessage({
          type: "unknown_message",
          error: `Unknown message type: ${type}`,
          messageId,
        });
    }
  } catch (error) {
    const errorMessage = error instanceof Error ? error.message : String(error);
    console.error(`Error in SpectrogramWorker (type: ${type}):`, error);
    self.postMessage({
      type: `${type}_ERROR` as string,
      error: errorMessage,
      messageId,
    });
  }
};

````
--- End of File: vibe-player-v2/src/lib/workers/spectrogram.worker.ts ---
--- File: vibe-player-v2/src/routes/+layout.svelte ---
````svelte
<script lang="ts">
  import "../app.css";
  // Assuming use of Skeleton UI's AppBar component for the header
  import { AppBar } from '@skeletonlabs/skeleton';
</script>

<AppBar>
  <svelte:fragment slot="lead">
    <strong class="text-xl uppercase">Vibe Player V2</strong>
  </svelte:fragment>
  <svelte:fragment slot="trail">
    <!-- Other nav elements could go here -->
    <a href="https://github.com/averykhoo/vibe-player" target="_blank" rel="noopener noreferrer" class="btn btn-sm variant-ghost-surface">GitHub</a>
  </svelte:fragment>
</AppBar>

<!-- Main content slot -->
<main class="p-4">
  <slot />
</main>

````
--- End of File: vibe-player-v2/src/routes/+layout.svelte ---
--- File: vibe-player-v2/src/routes/+page.svelte ---
````svelte
<!-- vibe-player-v2/src/routes/+page.svelte -->
<script lang="ts">
  import { onMount, onDestroy } from 'svelte';
	import { get } from 'svelte/store';
  import { Toaster } from 'svelte-sonner';
	import { RangeSlider } from '@skeletonlabs/skeleton'; // <-- ADD THIS IMPORT

  // Components
  import Controls from '$lib/components/Controls.svelte';
  import FileLoader from '$lib/components/FileLoader.svelte';
  import ToneDisplay from '$lib/components/ToneDisplay.svelte';
  import Waveform from '$lib/components/visualizers/Waveform.svelte';
  import Spectrogram from '$lib/components/visualizers/Spectrogram.svelte';

	// Services and Stores
  import audioEngineService from '$lib/services/audioEngine.service';
  import analysisService from '$lib/services/analysis.service';
  import dtmfService from '$lib/services/dtmf.service';
  import spectrogramService from '$lib/services/spectrogram.service';
  import { VAD_CONSTANTS } from '$lib/utils/constants';
  import { playerStore } from '$lib/stores/player.store';
	import { analysisStore } from '$lib/stores/analysis.store'; // analysisStore is needed
	import { formatTime } from '$lib/utils/formatters'; // <-- ADD THIS IMPORT

	// --- NEW: Function to handle seeking ---
	function handleSeek(event: Event) {
		const target = event.target as HTMLInputElement;
		const time = parseFloat(target.value);
		// --- ADD THIS GUARD ---
		if (!isNaN(time)) {
			audioEngineService.seek(time);
		} else {
			console.warn("handleSeek received a non-numeric value:", target.value);
		}
		// --- END GUARD ---
	}

  onMount(() => {
    // Initialize all services eagerly when the application component mounts.
    // This is the most robust approach to ensure everything is ready.
    console.log('Initializing all services onMount...');

    // Initialize the analysis service, which prepares the SileroVAD worker.
    analysisService.initialize();

    // Initialize the DTMF service and its worker.
    dtmfService.initialize(VAD_CONSTANTS.SAMPLE_RATE);

    // Subscribe to the playerStore to initialize the spectrogram service
    // once an audio file's sample rate is known.
    const unsub = playerStore.subscribe(state => {
      // Initialize the spectrogram service as soon as we have a sample rate.
      // This will happen after the first file is loaded.
      if (state.sampleRate && !get(analysisStore).spectrogramInitialized) {
        console.log(`Initializing spectrogram service with sample rate: ${state.sampleRate}`);
        spectrogramService.initialize({ sampleRate: state.sampleRate });
      }
    });

    // Original keydown handler can remain if needed for global shortcuts
    const handleKeyDown = (event: KeyboardEvent) => {
      if (event.code === 'Space') {
        event.preventDefault();
        // Play/pause logic here if not handled within Controls component
      }
    };

    window.addEventListener('keydown', handleKeyDown);

    // Cleanup function
    return () => {
      console.log('Disposing all services onDestroy...');
      window.removeEventListener('keydown', handleKeyDown);

      // Dispose all services when the component is destroyed.
      audioEngineService.dispose();
      analysisService.dispose();
      dtmfService.dispose();
      spectrogramService.dispose();
      unsub(); // Unsubscribe from the player store
    };
  });
</script>

<Toaster />

<div class="container mx-auto p-4 max-w-4xl">
  <header class="mb-6 text-center">
		<h1 class="text-4xl font-bold text-primary" data-testid="app-bar-title">Vibe Player V2</h1>
    <p class="text-muted-foreground">Experimental Audio Analysis & Playback</p>
  </header>

  <section id="file-loader" class="mb-8 p-6 bg-card rounded-lg shadow">
    <FileLoader />
  </section>

	<section class="mb-8 p-6 bg-card rounded-lg shadow">
		<div class="text-center font-mono text-lg" data-testid="time-display">
			{formatTime($playerStore.currentTime)} / {formatTime($playerStore.duration)}
		</div>
		<RangeSlider
			name="seek"
			bind:value={$playerStore.currentTime}
			max={$playerStore.duration || 1}
			on:input={handleSeek}
			disabled={!$playerStore.isPlayable}
			data-testid="seek-slider-input"
		/>
	</section>

  <section id="controls" class="mb-8 p-6 bg-card rounded-lg shadow">
    <Controls />
  </section>

  <div class="grid grid-cols-1 md:grid-cols-2 gap-8 mb-8">
    <section id="waveform" class="p-6 bg-card rounded-lg shadow">
      <h2 class="text-2xl font-semibold mb-4 text-center text-primary">Waveform</h2>
      <Waveform />
    </section>

    <section id="tone-display" class="p-6 bg-card rounded-lg shadow">
      <h2 class="text-2xl font-semibold mb-4 text-center text-primary">Tone Activity</h2>
      <ToneDisplay />
    </section>
  </div>

  <section id="spectrogram" class="p-6 bg-card rounded-lg shadow">
    <h2 class="text-2xl font-semibold mb-4 text-center text-primary">Spectrogram</h2>
    <Spectrogram />
  </section>

  <footer class="mt-12 text-center text-sm text-muted-foreground">
    <p>Vibe Player V2 written mostly by Gemini and Jules</p>
  </footer>
</div>
````
--- End of File: vibe-player-v2/src/routes/+page.svelte ---
--- File: vibe-player-v2/src/setupTests.ts ---
````typescript
// General setup for Svelte component testing with Vitest and Testing Library
import "@testing-library/svelte/vitest";
import * as matchers from "@testing-library/jest-dom/matchers";
import { expect, vi } from "vitest";

// Extend Vitest's expect with jest-dom matchers
expect.extend(matchers);

// Force $app/environment 'browser' to true
vi.mock("$app/environment", () => ({
  browser: true,
  dev: true,
  building: false,
  version: "test-version",
}));

// Mock window.matchMedia for jsdom environment (used by Skeleton UI)
Object.defineProperty(window, "matchMedia", {
  writable: true,
  value: vi.fn().mockImplementation((query) => ({
    matches: false,
    media: query,
    onchange: null,
    addListener: vi.fn(), // deprecated
    removeListener: vi.fn(), // deprecated
    addEventListener: vi.fn(),
    removeEventListener: vi.fn(),
    dispatchEvent: vi.fn(),
  })),
});

// Mock AudioBuffer for jsdom environment
if (typeof global.AudioBuffer === "undefined") {
  global.AudioBuffer = class AudioBuffer {
    // Add any properties or methods your tests might need
    // For instanceof checks, a class definition is sufficient
    public readonly duration: number = 0;
    public readonly length: number = 0;
    public readonly numberOfChannels: number = 0;
    public readonly sampleRate: number = 0;
    getChannelData(_channel: number): Float32Array {
      return new Float32Array(0);
    }
    copyFromChannel(
      _destination: Float32Array,
      _channelNumber: number,
      _bufferOffset?: number,
    ): void {}
    copyToChannel(
      _source: Float32Array,
      _channelNumber: number,
      _bufferOffset?: number,
    ): void {}
  };
  console.log("Mocked global.AudioBuffer for jsdom.");
}

console.log(
  "Test setup file loaded: @testing-library/svelte/vitest imported, jest-dom matchers extended, $app/environment mocked, and window.matchMedia mocked.",
);

// Mock all @skeletonlabs/skeleton components with a generic one
// IMPORTANT: Adjust the path to Generic.svelte if your __mocks__ directory is elsewhere.
// Assuming Generic.svelte is in src/lib/components/__mocks__/Generic.svelte
// and setupTests.ts is in src/
vi.mock("@skeletonlabs/skeleton", async () => {
  const GenericSvelteMock = await import(
    "./lib/components/__mocks__/Generic.svelte"
  );
  const ButtonMock = await import("./lib/components/__mocks__/Button.svelte");
  const RangeSliderMock = await import(
    "./lib/components/__mocks__/RangeSlider.svelte"
  );
  const ProgressBarMock = await import(
    "./lib/components/__mocks__/ProgressBar.svelte"
  );

  console.log(
    "(setupTests.ts) Loaded specific mocks. GenericSvelteMock.default:",
    GenericSvelteMock.default,
  );

  const specificMocks = {
    Button: ButtonMock.default,
    RangeSlider: RangeSliderMock.default,
    ProgressBar: ProgressBarMock.default,
    storePopup: vi.fn(), // Example utility
  };

  return new Proxy(specificMocks, {
    get: (target, propKey) => {
      const prop = String(propKey);
      if (prop in target) {
        return target[prop];
      }
      // Fallback for any other Svelte component (PascalCase) to GenericSvelteMock
      if (prop[0] >= "A" && prop[0] <= "Z") {
        // console.warn(`(setupTests.ts)   --> Fallback: Returning GenericSvelteMock.default for ${prop}`);
        return GenericSvelteMock.default;
      }
      // console.warn(`(setupTests.ts) Accessing undefined Skeleton export: ${prop}`);
      return undefined; // Or vi.fn() for non-component functions
    },
  });
});

// Add a new console log to confirm this specific mock is applied.
console.log(
  "Global Skeleton mock via specific mocks + Generic fallback is NOW ENABLED.",
);

````
--- End of File: vibe-player-v2/src/setupTests.ts ---
--- File: vibe-player-v2/static/vendor/fft.js ---
````javascript
// --- /vibe-player/lib/fft.js ---
// NOTE: This is 3rd party code (adapted). JSDoc annotations not added here.
"use strict";

// =============================================
// == Fast Fourier Transform (FFT) Library ==
// Based on https://github.com/indutny/fft.js
// Creates a global FFT constructor.
// =============================================

function FFT(size) {
  this.size = size | 0;
  if (this.size <= 1 || (this.size & (this.size - 1)) !== 0)
    throw new Error("FFT size must be a power of two and bigger than 1");

  this._csize = size << 1;

  var table = new Array(this.size * 2);
  for (var i = 0; i < table.length; i += 2) {
    const angle = (Math.PI * i) / this.size;
    table[i] = Math.cos(angle);
    table[i + 1] = -Math.sin(angle);
  }
  this.table = table;

  var power = 0;
  for (var t = 1; this.size > t; t <<= 1) power++;

  this._width = power % 2 === 0 ? power - 1 : power;

  this._bitrev = new Array(1 << this._width);
  for (var j = 0; j < this._bitrev.length; j++) {
    this._bitrev[j] = 0;
    for (var shift = 0; shift < this._width; shift += 2) {
      var revShift = this._width - shift - 2;
      this._bitrev[j] |= ((j >>> shift) & 3) << revShift;
    }
  }

  this._out = null;
  this._data = null;
  this._inv = 0;
}

FFT.prototype.fromComplexArray = function fromComplexArray(complex, storage) {
  var res = storage || new Array(complex.length >>> 1);
  for (var i = 0; i < complex.length; i += 2) res[i >>> 1] = complex[i];
  return res;
};

FFT.prototype.createComplexArray = function createComplexArray() {
  const res = new Array(this._csize);
  for (var i = 0; i < res.length; i++) res[i] = 0;
  return res;
};

FFT.prototype.toComplexArray = function toComplexArray(input, storage) {
  var res = storage || this.createComplexArray();
  for (var i = 0; i < res.length; i += 2) {
    res[i] = input[i >>> 1];
    res[i + 1] = 0;
  }
  return res;
};

FFT.prototype.completeSpectrum = function completeSpectrum(spectrum) {
  var size = this._csize;
  var half = size >>> 1;
  for (var i = 2; i < half; i += 2) {
    spectrum[size - i] = spectrum[i];
    spectrum[size - i + 1] = -spectrum[i + 1];
  }
};

FFT.prototype.transform = function transform(out, data) {
  if (out === data)
    throw new Error("Input and output buffers must be different");
  this._out = out;
  this._data = data;
  this._inv = 0;
  this._transform4();
  this._out = null;
  this._data = null;
};

FFT.prototype.realTransform = function realTransform(out, data) {
  if (out === data)
    throw new Error("Input and output buffers must be different");
  this._out = out;
  this._data = data;
  this._inv = 0;
  this._realTransform4();
  this._out = null;
  this._data = null;
};

FFT.prototype.inverseTransform = function inverseTransform(out, data) {
  if (out === data)
    throw new Error("Input and output buffers must be different");
  this._out = out;
  this._data = data;
  this._inv = 1;
  this._transform4();
  for (var i = 0; i < out.length; i++) out[i] /= this.size;
  this._out = null;
  this._data = null;
};

FFT.prototype._transform4 = function _transform4() {
  var out = this._out,
    size = this._csize,
    width = this._width;
  var step = 1 << width,
    len = (size / step) << 1,
    bitrev = this._bitrev;
  var outOff, t;
  if (len === 4) {
    for (outOff = 0, t = 0; outOff < size; outOff += len, t++)
      this._singleTransform2(outOff, bitrev[t], step);
  } else {
    for (outOff = 0, t = 0; outOff < size; outOff += len, t++)
      this._singleTransform4(outOff, bitrev[t], step);
  }
  var inv = this._inv ? -1 : 1,
    table = this.table;
  for (step >>= 2; step >= 2; step >>= 2) {
    len = (size / step) << 1;
    var quarterLen = len >>> 2;
    for (outOff = 0; outOff < size; outOff += len) {
      var limit = outOff + quarterLen;
      for (var i = outOff, k = 0; i < limit; i += 2, k += step) {
        const A = i,
          B = A + quarterLen,
          C = B + quarterLen,
          D = C + quarterLen;
        const Ar = out[A],
          Ai = out[A + 1],
          Br = out[B],
          Bi = out[B + 1],
          Cr = out[C],
          Ci = out[C + 1],
          Dr = out[D],
          Di = out[D + 1];
        const MAr = Ar,
          MAi = Ai;
        const tableBr = table[k],
          tableBi = inv * table[k + 1];
        const MBr = Br * tableBr - Bi * tableBi,
          MBi = Br * tableBi + Bi * tableBr;
        const tableCr = table[2 * k],
          tableCi = inv * table[2 * k + 1];
        const MCr = Cr * tableCr - Ci * tableCi,
          MCi = Cr * tableCi + Ci * tableCr;
        const tableDr = table[3 * k],
          tableDi = inv * table[3 * k + 1];
        const MDr = Dr * tableDr - Di * tableDi,
          MDi = Dr * tableDi + Di * tableDr;
        const T0r = MAr + MCr,
          T0i = MAi + MCi,
          T1r = MAr - MCr,
          T1i = MAi - MCi;
        const T2r = MBr + MDr,
          T2i = MBi + MDi,
          T3r = inv * (MBr - MDr),
          T3i = inv * (MBi - MDi);
        const FAr = T0r + T2r,
          FAi = T0i + T2i,
          FCr = T0r - T2r,
          FCi = T0i - T2i;
        const FBr = T1r + T3i,
          FBi = T1i - T3r,
          FDr = T1r - T3i,
          FDi = T1i + T3r;
        out[A] = FAr;
        out[A + 1] = FAi;
        out[B] = FBr;
        out[B + 1] = FBi;
        out[C] = FCr;
        out[C + 1] = FCi;
        out[D] = FDr;
        out[D + 1] = FDi;
      }
    }
  }
};
FFT.prototype._singleTransform2 = function _singleTransform2(
  outOff,
  off,
  step,
) {
  const out = this._out,
    data = this._data;
  const evenR = data[off],
    evenI = data[off + 1];
  const oddR = data[off + step],
    oddI = data[off + step + 1];
  const leftR = evenR + oddR,
    leftI = evenI + oddI;
  const rightR = evenR - oddR,
    rightI = evenI - oddI;
  out[outOff] = leftR;
  out[outOff + 1] = leftI;
  out[outOff + 2] = rightR;
  out[outOff + 3] = rightI;
};
FFT.prototype._singleTransform4 = function _singleTransform4(
  outOff,
  off,
  step,
) {
  const out = this._out,
    data = this._data;
  const inv = this._inv ? -1 : 1;
  const step2 = step * 2,
    step3 = step * 3;
  const Ar = data[off],
    Ai = data[off + 1],
    Br = data[off + step],
    Bi = data[off + step + 1],
    Cr = data[off + step2],
    Ci = data[off + step2 + 1],
    Dr = data[off + step3],
    Di = data[off + step3 + 1];
  const T0r = Ar + Cr,
    T0i = Ai + Ci,
    T1r = Ar - Cr,
    T1i = Ai - Ci;
  const T2r = Br + Dr,
    T2i = Bi + Di,
    T3r = inv * (Br - Dr),
    T3i = inv * (Bi - Di);
  const FAr = T0r + T2r,
    FAi = T0i + T2i,
    FBr = T1r + T3i,
    FBi = T1i - T3r;
  const FCr = T0r - T2r,
    FCi = T0i - T2i,
    FDr = T1r - T3i,
    FDi = T1i + T3r;
  out[outOff] = FAr;
  out[outOff + 1] = FAi;
  out[outOff + 2] = FBr;
  out[outOff + 3] = FBi;
  out[outOff + 4] = FCr;
  out[outOff + 5] = FCi;
  out[outOff + 6] = FDr;
  out[outOff + 7] = FDi;
};
FFT.prototype._realTransform4 = function _realTransform4() {
  var out = this._out,
    size = this._csize,
    width = this._width;
  var step = 1 << width,
    len = (size / step) << 1,
    bitrev = this._bitrev;
  var outOff, t;
  if (len === 4) {
    for (outOff = 0, t = 0; outOff < size; outOff += len, t++)
      this._singleRealTransform2(outOff, bitrev[t] >>> 1, step >>> 1);
  } else {
    for (outOff = 0, t = 0; outOff < size; outOff += len, t++)
      this._singleRealTransform4(outOff, bitrev[t] >>> 1, step >>> 1);
  }
  var inv = this._inv ? -1 : 1,
    table = this.table;
  for (step >>= 2; step >= 2; step >>= 2) {
    len = (size / step) << 1;
    var halfLen = len >>> 1,
      quarterLen = halfLen >>> 1,
      hquarterLen = quarterLen >>> 1;
    for (outOff = 0; outOff < size; outOff += len) {
      for (var i = 0, k = 0; i <= hquarterLen; i += 2, k += step) {
        var A = outOff + i,
          B = A + quarterLen,
          C = B + quarterLen,
          D = C + quarterLen;
        var Ar = out[A],
          Ai = out[A + 1],
          Br = out[B],
          Bi = out[B + 1],
          Cr = out[C],
          Ci = out[C + 1],
          Dr = out[D],
          Di = out[D + 1];
        var MAr = Ar,
          MAi = Ai;
        var tableBr = table[k],
          tableBi = inv * table[k + 1];
        var MBr = Br * tableBr - Bi * tableBi,
          MBi = Br * tableBi + Bi * tableBr;
        var tableCr = table[2 * k],
          tableCi = inv * table[2 * k + 1];
        var MCr = Cr * tableCr - Ci * tableCi,
          MCi = Cr * tableCi + Ci * tableCr;
        var tableDr = table[3 * k],
          tableDi = inv * table[3 * k + 1];
        var MDr = Dr * tableDr - Di * tableDi,
          MDi = Dr * tableDi + Di * tableDr;
        var T0r = MAr + MCr,
          T0i = MAi + MCi,
          T1r = MAr - MCr,
          T1i = MAi - MCi;
        var T2r = MBr + MDr,
          T2i = MBi + MDi,
          T3r = inv * (MBr - MDr),
          T3i = inv * (MBi - MDi);
        var FAr = T0r + T2r,
          FAi = T0i + T2i,
          FBr = T1r + T3i,
          FBi = T1i - T3r;
        out[A] = FAr;
        out[A + 1] = FAi;
        out[B] = FBr;
        out[B + 1] = FBi;
        if (i === 0) {
          var FCr = T0r - T2r,
            FCi = T0i - T2i;
          out[C] = FCr;
          out[C + 1] = FCi;
          continue;
        }
        if (i === hquarterLen) continue;
        var ST0r = T1r,
          ST0i = -T1i,
          ST1r = T0r,
          ST1i = -T0i;
        var ST2r = -inv * T3i,
          ST2i = -inv * T3r,
          ST3r = -inv * T2i,
          ST3i = -inv * T2r;
        var SFAr = ST0r + ST2r,
          SFAi = ST0i + ST2i,
          SFBr = ST1r + ST3i,
          SFBi = ST1i - ST3r;
        var SA = outOff + quarterLen - i,
          SB = outOff + halfLen - i;
        out[SA] = SFAr;
        out[SA + 1] = SFAi;
        out[SB] = SFBr;
        out[SB + 1] = SFBi;
      }
    }
  }
};
FFT.prototype._singleRealTransform2 = function _singleRealTransform2(
  outOff,
  off,
  step,
) {
  const out = this._out,
    data = this._data;
  const evenR = data[off],
    oddR = data[off + step];
  const leftR = evenR + oddR,
    rightR = evenR - oddR;
  out[outOff] = leftR;
  out[outOff + 1] = 0;
  out[outOff + 2] = rightR;
  out[outOff + 3] = 0;
};
FFT.prototype._singleRealTransform4 = function _singleRealTransform4(
  outOff,
  off,
  step,
) {
  const out = this._out,
    data = this._data;
  const inv = this._inv ? -1 : 1;
  const step2 = step * 2,
    step3 = step * 3;
  const Ar = data[off],
    Br = data[off + step],
    Cr = data[off + step2],
    Dr = data[off + step3];
  const T0r = Ar + Cr,
    T1r = Ar - Cr,
    T2r = Br + Dr,
    T3r = inv * (Br - Dr);
  const FAr = T0r + T2r,
    FBr = T1r,
    FBi = -T3r,
    FCr = T0r - T2r,
    FDr = T1r,
    FDi = T3r;
  out[outOff] = FAr;
  out[outOff + 1] = 0;
  out[outOff + 2] = FBr;
  out[outOff + 3] = FBi;
  out[outOff + 4] = FCr;
  out[outOff + 5] = 0;
  out[outOff + 6] = FDr;
  out[outOff + 7] = FDi;
};

````
--- End of File: vibe-player-v2/static/vendor/fft.js ---
--- File: vibe-player-v2/static/vendor/rubberband/rubberband-loader.js ---
````javascript
// --- START OF FILE rubberband.js (Self-Contained Loader + Options) ---

// ** MODIFIED Emscripten Loader for AudioWorklet **
// Original source: Emscripten-generated loader for Rubberband library (@echogarden)
// Modifications:
// - Removed Node.js support, file loading, script path detection.
// - Executes via new Function(), expects WASM binary via moduleArg.wasmBinary.
// - Expects instantiation hook via moduleArg.instantiateWasm.
// - Includes RubberBandOptionFlag constants directly on the resolved Module object.
// - Removed 'export default'.
// - Structure adjusted to return the async loader function, not invoke it immediately.

var Rubberband = (() => {
  // Outer IIFE defines Rubberband scope

  // This async function is what the outer IIFE will return
  return async function (moduleArg = {}) {
    // Accepts { wasmBinary, instantiateWasm, ... }
    var Module = moduleArg; // Use the provided argument object directly
    var moduleRtn;

    // --- Promise for readiness ---
    var readyPromiseResolve, readyPromiseReject;
    var readyPromise = new Promise((resolve, reject) => {
      readyPromiseResolve = resolve;
      readyPromiseReject = reject;
    });

    // --- Basic Environment (Assume Worker/Worklet like) ---
    var out = Module["print"] || console.log.bind(console);
    var err = Module["printErr"] || console.error.bind(console);

    // --- State ---
    var wasmMemory;
    var ABORT = false;
    var runtimeInitialized = false;
    var HEAP8, HEAPU8, HEAP16, HEAPU16, HEAP32, HEAPU32, HEAPF32, HEAPF64;

    function updateMemoryViews() {
      if (!wasmMemory) return; // Prevent errors if called too early
      var b = wasmMemory.buffer;
      Module["HEAP8"] = HEAP8 = new Int8Array(b);
      Module["HEAP16"] = HEAP16 = new Int16Array(b);
      Module["HEAPU8"] = HEAPU8 = new Uint8Array(b);
      Module["HEAPU16"] = HEAPU16 = new Uint16Array(b);
      Module["HEAP32"] = HEAP32 = new Int32Array(b);
      Module["HEAPU32"] = HEAPU32 = new Uint32Array(b);
      Module["HEAPF32"] = HEAPF32 = new Float32Array(b);
      Module["HEAPF64"] = HEAPF64 = new Float64Array(b);
    }

    // --- Lifecycle Callbacks ---
    var __ATINIT__ = [];
    var __ATPOSTRUN__ = [];

    function addOnInit(cb) {
      __ATINIT__.unshift(cb);
    }

    function addOnPostRun(cb) {
      __ATPOSTRUN__.unshift(cb);
    }

    function callRuntimeCallbacks(callbacks) {
      callbacks.forEach((f) => f(Module));
    }

    // --- Dependency Tracking (Simplified) ---
    var runDependencies = 0;
    var dependenciesFulfilled = null;

    function addRunDependency(id) {
      runDependencies++;
    }

    function removeRunDependency(id) {
      runDependencies--;
      if (runDependencies == 0 && dependenciesFulfilled) {
        var callback = dependenciesFulfilled;
        dependenciesFulfilled = null;
        callback();
      }
    }

    // --- Abort ---
    function abort(what) {
      Module["onAbort"]?.(what);
      what = "Aborted(" + what + ")";
      err(what);
      ABORT = true;
      var e = new WebAssembly.RuntimeError(what);
      readyPromiseReject(e);
      throw e;
    }

    // --- WASM Instantiation ---
    var wasmExports;

    function createWasm() {
      // NOTE: 'a' is the expected import object name, 'n' is memory, 'o' is init func.
      // These might change if rubberband.wasm is rebuilt with different settings.
      var info = { a: wasmImports };

      function receiveInstance(instance, module) {
        wasmExports = instance.exports;
        wasmMemory = wasmExports["n"]; // Hardcoded memory export name
        updateMemoryViews();
        addOnInit(wasmExports["o"]); // Hardcoded init function export name
        removeRunDependency("wasm-instantiate");
        return wasmExports;
      }

      addRunDependency("wasm-instantiate");

      if (Module["instantiateWasm"]) {
        try {
          var exports = Module["instantiateWasm"](info, receiveInstance);
          // Handle potential sync return (less likely for WASM)
          if (exports instanceof WebAssembly.Instance) {
            receiveInstance(exports);
          }
        } catch (e) {
          err(`Module.instantiateWasm callback failed with error: ${e}`);
          readyPromiseReject(e);
        }
      } else {
        var missingHookError = new Error(
          "Fatal error: 'instantiateWasm' hook not provided to the WASM loader module.",
        );
        err(missingHookError.message);
        readyPromiseReject(missingHookError);
        return {};
      }
      return {}; // Required for async preparation
    }

    // --- Minimal Stubs needed *before* assignExports/runtime ---
    // Need a *basic* UTF8ToString for error reporting during init
    const _UTF8ToString_stub = (ptr) => {
      if (!ptr || !HEAPU8) return "";
      let str = "";
      let i = ptr;
      while (HEAPU8[i] && i < ptr + 1024) {
        // Limit length for safety
        str += String.fromCharCode(HEAPU8[i++]);
      }
      return str;
    };
    const ___assert_fail = (condition, filename, line, func) => {
      abort(`Assertion failed: ${_UTF8ToString_stub(condition)}`);
    };
    const ___cxa_throw = (ptr, type, destructor) => {
      abort(`Exception thrown from WASM: ptr=${ptr} type=${type}`);
    };
    const __abort_js = () => {
      abort("");
    };
    const __emscripten_memcpy_js = (dest, src, num) =>
      HEAPU8?.copyWithin(dest, src, src + num); // Check HEAPU8 exists
    const _emscripten_date_now = () => Date.now();
    const _emscripten_resize_heap = (requestedSize) => {
      err("_emscripten_resize_heap called - Not implemented.");
      return false;
    };
    const _environ_get = (__environ, environ_buf) => 0;
    const _environ_sizes_get = (penviron_count, penviron_buf_size) => {
      HEAPU32[penviron_count >> 2] = 0;
      HEAPU32[penviron_buf_size >> 2] = 0;
      return 0;
    };
    const __tzset_js = () => {};
    const _fd_close = (fd) => 0;
    const _fd_read = (fd, iov, iovcnt, pnum) => {
      HEAPU32[pnum >> 2] = 0;
      return 0;
    };
    const _fd_seek = (fd, offset_low, offset_high, whence, newOffset) => {
      HEAP32[newOffset >> 2] = 0;
      HEAP32[(newOffset + 4) >> 2] = 0;
      return 0;
    };
    const _fd_write = (fd, iov, iovcnt, pnum) => {
      // Basic logging stub
      let num = 0;
      try {
        for (let i = 0; i < iovcnt; i++) {
          let ptr = HEAPU32[iov >> 2];
          let len = HEAPU32[(iov + 4) >> 2];
          iov += 8;
          let str = _UTF8ToString_stub(ptr); /* Basic ASCII ok for debug */
          if (fd === 1) out(str);
          else err(str);
          num += len;
        }
        HEAPU32[pnum >> 2] = num;
      } catch (e) {
        /* ignore errors during logging */
      }
      return 0;
    };

    // --- Stack variables (will be assigned in assignExports) ---
    var stackSave,
      stackRestore,
      stackAlloc,
      __emscripten_stack_alloc,
      __emscripten_stack_restore,
      _emscripten_stack_get_current;

    // --- WASM Imports Object ---
    // These keys ('a', 'b', 'c'...) MUST match what rubberband.wasm expects.
    var wasmImports = {
      b: ___assert_fail,
      a: ___cxa_throw,
      j: __abort_js,
      i: __emscripten_memcpy_js,
      l: __tzset_js,
      h: _emscripten_date_now,
      e: _emscripten_resize_heap,
      m: _environ_get,
      d: _environ_sizes_get,
      f: _fd_close,
      g: _fd_read,
      k: _fd_seek,
      c: _fd_write,
      // Add other imports if rubberband.wasm requires them (check browser console errors)
    };

    // --- Runtime Initialization ---
    function initRuntime() {
      runtimeInitialized = true;
      callRuntimeCallbacks(__ATINIT__);
    }

    function postRun() {
      callRuntimeCallbacks(__ATPOSTRUN__);
    }

    // --- Main Execution Logic ---
    var calledRun;
    dependenciesFulfilled = function runCaller() {
      if (!calledRun) run();
      if (!calledRun) dependenciesFulfilled = runCaller;
    };

    function run() {
      if (runDependencies > 0) return; // Wait for WASM etc.
      // No preRun needed unless user adds callbacks
      if (calledRun) return;
      calledRun = true;
      Module["calledRun"] = true;
      if (ABORT) return;
      initRuntime(); // Calls __ATINIT__ (which includes assignExports)
      readyPromiseResolve(Module); // Resolve the main promise HERE
      Module["onRuntimeInitialized"]?.();
      postRun();
    }

    // --- assignExports Function (Called via __ATINIT__) ---
    function assignExports() {
      if (!wasmExports) {
        console.error("WASM Exports not available during assignExports!");
        abort("WASM exports missing");
        return;
      }

      // Define helpers *locally* within this scope
      updateMemoryViews(); // Ensure HEAP views are ready

      const getValue = (ptr, type = "i8") => {
        /* ... as in previous correct version ... */
        if (!HEAPU8) return 0;
        if (type.endsWith("*")) type = "*";
        switch (type) {
          case "i1":
            return HEAP8[ptr];
          case "i8":
            return HEAP8[ptr];
          case "i16":
            return HEAP16[ptr >> 1];
          case "i32":
            return HEAP32[ptr >> 2];
          case "i64":
            abort("getValue(i64)");
            return 0;
          case "float":
            return HEAPF32[ptr >> 2];
          case "double":
            return HEAPF64[ptr >> 3];
          case "*":
            return HEAPU32[ptr >> 2];
          default:
            abort(`invalid type for getValue: ${type}`);
            return 0;
        }
      };
      const setValue = (ptr, value, type = "i8") => {
        /* ... as in previous correct version ... */
        if (!HEAPU8) return;
        if (type.endsWith("*")) type = "*";
        switch (type) {
          case "i1":
            HEAP8[ptr] = value;
            break;
          case "i8":
            HEAP8[ptr] = value;
            break;
          case "i16":
            HEAP16[ptr >> 1] = value;
            break;
          case "i32":
            HEAP32[ptr >> 2] = value;
            break;
          case "i64":
            abort("setValue(i64)");
            break;
          case "float":
            HEAPF32[ptr >> 2] = value;
            break;
          case "double":
            HEAPF64[ptr >> 3] = value;
            break;
          case "*":
            HEAPU32[ptr >> 2] = value;
            break;
          default:
            abort(`invalid type for setValue: ${type}`);
        }
      };
      const UTF8Decoder =
        typeof TextDecoder != "undefined" ? new TextDecoder("utf8") : undefined;
      const UTF8ArrayToString = (
        heapOrArray,
        idx = 0,
        maxBytesToRead = Infinity,
      ) => {
        /* ... as in previous correct version ... */
        var endIdx = Math.min(idx + maxBytesToRead, heapOrArray.length);
        var endPtr = idx;
        while (heapOrArray[endPtr] && endPtr < endIdx) ++endPtr;
        if (endPtr - idx > 16 && heapOrArray.buffer && UTF8Decoder) {
          return UTF8Decoder.decode(heapOrArray.subarray(idx, endPtr));
        } else {
          var str = "";
          while (idx < endPtr) {
            var u0 = heapOrArray[idx++];
            if (!(u0 & 128)) {
              str += String.fromCharCode(u0);
              continue;
            }
            var u1 = heapOrArray[idx++] & 63;
            if ((u0 & 224) == 192) {
              str += String.fromCharCode(((u0 & 31) << 6) | u1);
              continue;
            }
            var u2 = heapOrArray[idx++] & 63;
            if ((u0 & 240) == 224) {
              u0 = ((u0 & 15) << 12) | (u1 << 6) | u2;
            } else {
              u0 =
                ((u0 & 7) << 18) |
                (u1 << 12) |
                (u2 << 6) |
                (heapOrArray[idx++] & 63);
            }
            if (u0 < 0x10000) {
              str += String.fromCharCode(u0);
            } else {
              var ch = u0 - 0x10000;
              str += String.fromCharCode(
                0xd800 | (ch >> 10),
                0xdc00 | (ch & 0x3ff),
              );
            }
          }
          return str;
        }
      };
      const UTF8ToString = (ptr, maxBytesToRead) =>
        ptr ? UTF8ArrayToString(HEAPU8, ptr, maxBytesToRead) : "";
      const stringToUTF8Array = (str, heap, outIdx, maxBytesToWrite) => {
        /* ... as in previous correct version ... */
        if (!(maxBytesToWrite > 0)) return 0;
        var startIdx = outIdx;
        var endIdx = outIdx + maxBytesToWrite - 1;
        for (var i = 0; i < str.length; ++i) {
          var u = str.charCodeAt(i);
          if (u >= 0xd800 && u <= 0xdfff) {
            var u1 = str.charCodeAt(++i);
            u = (0x10000 + ((u & 0x3ff) << 10)) | (u1 & 0x3ff);
          }
          if (u <= 0x7f) {
            if (outIdx >= endIdx) break;
            heap[outIdx++] = u;
          } else if (u <= 0x7ff) {
            if (outIdx + 1 >= endIdx) break;
            heap[outIdx++] = 0xc0 | (u >> 6);
            heap[outIdx++] = 0x80 | (u & 63);
          } else if (u <= 0xffff) {
            if (outIdx + 2 >= endIdx) break;
            heap[outIdx++] = 0xe0 | (u >> 12);
            heap[outIdx++] = 0x80 | ((u >> 6) & 63);
            heap[outIdx++] = 0x80 | (u & 63);
          } else {
            if (outIdx + 3 >= endIdx) break;
            heap[outIdx++] = 0xf0 | (u >> 18);
            heap[outIdx++] = 0x80 | ((u >> 12) & 63);
            heap[outIdx++] = 0x80 | ((u >> 6) & 63);
            heap[outIdx++] = 0x80 | (u & 63);
          }
        }
        heap[outIdx] = 0;
        return outIdx - startIdx;
      };
      const stringToUTF8 = (str, outPtr, maxBytesToWrite) =>
        stringToUTF8Array(str, HEAPU8, outPtr, maxBytesToWrite);
      const lengthBytesUTF8 = (str) => {
        /* ... as in previous correct version ... */
        let len = 0;
        for (let i = 0; i < str.length; ++i) {
          let c = str.charCodeAt(i);
          if (c <= 0x7f) {
            len++;
          } else if (c <= 0x7ff) {
            len += 2;
          } else if (c >= 0xd800 && c <= 0xdfff) {
            len += 4;
            ++i;
          } else {
            len += 3;
          }
        }
        return len;
      };

      // Assign mapped WASM functions to Module object
      // Using the export names ('q', 'r', etc.) presumed from previous attempts
      Module["_free"] = wasmExports["q"];
      Module["_malloc"] = wasmExports["V"];
      Module["_rubberband_new"] = wasmExports["r"];
      Module["_rubberband_delete"] = wasmExports["s"];
      Module["_rubberband_reset"] = wasmExports["t"];
      Module["_rubberband_get_engine_version"] = wasmExports["u"];
      Module["_rubberband_set_time_ratio"] = wasmExports["v"];
      Module["_rubberband_set_pitch_scale"] = wasmExports["w"];
      Module["_rubberband_get_time_ratio"] = wasmExports["x"];
      Module["_rubberband_get_pitch_scale"] = wasmExports["y"];
      Module["_rubberband_set_formant_scale"] = wasmExports["z"];
      Module["_rubberband_get_formant_scale"] = wasmExports["A"];
      Module["_rubberband_get_preferred_start_pad"] = wasmExports["B"];
      Module["_rubberband_get_start_delay"] = wasmExports["C"];
      Module["_rubberband_get_latency"] = wasmExports["D"];
      Module["_rubberband_set_transients_option"] = wasmExports["E"];
      Module["_rubberband_set_detector_option"] = wasmExports["F"];
      Module["_rubberband_set_phase_option"] = wasmExports["G"];
      Module["_rubberband_set_formant_option"] = wasmExports["H"];
      Module["_rubberband_set_pitch_option"] = wasmExports["I"];
      Module["_rubberband_set_expected_input_duration"] = wasmExports["J"];
      Module["_rubberband_get_samples_required"] = wasmExports["K"];
      Module["_rubberband_set_max_process_size"] = wasmExports["L"];
      Module["_rubberband_set_key_frame_map"] = wasmExports["M"];
      Module["_rubberband_study"] = wasmExports["N"];
      Module["_rubberband_process"] = wasmExports["O"];
      Module["_rubberband_available"] = wasmExports["P"];
      Module["_rubberband_retrieve"] = wasmExports["Q"];
      Module["_rubberband_get_channel_count"] = wasmExports["R"];
      Module["_rubberband_calculate_stretch"] = wasmExports["S"];
      Module["_rubberband_set_debug_level"] = wasmExports["T"];
      Module["_rubberband_set_default_debug_level"] = wasmExports["U"];

      // Assign Stack functions (CRITICAL)
      __emscripten_stack_alloc = wasmExports["X"];
      __emscripten_stack_restore = wasmExports["W"];
      _emscripten_stack_get_current = wasmExports["Y"];
      stackSave = _emscripten_stack_get_current;
      stackRestore = __emscripten_stack_restore;
      stackAlloc = __emscripten_stack_alloc;
      Module["stackSave"] = stackSave;
      Module["stackRestore"] = stackRestore;
      Module["stackAlloc"] = stackAlloc;

      // Assign locally defined helpers to Module object
      Module["getValue"] = getValue;
      Module["setValue"] = setValue;
      Module["UTF8ToString"] = UTF8ToString;
      Module["stringToUTF8"] = stringToUTF8;
      Module["lengthBytesUTF8"] = lengthBytesUTF8;

      // *** ADD RUBBERBAND OPTIONS FLAGS ***
      Module.RubberBandOptionFlag = {
        ProcessOffline: 0x00000000,
        ProcessRealTime: 0x00000001,
        StretchElastic: 0x00000000,
        StretchPrecise: 0x00000010,
        TransientsCrisp: 0x00000000,
        TransientsMixed: 0x00000100,
        TransientsSmooth: 0x00000200,
        DetectorCompound: 0x00000000,
        DetectorPercussive: 0x00000400,
        DetectorSoft: 0x00000800,
        PhaseLaminar: 0x00000000,
        PhaseIndependent: 0x00002000,
        ThreadingAuto: 0x00000000,
        ThreadingNever: 0x00010000,
        ThreadingAlways: 0x00020000,
        WindowStandard: 0x00000000,
        WindowShort: 0x00100000,
        WindowLong: 0x00200000,
        SmoothingOff: 0x00000000,
        SmoothingOn: 0x00800000,
        FormantShifted: 0x00000000,
        FormantPreserved: 0x01000000,
        PitchHighSpeed: 0x00000000,
        PitchHighQuality: 0x02000000,
        PitchHighConsistency: 0x04000000,
        ChannelsApart: 0x00000000,
        ChannelsTogether: 0x10000000,
        EngineFaster: 0x00000000,
        EngineFiner: 0x20000000,
        // Add presets too if desired
        // DefaultOptions: 0x00000000, PercussiveOptions: 0x00102000,
        // Convenience aliases from your example (might be slightly different from direct enum names)
        EngineDefault: 0, // Alias for EngineFaster
        // PitchHighQuality: 0x02000000, // Already defined above
      };
      // Make sure the specific options used in the processor are available
      // These are just copies/aliases for clarity if the names differ slightly.
      Module.RubberbandOptions = Module.RubberBandOptionFlag; // Alias the whole object
    } // End assignExports

    // --- Start the process ---
    addOnInit(assignExports); // Queue exports assignment
    createWasm(); // Start WASM loading (async)

    moduleRtn = readyPromise;
    return moduleRtn; // Return the promise that resolves with the Module object
  }; // <--- Inner async function is RETURNED, not invoked here
})(); // Outer IIFE is invoked immediately

// NO export default
// --- END OF FILE rubberband.js ---

````
--- End of File: vibe-player-v2/static/vendor/rubberband/rubberband-loader.js ---
--- File: vibe-player-v2/svelte.config.js ---
````javascript
import adapter from "@sveltejs/adapter-static";
import { vitePreprocess } from "@sveltejs/vite-plugin-svelte";

/** @type {import('@sveltejs/kit').Config} */
const config = {
  // Consult https://svelte.dev/docs/kit/integrations
  // for more information about preprocessors
  preprocess: vitePreprocess(),

  kit: {
    adapter: adapter({
      pages: "build",
      assets: "build",
      fallback: "index.html", // or 'index.html' or null if you have specific needs
      precompress: false,
      strict: true,
    }),
  },
};

export default config;

````
--- End of File: vibe-player-v2/svelte.config.js ---
--- File: vibe-player-v2/tailwind.config.ts ---
````typescript
import type { Config } from "tailwindcss";

export default {
  content: ["./src/**/*.{html,js,svelte,ts}"],

  theme: {
    extend: {},
  },

  plugins: [],
} as Config;

````
--- End of File: vibe-player-v2/tailwind.config.ts ---
--- File: vibe-player-v2/tests-e2e/00-load.e2e.spec.js ---
````javascript
// tests-e2e/00-load.e2e.spec.js
import { test, expect } from "@playwright/test";
import { PlayerPage } from "./PlayerPage.mjs";

/**
 * This is a foundational "smoke test". Its only purpose is to ensure the SvelteKit
 * application can build, start, and render its initial state without crashing.
 * If this test fails, it points to a critical problem in the application's
 * `onMount` lifecycle or initial component rendering.
 */
test.describe("Application Startup Smoke Test", () => {
  let playerPage;

  test.beforeEach(async ({ page }) => {
    // Set up a console listener to catch any critical errors during page load.
    page.on("console", (msg) => {
      if (msg.type() === "error") {
        console.error(`[Smoke Test Browser Console ERROR] ${msg.text()}`);
      }
    });
    playerPage = new PlayerPage(page);
  });

  test("should load the main page and display initial UI components", async () => {
    // 1. Navigate to the root of the application.
    await playerPage.goto();

    // 2. Assert that the main header is visible. This is a basic check that the
    //    Svelte layout has rendered. The timeout is generous for CI environments.
    await expect(playerPage.appBarTitle).toBeVisible({ timeout: 15000 });
    await expect(playerPage.appBarTitle).toHaveText("Vibe Player V2");

    // 3. Assert that the FileLoader component has rendered and its primary
    //    interactive element (the file input) is visible.
    await expect(playerPage.fileInput).toBeVisible();

    // 4. Assert that the Controls component has rendered. A good check for this
    //    is to ensure the play button is visible, and critically, that it is
    //    *disabled* in its initial state before any file is loaded.
    await expect(playerPage.playButton).toBeVisible();
    await expect(playerPage.playButton).toBeDisabled();
  });
});

````
--- End of File: vibe-player-v2/tests-e2e/00-load.e2e.spec.js ---
--- File: vibe-player-v2/tests-e2e/player.e2e.spec.js ---
````javascript
// tests-e2e/player.e2e.spec.js
import { test, expect } from "@playwright/test";
import { PlayerPage } from "./PlayerPage.mjs";

function parseTimeToSeconds(timeStr) {
  if (!timeStr || !timeStr.includes(":") || timeStr.includes("NaN")) return 0;
  const parts = timeStr.split(":");
  return parseInt(parts[0], 10) * 60 + parseInt(parts[1], 10);
}

// UPDATED: Paths are now relative to the server root, as they are in the static dir.
const TEST_AUDIO_FILE = "test-audio/C.Noisy_Voice.wav";
const DTMF_TEST_AUDIO_FILE = "test-audio/dtmf-123A456B789C(star)0(hex)D.mp3";

test.describe("Vibe Player V2 E2E", () => {
  let playerPage;

  test.beforeEach(async ({ page }) => {
    page.on("console", (msg) => {
      const text = msg.text();
      if (msg.type() === "error") {
        console.error(`[Browser Console ERROR] ${text}`);
        // Detect critical VAD/WASM errors and fail the test immediately
        if (
          text.includes("VAD error") ||
          text.includes("WASM error") ||
          text.includes("WebAssembly")
        ) {
          test.fail(
            true,
            `Critical VAD/WASM error detected in browser console: ${text}`,
          );
        }
      }
    });
    playerPage = new PlayerPage(page);
    await playerPage.goto();
  });

  test("should load an audio file and enable playback controls", async ({
    page,
  }) => {
    await playerPage.loadAudioFile(TEST_AUDIO_FILE);
    await playerPage.expectControlsToBeReadyForPlayback();
  });

  test('should display initial time as "0:00 / 0:00" or similar', async () => {
    await playerPage.loadAudioFile(TEST_AUDIO_FILE);
    await playerPage.expectControlsToBeReadyForPlayback();
    await expect(playerPage.timeDisplay).toHaveText(/0:00 \/ [0-9]+:[0-9]{2}/, {
      timeout: 5000,
    });
  });

  test("should play and pause audio", async ({ page }) => {
    await playerPage.loadAudioFile(TEST_AUDIO_FILE);
    await playerPage.expectControlsToBeReadyForPlayback();

    await expect(await playerPage.getPlayButtonText()).toMatch(/Play/i);

    await playerPage.playButton.click();
    await expect(await playerPage.getPlayButtonText()).toMatch(/Pause/i, {
      timeout: 2000,
    });

    // --- FIX: Replace waitForFunction with a robust auto-retrying expect ---
    await expect(
      playerPage.timeDisplay,
      "Playback did not start and time did not advance",
    ).not.toHaveText(/^0:00 \//, { timeout: 10000 });

    await playerPage.playButton.click();
    await expect(await playerPage.getPlayButtonText()).toMatch(/Play/i);
    const timeAfterPause = await playerPage.timeDisplay.textContent();
    await page.waitForTimeout(500);
    const timeAfterPauseAndDelay = await playerPage.timeDisplay.textContent();
    expect(timeAfterPauseAndDelay).toBe(timeAfterPause);
  });

  test("should seek audio using the seek bar", async ({ page }) => {
    await playerPage.loadAudioFile(TEST_AUDIO_FILE);
    await playerPage.expectControlsToBeReadyForPlayback();
    await playerPage.playButton.click();

    await page.waitForFunction(
      () =>
        document.querySelector('[data-testid="time-display"]')?.textContent !==
        "0:00 / 0:00",
      null,
      { timeout: 5000 },
    );

    const initialTimeText = await playerPage.timeDisplay.textContent();
    const durationSeconds = parseTimeToSeconds(initialTimeText.split(" / ")[1]);
    expect(durationSeconds).toBeGreaterThan(0);

    const currentMax =
      parseFloat(await playerPage.seekSliderInput.getAttribute("max")) ||
      durationSeconds;
    await playerPage.setSliderValue(
      playerPage.seekSliderInput,
      String(currentMax / 2),
    );

    await page.waitForTimeout(500);

    const timeAfterSeekText = await playerPage.timeDisplay.textContent();
    const currentTimeAfterSeek = parseTimeToSeconds(
      timeAfterSeekText.split(" / ")[0],
    );
    const durationAfterSeek = parseTimeToSeconds(
      timeAfterSeekText.split(" / ")[1],
    );

    expect(currentTimeAfterSeek).toBeGreaterThanOrEqual(
      durationAfterSeek * 0.4,
    );
    expect(currentTimeAfterSeek).toBeLessThanOrEqual(durationAfterSeek * 0.6);
    expect(await playerPage.getPlayButtonText()).toMatch(/Pause/i);
  });

  test("should detect and display DTMF tones", async ({ page }) => {
    await playerPage.loadAudioFile(DTMF_TEST_AUDIO_FILE);
    await playerPage.expectControlsToBeReadyForPlayback();

    const expectedDtmfSequence = "1 2 3 A 4 5 6 B 7 8 9 C * 0 # D";

    // --- FIX: Use the new robust locator and auto-retrying expect ---
    await expect(playerPage.dtmfDisplay).toHaveText(expectedDtmfSequence, {
      timeout: 15000,
    });
  });

  test.describe("URL State Serialization", () => {
    test("should update URL when settings change", async ({ page }) => {
      await playerPage.loadAudioFile(TEST_AUDIO_FILE);
      await playerPage.expectControlsToBeReadyForPlayback();

      await playerPage.setSliderValue(playerPage.speedSliderInput, "1.5");
      // --- FIX: Wait for the debounced function to execute ---
      await page.waitForURL("**/*speed=1.50", { timeout: 2000 });
      await expect(page).toHaveURL(/speed=1.50/); // Keep this assertion

      await playerPage.setSliderValue(playerPage.pitchSliderInput, "2");
      // --- FIX: Wait for the next change ---
      await page.waitForURL("**/*pitch=2.0", { timeout: 2000 });
      await expect(page).toHaveURL(/pitch=2.0/, { timeout: 2000 }); // It's fine to re-assert
      await expect(page).toHaveURL(/speed=1.50/); // Ensure previous param is still there
    });

    test("should load settings from URL parameters on page load", async ({
      page,
    }) => {
      await playerPage.page.goto(
        playerPage.devServerUrl + "?speed=1.75&pitch=-3",
      );
      await expect(playerPage.appBarTitle).toHaveText("Vibe Player V2", {
        timeout: 15000,
      });
      await expect(playerPage.fileInput).toBeVisible({ timeout: 10000 });

      await playerPage.loadAudioFile(TEST_AUDIO_FILE);
      await playerPage.expectControlsToBeReadyForPlayback();

      await expect(playerPage.speedSliderInput).toHaveValue("1.75", {
        timeout: 2000,
      });
      await expect(playerPage.pitchSliderInput).toHaveValue("-3", {
        timeout: 2000,
      });
    });
  });
});

````
--- End of File: vibe-player-v2/tests-e2e/player.e2e.spec.js ---
--- File: vibe-player-v2/tests-e2e/PlayerPage.mjs ---
````mjs
// tests-e2e/PlayerPage.mjs
import { expect } from "@playwright/test";

export class PlayerPage {
  constructor(page) {
    this.page = page;
    this.devServerUrl = "http://localhost:4173/";
    this.appBarTitle = page.getByTestId("app-bar-title");
    this.fileInput = page.locator('input[type="file"]');
    this.fileNameDisplay = page.getByTestId("file-name-display");
    this.fileStatusDisplay = page.getByTestId("file-status-display");
    this.fileErrorDisplay = page.getByTestId("file-error-display");
    this.playButton = page.getByTestId("play-button");
    this.stopButton = page.getByTestId("stop-button");
    this.timeDisplay = page.getByTestId("time-display");
    this.seekSliderInput = page.getByTestId("seek-slider-input");
    this.speedSliderInput = page.getByTestId("speed-slider-input");
    this.speedValueDisplay = page.getByTestId("speed-value");
    this.pitchSliderInput = page.getByTestId("pitch-slider-input");
    this.pitchValueDisplay = page.getByTestId("pitch-value");
    this.gainSliderInput = page.getByTestId("gain-slider-input");
    this.gainValueDisplay = page.getByTestId("gain-value");
    this.vadPositiveSliderInput = page.getByTestId("vad-positive-slider-input");
    this.vadPositiveValueDisplay = page.getByTestId("vad-positive-value");
    this.vadNegativeSliderInput = page.getByTestId("vad-negative-slider-input");
    this.vadNegativeValueDisplay = page.getByTestId("vad-negative-value");
    this.dtmfDisplay = page.getByTestId("dtmf-display");
  }

  async goto() {
    await this.page.goto(this.devServerUrl);
    await expect(this.appBarTitle).toHaveText("Vibe Player V2", {
      timeout: 15000,
    });
    await expect(this.fileInput).toBeVisible({ timeout: 10000 });
  }

  async loadAudioFile(fileName) {
    // --- THE FIX ---
    // The previous implementation used `page.request.get` which is good, but let's
    // simplify and use `setInputFiles` with a local path, which is more robust
    // for CI and local testing. Playwright will handle serving it.
    // We also need to construct the correct path relative to the project root.
    const filePath = `static/${fileName}`; // Assumes tests run from vibe-player-v2/

    await this.fileInput.setInputFiles(filePath);
  }

  async expectControlsToBeReadyForPlayback() {
    // *** REPLACE with robust wait ***
    await expect(
      this.timeDisplay,
      "Time display did not update with audio duration",
    ).not.toHaveText("0:00 / 0:00", { timeout: 20000 });

    await expect(
      this.playButton,
      "Play button was not enabled after file load",
    ).toBeEnabled({ timeout: 1000 });
  }

  async getPlayButtonText() {
    return this.playButton.textContent();
  }

  async setSliderValue(sliderInputLocator, value) {
    await sliderInputLocator.evaluate((el, val) => {
      const inputElement = el; // as HTMLInputElement; <-- not valid in mjs
      inputElement.value = val;
      inputElement.dispatchEvent(new Event("input", { bubbles: true }));
      inputElement.dispatchEvent(new Event("change", { bubbles: true }));
    }, String(value));
    await this.page.waitForTimeout(150);
  }

  async getSliderInputValue(sliderInputLocator) {
    return sliderInputLocator.inputValue();
  }
}

````
--- End of File: vibe-player-v2/tests-e2e/PlayerPage.mjs ---
--- File: vibe-player-v2/tsconfig.json ---
````json
// vibe-player-v2/tsconfig.json

{
  "extends": "./.svelte-kit/tsconfig.json",
  "compilerOptions": {
    "allowJs": true,
    "checkJs": true,
    "esModuleInterop": true,
    "forceConsistentCasingInFileNames": true,
    "resolveJsonModule": true,
    "skipLibCheck": true,
    "sourceMap": true,
    "strict": true,
    "module": "esnext",
    "moduleResolution": "bundler",
    // Change the target to a modern version that supports async/await natively.
    // "es2017" is a safe and widely supported choice.
    "target": "es2017",
    // Add "webworker" to the library list. This provides the correct
    // global types for your worker files (like `self`, `importScripts`, etc.)
    // and ensures "Promise" is available.
    "lib": ["es2017", "dom", "webworker"]
  },
  // --- ADD THIS "exclude" ARRAY ---
  "exclude": [
    "node_modules",
    "build",
    ".svelte-kit",
    "vite.config.ts",
    "svelte.config.js",
    "playwright.config.ts",
    "postcss.config.js",
    "eslint.config.js"
  ]

  // Path aliases are handled by https://svelte.dev/docs/kit/configuration#alias
  // except $lib which is handled by https://svelte.dev/docs/kit/configuration#files
  //
  // If you want to overwrite includes/excludes, make sure to copy over the relevant includes/excludes
  // from the referenced tsconfig.json - TypeScript does not merge them in
}

````
--- End of File: vibe-player-v2/tsconfig.json ---
--- File: vibe-player-v2/vite.config.ts ---
````typescript
import { sveltekit } from "@sveltejs/kit/vite";
import { defineConfig } from "vitest/config"; // Changed from "vite"
import { viteStaticCopy } from "vite-plugin-static-copy";

export default defineConfig({
  plugins: [
    sveltekit(),
    viteStaticCopy({
      targets: [
        {
          src: "./node_modules/onnxruntime-web/dist/*.{wasm,mjs}",
          dest: ".", // Copies to the root of the build directory
        },
      ],
    }),
  ],
  test: {
    globals: true,
    environment: "jsdom",
    include: ["src/**/*.{test,spec}.{js,ts}"],
    setupFiles: ["./src/setupTests.ts"],
  },
  resolve: {
    conditions: ["browser", "svelte"],
  },
});

````
--- End of File: vibe-player-v2/vite.config.ts ---
