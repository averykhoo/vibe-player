
System Prompt:

You will be provided with a snapshot of a repository, including its directory structure and the content of its key text files.

**Your primary task is to carefully read, analyze, and thoroughly understand the *entirety* of this provided information.** Do not just skim the contents. Process the directory structure, the relationships between files (e.g., how they might link, import, or relate thematically), and the substance within each file.

**Synthesize this information to build a comprehensive internal understanding of the repository's:**
*   **Overall purpose:** What is this repository *for*? (e.g., a software project, documentation, recipe collection, project plan, notes)
*   **Structure and Organization:** How are the files and directories laid out? How do they logically group together?
*   **Key Components and Content:** What are the most important files, concepts, topics, data points, or pieces of information contained within?

Your goal is to develop a robust mental model of this repository based *only* on the provided snapshot. This understanding is crucial for you to accurately and effectively answer subsequent user questions about any aspect of the repository.


**Repository Structure:**
````
.
├── .github
│   └── workflows
│       ├── deploy.yml
│       └── release.yml
├── .gitignore
├── .llmignore
├── README.md
├── build_system_prompt.py
├── system-prompt.txt
├── test-audio
│   ├── 449496_9289636-lq.mp3
│   ├── C.Noisy_Voice.wav
│   ├── CGI_Animated_Short_Film：_＂Watermelon_A_Cautionary_Tale＂_by_Kefei.m4a
│   ├── Dial DTMF sound _Busy Tone_ (480Hz+620Hz) [OnlineSound.net].mp3
│   ├── Dial DTMF sound _Ringing Tone_ (400Hz+450Hz) [OnlineSound.net].mp3
│   ├── IELTS13-Tests1-4CD1Track_01.mp3
│   ├── LearningEnglishConversations-20250325-TheEnglishWeSpeakTwistSomeonesArm.mp3
│   ├── Michael Jackson - Bad.mp3
│   ├── Rename me to just Music.mp3
│   ├── Tracing the thoughts of a large language model [Bj9BD2D3DzA].m4a
│   ├── call going to voicemail - sound effect [SozAG1STa08].m4a
│   ├── dtmf-123A456B789C(star)0(hex)D.mp3
│   ├── file_example_MP3_5MG.mp3
│   ├── off-hook-tone-43891.mp3
│   ├── overlordVol14Prologue.mp3
│   ├── warning.mp3
│   └── 【Sound_of_Japan】Outgoing_Phone_Call_Dial_Sound⧸_Answering_Machine.m4a
├── vibe-player
│   ├── CONTRIBUTING-LLM.md
│   ├── README.md
│   ├── REFACTOR.md
│   ├── TODO.md
│   ├── architecture.md
│   ├── css
│   │   ├── 98.css
│   │   └── styles.css
│   ├── fonts
│   │   ├── ms_sans_serif.woff
│   │   ├── ms_sans_serif.woff2
│   │   ├── ms_sans_serif_bold.woff
│   │   └── ms_sans_serif_bold.woff2
│   ├── index.html
│   ├── js
│   │   ├── app.js
│   │   ├── constants.js
│   │   ├── goertzel.js
│   │   ├── player
│   │   │   ├── audioEngine.js
│   │   │   └── rubberbandProcessor.js
│   │   ├── sparkles.js
│   │   ├── uiManager.js
│   │   ├── utils.js
│   │   ├── vad
│   │   │   ├── sileroProcessor.js
│   │   │   ├── sileroWrapper.js
│   │   │   ├── vad.worker.js
│   │   │   └── vadAnalyzer.js
│   │   └── visualizers
│   │       ├── spectrogram.worker.js
│   │       ├── spectrogramVisualizer.js
│   │       └── waveformVisualizer.js
│   ├── lib
│   │   ├── fft.js
│   │   ├── ort-wasm-simd-threaded.jsep.mjs
│   │   ├── ort-wasm-simd-threaded.jsep.wasm
│   │   ├── ort-wasm-simd-threaded.mjs
│   │   ├── ort-wasm-simd-threaded.wasm
│   │   ├── ort.min.js
│   │   ├── ort.min.js.map
│   │   ├── rubberband-loader.js
│   │   └── rubberband.wasm
│   └── model
│       └── silero_vad.onnx
└── vibe-player-gui-state-diagram.md
````

**File Contents:**

--- File: .github/workflows/deploy.yml ---
````yaml
# .github/workflows/deploy.yml
name: Deploy Vibe Player to GitHub Pages

on:
  # Runs on pushes targeting the default branch (main or master)
  push:
    branches: ["main"] # Or "master", depending on your default branch name
  # Allows you to run this workflow manually from the Actions tab
  workflow_dispatch:

# Sets permissions of the GITHUB_TOKEN to allow deployment to GitHub Pages
permissions:
  contents: read
  pages: write
  id-token: write

# Allow only one concurrent deployment, skipping runs queued between the run in-progress and latest queued.
# However, do NOT cancel in-progress runs as we want to allow these production deployments to complete.
concurrency:
  group: "pages"
  cancel-in-progress: false

jobs:
  # Single deploy job since we're just deploying static files
  deploy:
    environment:
      name: github-pages
      url: ${{ steps.deployment.outputs.page_url }}
    runs-on: ubuntu-latest
    steps:
      - name: Checkout
        uses: actions/checkout@v4 # Use latest checkout action

      - name: Setup Pages
        uses: actions/configure-pages@v5 # Use latest configure-pages action

      # This is the crucial step: Upload the *contents* of ./vibe-player as the artifact
      - name: Upload artifact
        uses: actions/upload-pages-artifact@v3 # Use latest upload-artifact action
        with:
          # Upload content from the vibe-player directory
          path: './vibe-player'

      - name: Deploy to GitHub Pages
        id: deployment
        uses: actions/deploy-pages@v4 # Use latest deploy-pages action

````
--- End of File: .github/workflows/deploy.yml ---
--- File: .github/workflows/release.yml ---
````yaml
# .github/workflows/create-release-official.yml
name: Create Release Zip (Official Actions Only)

on:
  push:
    tags:
      - 'v*.*.*'

permissions:
  # Need write access to repository contents to create releases and upload assets
  contents: write

jobs:
  build-release:
    runs-on: ubuntu-latest # Using Ubuntu for easy access to 'zip' command
    steps:
      - name: Checkout code
        uses: actions/checkout@v4 # Official: Checks out the repository code at the specific tag

      - name: Get the version tag
        id: get_tag
        run: echo "TAG_NAME=${GITHUB_REF_NAME}" >> $GITHUB_ENV
        # Standard shell command + GitHub Actions environment variable feature

      - name: Build the zip archive
        run: |
          echo "Creating zip for tag ${{ env.TAG_NAME }}"
          cd vibe-player # Move into the target directory
          # Use standard 'zip' command available on ubuntu runners
          zip -r ../vibe-player-${{ env.TAG_NAME }}.zip .
          cd .. # Move back to the root
        # Standard shell commands

      - name: Create GitHub Release
        id: create_release # Give this step an ID to reference its outputs
        uses: actions/create-release@v1 # Official: Creates the release entry
        env:
          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }} # Required for authentication
        with:
          tag_name: ${{ env.TAG_NAME }}
          release_name: Release ${{ env.TAG_NAME }}
          body: | # Optional: Add release notes here, can be simple or more complex
            Automated release for version ${{ env.TAG_NAME }}.
            Contains contents of the vibe-player directory.
          draft: false
          prerelease: false # Set to true if needed based on tag format

      - name: Upload Release Asset (Zip)
        uses: actions/upload-release-asset@v1 # Official: Uploads a file to the created release
        env:
          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }} # Required for authentication
        with:
          upload_url: ${{ steps.create_release.outputs.upload_url }} # Get upload URL from the previous step's output
          asset_path: ./vibe-player-${{ env.TAG_NAME }}.zip # Path to the zip file we created
          asset_name: vibe-player-${{ env.TAG_NAME }}.zip # Name for the asset file on GitHub Releases
          asset_content_type: application/zip # MIME type for zip files

````
--- End of File: .github/workflows/release.yml ---
--- File: .gitignore ---
````.gitignore
# Byte-compiled / optimized / DLL files
__pycache__/
*.py[cod]
*$py.class

# C extensions
*.so

# Distribution / packaging
.Python
build/
develop-eggs/
dist/
downloads/
eggs/
.eggs/
#lib/
lib64/
parts/
sdist/
var/
wheels/
share/python-wheels/
*.egg-info/
.installed.cfg
*.egg
MANIFEST

# PyInstaller
#  Usually these files are written by a python script from a template
#  before PyInstaller builds the exe, so as to inject date/other infos into it.
*.manifest
*.spec

# Installer logs
pip-log.txt
pip-delete-this-directory.txt

# Unit test / coverage reports
htmlcov/
.tox/
.nox/
.coverage
.coverage.*
.cache
nosetests.xml
coverage.xml
*.cover
*.py,cover
.hypothesis/
.pytest_cache/
cover/

# Translations
*.mo
*.pot

# Django stuff:
*.log
local_settings.py
db.sqlite3
db.sqlite3-journal

# Flask stuff:
instance/
.webassets-cache

# Scrapy stuff:
.scrapy

# Sphinx documentation
docs/_build/

# PyBuilder
.pybuilder/
target/

# Jupyter Notebook
.ipynb_checkpoints

# IPython
profile_default/
ipython_config.py

# pyenv
#   For a library or package, you might want to ignore these files since the code is
#   intended to run in multiple environments; otherwise, check them in:
# .python-version

# pipenv
#   According to pypa/pipenv#598, it is recommended to include Pipfile.lock in version control.
#   However, in case of collaboration, if having platform-specific dependencies or dependencies
#   having no cross-platform support, pipenv may install dependencies that don't work, or not
#   install all needed dependencies.
#Pipfile.lock

# UV
#   Similar to Pipfile.lock, it is generally recommended to include uv.lock in version control.
#   This is especially recommended for binary packages to ensure reproducibility, and is more
#   commonly ignored for libraries.
#uv.lock

# poetry
#   Similar to Pipfile.lock, it is generally recommended to include poetry.lock in version control.
#   This is especially recommended for binary packages to ensure reproducibility, and is more
#   commonly ignored for libraries.
#   https://python-poetry.org/docs/basic-usage/#commit-your-poetrylock-file-to-version-control
#poetry.lock

# pdm
#   Similar to Pipfile.lock, it is generally recommended to include pdm.lock in version control.
#pdm.lock
#   pdm stores project-wide configurations in .pdm.toml, but it is recommended to not include it
#   in version control.
#   https://pdm.fming.dev/latest/usage/project/#working-with-version-control
.pdm.toml
.pdm-python
.pdm-build/

# PEP 582; used by e.g. github.com/David-OConnor/pyflow and github.com/pdm-project/pdm
__pypackages__/

# Celery stuff
celerybeat-schedule
celerybeat.pid

# SageMath parsed files
*.sage.py

# Environments
.env
.venv
env/
venv/
ENV/
env.bak/
venv.bak/

# Spyder project settings
.spyderproject
.spyproject

# Rope project settings
.ropeproject

# mkdocs documentation
/site

# mypy
.mypy_cache/
.dmypy.json
dmypy.json

# Pyre type checker
.pyre/

# pytype static type analyzer
.pytype/

# Cython debug symbols
cython_debug/

# PyCharm
#  JetBrains specific template is maintained in a separate JetBrains.gitignore that can
#  be found at https://github.com/github/gitignore/blob/main/Global/JetBrains.gitignore
#  and can be added to the global gitignore or merged into this file.  For a more nuclear
#  option (not recommended) you can uncomment the following to ignore the entire idea folder.
.idea/

# Ruff stuff:
.ruff_cache/

# PyPI configuration file
.pypirc

````
--- End of File: .gitignore ---
--- File: .llmignore ---
````.llmignore
rubberband-app/
rubberband-test-harness/
soundtouch-app/
````
--- End of File: .llmignore ---
--- File: README.md ---
````markdown
<!-- README.md -->
# Vibe Player

Vibe Player is a simple, browser-based audio player designed for analyzing and manipulating audio files, inspired by classic desktop application aesthetics. It runs entirely client-side using static files.

**Live Demo: [Vibe Player](https://averykhoo.github.io/vibe-player/)**

## Features

*   Load local audio files (common formats supported by browser `decodeAudioData`) and from URLs.
*   Real-time playback control (Play, Pause, Seek).
*   Adjust playback Speed (0.25x - 2.0x) using Rubberband WASM.
*   Adjust playback Pitch (0.25x - 2.0x) using Rubberband WASM.
*   Adjust playback Gain (Volume Boost up to 5x).
*   Voice Activity Detection (VAD) using Silero VAD model (ONNX Runtime):
    *   Displays VAD progress during analysis.
    *   Highlights detected speech segments on the waveform.
    *   Allows tuning VAD thresholds (Positive/Negative) after initial analysis.
*   Visualizations:
    *   Real-time Waveform display.
    *   Spectrogram display.
*   **DTMF and Call Progress Tone (CPT) detection and display.**
*   Keyboard shortcuts for common actions (visible in the application UI).

## Usage

1.  Serve the project files using a simple static file server (e.g., `python -m http.server` or VS Code Live Server). The server should be run from the project root directory.
2.  Open `vibe-player/index.html` in your web browser (Chrome/Edge/Firefox recommended).
3.  Click "Choose File..." and select an audio file, or provide a URL.
4.  Wait for the initial processing (decoding, visuals). The waveform and spectrogram will appear.
5.  Playback controls (Play, Seek, Speed, Pitch, Gain) become active once the audio engine is ready.
6.  VAD processing runs in the background. Its progress is shown, and waveform highlights appear upon completion. VAD tuning sliders become active then.
7.  Use the controls or click on the waveform/spectrogram to interact.

## Controls

*   **Choose File...:** Select a local audio file.
*   **Load URL:** Load audio from a URL.
*   **Speed Slider:** Adjust playback speed (0.25x - 2.0x).
*   **Pitch Slider:** Adjust playback pitch scale (0.25x - 2.0x).
*   **Gain Slider:** Adjust output volume boost (1x - 5x).
*   **Play/Pause Button:** Toggle playback.
*   **Back/Forward Buttons & Input:** Jump backward or forward by the specified number of seconds.
*   **Seek Bar / Time Display:** Shows current position / total duration. Click or drag seek bar to jump.
*   **Waveform/Spectrogram:** Click to seek to that position.
*   **VAD Threshold Sliders:** (Enabled after VAD) Adjust positive/negative thresholds to re-evaluate speech segments based on the initial analysis probabilities.
*   **(Keyboard Shortcuts are listed within the application UI)**

## Developer Notes

*   **Static Environment:** This application is designed to run entirely client-side without any build steps or server-side logic. See `vibe-player/architecture.md` for more details.
*   **Key Technologies/Dependencies:** Vanilla JS (ES6), Web Audio API, ONNX Runtime Web (`ort.min.js`), Rubberband WASM (`rubberband.wasm`, `rubberband-loader.js`), FFT.js. These are included in the `vibe-player/lib/` directory.
*   **Code Structure:** Uses Vanilla JS (ES6) with an IIFE module pattern. See `vibe-player/architecture.md` for more details.

## Contributing / LLM Collaboration

Development involving LLM assistance should follow the guidelines outlined in `vibe-player/CONTRIBUTING-LLM.md`. Please ensure this file is loaded into the LLM's context before starting work. If the file is missing, please request it.

<!-- README.md -->
````
--- End of File: README.md ---
--- File: vibe-player/architecture.md ---
````markdown
<!-- /vibe-player/architecture.md -->
# Vibe Player Architecture

## 1. Overview

*   **Purpose:** Browser-based audio player focused on playback speed/pitch manipulation, voice activity detection (VAD) visualization, and waveform/spectrogram display. Designed for static file deployment.
*   **Core Philosophy:** Prioritize simplicity and minimal dependencies by using Vanilla JS, HTML, and CSS. Leverage WebAssembly (WASM) via standardized Web APIs (`AudioWorklet`, `ONNX Runtime Web`) for computationally intensive tasks (audio processing, ML inference) that would otherwise be difficult or impossible client-side. The application follows an event-driven interaction flow managed by a central controller (`app.js`).

## 2. Key Technologies

*   **Frontend:** HTML5, CSS3 (98.css for styling + custom `styles.css`), Vanilla JavaScript (ES6 Modules via IIFE pattern on `AudioApp` namespace)
*   **Audio Engine:** Web Audio API (`AudioContext`, `GainNode`, `AudioWorkletNode`, `OfflineAudioContext` for resampling)
*   **Time/Pitch Shifting:** Rubberband WASM library (via `js/player/rubberbandProcessor.js` AudioWorklet).
    *   **Loader (`lib/rubberband-loader.js`):** ***Note:*** *This is a heavily modified version of the standard Emscripten loader, adapted specifically for use within the AudioWorklet context and to handle WASM instantiation via a hook.*
    *   **Temporal Accuracy:** ***Note:*** *Rubberband prioritizes audio quality over strict temporal accuracy. The number of output frames generated may not perfectly match the requested time ratio for a given input block, and its internal time/latency reporting can drift relative to the Web Audio clock. Therefore, its time reports are not used directly for precise UI indicator synchronization.*
*   **VAD:** Silero VAD model (`model/silero_vad.onnx`) executed via ONNX Runtime Web (WASM backend in `lib/`)
*   **Visualizations:** HTML Canvas API (2D Context), FFT.js library (`lib/fft.js`).
    *   **FFT Library (`lib/fft.js`):** ***Note:*** *This is based on indutny/fft.js but contains modifications made during initial development to ensure compatibility or functionality.*
*   **DTMF & Call Progress Tone (CPT) Detection:**
    *   The application can detect and display common DTMF tones (0-9, *, #, A-D) and Call Progress Tones (e.g., Dial Tone, Busy Signal, Ringback).
    *   This is achieved using JavaScript implementations of the Goertzel algorithm and custom parsers (`DTMFParser`, `CallProgressToneParser`) located in `js/goertzel.js`.
    *   `DTMFParser` identifies DTMF characters by detecting pairs of specific frequencies.
    *   `CallProgressToneParser` identifies CPTs by detecting specific frequencies and their cadences (on/off patterns).

## 3. Code Structure (`js/` directory)

*   **`app.js` (Controller):** Initializes modules, orchestrates loading/VAD/DTMF-CPT/playback flow, handles events, manages core state. Manages main-thread time updates using `AudioContext.currentTime`. For DTMF/CPT detection, it resamples audio to 16kHz mono, iterates through it in blocks, passes these to `DTMFParser` and `CallProgressToneParser` instances, and relays results to `uiManager.js` for display.
*   **`constants.js`:** Defines shared constants (paths, parameters, colors, etc.).
*   **`goertzel.js`:** Contains implementations of the Goertzel algorithm (`GoertzelFilter`), `DTMFParser`, and `CallProgressToneParser` for detecting specific frequencies and patterns for DTMF and CPTs.
*   **`utils.js`:** Contains shared utility functions (e.g., `formatTime`, `yieldToMainThread`, `hannWindow`, `viridisColor`).
*   **`uiManager.js` (View/UI Logic):** Handles all direct DOM manipulation, UI event listeners, and dispatches UI events. Manages VAD progress bar UI.
*   **`js/player/`:**
    *   **`audioEngine.js` (Audio Backend):** Manages Web Audio API, `AudioWorkletNode` lifecycle/communication, audio decoding, and resampling capability. Relays time updates from worklet but isn't the primary source for UI timing.
    *   **`rubberbandProcessor.js` (AudioWorklet):** Runs in worklet thread. Interfaces with Rubberband WASM for time/pitch processing. Communicates via messages with `audioEngine.js`. Reports its consumed source time, acknowledging potential inaccuracies.
*   **`js/vad/`:**
    *   **`sileroWrapper.js` (VAD ONNX Interface):** Wraps ONNX Runtime session for the Silero VAD model. Handles inference calls and state tensors.
    *   **`sileroProcessor.js` (VAD Frame Logic):** Iterates audio frames, calls `sileroWrapper`, calculates regions based on probabilities/thresholds, yields to main thread, reports progress.
    *   **`vadAnalyzer.js` (VAD State Manager):** Bridges `app.js` and VAD processing. Holds VAD results/thresholds. Initiates analysis and recalculation.
*   **`js/visualizers/`:**
    *   **`waveformVisualizer.js`:** Computes and draws the waveform display, handles highlighting, resizing, progress indicator, and click-to-seek.
    *   **`spectrogramVisualizer.js`:** Computes (using FFT.js) and draws the spectrogram display, manages caching, resizing, progress indicator, click-to-seek, and loading spinner.

## 4. Interaction Flow & State Management

*   **Loading Sequence:**
    1.  `UI (Choose File)` -> `uiManager` dispatches `audioapp:fileSelected`.
    2.  `app.js (handleFileSelected)`: Resets state/UI, shows spinner, calls `audioEngine.loadAndProcessFile`.
    3.  `audioEngine`: Decodes audio, dispatches `audioapp:audioLoaded`. Sets up worklet asynchronously.
    4.  `app.js (handleAudioLoaded)`: Stores `currentAudioBuffer`, updates time/seek UI, calls `visualizer.computeAndDrawVisuals([])` (triggers gray waveform + spectrogram draw), hides main spinner, calls `runVadInBackground` (async), and calls `processAudioForTones` (async).
    5.  `audioEngine`: When worklet setup is complete, dispatches `audioapp:workletReady`.
    6.  `app.js (handleWorkletReady)`: Sets `workletPlaybackReady=true`, enables playback controls/seek bar. **Playback is now possible.**
    7.  `app.js (runVadInBackground)` (Running concurrently with tone detection):
        *   Initializes VAD model if needed (`sileroWrapper.create`).
        *   Shows VAD progress bar (`uiManager`).
        *   Calls `audioEngine.resampleTo16kMono` (if not already done for tones, or uses existing resampled data).
        *   Calls `vadAnalyzer.analyze` (which calls `sileroProcessor.analyzeAudio` with progress callback).
        *   `sileroProcessor`: Iterates frames, calls `sileroWrapper.process`, yields, calls progress callback -> `uiManager.updateVadProgress`.
        *   On VAD completion/error: Updates VAD results in `app.js`, updates VAD slider UI (`uiManager`), redraws waveform highlights (`visualizer.redrawWaveformHighlight`), updates progress bar to 100% or 0%.
    8.  `app.js (processAudioForTones)` (Running concurrently with VAD):
        *   Calls `audioEngine.resampleTo16kMono` (if not already done for VAD, or uses existing resampled data).
        *   Initializes `DTMFParser` and `CallProgressToneParser`.
        *   Iterates through resampled audio data in blocks, feeding them to the parsers.
        *   Collects results and passes them to `uiManager.setDtmfCptResults` for display.
*   **Playback Control:** `UI (Button Click)` -> `uiManager` dispatches event -> `app.js (handlePlayPause/Jump/Seek)` -> `audioEngine` (sends command message) -> `rubberbandProcessor`. Status feedback: `rubberbandProcessor` (sends state message) -> `audioEngine` (dispatches event) -> `app.js (handlePlaybackStateChange)` -> `uiManager` (updates button).
*   **Parameter Control (Speed/Pitch/Gain):** `UI (Slider Input)` -> `uiManager` dispatches event -> `app.js (handleSpeed/Pitch/GainChange)` -> `audioEngine`. Gain applied directly via `GainNode`. Speed/Pitch command message sent to `rubberbandProcessor`.
*   **VAD Threshold Tuning:** `UI (Slider Input)` -> `uiManager` dispatches `audioapp:thresholdChanged` -> `app.js (handleThresholdChange)` (checks if VAD done) -> `vadAnalyzer.handleThresholdUpdate` -> `sileroProcessor.recalculateSpeechRegions` -> `app.js` receives new regions -> `visualizer.redrawWaveformHighlight` & `uiManager.setSpeechRegionsText`.
*   **State:** Core state (`currentAudioBuffer`, playback flags, `currentVadResults`, DTMF/CPT results) managed centrally in `app.js`. `audioEngine` manages worklet communication state. `vadAnalyzer` manages VAD results/thresholds. `uiManager` reflects state in the DOM. `sileroWrapper` and `rubberbandProcessor` manage internal WASM state.
*   **Key Points:** Loading involves: Decode -> Initial Visuals (Waveform+Spectrogram) -> Background VAD & DTMF/CPT Processing (concurrently) -> Waveform Highlighting & Tone Display. Playback enabled after worklet ready, independent of VAD/Tone completion.
*   **Time Synchronization:** UI progress indicator is driven by `app.js` using main-thread `AudioContext.currentTime` calculations, compensated for speed changes. Explicit seeks are sent to `audioEngine` on pause and after speed slider adjustments (debounced) to force engine synchronization with the main thread's estimate, mitigating drift from Rubberband's internal timing.

### 4.1 GUI State Transitions

The following diagram illustrates the primary states and transitions of the Vibe Player GUI.

```mermaid
stateDiagram-v2
    direction LR

    [*] --> S_Initial
    S_Initial: Initial (No File Loaded)

    S_Initial --> S_LoadingFile: File/URL selected
    S_LoadingFile: Loading File (Fetching/Decoding)

    S_LoadingFile --> S_ProcessingAudio: Audio Decoded (audioLoaded event)
    note right of S_LoadingFile: Can transition to S_Error on decode/load failure

    S_LoadingFile --> S_Error: Decoding/Network Error

    S_ProcessingAudio: Processing Audio (Worklet Setup, VAD/Tone Analysis Initiated)
    note right of S_ProcessingAudio
        - Worklet being set up.
        - VAD analysis starts.
        - DTMF/CPT analysis starts.
        - Initial visuals (waveform/spectrogram) drawn.
    end note
    S_ProcessingAudio --> S_Ready: Worklet Ready (workletReady event)

    S_Ready: Ready to Play (Paused by default)
    note right of S_Ready
        - Playback controls active.
        - VAD/Tone results may still be processing
          or may complete in this state.
    end note

    S_Ready --> S_Playing: Play clicked
    S_Playing: Playing Audio

    S_Playing --> S_Ready: Pause clicked
    S_Playing --> S_Ready: Playback ended
    S_Playing --> S_Playing: Seek operation

    S_Ready --> S_Ready: Seek operation

    S_Ready --> S_LoadingFile: New File/URL selected (resets flow)
    S_Playing --> S_LoadingFile: New File/URL selected (resets flow)

    S_Error: Error State (e.g., Load/Decode Failed)
    S_Error --> S_Initial: UI Reset (user can select new file)

```

## 5. Design Decisions, Constraints & Tradeoffs

*   **Static Hosting:** Simplifies deployment, no backend required. Limits features requiring server interaction. (Constraint C1)
*   **Vanilla JS:** Reduces dependency footprint, avoids framework overhead/learning curve. Requires manual implementation of patterns (modules, state management). (Constraint C2)
*   **IIFE Module Pattern:** Provides simple namespacing (`AudioApp`) without requiring a build step. Relies on careful script loading order.
*   **Custom Events (`audioapp:*`):** Decouples UI Manager and Audio Engine from the main App controller, allowing modules to signal state changes or requests without direct dependencies on `app.js`'s internal methods. (Constraint C3)
*   **AudioWorklet for Rubberband:** Essential for performing complex audio processing (time-stretching) off the main thread without blocking UI or audio playback. Adds architectural complexity for message passing and state synchronization between main thread (`audioEngine`) and worklet thread (`rubberbandProcessor`). Required a **customized WASM loader** (`lib/rubberband-loader.js`).
    *   **Alternative Considered (SoundTouchJS):** SoundTouchJS was evaluated, but the audio quality, especially at slower speeds, was significantly worse than Rubberband. Rubberband's computational cost was deemed acceptable for the quality improvement. Native Web Audio playback rate changes were also too choppy at low speeds.
    *   **Rubberband Flags:** The primary goal for flag tuning was improving voice quality. The primary flags used are `ProcessRealTime`, `PitchHighQuality`, and `PhaseIndependent`. Other flags like `TransientsCrisp` might be part of the default behavior of the Rubberband library version used or were considered in earlier configurations. `EngineFiner` was tested but resulted in stuttering playback, likely due to exceeding CPU limits on the test machine; the default (faster) engine is currently used.
    *   **Rubberband Temporal Inaccuracy:** ***(RESTORED)*** Rubberband prioritizes audio quality, leading to potential drift in its output duration and time reporting relative to Web Audio clock. This necessitates **main-thread time calculation** for the UI indicator and periodic seek-based synchronization. Analogy: Cannot use a rubber band as a precise ruler.
*   **ONNX Runtime Web for VAD:** Enables use of standard ML models (like Silero VAD) directly in the browser via WASM. Avoids needing a dedicated VAD implementation.
*   **Main-Thread VAD (Async):** VAD processing (`sileroProcessor`) runs on the main thread but uses `async/await` and `setTimeout(0)` to yield periodically.
    *   **Tradeoff:** Simpler implementation for MVP compared to setting up a dedicated Web Worker for VAD. Avoids additional complexity of worker communication and state transfer.
    *   **Downside:** Can still cause minor UI sluggishness during intense computation phases within `sileroWrapper.process`. Susceptible to browser throttling in background tabs (prevents VAD completion if tab is unfocused for a long time).
    *   **(Clarification):** VAD processing currently does *not* run in a Web Worker. The idea was considered to allow completion even when the tab is backgrounded, but not implemented yet.
*   **VAD Progress Updates:** Initial attempts at direct UI updates or simple `setTimeout(0)` from the VAD loop were unreliable for progress bar updates. The current solution uses a callback function passed down to `sileroProcessor` which calls `uiManager.updateVadProgress`.
*   **JSDoc:** Chosen standard for JavaScript documentation in this project. (Constraint C7)
*   **Manual Testing:** Adopted for rapid iteration during MVP phase. Lacks automated checks for regressions. (Constraint C5)
*   **Visualizer Computation:** Waveform data calculated per-pixel. Spectrogram data computed entirely upfront (using **modified `lib/fft.js`**) before being drawn asynchronously chunk-by-chunk.
    *   **Tradeoff:** Faster waveform display. Spectrogram has an initial computation delay before drawing starts, but avoids the complexity of streaming FFT computation. Async drawing prevents blocking during render.
*   **File Structure:** Modular approach with separate files/folders for distinct responsibilities (UI, Player, VAD, Visualizers, Controller, Constants, Utils). Asset types (CSS, Fonts) organized into folders. (Constraint C6, Asset Reorg)

## 6. Known Issues & Development Log

*   **Formant Shifting (Non-Functional):** The mechanism for formant shifting is implemented, but it produces no audible effect with the current Rubberband WASM build and configuration.
    *   **Details:** Attempts were made to enable formant scaling using `_rubberband_set_formant_scale`. Rubberband flags tested included permutations of `EngineFiner`, `PhaseIndependent`, `FormantPreserved`, and the current default flag set. Formant scaling was tested alone and in combination with phase/speed shifting (0.25x to 2.0x). Debugging confirmed the target scale value was successfully passed to the WASM function via the correct API call.
    *   **Result:** No errors were thrown, but **no audible effect** from formant shifting was ever observed. The feature was abandoned as non-functional in the current Rubberband WASM build/configuration. It's uncertain if the issue is in the WASM compilation, the underlying library's formant preservation interaction with other flags, or a misunderstanding of the scale parameter (though multiplier is standard).
*   **VAD Performance & Backgrounding:** Runs on main thread; may cause minor UI jank and pauses when tab unfocused.
*   **Spectrogram Latency:** Initial computation delay before drawing begins.
*   **Rubberband Engine Choice:** `EngineFiner` caused stuttering; using default (faster) engine.
*   **Playback Indicator Drift (Mitigated):** Reliance on main-thread calculation and sync-on-pause/speed-change significantly reduces drift compared to trusting worklet time reports, but minor visual discrepancies *during* rapid parameter changes might still occur due to inherent system latencies.

<!-- /vibe-player/architecture.md -->

````
--- End of File: vibe-player/architecture.md ---
--- File: vibe-player/CONTRIBUTING-LLM.md ---
````markdown
<!-- /CONTRIBUTING-LLM.md -->
# Coding Agent Collaboration Guidelines

This document outlines the principles and procedures for collaborating with a coding agent or automated/semi-automated development assistant on software projects. Adherence to these guidelines ensures efficient, maintainable, and architecturally sound development. These guidelines can also support various LLM collaboration models, but the primary focus is on agent-based development.

### P0: Agent Autonomy & Minimized Interaction
**Principle Statement:** The agent should operate with a high degree of autonomy once a task and its objectives are clearly defined.
*   **Reason:** To improve development velocity, reduce unnecessary user interruptions, and allow the agent to perform comprehensive tasks efficiently.
*   **Context:** After the initial plan or task has been approved by the user, or for routine tasks that align with established patterns and guidelines.
*   **Action:**
    *   The agent must proceed with task implementation without seeking confirmation for intermediate steps, unless a step involves significant architectural deviation, conflicts with core guidelines, or encounters critical ambiguity not solvable with P2.1 (Proactive Clarification Seeking).
    *   Confirmation should primarily be reserved for: initial plan approval, major changes to agreed-upon plans, situations explicitly requiring user choice, or when critical information is missing after an attempt to clarify.
    *   The agent should default to making reasonable, well-documented decisions to keep work flowing, reporting these decisions in its task summary or commit messages.

### P1: Task-Driven Workflow & Initial Confirmation
**Principle Statement:** Complex tasks or those initiating significant changes require an initial proposal and user confirmation before full implementation.
*   **Reason:** Ensures user alignment on scope and approach for major work, prevents wasted effort on undesired solutions, and maintains user oversight on architectural decisions.
*   **Context:** When initiating any non-trivial change (new features, significant refactoring, extensive documentation rewrites) or when explicitly requested by the user.
*   **Action:** The agent first analyzes the task, then outlines a proposed solution (e.g., affected files, high-level logic changes, key components to be developed/modified). This proposal is presented to the user for explicit confirmation. Only after confirmation should the agent proceed with the detailed implementation of that proposal. Minor, clearly defined sub-tasks within an approved plan generally do not require re-confirmation (see P0).

### P2: Clarity & Explicit Communication

#### P2.1: Proactive Clarification Seeking
**Principle Statement:** The agent must seek clarification for ambiguous tasks or requirements.
*   **Reason:** Avoids incorrect assumptions and wasted effort. Leverages user's domain/project knowledge.
*   **Context:** Whenever requirements, existing code, constraints, or user intent seem ambiguous or underspecified.
*   **Action:** The agent **must halt and ask** clarifying questions before making assumptions or generating potentially incorrect output.

#### P2.2: Explanation of Changes (Structured Output)
**Principle Statement:** The agent must explain its actions and rationale in a structured manner.
*   **Reason:** Provides a clear record of actions and rationale, especially regarding design choices or non-obvious logic. Aids user review and architectural oversight.
*   **Context:** When providing any generated code, text block, or completing a task.
*   **Action:** The agent explains *what* it did and *why* the specific approach was taken (e.g., in a commit message draft, task report, or logs), especially if there were alternatives.

### P3: Maintainability & Consistency

#### P3.1: Adherence to Existing Patterns & Controlled Refactoring
**Principle Statement:** The agent must adhere to existing project patterns by default and propose refactoring only with explicit user approval.
*   **Reason:** Ensures codebase remains cohesive and allows for controlled improvements. Reduces cognitive load.
*   **Context:** When adding or modifying code or documentation.
*   **Action:**
    *   The agent **must analyze and strictly adhere** to existing project patterns (style, structure, naming conventions) during initial implementation or when not explicitly told to refactor. This is the default operational mode.
    *   If the agent identifies areas where deviation from existing patterns could significantly improve code health, maintainability, performance, or align better with best practices, it **may propose these refactoring changes** to the user, explaining the rationale clearly. Such refactoring requires explicit user approval and activation of a "Refactor phase" before implementation.

#### P3.2: High-Quality Documentation & Comments
**Principle Statement:** The agent must generate high-quality documentation and comments for the code it produces and preserve existing relevant comments.
*   **Reason:** Critical for future agent understanding and maintenance (including historical context), aids human comprehension, enables IDE features.
*   **Context:** When generating or modifying functions, classes, complex variables, modules, or significant logic blocks.
*   **Action:**
    *   The agent generates comprehensive Doc comments compatible with project standards (e.g., JSDoc, reST - specify further if needed). Include descriptions, parameters, returns, types, and potentially exceptions/raises.
    *   Use inline comments for complex logic steps.
    *   **Crucially, preserve existing meaningful comments unless the code they refer to is removed. These comments serve as a historical log for future agent context to understand *why* code evolved.** Maintain documentation alongside code.

#### P3.3: Conciseness and Non-Redundancy in Documentation
**Principle Statement:** All generated documentation and explanations should be concise and non-redundant.
*   **Reason:** Optimizes agent processing time/cost, reduces noise for human readers, improves maintainability of the documentation itself.
*   **Context:** When generating or updating *any* documentation, including this `CONTRIBUTING-LLM.md`, `README.md`, `architecture.md`, or code comments/docstrings.
*   **Action:** The agent should strive for concise language in all generated text. Avoid redundancy. Use precise terminology. However, when explaining complex logic or design choices, **prioritize the clarity needed for both human and future agent understanding**, even if it requires slightly more detail than absolute minimum brevity would allow.

#### P3.4: File Identification Comments (Full Files Only)
**Principle Statement:** Full file content generated by the agent must include file identification comments.
*   **Reason:** Allows agent to identify file context when receiving pasted content; allows user to verify paste location.
*   **Context:** When generating the *entire content* of a file.
*   **Action:** The agent includes file path comments at the **absolute start and end** of the generated file content (e.g., `# /path/to/script.py`, `<!-- /path/to/file.html -->`). Use the appropriate comment style for the file type. Not needed for partial replacements.

#### P3.5: Logical Sectioning (Long Files)
**Principle Statement:** Long files should be logically sectioned using comments.
*   **Reason:** Improves readability and navigation for humans and agents. Facilitates targeted section replacements.
*   **Context:** When working with files containing multiple distinct logical parts.
*   **Action:** The agent uses clear section header comments (e.g., `# --- Initialization ---`, `/* === API Handlers === */`) to delineate logical blocks. Use the appropriate comment style.

### P4: Guideline Adherence & Conflict Reporting

#### P4.1: Proactive Viability Check & Reporting
**Principle Statement:** The agent should report if its knowledge suggests a guideline or constraint is suboptimal for a task.
*   **Reason:** To proactively identify guidelines or constraints that might be outdated or conflict with best practices, based on the agent's internal knowledge.
*   **Context:** When a task relates to specific guidelines or constraints.
*   **Action:** If the agent's internal knowledge suggests a guideline might be outdated or conflict with best practices for the given task, it **must report** this to the user as part of its analysis or proposal. It should not independently act against the guideline but await user instruction.

#### P4.2: Identify and Report Guideline Conflicts
**Principle Statement:** The agent must identify and report conflicts between user instructions and established guidelines, seeking explicit direction.
*   **Reason:** To resolve discrepancies when user instructions contradict established guidelines, ensuring consistent application or conscious deviation.
*   **Context:** When a direct user instruction conflicts with a specific rule in these guidelines.
*   **Action:** The agent **must** identify and clearly point out any conflict between user instructions and established guidelines, referencing the specific rule. It must then report this conflict and ask the user for explicit instruction on how to proceed for that instance.

### P6: README Generation Requirement
**Principle Statement:** A reference to these coding agent collaboration guidelines must be included in the project's main README.md.
*   **Reason:** Ensures project users and future agents are aware these collaboration guidelines exist and should be followed for consistency.
*   **Context:** When generating or significantly updating a project's `README.md` file.
*   **Action:** The agent **must** include a statement in the `README.md` (e.g., in a "Developer Notes" or "Contributing" section) advising that development involving agent assistance should follow the rules outlined in `CONTRIBUTING-LLM.md` (adjust path if needed) and instructing potential contributors/agents to request this file if it wasn't provided.

### P7: Branch-Based Code Submission
**Principle Statement:** The agent submits work by committing to feature branches and pushing to the remote repository, enabling review and CI/CD.
*   **Reason:** Ensures code changes are visible for review, allows CI/CD integration, facilitates collaboration, and avoids inaccessible local code.
*   **Context:** Upon completion of a defined task, a logical sub-task, or when needing to share work-in-progress that is stable enough for review.
*   **Action:** The agent commits changes with clear, descriptive messages to a dedicated feature branch and pushes it to the remote repository. The agent should not require users to perform local tests before code is pushed; testing is assumed to occur post-push (automated or manual review). Commits should represent logical units of work.

<!-- /CONTRIBUTING-LLM.md -->

````
--- End of File: vibe-player/CONTRIBUTING-LLM.md ---
--- File: vibe-player/css/98.css ---
````css
/*! 98.css v0.1.20 - https://github.com/jdan/98.css */
@font-face {
    font-family: "Pixelated MS Sans Serif";
    font-style: normal;
    font-weight: 400;
    src: url(../fonts/ms_sans_serif.woff) format("woff");
    src: url(../fonts/ms_sans_serif.woff2) format("woff2")
}

@font-face {
    font-family: "Pixelated MS Sans Serif";
    font-style: normal;
    font-weight: 700;
    src: url(../fonts/ms_sans_serif_bold.woff) format("woff");
    src: url(../fonts/ms_sans_serif_bold.woff2) format("woff2")
}

body {
    color: #222;
    font-family: Arial;
    font-size: 12px
}

.title-bar,.window,button,input,label,legend,li[role=tab],option,select,table,textarea,ul.tree-view {
    -webkit-font-smoothing: none;
    font-family: "Pixelated MS Sans Serif",Arial;
    font-size: 11px
}

h1 {
    font-size: 5rem
}

h2 {
    font-size: 2.5rem
}

h3 {
    font-size: 2rem
}

h4 {
    font-size: 1.5rem
}

u {
    border-bottom: .5px solid #222;
    text-decoration: none
}

button,input[type=reset],input[type=submit] {
    background: silver;
    border: none;
    border-radius: 0;
    box-shadow: inset -1px -1px #0a0a0a,inset 1px 1px #fff,inset -2px -2px grey,inset 2px 2px #dfdfdf;
    box-sizing: border-box;
    color: transparent;
    min-height: 23px;
    min-width: 75px;
    padding: 0 12px;
    text-shadow: 0 0 #222
}

button.default,input[type=reset].default,input[type=submit].default {
    box-shadow: inset -2px -2px #0a0a0a,inset 1px 1px #0a0a0a,inset 2px 2px #fff,inset -3px -3px grey,inset 3px 3px #dfdfdf
}

.vertical-bar {
    background: silver;
    box-shadow: inset -1px -1px #0a0a0a,inset 1px 1px #fff,inset -2px -2px grey,inset 2px 2px #dfdfdf;
    height: 20px;
    width: 4px
}

button:not(:disabled):active,input[type=reset]:not(:disabled):active,input[type=submit]:not(:disabled):active {
    box-shadow: inset -1px -1px #fff,inset 1px 1px #0a0a0a,inset -2px -2px #dfdfdf,inset 2px 2px grey;
    text-shadow: 1px 1px #222
}

button.default:not(:disabled):active,input[type=reset].default:not(:disabled):active,input[type=submit].default:not(:disabled):active {
    box-shadow: inset 2px 2px #0a0a0a,inset -1px -1px #0a0a0a,inset -2px -2px #fff,inset 3px 3px grey,inset -3px -3px #dfdfdf
}

/*
@media (not(hover)) {
    button:not(:disabled):hover,input[type=reset]:not(:disabled):hover,input[type=submit]:not(:disabled):hover {
        box-shadow:inset -1px -1px #fff,inset 1px 1px #0a0a0a,inset -2px -2px #dfdfdf,inset 2px 2px grey
    }
}
*/

button:focus,input[type=reset]:focus,input[type=submit]:focus {
    outline: 1px dotted #000;
    outline-offset: -4px
}

button::-moz-focus-inner,input[type=reset]::-moz-focus-inner,input[type=submit]::-moz-focus-inner {
    border: 0
}

:disabled,:disabled+label,input[readonly],input[readonly]+label {
    color: grey
}

:disabled+label,button:disabled,input[type=reset]:disabled,input[type=submit]:disabled {
    text-shadow: 1px 1px 0 #fff
}

.window {
    background: silver;
    box-shadow: inset -1px -1px #0a0a0a,inset 1px 1px #dfdfdf,inset -2px -2px grey,inset 2px 2px #fff;
    padding: 3px
}

.title-bar {
    align-items: center;
    background: linear-gradient(90deg,navy,#1084d0);
    display: flex;
    justify-content: space-between;
    padding: 3px 2px 3px 3px
}

.title-bar.inactive {
    background: linear-gradient(90deg,grey,#b5b5b5)
}

.title-bar-text {
    color: #fff;
    font-weight: 700;
    letter-spacing: 0;
    margin-right: 24px
}

.title-bar-controls {
    display: flex
}

.title-bar-controls button {
    display: block;
    min-height: 14px;
    min-width: 16px;
    padding: 0
}

.title-bar-controls button:active {
    padding: 0
}

.title-bar-controls button:focus {
    outline: none
}

.title-bar-controls button[aria-label=Minimize],.title-bar-controls button[aria-label].minimize {
    background-image: url("data:image/svg+xml;charset=utf-8,%3Csvg width='6' height='2' fill='none' xmlns='http://www.w3.org/2000/svg'%3E%3Cpath fill='%23000' d='M0 0h6v2H0z'/%3E%3C/svg%3E");
    background-position: bottom 3px left 4px;
    background-repeat: no-repeat
}

.title-bar-controls button[aria-label=Maximize],.title-bar-controls button[aria-label].maximize {
    background-image: url("data:image/svg+xml;charset=utf-8,%3Csvg width='9' height='9' fill='none' xmlns='http://www.w3.org/2000/svg'%3E%3Cpath fill-rule='evenodd' clip-rule='evenodd' d='M9 0H0v9h9V0zM8 2H1v6h7V2z' fill='%23000'/%3E%3C/svg%3E");
    background-position: top 2px left 3px;
    background-repeat: no-repeat
}

.title-bar-controls button[aria-label=Maximize]:disabled,.title-bar-controls button[aria-label].maximize:disabled {
    background-image: url("data:image/svg+xml;charset=utf-8,%3Csvg width='10' height='10' fill='none' xmlns='http://www.w3.org/2000/svg'%3E%3Cpath fill-rule='evenodd' clip-rule='evenodd' d='M10 1H1v9h9V1zM9 3H2v6h7V3z' fill='%23fff'/%3E%3Cpath fill-rule='evenodd' clip-rule='evenodd' d='M9 0H0v9h9V0zM8 2H1v6h7V2z' fill='gray'/%3E%3C/svg%3E");
    background-position: top 2px left 3px;
    background-repeat: no-repeat
}

.title-bar-controls button[aria-label=Restore],.title-bar-controls button[aria-label].restore {
    background-image: url("data:image/svg+xml;charset=utf-8,%3Csvg width='8' height='9' fill='none' xmlns='http://www.w3.org/2000/svg'%3E%3Cpath fill='%23000' d='M2 0h6v2H2zM7 2h1v4H7zM2 2h1v1H2zM6 5h1v1H6zM0 3h6v2H0zM5 5h1v4H5zM0 5h1v4H0zM1 8h4v1H1z'/%3E%3C/svg%3E");
    background-position: top 2px left 3px;
    background-repeat: no-repeat
}

.title-bar-controls button[aria-label=Help],.title-bar-controls button[aria-label].help {
    background-image: url("data:image/svg+xml;charset=utf-8,%3Csvg width='6' height='9' fill='none' xmlns='http://www.w3.org/2000/svg'%3E%3Cpath fill='%23000' d='M0 1h2v2H0zM1 0h4v1H1zM4 1h2v2H4zM3 3h2v1H3zM2 4h2v2H2zM2 7h2v2H2z'/%3E%3C/svg%3E");
    background-position: top 2px left 5px;
    background-repeat: no-repeat
}

.title-bar-controls button[aria-label=Close],.title-bar-controls button[aria-label].close {
    background-image: url("data:image/svg+xml;charset=utf-8,%3Csvg width='8' height='7' fill='none' xmlns='http://www.w3.org/2000/svg'%3E%3Cpath fill-rule='evenodd' clip-rule='evenodd' d='M0 0h2v1h1v1h2V1h1V0h2v1H7v1H6v1H5v1h1v1h1v1h1v1H6V6H5V5H3v1H2v1H0V6h1V5h1V4h1V3H2V2H1V1H0V0z' fill='%23000'/%3E%3C/svg%3E");
    background-position: top 3px left 4px;
    background-repeat: no-repeat;
    margin-left: 2px
}

.status-bar {
    gap: 1px;
    display: flex;
    margin: 0 1px
}

.status-bar-field {
    box-shadow: inset -1px -1px #dfdfdf,inset 1px 1px grey;
    flex-grow: 1;
    margin: 0;
    padding: 2px 3px
}

.window-body {
    margin: 8px
}

fieldset {
    border-image: url("data:image/svg+xml;charset=utf-8,%3Csvg width='5' height='5' fill='gray' xmlns='http://www.w3.org/2000/svg'%3E%3Cpath fill-rule='evenodd' clip-rule='evenodd' d='M0 0h5v5H0V2h2v1h1V2H0' fill='%23fff'/%3E%3Cpath fill-rule='evenodd' clip-rule='evenodd' d='M0 0h4v4H0V1h1v2h2V1H0'/%3E%3C/svg%3E") 2;
    margin: 0;
    padding: 10px;
    padding-block-start:8px}

legend {
    background: silver
}

.field-row {
    align-items: center;
    display: flex
}

[class^=field-row]+[class^=field-row] {
    margin-top: 6px
}

.field-row>*+* {
    margin-left: 6px
}

.field-row-stacked {
    display: flex;
    flex-direction: column
}

.field-row-stacked *+* {
    margin-top: 6px
}

label {
    align-items: center;
    display: inline-flex
}

input[type=checkbox],input[type=radio] {
    appearance: none;
    -webkit-appearance: none;
    -moz-appearance: none;
    background: 0;
    border: none;
    margin: 0;
    opacity: 0;
    position: fixed
}

input[type=checkbox]+label,input[type=radio]+label {
    line-height: 13px
}

input[type=radio]+label {
    margin-left: 18px;
    position: relative
}

input[type=radio]+label:before {
    background: url("data:image/svg+xml;charset=utf-8,%3Csvg width='12' height='12' fill='none' xmlns='http://www.w3.org/2000/svg'%3E%3Cpath fill-rule='evenodd' clip-rule='evenodd' d='M8 0H4v1H2v1H1v2H0v4h1v2h1V8H1V4h1V2h2V1h4v1h2V1H8V0z' fill='gray'/%3E%3Cpath fill-rule='evenodd' clip-rule='evenodd' d='M8 1H4v1H2v2H1v4h1v1h1V8H2V4h1V3h1V2h4v1h2V2H8V1z' fill='%23000'/%3E%3Cpath fill-rule='evenodd' clip-rule='evenodd' d='M9 3h1v1H9V3zm1 5V4h1v4h-1zm-2 2V9h1V8h1v2H8zm-4 0v1h4v-1H4zm0 0V9H2v1h2z' fill='%23DFDFDF'/%3E%3Cpath fill-rule='evenodd' clip-rule='evenodd' d='M11 2h-1v2h1v4h-1v2H8v1H4v-1H2v1h2v1h4v-1h2v-1h1V8h1V4h-1V2z' fill='%23fff'/%3E%3Cpath fill-rule='evenodd' clip-rule='evenodd' d='M4 2h4v1h1v1h1v4H9v1H8v1H4V9H3V8H2V4h1V3h1V2z' fill='%23fff'/%3E%3C/svg%3E");
    content: "";
    display: inline-block;
    height: 12px;
    left: -18px;
    margin-right: 6px;
    position: absolute;
    top: 0;
    width: 12px
}

input[type=radio]:active+label:before {
    background: url("data:image/svg+xml;charset=utf-8,%3Csvg width='12' height='12' fill='none' xmlns='http://www.w3.org/2000/svg'%3E%3Cpath fill-rule='evenodd' clip-rule='evenodd' d='M8 0H4v1H2v1H1v2H0v4h1v2h1V8H1V4h1V2h2V1h4v1h2V1H8V0z' fill='gray'/%3E%3Cpath fill-rule='evenodd' clip-rule='evenodd' d='M8 1H4v1H2v2H1v4h1v1h1V8H2V4h1V3h1V2h4v1h2V2H8V1z' fill='%23000'/%3E%3Cpath fill-rule='evenodd' clip-rule='evenodd' d='M9 3h1v1H9V3zm1 5V4h1v4h-1zm-2 2V9h1V8h1v2H8zm-4 0v1h4v-1H4zm0 0V9H2v1h2z' fill='%23DFDFDF'/%3E%3Cpath fill-rule='evenodd' clip-rule='evenodd' d='M11 2h-1v2h1v4h-1v2H8v1H4v-1H2v1h2v1h4v-1h2v-1h1V8h1V4h-1V2z' fill='%23fff'/%3E%3Cpath fill-rule='evenodd' clip-rule='evenodd' d='M4 2h4v1h1v1h1v4H9v1H8v1H4V9H3V8H2V4h1V3h1V2z' fill='silver'/%3E%3C/svg%3E")
}

input[type=radio]:checked+label:after {
    background: url("data:image/svg+xml;charset=utf-8,%3Csvg width='4' height='4' fill='none' xmlns='http://www.w3.org/2000/svg'%3E%3Cpath fill-rule='evenodd' clip-rule='evenodd' d='M3 0H1v1H0v2h1v1h2V3h1V1H3V0z' fill='%23000'/%3E%3C/svg%3E");
    content: "";
    display: block;
    height: 4px;
    left: -14px;
    position: absolute;
    top: 4px;
    width: 4px
}

input[type=checkbox]:focus+label,input[type=radio]:focus+label {
    outline: 1px dotted #000
}

input[type=radio][disabled]+label:before {
    background: url("data:image/svg+xml;charset=utf-8,%3Csvg width='12' height='12' fill='none' xmlns='http://www.w3.org/2000/svg'%3E%3Cpath fill-rule='evenodd' clip-rule='evenodd' d='M8 0H4v1H2v1H1v2H0v4h1v2h1V8H1V4h1V2h2V1h4v1h2V1H8V0z' fill='gray'/%3E%3Cpath fill-rule='evenodd' clip-rule='evenodd' d='M8 1H4v1H2v2H1v4h1v1h1V8H2V4h1V3h1V2h4v1h2V2H8V1z' fill='%23000'/%3E%3Cpath fill-rule='evenodd' clip-rule='evenodd' d='M9 3h1v1H9V3zm1 5V4h1v4h-1zm-2 2V9h1V8h1v2H8zm-4 0v1h4v-1H4zm0 0V9H2v1h2z' fill='%23DFDFDF'/%3E%3Cpath fill-rule='evenodd' clip-rule='evenodd' d='M11 2h-1v2h1v4h-1v2H8v1H4v-1H2v1h2v1h4v-1h2v-1h1V8h1V4h-1V2z' fill='%23fff'/%3E%3Cpath fill-rule='evenodd' clip-rule='evenodd' d='M4 2h4v1h1v1h1v4H9v1H8v1H4V9H3V8H2V4h1V3h1V2z' fill='silver'/%3E%3C/svg%3E")
}

input[type=radio][disabled]:checked+label:after {
    background: url("data:image/svg+xml;charset=utf-8,%3Csvg width='4' height='4' fill='none' xmlns='http://www.w3.org/2000/svg'%3E%3Cpath fill-rule='evenodd' clip-rule='evenodd' d='M3 0H1v1H0v2h1v1h2V3h1V1H3V0z' fill='gray'/%3E%3C/svg%3E")
}

input[type=checkbox]+label {
    margin-left: 19px;
    position: relative
}

input[type=checkbox]+label:before {
    background: #fff;
    box-shadow: inset -1px -1px #fff,inset 1px 1px grey,inset -2px -2px #dfdfdf,inset 2px 2px #0a0a0a;
    content: "";
    display: inline-block;
    height: 13px;
    left: -19px;
    margin-right: 6px;
    position: absolute;
    width: 13px
}

input[type=checkbox]:active+label:before {
    background: silver
}

input[type=checkbox]:checked+label:after {
    background: url("data:image/svg+xml;charset=utf-8,%3Csvg width='7' height='7' fill='none' xmlns='http://www.w3.org/2000/svg'%3E%3Cpath fill-rule='evenodd' clip-rule='evenodd' d='M7 0H6v1H5v1H4v1H3v1H2V3H1V2H0v3h1v1h1v1h1V6h1V5h1V4h1V3h1V0z' fill='%23000'/%3E%3C/svg%3E");
    content: "";
    display: block;
    height: 7px;
    left: -16px;
    position: absolute;
    width: 7px
}

input[type=checkbox][disabled]+label:before {
    background: silver
}

input[type=checkbox][disabled]:checked+label:after {
    background: url("data:image/svg+xml;charset=utf-8,%3Csvg width='7' height='7' fill='none' xmlns='http://www.w3.org/2000/svg'%3E%3Cpath fill-rule='evenodd' clip-rule='evenodd' d='M7 0H6v1H5v1H4v1H3v1H2V3H1V2H0v3h1v1h1v1h1V6h1V5h1V4h1V3h1V0z' fill='gray'/%3E%3C/svg%3E")
}

input[type=email],input[type=number],input[type=password],input[type=search],input[type=tel],input[type=text] {
    -webkit-appearance: none;
    -moz-appearance: none;
    appearance: none;
    border: none;
    border-radius: 0
}

input[type=email],input[type=number],input[type=password],input[type=search],input[type=tel],input[type=text],select {
    background-color: #fff;
    box-shadow: inset -1px -1px #fff,inset 1px 1px grey,inset -2px -2px #dfdfdf,inset 2px 2px #0a0a0a;
    box-sizing: border-box;
    padding: 3px 4px
}

select,textarea {
    border: none
}

textarea {
    -webkit-appearance: none;
    -moz-appearance: none;
    appearance: none;
    background-color: #fff;
    border-radius: 0;
    box-shadow: inset -1px -1px #fff,inset 1px 1px grey,inset -2px -2px #dfdfdf,inset 2px 2px #0a0a0a;
    box-sizing: border-box;
    padding: 3px 4px
}

input[type=email],input[type=password],input[type=search],input[type=tel],input[type=text],select {
    height: 21px
}

input[type=number] {
    height: 22px
}

input[type=search]::-ms-clear,input[type=search]::-ms-reveal {
    display: none;
    height: 0;
    width: 0
}

input[type=search]::-webkit-search-cancel-button,input[type=search]::-webkit-search-decoration,input[type=search]::-webkit-search-results-button,input[type=search]::-webkit-search-results-decoration {
    display: none
}

input[type=email],input[type=number],input[type=password],input[type=search],input[type=tel],input[type=text] {
    line-height: 2
}

input[type=email]:disabled,input[type=email]:read-only,input[type=number]:disabled,input[type=number]:read-only,input[type=password]:disabled,input[type=password]:read-only,input[type=search]:disabled,input[type=search]:read-only,input[type=tel]:disabled,input[type=tel]:read-only,input[type=text]:disabled,input[type=text]:read-only,textarea:disabled {
    background-color: silver
}

select {
    appearance: none;
    -webkit-appearance: none;
    -moz-appearance: none;
    background-image: url("data:image/svg+xml;charset=utf-8,%3Csvg width='16' height='17' fill='none' xmlns='http://www.w3.org/2000/svg'%3E%3Cpath fill-rule='evenodd' clip-rule='evenodd' d='M15 0H0v16h1V1h14V0z' fill='%23DFDFDF'/%3E%3Cpath fill-rule='evenodd' clip-rule='evenodd' d='M2 1H1v14h1V2h12V1H2z' fill='%23fff'/%3E%3Cpath fill-rule='evenodd' clip-rule='evenodd' d='M16 17H0v-1h15V0h1v17z' fill='%23000'/%3E%3Cpath fill-rule='evenodd' clip-rule='evenodd' d='M15 1h-1v14H1v1h14V1z' fill='gray'/%3E%3Cpath fill='silver' d='M2 2h12v13H2z'/%3E%3Cpath fill-rule='evenodd' clip-rule='evenodd' d='M11 6H4v1h1v1h1v1h1v1h1V9h1V8h1V7h1V6z' fill='%23000'/%3E%3C/svg%3E");
    background-position: top 2px right 2px;
    background-repeat: no-repeat;
    border-radius: 0;
    padding-right: 32px;
    position: relative
}

input[type=email]:focus,input[type=number]:focus,input[type=password]:focus,input[type=search]:focus,input[type=tel]:focus,input[type=text]:focus,select:focus,textarea:focus {
    outline: none
}

input[type=range] {
    -webkit-appearance: none;
    background: transparent;
    width: 100%
}

input[type=range]:focus {
    outline: none
}

input[type=range]::-webkit-slider-thumb {
    -webkit-appearance: none;
    background: url("data:image/svg+xml;charset=utf-8,%3Csvg width='11' height='21' fill='none' xmlns='http://www.w3.org/2000/svg'%3E%3Cpath fill-rule='evenodd' clip-rule='evenodd' d='M0 0v16h2v2h2v2h1v-1H3v-2H1V1h9V0z' fill='%23fff'/%3E%3Cpath fill-rule='evenodd' clip-rule='evenodd' d='M1 1v15h1v1h1v1h1v1h2v-1h1v-1h1v-1h1V1z' fill='%23C0C7C8'/%3E%3Cpath fill-rule='evenodd' clip-rule='evenodd' d='M9 1h1v15H8v2H6v2H5v-1h2v-2h2z' fill='%2387888F'/%3E%3Cpath fill-rule='evenodd' clip-rule='evenodd' d='M10 0h1v16H9v2H7v2H5v1h1v-2h2v-2h2z' fill='%23000'/%3E%3C/svg%3E");
    border: none;
    box-shadow: none;
    height: 21px;
    transform: translateY(-8px);
    width: 11px
}

input[type=range].has-box-indicator::-webkit-slider-thumb {
    background: url("data:image/svg+xml;charset=utf-8,%3Csvg width='11' height='21' fill='none' xmlns='http://www.w3.org/2000/svg'%3E%3Cpath fill-rule='evenodd' clip-rule='evenodd' d='M0 0v20h1V1h9V0z' fill='%23fff'/%3E%3Cpath fill='%23C0C7C8' d='M1 1h8v18H1z'/%3E%3Cpath fill-rule='evenodd' clip-rule='evenodd' d='M9 1h1v19H1v-1h8z' fill='%2387888F'/%3E%3Cpath fill-rule='evenodd' clip-rule='evenodd' d='M10 0h1v21H0v-1h10z' fill='%23000'/%3E%3C/svg%3E");
    transform: translateY(-10px)
}

input[type=range]::-moz-range-thumb {
    background: url("data:image/svg+xml;charset=utf-8,%3Csvg width='11' height='21' fill='none' xmlns='http://www.w3.org/2000/svg'%3E%3Cpath fill-rule='evenodd' clip-rule='evenodd' d='M0 0v16h2v2h2v2h1v-1H3v-2H1V1h9V0z' fill='%23fff'/%3E%3Cpath fill-rule='evenodd' clip-rule='evenodd' d='M1 1v15h1v1h1v1h1v1h2v-1h1v-1h1v-1h1V1z' fill='%23C0C7C8'/%3E%3Cpath fill-rule='evenodd' clip-rule='evenodd' d='M9 1h1v15H8v2H6v2H5v-1h2v-2h2z' fill='%2387888F'/%3E%3Cpath fill-rule='evenodd' clip-rule='evenodd' d='M10 0h1v16H9v2H7v2H5v1h1v-2h2v-2h2z' fill='%23000'/%3E%3C/svg%3E");
    border: 0;
    border-radius: 0;
    height: 21px;
    transform: translateY(2px);
    width: 11px
}

input[type=range].has-box-indicator::-moz-range-thumb {
    background: url("data:image/svg+xml;charset=utf-8,%3Csvg width='11' height='21' fill='none' xmlns='http://www.w3.org/2000/svg'%3E%3Cpath fill-rule='evenodd' clip-rule='evenodd' d='M0 0v20h1V1h9V0z' fill='%23fff'/%3E%3Cpath fill='%23C0C7C8' d='M1 1h8v18H1z'/%3E%3Cpath fill-rule='evenodd' clip-rule='evenodd' d='M9 1h1v19H1v-1h8z' fill='%2387888F'/%3E%3Cpath fill-rule='evenodd' clip-rule='evenodd' d='M10 0h1v21H0v-1h10z' fill='%23000'/%3E%3C/svg%3E");
    transform: translateY(0)
}

input[type=range]::-webkit-slider-runnable-track {
    background: #000;
    border-bottom: 1px solid grey;
    border-right: 1px solid grey;
    box-shadow: 1px 0 0 #fff,1px 1px 0 #fff,0 1px 0 #fff,-1px 0 0 #a9a9a9,-1px -1px 0 #a9a9a9,0 -1px 0 #a9a9a9,-1px 1px 0 #fff,1px -1px #a9a9a9;
    box-sizing: border-box;
    height: 2px;
    width: 100%
}

input[type=range]::-moz-range-track {
    background: #000;
    border-bottom: 1px solid grey;
    border-right: 1px solid grey;
    box-shadow: 1px 0 0 #fff,1px 1px 0 #fff,0 1px 0 #fff,-1px 0 0 #a9a9a9,-1px -1px 0 #a9a9a9,0 -1px 0 #a9a9a9,-1px 1px 0 #fff,1px -1px #a9a9a9;
    box-sizing: border-box;
    height: 2px;
    width: 100%
}

.is-vertical {
    display: inline-block;
    height: 150px;
    transform: translateY(50%);
    width: 4px
}

.is-vertical>input[type=range] {
    height: 4px;
    margin: 0 16px 0 10px;
    transform: rotate(270deg) translateX(calc(-50% + 8px));
    transform-origin: left;
    width: 150px
}

.is-vertical>input[type=range]::-webkit-slider-runnable-track {
    border-bottom: 1px solid grey;
    border-left: 1px solid grey;
    border-right: 0;
    box-shadow: -1px 0 0 #fff,-1px 1px 0 #fff,0 1px 0 #fff,1px 0 0 #a9a9a9,1px -1px 0 #a9a9a9,0 -1px 0 #a9a9a9,1px 1px 0 #fff,-1px -1px #a9a9a9
}

.is-vertical>input[type=range]::-moz-range-track {
    border-bottom: 1px solid grey;
    border-left: 1px solid grey;
    border-right: 0;
    box-shadow: -1px 0 0 #fff,-1px 1px 0 #fff,0 1px 0 #fff,1px 0 0 #a9a9a9,1px -1px 0 #a9a9a9,0 -1px 0 #a9a9a9,1px 1px 0 #fff,-1px -1px #a9a9a9
}

.is-vertical>input[type=range]::-webkit-slider-thumb {
    transform: translateY(-8px) scaleX(-1)
}

.is-vertical>input[type=range].has-box-indicator::-webkit-slider-thumb {
    transform: translateY(-10px) scaleX(-1)
}

.is-vertical>input[type=range]::-moz-range-thumb {
    transform: translateY(2px) scaleX(-1)
}

.is-vertical>input[type=range].has-box-indicator::-moz-range-thumb {
    transform: translateY(0) scaleX(-1)
}

select:focus {
    background-color: navy;
    color: #fff
}

select:focus option {
    background-color: #fff;
    color: #000
}

select:active {
    background-image: url("data:image/svg+xml;charset=utf-8,%3Csvg width='16' height='17' fill='none' xmlns='http://www.w3.org/2000/svg'%3E%3Cpath fill-rule='evenodd' clip-rule='evenodd' d='M0 0h16v17H0V0zm1 16h14V1H1v15z' fill='gray'/%3E%3Cpath fill='silver' d='M1 1h14v15H1z'/%3E%3Cpath fill-rule='evenodd' clip-rule='evenodd' d='M12 7H5v1h1v1h1v1h1v1h1v-1h1V9h1V8h1V7z' fill='%23000'/%3E%3C/svg%3E")
}

a {
    color: #00f
}

a:focus {
    outline: 1px dotted #00f
}

ul.tree-view {
    background: #fff;
    box-shadow: inset -1px -1px #fff,inset 1px 1px grey,inset -2px -2px #dfdfdf,inset 2px 2px #0a0a0a;
    display: block;
    margin: 0;
    padding: 6px
}

ul.tree-view li {
    list-style-type: none
}

ul.tree-view a {
    color: #000;
    text-decoration: none
}

ul.tree-view a:focus {
    background-color: navy;
    color: #fff
}

ul.tree-view li,ul.tree-view ul {
    margin-top: 3px
}

ul.tree-view ul {
    border-left: 1px dotted grey;
    margin-left: 16px;
    padding-left: 16px
}

ul.tree-view ul>li {
    position: relative
}

ul.tree-view ul>li:before {
    border-bottom: 1px dotted grey;
    content: "";
    display: block;
    left: -16px;
    position: absolute;
    top: 6px;
    width: 12px
}

ul.tree-view ul>li:last-child:after {
    background: #fff;
    bottom: 0;
    content: "";
    display: block;
    left: -20px;
    position: absolute;
    top: 7px;
    width: 8px
}

ul.tree-view details {
    margin-top: 0
}

ul.tree-view details[open] summary {
    margin-bottom: 0
}

ul.tree-view ul details>summary:before {
    margin-left: -22px;
    position: relative;
    z-index: 1
}

ul.tree-view details>summary:before {
    background-color: #fff;
    border: 1px solid grey;
    content: "+";
    display: block;
    float: left;
    height: 9px;
    line-height: 8px;
    margin-right: 5px;
    padding-left: 1px;
    text-align: center;
    width: 8px
}

ul.tree-view details[open]>summary:before {
    content: "-"
}

ul.tree-view details>summary::-webkit-details-marker,ul.tree-view details>summary::marker {
    content: ""
}

pre {
    background: #fff;
    box-shadow: inset -1px -1px #fff,inset 1px 1px grey,inset -2px -2px #dfdfdf,inset 2px 2px #0a0a0a;
    display: block;
    margin: 0;
    padding: 12px 8px
}

code,code * {
    font-family: monospace
}

summary:focus {
    outline: 1px dotted #000
}

::-webkit-scrollbar {
    width: 16px
}

::-webkit-scrollbar:horizontal {
    height: 17px
}

::-webkit-scrollbar-corner {
    background: #dfdfdf
}

::-webkit-scrollbar-track {
    background-image: url("data:image/svg+xml;charset=utf-8,%3Csvg width='2' height='2' fill='none' xmlns='http://www.w3.org/2000/svg'%3E%3Cpath fill-rule='evenodd' clip-rule='evenodd' d='M1 0H0v1h1v1h1V1H1V0z' fill='silver'/%3E%3Cpath fill-rule='evenodd' clip-rule='evenodd' d='M2 0H1v1H0v1h1V1h1V0z' fill='%23fff'/%3E%3C/svg%3E")
}

::-webkit-scrollbar-thumb {
    background-color: #dfdfdf;
    box-shadow: inset -1px -1px #0a0a0a,inset 1px 1px #fff,inset -2px -2px grey,inset 2px 2px #dfdfdf
}

::-webkit-scrollbar-button:horizontal:end:increment,::-webkit-scrollbar-button:horizontal:start:decrement,::-webkit-scrollbar-button:vertical:end:increment,::-webkit-scrollbar-button:vertical:start:decrement {
    display: block
}

::-webkit-scrollbar-button:vertical:start {
    background-image: url("data:image/svg+xml;charset=utf-8,%3Csvg width='16' height='17' fill='none' xmlns='http://www.w3.org/2000/svg'%3E%3Cpath fill-rule='evenodd' clip-rule='evenodd' d='M15 0H0v16h1V1h14V0z' fill='%23DFDFDF'/%3E%3Cpath fill-rule='evenodd' clip-rule='evenodd' d='M2 1H1v14h1V2h12V1H2z' fill='%23fff'/%3E%3Cpath fill-rule='evenodd' clip-rule='evenodd' d='M16 17H0v-1h15V0h1v17z' fill='%23000'/%3E%3Cpath fill-rule='evenodd' clip-rule='evenodd' d='M15 1h-1v14H1v1h14V1z' fill='gray'/%3E%3Cpath fill='silver' d='M2 2h12v13H2z'/%3E%3Cpath fill-rule='evenodd' clip-rule='evenodd' d='M8 6H7v1H6v1H5v1H4v1h7V9h-1V8H9V7H8V6z' fill='%23000'/%3E%3C/svg%3E");
    height: 17px
}

::-webkit-scrollbar-button:vertical:end {
    background-image: url("data:image/svg+xml;charset=utf-8,%3Csvg width='16' height='17' fill='none' xmlns='http://www.w3.org/2000/svg'%3E%3Cpath fill-rule='evenodd' clip-rule='evenodd' d='M15 0H0v16h1V1h14V0z' fill='%23DFDFDF'/%3E%3Cpath fill-rule='evenodd' clip-rule='evenodd' d='M2 1H1v14h1V2h12V1H2z' fill='%23fff'/%3E%3Cpath fill-rule='evenodd' clip-rule='evenodd' d='M16 17H0v-1h15V0h1v17z' fill='%23000'/%3E%3Cpath fill-rule='evenodd' clip-rule='evenodd' d='M15 1h-1v14H1v1h14V1z' fill='gray'/%3E%3Cpath fill='silver' d='M2 2h12v13H2z'/%3E%3Cpath fill-rule='evenodd' clip-rule='evenodd' d='M11 6H4v1h1v1h1v1h1v1h1V9h1V8h1V7h1V6z' fill='%23000'/%3E%3C/svg%3E");
    height: 17px
}

::-webkit-scrollbar-button:horizontal:start {
    background-image: url("data:image/svg+xml;charset=utf-8,%3Csvg width='16' height='17' fill='none' xmlns='http://www.w3.org/2000/svg'%3E%3Cpath fill-rule='evenodd' clip-rule='evenodd' d='M15 0H0v16h1V1h14V0z' fill='%23DFDFDF'/%3E%3Cpath fill-rule='evenodd' clip-rule='evenodd' d='M2 1H1v14h1V2h12V1H2z' fill='%23fff'/%3E%3Cpath fill-rule='evenodd' clip-rule='evenodd' d='M16 17H0v-1h15V0h1v17z' fill='%23000'/%3E%3Cpath fill-rule='evenodd' clip-rule='evenodd' d='M15 1h-1v14H1v1h14V1z' fill='gray'/%3E%3Cpath fill='silver' d='M2 2h12v13H2z'/%3E%3Cpath fill-rule='evenodd' clip-rule='evenodd' d='M9 4H8v1H7v1H6v1H5v1h1v1h1v1h1v1h1V4z' fill='%23000'/%3E%3C/svg%3E");
    width: 16px
}

::-webkit-scrollbar-button:horizontal:end {
    background-image: url("data:image/svg+xml;charset=utf-8,%3Csvg width='16' height='17' fill='none' xmlns='http://www.w3.org/2000/svg'%3E%3Cpath fill-rule='evenodd' clip-rule='evenodd' d='M15 0H0v16h1V1h14V0z' fill='%23DFDFDF'/%3E%3Cpath fill-rule='evenodd' clip-rule='evenodd' d='M2 1H1v14h1V2h12V1H2z' fill='%23fff'/%3E%3Cpath fill-rule='evenodd' clip-rule='evenodd' d='M16 17H0v-1h15V0h1v17z' fill='%23000'/%3E%3Cpath fill-rule='evenodd' clip-rule='evenodd' d='M15 1h-1v14H1v1h14V1z' fill='gray'/%3E%3Cpath fill='silver' d='M2 2h12v13H2z'/%3E%3Cpath fill-rule='evenodd' clip-rule='evenodd' d='M7 4H6v7h1v-1h1V9h1V8h1V7H9V6H8V5H7V4z' fill='%23000'/%3E%3C/svg%3E");
    width: 16px
}

.window[role=tabpanel] {
    position: relative;
    z-index: 2
}

menu[role=tablist] {
    display: flex;
    list-style-type: none;
    margin: 0 0 -2px;
    padding-left: 3px;
    position: relative;
    text-indent: 0
}

menu[role=tablist]>li {
    border-top-left-radius: 3px;
    border-top-right-radius: 3px;
    box-shadow: inset -1px 0 #0a0a0a,inset 1px 1px #dfdfdf,inset -2px 0 grey,inset 2px 2px #fff;
    z-index: 1
}

menu[role=tablist]>li[aria-selected=true] {
    background-color: silver;
    margin-left: -3px;
    margin-top: -2px;
    padding-bottom: 2px;
    position: relative;
    z-index: 8
}

menu[role=tablist]>li>a {
    color: #222;
    display: block;
    margin: 6px;
    text-decoration: none
}

menu[role=tablist]>li[aria-selected=true]>a:focus {
    outline: none
}

menu[role=tablist]>li>a:focus {
    outline: 1px dotted #222
}

menu[role=tablist].multirows>li {
    flex-grow: 1;
    text-align: center
}

.sunken-panel {
    border: 2px groove transparent;
    border-image: url("data:image/svg+xml;charset=utf-8,%3Csvg width='5' height='5' xmlns='http://www.w3.org/2000/svg'%3E%3Cpath fill='gray' d='M0 0h4v1H0z'/%3E%3Cpath fill='gray' d='M0 0h1v4H0z'/%3E%3Cpath fill='%230a0a0a' d='M1 1h2v1H1z'/%3E%3Cpath fill='%230a0a0a' d='M1 1h1v2H1z'/%3E%3Cpath fill='%23fff' d='M0 4h5v1H0z'/%3E%3Cpath fill='%23fff' d='M4 0h1v5H4z'/%3E%3Cpath fill='%23dfdfdf' d='M3 1h1v3H3z'/%3E%3Cpath fill='%23dfdfdf' d='M1 3h3v1H1z'/%3E%3C/svg%3E") 2;
    box-sizing: border-box;
    overflow: auto
}

.sunken-panel,table {
    background-color: #fff
}

table {
    border-collapse: collapse;
    position: relative;
    text-align: left;
    white-space: nowrap
}

table>thead>tr>* {
    background: silver;
    box-shadow: inset -1px -1px #0a0a0a,inset 1px 1px #fff,inset -2px -2px grey,inset 2px 2px #dfdfdf;
    box-sizing: border-box;
    font-weight: 400;
    height: 17px;
    padding: 0 6px;
    position: sticky;
    top: 0
}

table.interactive>tbody>tr {
    cursor: pointer
}

table>tbody>tr.highlighted {
    background-color: navy;
    color: #fff
}

table>tbody>tr>* {
    height: 14px;
    padding: 0 6px
}

.progress-indicator {
    -webkit-appearance: none;
    -moz-appearance: none;
    appearance: none;
    border: none;
    border-radius: 0;
    box-shadow: inset -2px -2px #dfdfdf,inset 2px 2px grey;
    box-sizing: border-box;
    height: 32px;
    padding: 4px;
    position: relative
}

.progress-indicator>.progress-indicator-bar {
    background-color: navy;
    display: block;
    height: 100%
}

.progress-indicator.segmented>.progress-indicator-bar {
    background-color: transparent;
    background-image: linear-gradient(90deg,navy 16px,transparent 0 2px);
    background-repeat: repeat;
    background-size: 18px 100%;
    width: 100%
}

/*# sourceMappingURL=98.css.map */

````
--- End of File: vibe-player/css/98.css ---
--- File: vibe-player/css/styles.css ---
````css
/* --- /vibe-player/styles.css --- */

/* --- Global Styles --- */
body {
  font-family: "Pixelated MS Sans Serif", Arial;
  font-size: 15px;
  margin: 8px;
  background-color: silver;
  color: #222;
  -webkit-font-smoothing: none;
  -moz-osx-font-smoothing: grayscale;
  font-smooth: never;
  text-rendering: optimizeSpeed;
  image-rendering: pixelated;
  image-rendering: -moz-crisp-edges;
  image-rendering: crisp-edges;
}

/* Style H2 and H3 */
h2, h3 {
  border-bottom: 1px solid grey;
  padding-bottom: 1px;
  margin-top: 0.8em;
  margin-bottom: 0.4em;
  font-weight: bold;
  font-size: 15px;
}

/* --- Layout Sections --- */
section {
  margin-bottom: 8px;
  background: silver;
  box-shadow: inset -1px -1px #0a0a0a, inset 1px 1px #dfdfdf, inset -2px -2px grey, inset 2px 2px #fff;
  padding: 8px 8px;
}

section h2, section h3 {
    margin-top: 0;
    margin-bottom: 0.4em;
}

/* --- File Input --- */
#hiddenAudioFile {
    display: none;
}
#file-loader .field-row {
    align-items: baseline;
}
#file-loader .field-row button {
    flex-shrink: 0;
    font-size: 15px;
    min-height: 26px;
    padding: 1px 10px;
}
#file-loader .field-row span#fileNameDisplay {
    margin-left: 6px;
    white-space: nowrap;
    overflow: hidden;
    text-overflow: ellipsis;
    flex-shrink: 1;
    min-width: 80px;
    font-size: 15px;
    line-height: 1.4;
}
#file-loader p#fileInfo {
    margin: 0 0 0 10px;
    flex-grow: 1;
    font-size: 15px;
    color: grey;
    white-space: nowrap;
    overflow: hidden;
    text-overflow: ellipsis;
}

/* --- URL Input Styling --- */
#audioUrlInput.url-style-default {
    color: black;
    background-color: white;
}

#audioUrlInput.url-style-success {
    color: blue;
    background-color: white;
}

#audioUrlInput.url-style-error {
    color: red;
    background-color: white;
}

#audioUrlInput.url-style-file {
    color: dimgray;
    background-color: white;
}

.url-input.url-style-modified {
    color: black;
    background-color: #ffffff; /* Assuming a white background like default */
}

/* --- REMOVED Old VAD Progress Bar Styles --- */
/* (No rules here anymore) */

/* --- NEW: Style for 98.css VAD progress bar container --- */
#vadProgressContainer {
    margin-top: 5px; /* Add space above the progress bar */
    display: block; /* Ensure it's always visible */
    /* Height is determined by 98.css */
}


/* --- Seek Bar Section --- */
#playback-progress {
    display: flex;
    align-items: center;
    padding: 2px 0px;
    margin-bottom: 4px;
    background: none;
    box-shadow: none;
    border-image: none;
    border: none;
}
#playback-progress input[type=range]#seekBar {
    flex-grow: 1;
    margin: 0 8px;
    height: auto;
    vertical-align: middle;
}
#playback-progress #timeDisplay {
    margin: 0;
    flex-shrink: 0;
    font-size: 15px;
    font-weight: normal;
}
.visually-hidden {
  position: absolute; width: 1px; height: 1px; padding: 0; margin: -1px;
  overflow: hidden; clip: rect(0, 0, 0, 0); white-space: nowrap; border: 0;
}


/* --- Controls Section --- */
#controls button, #controls input[type=number] {
  margin: 0 4px;
  cursor: pointer;
  vertical-align: middle;
  font-size: 15px;
}
#controls button {
    min-height: 26px;
    padding: 1px 10px;
}
#controls .control-group {
    margin-bottom: 5px;
}
#controls .control-group:last-child {
    margin-bottom: 0;
}
#controls .jump-controls {
    margin-bottom: 8px;
    margin-top: 6px;
    display: flex;
    align-items: center;
    justify-content: center;
}
#controls .jump-controls input[type=number] {
    width: 50px;
    height: 26px;
    padding: 2px 3px;
    box-shadow: inset -1px -1px #fff,inset 1px 1px grey,inset -2px -2px #dfdfdf,inset 2px 2px #0a0a0a;
    border: none;
    text-align: center; /* Center the number */
}

/* Horizontal Slider Layout (Applies to Controls and VAD) */
.horizontal-sliders {
    display: flex;
    flex-wrap: wrap;
    gap: 8px;
    margin-top: 6px;
    align-items: flex-start;
}
.horizontal-sliders .slider-unit {
    flex: 1;
    min-width: 180px;
    margin-bottom: 0;
    padding: 6px 15px 1.0em 15px;
}


/* --- Slider Units Styling (General) --- */
.slider-unit {
    position: relative;
    border: 2px groove transparent;
    border-image: url("data:image/svg+xml;charset=utf-8,%3Csvg width='5' height='5' xmlns='http://www.w3.org/2000/svg'%3E%3Cpath fill='gray' d='M0 0h4v1H0z'/%3E%3Cpath fill='gray' d='M0 0h1v4H0z'/%3E%3Cpath fill='%230a0a0a' d='M1 1h2v1H1z'/%3E%3Cpath fill='%230a0a0a' d='M1 1h1v2H1z'/%3E%3Cpath fill='%23fff' d='M0 4h5v1H0z'/%3E%3Cpath fill='%23fff' d='M4 0h1v5H4z'/%3E%3Cpath fill='%23dfdfdf' d='M3 1h1v3H3z'/%3E%3Cpath fill='%23dfdfdf' d='M1 3h3v1H1z'/%3E%3C/svg%3E") 2;
    box-sizing: border-box;
    background-color: silver;
}
.slider-label-value {
    margin-bottom: 2px;
    font-size: 15px;
}
.slider-label-value label {
    margin-right: 4px;
    font-weight: bold;
    display: inline;
    font-size: 15px;
}
.slider-label-value span {
    display: inline;
    margin-left: 3px;
    font-size: 15px;
}
input[type=range] {
    width: 100%;
    box-sizing: border-box;
    margin: 4px 0 4px 0;
    height: 21px;
    cursor: pointer;
    display: block;
    vertical-align: middle;
}
.slider-markers {
    position: relative;
    width: 100%;
    height: 1.3em;
    margin-top: 2px;
}
.slider-markers span {
    position: absolute;
    bottom: 0;
    color: #222;
    cursor: pointer;
    transform: translateX(-50%);
    white-space: nowrap;
    font-size: 15px;
}
.slider-markers span:hover {
    color: #00f;
}


/* --- VAD Tuning Section --- */
#vad-tuning .horizontal-sliders {
    margin-top: 0;
}
#vad-tuning .slider-unit {
    padding: 6px 15px 6px 15px;
}
#vad-tuning .control-group {
    margin-bottom: 0;
}
#vad-tuning .slider-label-value {
     display: flex;
     justify-content: flex-start;
     align-items: center;
     width: 100%;
     margin-bottom: 2px;
     font-size: 15px;
}
#vad-tuning .slider-label-value label {
    font-size: 15px;
}
#vad-tuning .slider-label-value span {
    margin-left: 6px;
    font-size: 15px;
}
#vad-tuning input[type=range] {
    margin: 4px 0 4px 0;
    height: 21px;
}


/* --- Visualizations Section --- */
.visualization {
    margin-bottom: 8px;
    border: 2px groove transparent;
    border-image: url("data:image/svg+xml;charset=utf-8,%3Csvg width='5' height='5' xmlns='http://www.w3.org/2000/svg'%3E%3Cpath fill='gray' d='M0 0h4v1H0z'/%3E%3Cpath fill='gray' d='M0 0h1v4H0z'/%3E%3Cpath fill='%230a0a0a' d='M1 1h2v1H1z'/%3E%3Cpath fill='%230a0a0a' d='M1 1h1v2H1z'/%3E%3Cpath fill='%23fff' d='M0 4h5v1H0z'/%3E%3Cpath fill='%23fff' d='M4 0h1v5H4z'/%3E%3Cpath fill='%23dfdfdf' d='M3 1h1v3H3z'/%3E%3Cpath fill='%23dfdfdf' d='M1 3h3v1H1z'/%3E%3C/svg%3E") 2;
    box-sizing: border-box;
    padding: 7px 7px;
    background-color: silver;
}
.canvas-container {
    position: relative;
}
.visualization h3 {
    margin: 0 0 4px 0;
    display: flex;
    justify-content: space-between;
    align-items: center;
    border-bottom: none;
    font-size: 15px;
}
.visualization h3 small {
    font-size: 15px;
    font-weight: normal;
}
/* Removed .vad-indicator styles */
canvas {
    display: block;
    width: 100%;
    height: 120px;
    cursor: crosshair;
    box-sizing: border-box;
    border: 1px solid grey;
    box-shadow: inset 1px 1px #dfdfdf, inset -1px -1px grey;
    image-rendering: pixelated;
}
#waveformCanvas {
    background-color: #000;
}
#spectrogramCanvas {
    height: 200px;
    background-color: #000;
}


/* ---* --- Progress Bar Overlay --- */
/* Container for the overlay elements */
.progress-bar {
    position: absolute;
    top: 0;
    left: 0;
    width: 100%;
    pointer-events: none; /* Allow clicks through */
    box-sizing: border-box;
}
/* Match height to corresponding canvas */
#waveformProgressBar { height: 120px; }
#spectrogramProgressBar { height: 200px; }

/* The actual red line indicator - uses the NEW class name */
.playback-position-indicator {
    position: absolute;
    top: 0;
    bottom: 0;
    left: 0px; /* Position set by JS */
    width: 2px; /* Width of the red line */
    background: rgba(255, 0, 0, 0.7); /* Semi-transparent red */
    pointer-events: none; /* Allow clicks through */
    /* Reset styles inherited from 98.css if necessary */
    height: 100%; /* Make sure it spans full height */
    padding: 0;
    margin: 0;
    box-shadow: none;
    min-height: auto; /* Override 98.css min-height */
}

/* --- UI Elements --- */
.spinner {
    display: none;
    font-size: 15px;
    color: #222;
    font-weight: normal;
}
#speechRegionsDisplay {
    white-space: pre-wrap; word-break: break-all; max-height: 120px; overflow-y: auto;
    border: 2px groove transparent;
    border-image: url("data:image/svg+xml;charset=utf-8,%3Csvg width='5' height='5' xmlns='http://www.w3.org/2000/svg'%3E%3Cpath fill='gray' d='M0 0h4v1H0z'/%3E%3Cpath fill='gray' d='M0 0h1v4H0z'/%3E%3Cpath fill='%230a0a0a' d='M1 1h2v1H1z'/%3E%3Cpath fill='%230a0a0a' d='M1 1h1v2H1z'/%3E%3Cpath fill='%23fff' d='M0 4h5v1H0z'/%3E%3Cpath fill='%23fff' d='M4 0h1v5H4z'/%3E%3Cpath fill='%23dfdfdf' d='M3 1h1v3H3z'/%3E%3Cpath fill='%23dfdfdf' d='M1 3h3v1H1z'/%3E%3C/svg%3E") 2;
    background-color: #fff;
    padding: 2px 3px;
    font-family: monospace;
    font-size: 15px;
    line-height: 1.2;
}


/* --- Keybinds Table --- */
#keybinds { margin-top: 8px; }
#keybinds table {
    width: 100%; border-collapse: collapse;
    border: 2px groove transparent;
    border-image: url("data:image/svg+xml;charset=utf-8,%3Csvg width='5' height='5' xmlns='http://www.w3.org/2000/svg'%3E%3Cpath fill='gray' d='M0 0h4v1H0z'/%3E%3Cpath fill='gray' d='M0 0h1v4H0z'/%3E%3Cpath fill='%230a0a0a' d='M1 1h2v1H1z'/%3E%3Cpath fill='%230a0a0a' d='M1 1h1v2H1z'/%3E%3Cpath fill='%23fff' d='M0 4h5v1H0z'/%3E%3Cpath fill='%23fff' d='M4 0h1v5H4z'/%3E%3Cpath fill='%23dfdfdf' d='M3 1h1v3H3z'/%3E%3Cpath fill='%23dfdfdf' d='M1 3h3v1H1z'/%3E%3C/svg%3E") 2;
    background-color: #fff;
    font-size: 15px;
}
#keybinds th, #keybinds td {
    padding: 2px 4px;
    border-bottom: 1px solid silver;
    text-align: left;
    font-size: 15px;
}
#keybinds tr:last-child td {
    border-bottom: none;
}
#keybinds th {
    background: silver;
    box-shadow: inset -1px -1px #0a0a0a, inset 1px 1px #fff, inset -2px -2px grey, inset 2px 2px #dfdfdf;
    box-sizing: border-box; font-weight: normal;
    padding: 2px 4px;
    border-bottom: 1px solid #0a0a0a;
    font-size: 15px;
}

/* --- Small Tag --- */
small {
  font-size: 15px;
}

/* --- Drop Zone Overlay Styles --- */
#dropZoneOverlay {
    display: none; /* This ensures it's hidden initially */
    position: fixed;
    top: 0;
    left: 0;
    right: 0;
    bottom: 0;
    background-color: rgba(0, 0, 0, 0.75);
    z-index: 10000;
    /* Flexbox for centering will be applied when JS changes display to 'flex' */
    align-items: center; /* These are fine to keep for when it becomes flex */
    justify-content: center; /* These are fine to keep for when it becomes flex */
    color: white;
    font-size: 1.5em;
    text-align: center;
}

#dropZoneMessage {
    padding: 20px;
    background-color: rgba(0, 0, 0, 0.5); /* Darker, slightly transparent background for the message box */
    border-radius: 5px;
    box-shadow: 0 4px 8px rgba(0,0,0,0.3); /* Optional: some shadow for the message box */
}

/* Class to apply blur/grayscale effect to the background content */
.blurred-background {
    filter: blur(4px) grayscale(50%);
    /* transition: filter 0.3s ease-out; */ /* Optional: smooth transition for the filter effect */
}

/* /vibe-player/styles.css */

````
--- End of File: vibe-player/css/styles.css ---
--- File: vibe-player/index.html ---
````html
<!-- /vibe-player/index.html -->
<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Vibe Player</title>
    <!-- Add 98.css -->
    <link rel="stylesheet" href="css/98.css"/>
    <!-- Your custom styles (load after 98.css) -->
    <link rel="stylesheet" href="css/styles.css">
    <script src="js/sparkles.js"></script>
</head>
<body>

<!-- === File Loading Section === -->
<section id="file-loader">
    <h2>Load Audio File</h2>
    <!-- Row for button, name, info -->
    <div class="field-row" style="align-items: baseline;">
        <button id="chooseFileButton">Choose File...</button>
        <span id="fileNameDisplay" style="margin-left: 5px; flex-shrink: 1; min-width: 5px;"></span>
        <p id="fileInfo" style="margin-left: 10px; flex-grow: 1; color: grey;"></p>
    </div>
    <!-- Hidden actual file input -->
    <input type="file" id="hiddenAudioFile" accept="audio/*" style="display: none;">

    <!-- New Row for URL input -->
    <div class="field-row" style="margin-top: 10px;">
        <input type="text" id="audioUrlInput" placeholder="Enter audio URL" style="flex-grow: 1; margin-right: 5px;">
        <button id="loadUrlButton">Load from URL</button>
    </div>
    <span id="urlLoadingErrorDisplay" style="color: red; display: block; margin-top: 5px;"></span>
</section>

<!-- === Controls Section === -->
<section id="controls">
    <h2>Controls</h2>


    <!-- Horizontal Slider Container -->
    <div class="horizontal-sliders">
        <!-- Speed Control Unit -->
        <div class="control-group slider-unit">
            <div class="slider-label-value">
                <label for="playbackSpeed">Speed:</label>
                <span id="speedValue">1.00x</span>
            </div>
            <input type="range" id="playbackSpeed" min="0.25" max="2.0" value="1.0" step="0.01">
            <div class="slider-markers" id="speedMarkers">
                <span data-value="0.5">0.5x</span>
                <span data-value="1.0">1.0x</span>
                <span data-value="1.5">1.5x</span>
                <span data-value="2.0">2.0x</span>
            </div>
        </div>

        <!-- Pitch Control Unit -->
        <div class="control-group slider-unit">
            <div class="slider-label-value">
                <label for="pitchControl">Pitch:</label>
                <span id="pitchValue">1.00x</span>
            </div>
            <input type="range" id="pitchControl" min="0.25" max="2.0" value="1.0" step="0.01">
            <div class="slider-markers" id="pitchMarkers">
                <span data-value="0.5">0.5x</span>
                <span data-value="1.0">1.0x</span>
                <span data-value="1.5">1.5x</span>
                <span data-value="2.0">2.0x</span>
            </div>
        </div>

        <!-- Gain Control Unit -->
        <div class="control-group slider-unit">
            <div class="slider-label-value">
                <label for="gainControl">Gain:</label>
                <span id="gainValue">1.00x</span>
            </div>
            <input type="range" id="gainControl" min="1" max="5" value="1.0" step="0.01">
            <!-- Gain enabled by default -->
            <div class="slider-markers" id="gainMarkers">
                <span data-value="1.0">1x</span>
                <span data-value="2.0">2x</span>
                <span data-value="3.0">3x</span>
                <span data-value="4.0">4x</span>
                <span data-value="5.0">5x</span>
            </div>
        </div>
    </div> <!-- End Horizontal Slider Container -->

    <!-- Jump Controls -->
    <div class="control-group jump-controls">
        <button id="playPause" disabled>Play</button>
        <button id="jumpBack" disabled>◀◀ Back</button>
        <input type="number" id="jumpTime" value="5" min="1" step="1" title="Seconds to jump"> seconds
        <!-- Changed 's' to 'seconds' -->
        <button id="jumpForward" disabled>Forward ▶▶</button>
    </div>

    <!-- === Seek Bar and Time Display Section === -->
    <section id="playback-progress">
        <label for="seekBar" class="visually-hidden">Seek:</label> <!-- Hidden label for accessibility -->
        <input type="range" id="seekBar" min="0" max="1" value="0" step="any" disabled>
        <div id="timeDisplay">0:00 / 0:00</div>
    </section>

</section>


<!-- === Visualizations Section === -->
<section class="visualization">
    <h3>Spectrogram <span id="spectrogramSpinner" class="spinner">(Computing...)</span></h3>
    <div class="canvas-container">
        <canvas id="spectrogramCanvas"></canvas>
        <div id="spectrogramProgressBar" class="progress-bar">
            <div id="spectrogramProgressIndicator" class="playback-position-indicator"></div>
        </div>
    </div>
</section>

<section class="visualization">
    <h3>Waveform <small>(Speech in Yellow)</small></h3>
    <div class="canvas-container">
        <canvas id="waveformCanvas"></canvas>
        <div id="waveformProgressBar" class="progress-bar">
            <div id="waveformProgressIndicator" class="playback-position-indicator"></div>
        </div>
    </div>
</section>

<!-- === VAD Tuning Section === -->
<section id="vad-tuning">
    <h2>Voice Activity Detection (Silero)</h2>

    <!-- NEW: VAD Progress Bar using 98.css structure -->
    <div id="vadProgressContainer" class="progress-indicator segmented vad-progress-indicator-container"
         style="margin-top: 5px; margin-bottom: 5px;">
        <span id="vadProgressBar" class="progress-indicator-bar" style="width: 0;"></span>
        <!-- Corrected width attribute -->
    </div>

    <!-- Corrected Structure: Both VAD controls inside one horizontal container -->
    <div class="horizontal-sliders">
        <div class="control-group slider-unit"> <!-- Unit for Positive -->
            <div class="control-group">
                <div class="slider-label-value">
                    <label for="vadThreshold"
                           title="Probability above which a frame is considered speech.">Positive Threshold:</label>
                    <span id="vadThresholdValue">N/A</span>
                </div>
                <input type="range" id="vadThreshold" min="0.01" max="0.99" value="0.5" step="0.01">
            </div>
        </div>
        <div class="control-group slider-unit"> <!-- Unit for Negative -->
            <div class="control-group">
                <div class="slider-label-value">
                    <label for="vadNegativeThreshold"
                           title="Probability below which non-speech frames trigger ending the segment (after redemption).">Negative
                        Threshold:</label>
                    <span id="vadNegativeThresholdValue">N/A</span>
                </div>
                <input type="range" id="vadNegativeThreshold" min="0.01" max="0.99" value="0.35" step="0.01">
            </div>
        </div>
    </div> <!-- End horizontal-sliders for VAD -->

</section>

<!-- === Keyboard Shortcuts Section === -->
<section id="keybinds">
    <h2>Keyboard Shortcuts</h2>
    <table>
        <thead>
        <tr>
            <th>Key</th>
            <th>Action</th>
        </tr>
        </thead>
        <tbody>
        <tr>
            <td>Space</td>
            <td>Play / Pause</td>
        </tr>
        <tr>
            <td>Left Arrow</td>
            <td>Jump Back (by specified seconds)</td>
        </tr>
        <tr>
            <td>Right Arrow</td>
            <td>Jump Forward (by specified seconds)</td>
        </tr>
        </tbody>
    </table>
</section>

<!-- === DTMF Tones Section === -->
<section id="dtmf-tones">
    <h2>DTMF Tones</h2>
    <div id="dtmfDisplay" style="min-height: 50px; background-color: #f0f0f0; border: 1px solid #ccc; padding: 5px;">
        No DTMF tones detected yet.
    </div>
    <br>
    <div id="cpt-display-content"
         style="min-height: 50px; background-color: #f0f0f0; border: 1px solid #ccc; padding: 5px;">
        No ringtones detected yet.
    </div>
</section>

<!-- Drop Zone Overlay -->
<div id="dropZoneOverlay">
    <div id="dropZoneMessage"></div>
</div>

<!-- === SCRIPT LOADING ORDER (CRITICAL!) === -->
<!-- External Libs -->
<script src="lib/ort.min.js"></script> <!-- ONNX Runtime -->
<script src="lib/fft.js"></script> <!-- FFT for Visualizer -->

<!-- Core App Namespace & Foundational Modules -->
<!-- 1. app.js: Establishes AudioApp IIFE structure. Other files attach to this. -->
<script src="js/app.js"></script>
<!-- 2. constants.js: Defines AudioApp.Constants. Needed by many modules. -->
<script src="js/constants.js"></script>
<!-- 3. utils.js: Defines AudioApp.Utils. Needed by many modules. -->
<script src="js/utils.js"></script>

<!-- App Feature Modules & Components -->
<!-- These may depend on AudioApp, Constants, Utils -->
<!-- 4. goertzel.js: Defines AudioApp.GoertzelFilter & AudioApp.DTMFParser. May use Constants. DTMFParser is checked by app.js's init. -->
<script src="js/goertzel.js"></script>
<!-- 5. uiManager.js: Defines AudioApp.uiManager. Uses Utils. Checked by app.js's init. -->
<script src="js/uiManager.js"></script>
<!-- 6. player/audioEngine.js: Defines AudioApp.audioEngine. Uses Constants. Checked by app.js's init. -->
<script src="js/player/audioEngine.js"></script>

<!-- VAD Modules (Order within this group matters) -->
<!-- 7. vad/sileroWrapper.js: Defines AudioApp.sileroWrapper. Checked by app.js's init. -->
<script src="js/vad/sileroWrapper.js"></script>
<!-- 8. vad/sileroProcessor.js: Defines AudioApp.sileroProcessor. Uses Wrapper, Constants, Utils. -->
<script src="js/vad/sileroProcessor.js"></script>
<!-- 9. vad/vadAnalyzer.js: Defines AudioApp.vadAnalyzer. Uses Processor, Constants. Checked by app.js's init. -->
<script src="js/vad/vadAnalyzer.js"></script>

<!-- Visualizer Modules -->
<!-- 10. visualizers/waveformVisualizer.js: Defines AudioApp.waveformVisualizer. Uses Constants, Utils. Checked by app.js's init. -->
<script src="js/visualizers/waveformVisualizer.js"></script>
<!-- 11. visualizers/spectrogramVisualizer.js: Defines AudioApp.spectrogramVisualizer. Uses FFT, Constants, Utils. Checked by app.js's init. -->
<script src="js/visualizers/spectrogramVisualizer.js"></script>
<!-- <script src="js/visualizers/visualizer.js"></script> --> <!-- REMOVED OLD COMBINED VISUALIZER -->

<!-- App Initialization -->
<script>
    // Ensure DOM is fully loaded before initializing the application
    document.addEventListener('DOMContentLoaded', () => {
        // Check if core AudioApp is defined before init
        if (window.AudioApp && typeof window.AudioApp.init === 'function') {
            AudioApp.init(); // Call the main init function
        } else {
            console.error("CRITICAL: AudioApp or AudioApp.init not defined! Check script loading order and errors.");
            // Optionally display error to user in the UI
            const fileInfo = document.getElementById('fileInfo');
            if (fileInfo) fileInfo.textContent = "Fatal Error: Application failed to load. Check console.";
        }
    });
</script>

<!-- Sparkle when the filename is double-clicked -->
<script>
    document.addEventListener("DOMContentLoaded", () => {
        // 1) Wire up dblclick → toggle sparkle
        const fileSpan = document.getElementById("file-loader");
        if (fileSpan) {
            fileSpan.addEventListener("dblclick", () => {
                sparkle(); // calling with no args toggles on/off
            });
        }

        // 2) If today is April 1st, automatically enable on page load
        const today = new Date();
        if (today.getMonth() === 3 && today.getDate() === 1) {
            // Month is zero-based: 3 = April
            sparkle(true);
        }
    });
</script>

</body>
</html>
<!-- /vibe-player/index.html -->

````
--- End of File: vibe-player/index.html ---
--- File: vibe-player/js/app.js ---
````javascript
// --- /vibe-player/js/app.js ---
// Creates the global namespace and orchestrates the application flow.
// MUST be loaded FIRST after libraries.

/**
 * @namespace AudioApp
 * @description Main application namespace for Vibe Player.
 */
var AudioApp = AudioApp || {};

/**
 * @fileoverview Main application logic for Vibe Player.
 * Orchestrates UI, audio engine, visualizers, and VAD processing.
 * Handles user interactions and manages application state.
 * @version 1.0.0
 */

/**
 * @typedef {Object} VadResultRegion
 * @property {number} start - Start time of the speech region in seconds.
 * @property {number} end - End time of the speech region in seconds.
 */

/**
 * @typedef {Object} VadResult
 * @property {VadResultRegion[]} regions - Array of detected speech regions.
 * @property {number} initialPositiveThreshold - The positive VAD threshold used for this result.
 * @property {number} initialNegativeThreshold - The negative VAD threshold used for this result.
 */

/**
 * @typedef {Object} HashSettings
 * @property {number} [speed] - Playback speed.
 * @property {number} [pitch] - Playback pitch.
 * @property {number} [vadPositive] - VAD positive threshold.
 * @property {number} [vadNegative] - VAD negative threshold.
 * @property {number} [volume] - Playback volume/gain.
 * @property {string} [audioUrl] - URL of the audio file to load.
 * @property {number} [position] - Playback position in seconds.
 */


AudioApp = (function() {
    'use strict';

    /** @type {HashSettings} Stores settings parsed from the URL hash. */
    let initialHashSettings = {};
    /** @type {number} Timestamp of the last URL hash update. */
    let lastHashUpdateTime = 0;

    // Constants for URL hash parameters
    /** @const @private @type {string} */ const HASH_PARAM_SPEED = 's';
    /** @const @private @type {string} */ const HASH_PARAM_PITCH = 'p';
    /** @const @private @type {string} */ const HASH_PARAM_VAD_POSITIVE = 'vp';
    /** @const @private @type {string} */ const HASH_PARAM_VAD_NEGATIVE = 'vn';
    /** @const @private @type {string} */ const HASH_PARAM_VOLUME = 'v';
    /** @const @private @type {string} */ const HASH_PARAM_AUDIO_URL = 'url';
    /** @const @private @type {string} */ const HASH_PARAM_POSITION = 't';

    /**
     * @private
     * @type {AudioApp.Utils} Reference to the Utils module.
     */
    const Utils = AudioApp.Utils;

    // --- Application State ---
    /** @type {AudioBuffer|null} The currently loaded and decoded audio buffer. */
    let currentAudioBuffer = null;
    /** @type {string|null} The URL to display in the input field (can be a remote URL or a "file:///" local path). */
    let currentDisplayUrl = null;
    /** @type {'default'|'success'|'error'|'file'|'modified'} The style to apply to the URL input field. */
    let currentUrlStyle = 'default';
    /** @type {VadResult|null} Results from the VAD analysis. */
    let currentVadResults = null;
    /** @type {File|null} The currently loaded audio file object (if loaded from disk or drag-and-drop). */
    let currentFile = null;
    /** @type {boolean} Flag indicating if the Silero VAD model is loaded and ready. */
    let vadModelReady = false;
    /** @type {boolean} Flag indicating if the AudioWorklet processor is loaded and ready for playback commands. */
    let workletPlaybackReady = false;
    /** @type {boolean} Flag indicating if the background VAD task is currently running. */
    let isVadProcessing = false;
    /** @type {number} Counter for drag enter/leave events to manage drop zone visibility. */
    let dragCounter = 0;
    /** @type {AudioApp.DTMFParser|null} The DTMF parser instance. */
    let dtmfParser = null;
    /** @type {AudioApp.CallProgressToneParser|null} The Call Progress Tone parser instance. */
    let cptParser = null;

    // --- Main Thread Playback Time State ---
    /** @type {number|null} AudioContext time (in seconds) when playback/seek started. Null if paused. */
    let playbackStartTimeContext = null;
    /** @type {number} Source time (in seconds within the audioBuffer) when playback/seek started. */
    let playbackStartSourceTime = 0.0;
    /** @type {boolean} Tracks if the audio engine is confirmed to be in a playing state. */
    let isActuallyPlaying = false;
    /** @type {number|null} Handle for the requestAnimationFrame UI update loop. Null if not running. */
    let rAFUpdateHandle = null;
    /** @type {number} Current playback speed factor used for UI time estimation. */
    let currentSpeedForUpdate = 1.0;
    /** @type {boolean} Flag indicating if playback ended naturally (reached end of audio). */
    let playbackNaturallyEnded = false;

    // --- Debounced Functions ---
    /** @type {Function|null} Debounced function for synchronizing the audio engine after speed changes. */
    let debouncedSyncEngine = null;
    /** @const @private @type {number} Debounce wait time in milliseconds for engine sync. */
    const SYNC_DEBOUNCE_WAIT_MS = 300;

    /** @const @private @type {number} Debounce wait time in milliseconds for URL hash updates. */
    const DEBOUNCE_HASH_UPDATE_MS = 500;
    /** @type {Function|null} Debounced function for updating the URL hash from current settings. */
    let debouncedUpdateHashFromSettings = null;

    /**
     * Parses application settings from the URL hash.
     * @private
     * @returns {HashSettings} An object containing the parsed settings.
     */
    function parseSettingsFromHash() {
        /** @type {HashSettings} */
        const settings = {};
        const hash = window.location.hash.substring(1);
        if (!hash) return settings;

        const params = new URLSearchParams(hash);

        const speed = params.get(HASH_PARAM_SPEED);
        if (speed !== null && !isNaN(parseFloat(speed))) settings.speed = parseFloat(speed);

        const pitch = params.get(HASH_PARAM_PITCH);
        if (pitch !== null && !isNaN(parseFloat(pitch))) settings.pitch = parseFloat(pitch);

        const vadPositive = params.get(HASH_PARAM_VAD_POSITIVE);
        if (vadPositive !== null && !isNaN(parseFloat(vadPositive))) settings.vadPositive = parseFloat(vadPositive);

        const vadNegative = params.get(HASH_PARAM_VAD_NEGATIVE);
        if (vadNegative !== null && !isNaN(parseFloat(vadNegative))) settings.vadNegative = parseFloat(vadNegative);

        const volume = params.get(HASH_PARAM_VOLUME);
        if (volume !== null && !isNaN(parseFloat(volume))) settings.volume = parseFloat(volume);

        const audioUrl = params.get(HASH_PARAM_AUDIO_URL);
        if (audioUrl !== null && audioUrl !== '') settings.audioUrl = audioUrl;

        const position = params.get(HASH_PARAM_POSITION);
        if (position !== null && !isNaN(parseFloat(position))) settings.position = parseFloat(position);

        console.log('App: Parsed settings from hash:', settings);
        return settings;
    }

    /**
     * Updates the URL hash based on the current application settings.
     * @private
     */
    function updateHashFromSettings() {
        if (!AudioApp.uiManager) return;

        const params = new URLSearchParams();
        let newHash = '';

        try {
            const speed = AudioApp.uiManager.getPlaybackSpeedValue();
            if (speed !== 1.0) params.set(HASH_PARAM_SPEED, speed.toFixed(2));

            const pitch = AudioApp.uiManager.getPitchValue();
            if (pitch !== 1.0) params.set(HASH_PARAM_PITCH, pitch.toFixed(2));

            const vadPositive = AudioApp.uiManager.getVadPositiveThresholdValue();
            if (vadPositive !== 0.5) params.set(HASH_PARAM_VAD_POSITIVE, vadPositive.toFixed(2));

            const vadNegative = AudioApp.uiManager.getVadNegativeThresholdValue();
            if (vadNegative !== 0.35) params.set(HASH_PARAM_VAD_NEGATIVE, vadNegative.toFixed(2));

            const volume = AudioApp.uiManager.getGainValue();
            if (volume !== 1.0) params.set(HASH_PARAM_VOLUME, volume.toFixed(2));

            if (currentDisplayUrl !== null && currentDisplayUrl !== '') {
                params.set(HASH_PARAM_AUDIO_URL, currentDisplayUrl);
            }

            const position = calculateEstimatedSourceTime();
            if (position > 0) { // Save position if it's greater than 0
                params.set(HASH_PARAM_POSITION, position.toFixed(2));
            }

            newHash = params.toString();

            if (newHash) {
                // Using replaceState to avoid flooding browser history during playback.
                // For more persistent hash updates (e.g., on pause or explicit share),
                // window.location.hash might be preferred.
                history.replaceState(null, '', `#${newHash}`);
            } else {
                history.replaceState(null, '', window.location.pathname + window.location.search);
            }
        } catch (e) {
            console.warn('App: Error updating hash from settings.', e);
        }
    }

    /**
     * Initializes the main application.
     * Sets up modules, event listeners, and applies initial settings from URL hash.
     * @public
     * @memberof AudioApp
     */
    function init() {
        console.log("AudioApp: Initializing...");

        if (!AudioApp.uiManager || !AudioApp.audioEngine || !AudioApp.waveformVisualizer ||
            !AudioApp.spectrogramVisualizer || !AudioApp.vadAnalyzer || !AudioApp.sileroWrapper ||
            !AudioApp.Constants || !AudioApp.Utils || !AudioApp.DTMFParser || !AudioApp.CallProgressToneParser) {
             console.error("AudioApp: CRITICAL - One or more required modules not found! Check script loading order.");
             AudioApp.uiManager?.setFileInfo("Initialization Error: Missing modules. Check console.");
             return;
        }

        debouncedSyncEngine = AudioApp.Utils.debounce(syncEngineToEstimatedTime, SYNC_DEBOUNCE_WAIT_MS);
        debouncedUpdateHashFromSettings = AudioApp.Utils.debounce(updateHashFromSettings, DEBOUNCE_HASH_UPDATE_MS);

        AudioApp.uiManager.init();
        setupAppEventListeners();
        initialHashSettings = parseSettingsFromHash();

        // Apply settings from hash before loading audio
        if (initialHashSettings.speed !== undefined) AudioApp.uiManager.setPlaybackSpeedValue(initialHashSettings.speed);
        if (initialHashSettings.pitch !== undefined) AudioApp.uiManager.setPitchValue(initialHashSettings.pitch);
        if (initialHashSettings.volume !== undefined) AudioApp.uiManager.setGainValue(initialHashSettings.volume);
        if (initialHashSettings.vadPositive !== undefined) AudioApp.uiManager.setVadPositiveThresholdValue(initialHashSettings.vadPositive);
        if (initialHashSettings.vadNegative !== undefined) AudioApp.uiManager.setVadNegativeThresholdValue(initialHashSettings.vadNegative);
        // Engine speed/pitch/gain will be set after audio is loaded or worklet is ready.

        if (initialHashSettings.audioUrl) {
            console.log("App: Applying audioUrl from hash:", initialHashSettings.audioUrl);
            currentDisplayUrl = initialHashSettings.audioUrl; // Store it
            AudioApp.uiManager.setAudioUrlInputValue(currentDisplayUrl);

            if (initialHashSettings.audioUrl.startsWith('file:///')) {
                currentUrlStyle = 'error'; // Cannot auto-reload local files
                AudioApp.uiManager.setUrlInputStyle(currentUrlStyle);
                AudioApp.uiManager.setUrlLoadingError("Local files cannot be automatically reloaded from the URL. Please re-select the file.");
            } else {
                AudioApp.uiManager.setUrlInputStyle('modified'); // Indicate it's from hash, about to load
                document.dispatchEvent(new CustomEvent('audioapp:urlSelected', { detail: { url: currentDisplayUrl } }));
            }
        }

        setTimeout(() => { AudioApp.uiManager?.unfocusUrlInput(); }, 100);

        AudioApp.audioEngine.init();
        AudioApp.waveformVisualizer.init();
        AudioApp.spectrogramVisualizer.init(() => currentAudioBuffer);

        if (AudioApp.DTMFParser) dtmfParser = new AudioApp.DTMFParser();
        if (AudioApp.CallProgressToneParser) cptParser = new AudioApp.CallProgressToneParser();

        console.log("AudioApp: Initialized. Waiting for file...");
    }

    /**
     * Sets up global event listeners for the application.
     * @private
     */
    function setupAppEventListeners() {
        document.addEventListener('audioapp:fileSelected', /** @type {EventListener} */ (handleFileSelected));
        document.addEventListener('audioapp:urlSelected', /** @type {EventListener} */ (handleUrlSelected));
        document.addEventListener('audioapp:playPauseClicked', handlePlayPause);
        document.addEventListener('audioapp:jumpClicked', /** @type {EventListener} */ (handleJump));
        document.addEventListener('audioapp:seekRequested', /** @type {EventListener} */ (handleSeek));
        document.addEventListener('audioapp:seekBarInput', /** @type {EventListener} */ (handleSeekBarInput));
        document.addEventListener('audioapp:speedChanged', /** @type {EventListener} */ (handleSpeedChange));
        document.addEventListener('audioapp:pitchChanged', /** @type {EventListener} */ (handlePitchChange));
        document.addEventListener('audioapp:gainChanged', /** @type {EventListener} */ (handleGainChange));
        document.addEventListener('audioapp:thresholdChanged', /** @type {EventListener} */ (handleThresholdChange));
        document.addEventListener('audioapp:keyPressed', /** @type {EventListener} */ (handleKeyPress));

        document.addEventListener('audioapp:audioLoaded', /** @type {EventListener} */ (handleAudioLoaded));
        document.addEventListener('audioapp:workletReady', /** @type {EventListener} */ (handleWorkletReady));
        document.addEventListener('audioapp:decodingError', /** @type {EventListener} */ (handleAudioError));
        document.addEventListener('audioapp:resamplingError', /** @type {EventListener} */ (handleAudioError));
        document.addEventListener('audioapp:playbackError', /** @type {EventListener} */ (handleAudioError));
        document.addEventListener('audioapp:engineError', /** @type {EventListener} */ (handleAudioError));
        document.addEventListener('audioapp:playbackEnded', handlePlaybackEnded);
        document.addEventListener('audioapp:playbackStateChanged', /** @type {EventListener} */ (handlePlaybackStateChange));
        document.addEventListener('audioapp:internalSpeedChanged', /** @type {EventListener} */ (handleInternalSpeedChange));

        window.addEventListener('resize', handleWindowResize);
        window.addEventListener('beforeunload', handleBeforeUnload);
        window.addEventListener('dragenter', handleDragEnter);
        window.addEventListener('dragover', handleDragOver);
        window.addEventListener('dragleave', handleDragLeave);
        window.addEventListener('drop', handleDrop);
    }


    // --- Drag and Drop Event Handlers ---
    /**
     * Handles the dragenter event for file drag-and-drop.
     * @private
     * @param {DragEvent} event - The drag event.
     */
    function handleDragEnter(event) {
        event.preventDefault();
        event.stopPropagation();
        dragCounter++;
        if (dragCounter === 1 && event.dataTransfer?.items) {
            let filePresent = false;
            for (let i = 0; i < event.dataTransfer.items.length; i++) {
                if (event.dataTransfer.items[i].kind === 'file') {
                    filePresent = true;
                    break;
                }
            }
            if (filePresent && event.dataTransfer.files.length > 0) {
                AudioApp.uiManager.showDropZone(event.dataTransfer.files[0]);
            }
        }
    }

    /**
     * Handles the dragover event for file drag-and-drop.
     * @private
     * @param {DragEvent} event - The drag event.
     */
    function handleDragOver(event) {
        event.preventDefault();
        event.stopPropagation();
        if (event.dataTransfer) event.dataTransfer.dropEffect = 'copy';
    }

    /**
     * Handles the dragleave event for file drag-and-drop.
     * @private
     * @param {DragEvent} event - The drag event.
     */
    function handleDragLeave(event) {
        event.preventDefault();
        event.stopPropagation();
        dragCounter--;
        if (dragCounter === 0) {
            AudioApp.uiManager.hideDropZone();
        }
    }

    /**
     * Handles the drop event for file drag-and-drop.
     * @private
     * @param {DragEvent} event - The drop event.
     */
    function handleDrop(event) {
        event.preventDefault();
        event.stopPropagation();
        AudioApp.uiManager.hideDropZone();
        dragCounter = 0;

        const files = event.dataTransfer?.files;
        if (files && files.length > 0) {
            const file = files[0];
            if (file.type.startsWith('audio/')) {
                console.log("App: File dropped -", file.name);
                document.dispatchEvent(new CustomEvent('audioapp:fileSelected', { detail: { file: file } }));
            } else {
                console.warn("App: Invalid file type dropped -", file.name, file.type);
                AudioApp.uiManager.setFileInfo("Invalid file type. Please drop an audio file.");
            }
        }
    }

    /**
     * Handles the 'audioapp:fileSelected' event.
     * Resets application state and initiates loading of the selected file.
     * @private
     * @param {CustomEvent<{file: File}>} e - The event object.
     */
    async function handleFileSelected(e) {
        const file = e.detail.file; if (!file) return;

        const previousDisplayUrl = currentDisplayUrl;
        const newDisplayUrl = 'file:///' + file.name; // For display purposes

        currentFile = file;
        currentDisplayUrl = newDisplayUrl;
        currentUrlStyle = 'file';

        console.log("App: File selected -", file.name);
        resetAudioStateAndUI(file.name, newDisplayUrl !== previousDisplayUrl);

        try {
            await AudioApp.audioEngine.loadAndProcessFile(file);
        } catch (error) {
            console.error("App: Error initiating file processing -", error);
            AudioApp.uiManager.setFileInfo(`Error loading: ${error?.message || 'Unknown error'}`);
            AudioApp.uiManager.resetUI(); // Full UI reset on critical load error
            AudioApp.spectrogramVisualizer.showSpinner(false);
            stopUIUpdateLoop();
        }
    }

    /**
     * Handles the 'audioapp:urlSelected' event.
     * Resets application state and initiates loading of the audio from the URL.
     * @private
     * @param {CustomEvent<{url: string}>} e - The event object.
     */
    async function handleUrlSelected(e) {
        const newUrlFromEvent = e.detail.url;
        const previousDisplayUrl = currentDisplayUrl;

        currentDisplayUrl = newUrlFromEvent;
        currentUrlStyle = 'default'; // Initial style while loading

        if (!currentDisplayUrl) {
            console.warn("App: URL selected event received, but URL is empty.");
            AudioApp.uiManager.setAudioUrlInputValue("");
            AudioApp.uiManager.setUrlInputStyle('error');
            AudioApp.uiManager.setFileInfo("Error: No URL provided.");
            return;
        }
        console.log("App: URL selected -", currentDisplayUrl);
        AudioApp.uiManager.setUrlLoadingError("");

        let filename = "loaded_from_url";
        try {
            const urlPath = new URL(currentDisplayUrl).pathname;
            const lastSegment = urlPath.substring(urlPath.lastIndexOf('/') + 1);
            if (lastSegment) filename = decodeURIComponent(lastSegment);
        } catch (urlError) {
            filename = currentDisplayUrl; // Use full URL if parsing fails
        }

        resetAudioStateAndUI(filename, newUrlFromEvent !== previousDisplayUrl, true);
        AudioApp.uiManager.setAudioUrlInputValue(currentDisplayUrl); // Ensure input shows the URL being loaded

        try {
            AudioApp.uiManager.setFileInfo(`Fetching: ${filename}...`);
            const response = await fetch(currentDisplayUrl);
            if (!response.ok) throw new Error(`Network response was not ok: ${response.status} ${response.statusText}`);

            const arrayBuffer = await response.arrayBuffer();
            AudioApp.uiManager.setFileInfo(`Processing: ${filename}...`);

            let mimeType = response.headers.get('Content-Type')?.split(';')[0] || 'audio/*';
            // Fallback or refine mimeType based on extension if necessary
            const ext = filename.substring(filename.lastIndexOf('.') + 1).toLowerCase();
            if (mimeType === 'application/octet-stream' || mimeType === 'audio/*') { // Common generic types
                if (ext === 'mp3') mimeType = 'audio/mpeg';
                else if (ext === 'wav') mimeType = 'audio/wav';
                else if (ext === 'ogg') mimeType = 'audio/ogg';
            }

            const newFileObject = new File([arrayBuffer], filename, { type: mimeType });
            currentFile = newFileObject; // Store the fetched content as a File object

            await AudioApp.audioEngine.loadAndProcessFile(newFileObject);
            currentUrlStyle = 'success';
            AudioApp.uiManager.setUrlInputStyle(currentUrlStyle);
            debouncedUpdateHashFromSettings();
        } catch (error) {
            console.error(`App: Error fetching/processing URL ${currentDisplayUrl}:`, error);
            AudioApp.uiManager.resetUI(); // Full UI reset
            currentUrlStyle = 'error';
            AudioApp.uiManager.setAudioUrlInputValue(currentDisplayUrl);
            AudioApp.uiManager.setUrlInputStyle(currentUrlStyle);
            AudioApp.uiManager.setUrlLoadingError(`Error loading from URL. (${error?.message?.substring(0,100) || 'Unknown error'})`);
            AudioApp.uiManager.setFileInfo("Failed to load audio from URL.");
            AudioApp.spectrogramVisualizer.showSpinner(false);
            stopUIUpdateLoop();
            currentFile = null;
        }
    }

    /**
     * Resets audio-related state and parts of the UI.
     * @private
     * @param {string} displayName - The name to display for the file/URL.
     * @param {boolean} fullUIRestart - Whether to perform a full UI reset or a partial one.
     * @param {boolean} [isUrl=false] - Indicates if loading from a URL.
     */
    function resetAudioStateAndUI(displayName, fullUIRestart, isUrl = false) {
        stopUIUpdateLoop();
        isActuallyPlaying = false; playbackNaturallyEnded = false; isVadProcessing = false;
        playbackStartTimeContext = null; playbackStartSourceTime = 0.0;
        currentSpeedForUpdate = 1.0; currentAudioBuffer = null;
        currentVadResults = null; workletPlaybackReady = false;
        if (!isUrl) currentFile = null; // Clear file object only if not a URL load (URL load will set it)

        if (fullUIRestart) {
            AudioApp.uiManager.resetUI();
        } else {
            // Partial reset: preserve speed/pitch/gain, reset time, VAD, etc.
            AudioApp.uiManager.updateTimeDisplay(0, 0);
            AudioApp.uiManager.updateSeekBar(0);
            AudioApp.uiManager.setSpeechRegionsText("None");
            AudioApp.uiManager.showVadProgress(false);
            AudioApp.uiManager.updateVadProgress(0);
            AudioApp.uiManager.setUrlLoadingError("");
        }
        AudioApp.uiManager.updateFileName(displayName);
        AudioApp.uiManager.setFileInfo(`Loading: ${displayName}...`);
        AudioApp.uiManager.setAudioUrlInputValue(currentDisplayUrl || ""); // currentDisplayUrl might be set by caller
        AudioApp.uiManager.setUrlInputStyle(currentUrlStyle); // currentUrlStyle might be set by caller

        AudioApp.waveformVisualizer.clearVisuals();
        AudioApp.spectrogramVisualizer.clearVisuals();
        AudioApp.spectrogramVisualizer.showSpinner(true); // Spinner shown during load

        debouncedUpdateHashFromSettings();
    }


        /**
     * Handles audio decoding completion.
     * This is the central point for kicking off all parallel analysis tasks.
     * @private
     * @param {CustomEvent<{audioBuffer: AudioBuffer}>} e - The event object.
     */
    async function handleAudioLoaded(e) {
        currentAudioBuffer = e.detail.audioBuffer;
        console.log(`App: Audio decoded (${currentAudioBuffer.duration.toFixed(2)}s). Starting parallel analysis.`);

        // --- 1. Basic UI Setup (Instant) ---
        AudioApp.uiManager.updateTimeDisplay(0, currentAudioBuffer.duration);
        AudioApp.uiManager.updateSeekBar(0);
        AudioApp.waveformVisualizer.updateProgressIndicator(0, currentAudioBuffer.duration);
        AudioApp.spectrogramVisualizer.updateProgressIndicator(0, currentAudioBuffer.duration);
        playbackStartSourceTime = 0.0;

        // Apply current UI settings to the engine
        if (AudioApp.audioEngine && AudioApp.uiManager) {
            AudioApp.audioEngine.setSpeed(AudioApp.uiManager.getPlaybackSpeedValue());
            AudioApp.audioEngine.setPitch(AudioApp.uiManager.getPitchValue());
            AudioApp.audioEngine.setGain(AudioApp.uiManager.getGainValue());
        }

        // --- 2. Draw Waveform First (Fastest visual feedback) ---
        // We can await this as it's quick and provides the first visual confirmation.
        await AudioApp.waveformVisualizer.computeAndDrawWaveform(currentAudioBuffer, []);

        // --- 3. Launch All Long-Running Tasks Concurrently ---
        // We DO NOT await these calls. We want them to start immediately and run in the background.
        // The main thread is now free to handle user input.

        console.log("App: Kicking off Spectrogram, VAD, and Tone analysis in parallel.");

        // A. Start Spectrogram Worker
        AudioApp.spectrogramVisualizer.computeAndDrawSpectrogram(currentAudioBuffer);

        // B. Start VAD Analysis
        runVadInBackground(currentAudioBuffer);

        // C. Start Tone Detection Analysis
        if (dtmfParser || cptParser) {
            processAudioForTones(currentAudioBuffer);
        }

        // --- 4. Update File Info ---
        // The UI now shows "Processing..." while the background tasks run.
        AudioApp.uiManager.setFileInfo(`Processing Analyses: ${currentFile?.name || currentDisplayUrl || 'Loaded Audio'}`);

        // If a local file was loaded, ensure its "file:///" URL is displayed correctly.
        if (currentFile && currentDisplayUrl && currentUrlStyle === 'file') {
            AudioApp.uiManager.setAudioUrlInputValue(currentDisplayUrl);
            AudioApp.uiManager.setUrlInputStyle(currentUrlStyle);
        }
    }

    /**
     * Handles the 'audioapp:workletReady' event. Enables playback controls.
     * @private
     * @param {CustomEvent} e - The event object.
     */
    function handleWorkletReady(e) {
        console.log("App: AudioWorklet processor is ready.");
        workletPlaybackReady = true;
        AudioApp.uiManager.enablePlaybackControls(true);
        AudioApp.uiManager.enableSeekBar(true);
        AudioApp.uiManager.setFileInfo(`Ready: ${currentFile?.name || currentDisplayUrl || 'Loaded Audio'}`);
        AudioApp.uiManager.unfocusUrlInput();

        // Re-affirm engine parameters from UI (might have changed or from hash)
        if (AudioApp.audioEngine && AudioApp.uiManager) {
            AudioApp.audioEngine.setSpeed(AudioApp.uiManager.getPlaybackSpeedValue());
            AudioApp.audioEngine.setPitch(AudioApp.uiManager.getPitchValue());
            AudioApp.audioEngine.setGain(AudioApp.uiManager.getGainValue());
        }

        // Apply position from hash settings if available and audio buffer exists
        if (initialHashSettings.position !== undefined && currentAudioBuffer) {
            const targetTime = Math.max(0, Math.min(initialHashSettings.position, currentAudioBuffer.duration));
            console.log(`App: Restoring position from hash: ${targetTime.toFixed(3)}s`);
            AudioApp.audioEngine.seek(targetTime);
            playbackStartSourceTime = targetTime;
            playbackStartTimeContext = null; // Not playing yet
            updateUIWithTime(targetTime);
        }
        initialHashSettings = {}; // Clear after use
    }

    /**
     * Runs VAD analysis in the background.
     * @private
     * @param {AudioBuffer} audioBuffer - The audio buffer to analyze.
     * @returns {Promise<void>}
     */
     async function runVadInBackground(audioBuffer) {
        if (!audioBuffer || !AudioApp.vadAnalyzer || !AudioApp.sileroWrapper || !AudioApp.audioEngine || !AudioApp.uiManager || !AudioApp.waveformVisualizer) {
             console.error("App (VAD): Missing dependencies for VAD task.");
             isVadProcessing = false; return;
        }
        if (isVadProcessing) { console.warn("App (VAD): Processing already running."); return; }
        isVadProcessing = true;
        /** @type {Float32Array|null} */ let pcm16k = null;

        try {
            if (!vadModelReady) {
                vadModelReady = await AudioApp.sileroWrapper.create(AudioApp.Constants.VAD_SAMPLE_RATE);
                if (!vadModelReady) throw new Error("Failed to create Silero VAD model.");
            }
            AudioApp.uiManager.showVadProgress(true); AudioApp.uiManager.updateVadProgress(0);
            pcm16k = await AudioApp.audioEngine.resampleTo16kMono(audioBuffer);
            if (!pcm16k || pcm16k.length === 0) {
                 AudioApp.uiManager.setSpeechRegionsText("No VAD data (empty audio?)");
                 AudioApp.uiManager.updateVadProgress(100); AudioApp.uiManager.enableVadControls(false);
                 isVadProcessing = false; return;
            }
            /** @type {function({processedFrames: number, totalFrames: number}): void} */
            const vadProgressCallback = (progress) => {
                 if (!AudioApp.uiManager) return;
                 const percentage = progress.totalFrames > 0 ? (progress.processedFrames / progress.totalFrames) * 100 : 0;
                 AudioApp.uiManager.updateVadProgress(percentage);
            };
            currentVadResults = await AudioApp.vadAnalyzer.analyze(pcm16k, { onProgress: vadProgressCallback });
            const speechRegions = currentVadResults.regions || [];
            AudioApp.uiManager.updateVadDisplay(currentVadResults.initialPositiveThreshold, currentVadResults.initialNegativeThreshold);
            AudioApp.uiManager.setSpeechRegionsText(speechRegions);
            AudioApp.uiManager.enableVadControls(true);
            // Apply current UI VAD thresholds to the analyzer post-analysis
            handleThresholdChange({ detail: { type: 'positive', value: AudioApp.uiManager.getVadPositiveThresholdValue() } });
            handleThresholdChange({ detail: { type: 'negative', value: AudioApp.uiManager.getVadNegativeThresholdValue() } });
            AudioApp.waveformVisualizer.redrawWaveformHighlight(audioBuffer, speechRegions);
            AudioApp.uiManager.updateVadProgress(100);
        } catch (error) {
            console.error("App (VAD): Error during VAD processing -", error);
            AudioApp.uiManager.setSpeechRegionsText(`VAD Error: ${error?.message || 'Unknown error'}`);
            AudioApp.uiManager.enableVadControls(false); AudioApp.uiManager.updateVadProgress(0);
            currentVadResults = null;
        } finally {
            isVadProcessing = false;
        }
    }

    /**
     * Resamples audio and processes it for DTMF and Call Progress Tones.
     * @private
     * @param {AudioBuffer} audioBuffer - The audio buffer to process.
     * @returns {Promise<void>}
     */
    async function processAudioForTones(audioBuffer) {
        if (!audioBuffer || !AudioApp.audioEngine || !AudioApp.uiManager || (!dtmfParser && !cptParser) ) {
            console.warn("App (Tones): Missing dependencies or parsers for tone processing.");
            return;
        }
        const pcmSampleRate = AudioApp.DTMFParser.DTMF_SAMPLE_RATE || 16000; // Use constant from parser
        const pcmBlockSize = AudioApp.DTMFParser.DTMF_BLOCK_SIZE || 410;   // Use constant from parser
        /** @type {Float32Array|null} */ let pcmData = null;

        try {
            pcmData = await AudioApp.audioEngine.resampleTo16kMono(audioBuffer);
            if (!pcmData || pcmData.length === 0) {
                if (dtmfParser) AudioApp.uiManager.updateDtmfDisplay("DTMF: No audio data.");
                if (cptParser) AudioApp.uiManager.updateCallProgressTonesDisplay(["CPT: No audio data."]);
                return;
            }
        } catch (error) {
            if (dtmfParser) AudioApp.uiManager.updateDtmfDisplay(`DTMF Error: ${error?.message?.substring(0,100) || 'Resample error'}`);
            if (cptParser) AudioApp.uiManager.updateCallProgressTonesDisplay([`CPT Error: ${error?.message?.substring(0,100) || 'Resample error'}`]);
            return;
        }

        if (dtmfParser) {
            AudioApp.uiManager.updateDtmfDisplay("Processing DTMF...");
            try {
                /** @type {string[]} */ const detectedDtmfTones = [];
                /** @type {string|null} */ let lastDetectedDtmf = null;
                let consecutiveDtmfDetections = 0;
                const minConsecutiveDtmf = 2; // Require a tone to be present for at least 2 blocks

                for (let i = 0; (i + pcmBlockSize) <= pcmData.length; i += pcmBlockSize) {
                    const audioBlock = pcmData.subarray(i, i + pcmBlockSize);
                    const tone = dtmfParser.processAudioBlock(audioBlock);
                    if (tone) {
                        if (tone === lastDetectedDtmf) {
                            consecutiveDtmfDetections++;
                        } else {
                            lastDetectedDtmf = tone;
                            consecutiveDtmfDetections = 1;
                        }
                        if (consecutiveDtmfDetections === minConsecutiveDtmf) {
                            // Add tone only once when it's confirmed, and only if it's different from the last added tone
                            if (detectedDtmfTones.length === 0 || detectedDtmfTones[detectedDtmfTones.length - 1] !== tone) {
                                detectedDtmfTones.push(tone);
                            }
                        }
                    } else {
                        lastDetectedDtmf = null; // Reset if no tone or different tone
                        consecutiveDtmfDetections = 0;
                    }
                }
                AudioApp.uiManager.updateDtmfDisplay(detectedDtmfTones.length > 0 ? detectedDtmfTones : "No DTMF detected.");
            } catch (error) {
                AudioApp.uiManager.updateDtmfDisplay(`DTMF Error: ${error?.message?.substring(0,100) || 'Processing error'}`);
            }
        }

        if (cptParser) {
            AudioApp.uiManager.updateCallProgressTonesDisplay(["Processing CPTs..."]);
            try {
                /** @type {Set<string>} */ const detectedCptSet = new Set();
                for (let i = 0; (i + pcmBlockSize) <= pcmData.length; i += pcmBlockSize) {
                    const audioBlock = pcmData.subarray(i, i + pcmBlockSize);
                    const toneName = cptParser.processAudioBlock(audioBlock);
                    if (toneName) detectedCptSet.add(toneName);
                }
                AudioApp.uiManager.updateCallProgressTonesDisplay(detectedCptSet.size > 0 ? Array.from(detectedCptSet) : ["No CPTs detected."]);
            } catch (error) {
                AudioApp.uiManager.updateCallProgressTonesDisplay([`CPT Error: ${error?.message?.substring(0,100) || 'Processing error'}`]);
            }
        }
    }

    /**
     * Handles generic audio errors from the engine or processing stages.
     * @private
     * @param {CustomEvent<{type?: string, error: Error}>} e - The event object.
     */
    function handleAudioError(e) {
        const errorType = e.detail.type || 'Unknown Error';
        const errorMessage = e.detail.error?.message || 'An unknown error occurred';
        console.error(`App: Audio Error - Type: ${errorType}, Message: ${errorMessage}`, e.detail.error);
        stopUIUpdateLoop();
        AudioApp.uiManager.setFileInfo(`Error (${errorType}): ${errorMessage.substring(0, 100)}`);
        AudioApp.uiManager.resetUI(); // Full UI reset
        AudioApp.waveformVisualizer?.clearVisuals();
        AudioApp.spectrogramVisualizer?.clearVisuals();
        AudioApp.spectrogramVisualizer?.showSpinner(false);
        currentAudioBuffer = null; currentVadResults = null; currentFile = null;
        workletPlaybackReady = false; isActuallyPlaying = false; isVadProcessing = false;
        playbackStartTimeContext = null; playbackStartSourceTime = 0.0; currentSpeedForUpdate = 1.0;
    }

    /**
     * Handles play/pause button clicks. Manages playback state and UI synchronization.
     * @private
     */
    function handlePlayPause() {
        if (!workletPlaybackReady || !AudioApp.audioEngine) {
            console.warn("App: Play/Pause ignored - Engine/Worklet not ready."); return;
        }
        const audioCtx = AudioApp.audioEngine.getAudioContext();
        if (!audioCtx) { console.error("App: Cannot play/pause, AudioContext not available."); return; }

        const aboutToPlay = !isActuallyPlaying;

        if (!aboutToPlay) { // Requesting Pause
            playbackNaturallyEnded = false;
            const finalEstimatedTime = calculateEstimatedSourceTime();
            AudioApp.audioEngine.seek(finalEstimatedTime); // Sync engine to precise time
            playbackStartSourceTime = finalEstimatedTime; // Update our base time
            playbackStartTimeContext = null; // Mark as paused for time calculation
            stopUIUpdateLoop();
            updateUIWithTime(finalEstimatedTime); // Update UI immediately
            debouncedUpdateHashFromSettings(); // Update hash on pause
        }
        // For play, time base and UI loop are handled in 'playbackStateChanged'
        AudioApp.audioEngine.togglePlayPause(); // Request engine to toggle state
    }

    /**
     * Handles jump (forward/backward) button clicks.
     * @private
     * @param {CustomEvent<{seconds: number}>} e - The event object.
     */
    function handleJump(e) {
        playbackNaturallyEnded = false;
        if (!workletPlaybackReady || !currentAudioBuffer || !AudioApp.audioEngine) return;
        const audioCtx = AudioApp.audioEngine.getAudioContext(); if (!audioCtx) return;
        const duration = currentAudioBuffer.duration;
        if (isNaN(duration) || duration <= 0) return;

        const currentTime = calculateEstimatedSourceTime();
        const targetTime = Math.max(0, Math.min(currentTime + e.detail.seconds, duration));
        AudioApp.audioEngine.seek(targetTime);
        playbackStartSourceTime = targetTime;
        if (isActuallyPlaying) {
            playbackStartTimeContext = audioCtx.currentTime;
        } else {
            playbackStartTimeContext = null; updateUIWithTime(targetTime);
        }
        debouncedUpdateHashFromSettings();
    }

    /**
     * Handles seek requests from UI elements (e.g., spectrogram click, seek bar input).
     * @private
     * @param {CustomEvent<{fraction: number}>} e - The event object.
     */
    function handleSeek(e) {
        playbackNaturallyEnded = false;
        if (!workletPlaybackReady || !currentAudioBuffer || isNaN(currentAudioBuffer.duration) || currentAudioBuffer.duration <= 0 || !AudioApp.audioEngine) return;
        const audioCtx = AudioApp.audioEngine.getAudioContext(); if (!audioCtx) return;

        const targetTime = e.detail.fraction * currentAudioBuffer.duration;
        AudioApp.audioEngine.seek(targetTime);
        playbackStartSourceTime = targetTime;
        if (isActuallyPlaying) {
            playbackStartTimeContext = audioCtx.currentTime;
        } else {
            playbackStartTimeContext = null; updateUIWithTime(targetTime);
        }
        debouncedUpdateHashFromSettings();
    }
    /** Alias for handleSeek, used by seek bar 'input' event. @private */
    const handleSeekBarInput = handleSeek;

    /**
     * Handles speed changes from the UI slider.
     * @private
     * @param {CustomEvent<{speed: number}>} e - The event object.
     */
    function handleSpeedChange(e) {
        if (!AudioApp.audioEngine) return;
        AudioApp.audioEngine.setSpeed(e.detail.speed);
        if (debouncedSyncEngine) debouncedSyncEngine(); // Sync engine after a short delay
        debouncedUpdateHashFromSettings();
    }

    /**
     * Handles pitch changes from the UI slider.
     * @private
     * @param {CustomEvent<{pitch: number}>} e - The event object.
     */
    function handlePitchChange(e) {
        if (!AudioApp.audioEngine) return;
        AudioApp.audioEngine.setPitch(e.detail.pitch);
        debouncedUpdateHashFromSettings();
    }

    /**
     * Handles gain changes from the UI slider.
     * @private
     * @param {CustomEvent<{gain: number}>} e - The event object.
     */
    function handleGainChange(e) {
        if (!AudioApp.audioEngine) return;
        AudioApp.audioEngine.setGain(e.detail.gain);
        debouncedUpdateHashFromSettings();
    }

    /**
     * Synchronizes the audio engine's current time to the main thread's estimated time.
     * Called debounced after speed changes.
     * @private
     */
    function syncEngineToEstimatedTime() {
        if (!workletPlaybackReady || !currentAudioBuffer || !AudioApp.audioEngine) return;
        const audioCtx = AudioApp.audioEngine.getAudioContext(); if (!audioCtx) return;

        const targetTime = calculateEstimatedSourceTime();
        AudioApp.audioEngine.seek(targetTime);
        playbackStartSourceTime = targetTime;
        if (isActuallyPlaying) {
            playbackStartTimeContext = audioCtx.currentTime;
        } else {
            playbackStartTimeContext = null; updateUIWithTime(targetTime);
        }
    }

    /**
     * Handles internal speed changes confirmed by the audio engine.
     * Adjusts time tracking base to prevent UI jumps.
     * @private
     * @param {CustomEvent<{speed: number}>} e - The event object.
     */
    function handleInternalSpeedChange(e) {
        const newSpeed = e.detail.speed;
        const oldSpeed = currentSpeedForUpdate;
        currentSpeedForUpdate = newSpeed;

        const audioCtx = AudioApp.audioEngine?.getAudioContext();
        if (isActuallyPlaying && playbackStartTimeContext !== null && audioCtx) {
            const elapsedContextTime = audioCtx.currentTime - playbackStartTimeContext;
            const elapsedSourceTime = elapsedContextTime * oldSpeed;
            const previousSourceTime = playbackStartSourceTime + elapsedSourceTime;
            playbackStartSourceTime = previousSourceTime;
            playbackStartTimeContext = audioCtx.currentTime;
        }
    }

    /**
     * Handles VAD threshold changes from the UI.
     * @private
     * @param {CustomEvent<{type: string, value: number}>} e - The event object.
     */
    function handleThresholdChange(e) {
        if (!currentVadResults || isVadProcessing || !AudioApp.vadAnalyzer || !AudioApp.waveformVisualizer || !currentAudioBuffer) return;
        const { type, value } = e.detail;
        const newRegions = AudioApp.vadAnalyzer.handleThresholdUpdate(type, value);
        AudioApp.uiManager.setSpeechRegionsText(newRegions);
        AudioApp.waveformVisualizer.redrawWaveformHighlight(currentAudioBuffer, newRegions);
        debouncedUpdateHashFromSettings();
    }

    /**
     * Handles the 'audioapp:playbackEnded' event from the audio engine.
     * @private
     */
    function handlePlaybackEnded() {
        console.log("App: Playback ended event received.");
        isActuallyPlaying = false; stopUIUpdateLoop(); playbackStartTimeContext = null;
        if (currentAudioBuffer) {
             playbackStartSourceTime = currentAudioBuffer.duration;
             updateUIWithTime(currentAudioBuffer.duration);
        }
        playbackNaturallyEnded = true;
        AudioApp.uiManager.setPlayButtonState(false);
        debouncedUpdateHashFromSettings();
    }

    /**
     * Handles playback state changes confirmed by the audio engine.
     * @private
     * @param {CustomEvent<{isPlaying: boolean}>} e - The event object.
     */
     function handlePlaybackStateChange(e) {
        const workletIsPlaying = e.detail.isPlaying;
        const wasPlaying = isActuallyPlaying;
        isActuallyPlaying = workletIsPlaying;
        AudioApp.uiManager.setPlayButtonState(isActuallyPlaying);

        if (isActuallyPlaying) {
            const audioCtx = AudioApp.audioEngine?.getAudioContext();
            if (!wasPlaying && audioCtx) { // Transitioned from not playing to playing
                if (playbackNaturallyEnded && currentAudioBuffer) {
                    playbackStartSourceTime = 0; // Restart from beginning
                    playbackNaturallyEnded = false;
                } else {
                    // Resuming or starting normally, use engine's current time
                    playbackStartSourceTime = AudioApp.audioEngine.getCurrentTime().currentTime;
                }
                playbackStartTimeContext = audioCtx.currentTime;
                updateUIWithTime(playbackStartSourceTime); // Update UI immediately
            }
            startUIUpdateLoop();
        } else { // Transitioned to not playing
            stopUIUpdateLoop();
            playbackStartTimeContext = null; // Mark as paused for time calculation
            // UI time sync for pause is handled in handlePlayPause
        }
    }

    /**
     * Handles global key press events for shortcuts.
     * @private
     * @param {CustomEvent<{key: string}>} e - The event object.
     */
    function handleKeyPress(e) {
        if (!workletPlaybackReady) return;
        const key = e.detail.key;
        const jumpTimeValue = AudioApp.uiManager.getJumpTime();
        switch (key) {
            case 'Space': handlePlayPause(); break;
            case 'ArrowLeft': handleJump({ detail: { seconds: -jumpTimeValue } }); break;
            case 'ArrowRight': handleJump({ detail: { seconds: jumpTimeValue } }); break;
        }
    }

    /**
     * Handles window resize events to redraw visualizations.
     * @private
     */
    function handleWindowResize() {
        const regions = AudioApp.vadAnalyzer ? AudioApp.vadAnalyzer.getCurrentRegions() : [];
        AudioApp.waveformVisualizer?.resizeAndRedraw(currentAudioBuffer, regions);
        AudioApp.spectrogramVisualizer?.resizeAndRedraw(currentAudioBuffer);
    }

    /**
     * Handles the 'beforeunload' event to clean up resources.
     * @private
     */
    function handleBeforeUnload() {
        console.log("App: Unloading...");
        stopUIUpdateLoop();
        AudioApp.audioEngine?.cleanup();
    }


    /**
     * Starts the UI update loop using requestAnimationFrame.
     * @private
     */
    function startUIUpdateLoop() {
        if (rAFUpdateHandle === null) {
            rAFUpdateHandle = requestAnimationFrame(updateUIBasedOnContextTime);
        }
    }

    /**
     * Stops the UI update loop.
     * @private
     */
    function stopUIUpdateLoop() {
        if (rAFUpdateHandle !== null) {
            cancelAnimationFrame(rAFUpdateHandle);
            rAFUpdateHandle = null;
        }
    }

    /**
     * Calculates the estimated current source time based on AudioContext time and playback speed.
     * @private
     * @returns {number} The estimated current time in seconds within the audio source.
     */
    function calculateEstimatedSourceTime() {
        const audioCtx = AudioApp.audioEngine?.getAudioContext();
        const duration = currentAudioBuffer ? currentAudioBuffer.duration : 0;

        if (!isActuallyPlaying || playbackStartTimeContext === null || !audioCtx || !currentAudioBuffer || duration <= 0 || currentSpeedForUpdate <= 0) {
            return playbackStartSourceTime; // Return base time if not playing, speed is zero/negative, or essential info missing
        }

        const elapsedContextTime = audioCtx.currentTime - playbackStartTimeContext;
        const elapsedSourceTime = elapsedContextTime * currentSpeedForUpdate;
        let estimatedCurrentSourceTime = playbackStartSourceTime + elapsedSourceTime;
        return Math.max(0, Math.min(estimatedCurrentSourceTime, duration)); // Clamp to valid range
    }

    /**
     * Updates UI elements related to time (display, seek bar, visualizer progress).
     * @private
     * @param {number} time - The current source time to display.
     */
    function updateUIWithTime(time) {
        const duration = currentAudioBuffer ? currentAudioBuffer.duration : 0;
        if (isNaN(duration)) return;
        const clampedTime = Math.max(0, Math.min(time, duration));
        const fraction = duration > 0 ? clampedTime / duration : 0;
        AudioApp.uiManager.updateTimeDisplay(clampedTime, duration);
        AudioApp.uiManager.updateSeekBar(fraction);
        AudioApp.waveformVisualizer?.updateProgressIndicator(clampedTime, duration);
        AudioApp.spectrogramVisualizer?.updateProgressIndicator(clampedTime, duration);
    }

    /**
     * The main UI update loop function, called via requestAnimationFrame.
     * Calculates estimated time and updates UI elements. Also handles periodic hash updates.
     * @private
     * @param {DOMHighResTimeStamp} timestamp - The timestamp provided by requestAnimationFrame.
     */
    function updateUIBasedOnContextTime(timestamp) {
        if (!isActuallyPlaying) {
            rAFUpdateHandle = null; return; // Stop loop if not playing
        }
        const estimatedTime = calculateEstimatedSourceTime();
        updateUIWithTime(estimatedTime);

        const currentTime = performance.now();
        if (currentTime - lastHashUpdateTime > 3000 && debouncedUpdateHashFromSettings) { // Update hash roughly every 3 seconds
            debouncedUpdateHashFromSettings();
            lastHashUpdateTime = currentTime;
        }
        rAFUpdateHandle = requestAnimationFrame(updateUIBasedOnContextTime);
    }

    /**
     * @typedef {Object} AppPublicInterface
     * @property {function(): void} init - Initializes the application.
     */

    /** @type {AppPublicInterface} */
    return {
        init: init
    };
})();
// --- /vibe-player/js/app.js ---

````
--- End of File: vibe-player/js/app.js ---
--- File: vibe-player/js/constants.js ---
````javascript
// --- /vibe-player/js/constants.js ---
// Defines shared constants for the Vibe Player application.

/** @namespace AudioApp */
var AudioApp = AudioApp || {}; // Ensure main namespace exists

/**
 * @namespace AudioApp.Constants
 * @description Shared constants for the Vibe Player application.
 * @property {string} PROCESSOR_SCRIPT_URL - Path to the Rubberband processor script.
 * @property {string} PROCESSOR_NAME - Name of the AudioWorklet processor.
 * @property {string} WASM_BINARY_URL - Path to the WebAssembly binary for Rubberband.
 * @property {string} LOADER_SCRIPT_URL - Path to the Rubberband loader script.
 * @property {number} VAD_SAMPLE_RATE - Sample rate required by the Silero VAD model (Hz).
 * @property {number} DEFAULT_VAD_FRAME_SAMPLES - Default number of samples per VAD frame.
 * @property {number} VAD_PROGRESS_REPORT_INTERVAL - Interval (in frames) for reporting VAD progress.
 * @property {number} VAD_YIELD_INTERVAL - Interval (in frames) to yield the main thread during VAD.
 * @property {number} WAVEFORM_HEIGHT_SCALE - Vertical space (0-1) used by the waveform.
 * @property {string} WAVEFORM_COLOR_LOADING - Waveform color before VAD analysis.
 * @property {string} WAVEFORM_COLOR_DEFAULT - Waveform color for non-speech segments.
 * @property {string} WAVEFORM_COLOR_SPEECH - Waveform color for speech segments.
 * @property {number} SPEC_NORMAL_FFT_SIZE - Default FFT size for spectrograms.
 * @property {number} SPEC_SHORT_FFT_SIZE - FFT size for short audio files in spectrograms.
 * @property {number} SPEC_SHORT_FILE_FFT_THRESHOLD_S - Threshold (seconds) to use shorter FFT size.
 * @property {number[]} SPEC_MAX_FREQS - Array of maximum frequencies (Hz) for spectrogram display.
 * @property {number} SPEC_DEFAULT_MAX_FREQ_INDEX - Default index for SPEC_MAX_FREQS array.
 * @property {number} SPEC_FIXED_WIDTH - Internal calculation width (slices) for spectrograms.
 * @property {number} SPEC_SHORT_FILE_HOP_THRESHOLD_S - Threshold (seconds) to use smaller hop size for short files.
 * @property {number} SPEC_NORMAL_HOP_DIVISOR - Divisor for hop size calculation (e.g., 4 for 75% overlap).
 * @property {number} SPEC_SHORT_HOP_DIVISOR - Divisor for hop size for short files (e.g., 8 for 87.5% overlap).
 * @property {boolean} SPEC_CENTER_WINDOWS - Whether to use conceptual window centering for spectrogram FFT.
 */
AudioApp.Constants = (function() {
    'use strict';

    // === Audio Engine Constants ===
    /** @type {string} Path to the Rubberband processor script. */
    const PROCESSOR_SCRIPT_URL = 'js/player/rubberbandProcessor.js'; // Updated Path
    /** @type {string} Name of the AudioWorklet processor. */
    const PROCESSOR_NAME = 'rubberband-processor';
    /** @type {string} Path to the WebAssembly binary for Rubberband. */
    const WASM_BINARY_URL = 'lib/rubberband.wasm';
    /** @type {string} Path to the Rubberband loader script. */
    const LOADER_SCRIPT_URL = 'lib/rubberband-loader.js';

    // === VAD Constants ===
    /** @type {number} Sample rate required by the Silero VAD model (Hz). */
    const VAD_SAMPLE_RATE = 16000; // Required by Silero model
    /** @type {number} Default number of samples per VAD frame (e.g., 96ms @ 16kHz). */
    const DEFAULT_VAD_FRAME_SAMPLES = 1536; // Default samples per VAD frame (e.g., 96ms @ 16kHz)
    /** @type {number} Interval (in frames) for reporting VAD progress. */
    const VAD_PROGRESS_REPORT_INTERVAL = 20; // Report progress every N frames
    /** @type {number} Interval (in frames) to yield the main thread during VAD. */
    const VAD_YIELD_INTERVAL = 5; // Yield main thread every N frames during VAD

    // === Visualizer Constants ===
    // --- General ---
    /** @type {number} Vertical space (0-1) used by the waveform. */
    const WAVEFORM_HEIGHT_SCALE = 0.8; // Vertical space used by waveform (0-1)
    // --- Waveform Colors ---
    /** @type {string} Waveform color before VAD analysis. */
    const WAVEFORM_COLOR_LOADING = '#888888'; // Initial gray before VAD
    /** @type {string} Waveform color for non-speech segments. */
    const WAVEFORM_COLOR_DEFAULT = '#26828E'; // Non-speech color (Teal)
    /** @type {string} Waveform color for speech segments. */
    const WAVEFORM_COLOR_SPEECH = '#FDE725'; // Speech highlight color (Yellow)
    // --- Spectrogram ---
    /** @type {number} Default FFT size for spectrograms. */
    const SPEC_NORMAL_FFT_SIZE = 8192;
    /** @type {number} FFT size for short audio files in spectrograms. */
    const SPEC_SHORT_FFT_SIZE = 2048;
    /** @type {number} Threshold (seconds) to use shorter FFT size. */
    const SPEC_SHORT_FILE_FFT_THRESHOLD_S = 10.0; // Use short FFT for files shorter than this
    /** @type {number[]} Array of maximum frequencies (Hz) for spectrogram display. */
    const SPEC_MAX_FREQS = [6000, 10000, 16000]; // maximum frequencies for spectrogram
    /** @type {number} Default index for SPEC_MAX_FREQS array. */
    const SPEC_DEFAULT_MAX_FREQ_INDEX = 0; // default max frequency index for spectrogram
    /** @type {number} Internal calculation width (slices) for spectrograms. */
    const SPEC_FIXED_WIDTH = 2048; // Internal calculation width (slices)
    /** @type {number} Threshold (seconds) to use smaller hop size for short files. */
    const SPEC_SHORT_FILE_HOP_THRESHOLD_S = 5.0; // Use smaller hop for files shorter than this
    /** @type {number} Divisor for hop size calculation (e.g., 4 for 75% overlap). */
    const SPEC_NORMAL_HOP_DIVISOR = 4; // Hop size = fftSize / N (75% overlap)
    /** @type {number} Divisor for hop size for short files (e.g., 8 for 87.5% overlap). */
    const SPEC_SHORT_HOP_DIVISOR = 8; // Smaller hop for short files (87.5% overlap)
    /** @type {boolean} Whether to use conceptual window centering for spectrogram FFT. */
    const SPEC_CENTER_WINDOWS = true; // Use conceptual window centering

    // === Public Interface ===
    return {
        // Audio Engine
        PROCESSOR_SCRIPT_URL,
        PROCESSOR_NAME,
        WASM_BINARY_URL,
        LOADER_SCRIPT_URL,
        // VAD
        VAD_SAMPLE_RATE,
        DEFAULT_VAD_FRAME_SAMPLES,
        VAD_PROGRESS_REPORT_INTERVAL,
        VAD_YIELD_INTERVAL,
        // Visualizer
        WAVEFORM_HEIGHT_SCALE,
        WAVEFORM_COLOR_LOADING,
        WAVEFORM_COLOR_DEFAULT,
        WAVEFORM_COLOR_SPEECH,
        SPEC_NORMAL_FFT_SIZE,
        SPEC_SHORT_FFT_SIZE,
        SPEC_SHORT_FILE_FFT_THRESHOLD_S,
        SPEC_MAX_FREQS,
        SPEC_DEFAULT_MAX_FREQ_INDEX,
        SPEC_FIXED_WIDTH,
        SPEC_SHORT_FILE_HOP_THRESHOLD_S,
        SPEC_NORMAL_HOP_DIVISOR,
        SPEC_SHORT_HOP_DIVISOR,
        SPEC_CENTER_WINDOWS
    };

})(); // End of AudioApp.Constants IIFE
// --- /vibe-player/js/constants.js ---

````
--- End of File: vibe-player/js/constants.js ---
--- File: vibe-player/js/goertzel.js ---
````javascript
// --- goertzel.js ---
// Pure JavaScript Goertzel Algorithm Implementation for Vibe Player
// Attaches GoertzelFilter to AudioApp.

/** @namespace AudioApp */
var AudioApp = AudioApp || {}; // Ensure AudioApp namespace exists

/**
 * @module GoertzelModule
 * @description Provides GoertzelFilter, DTMFParser, CallProgressToneParser classes and related constants.
 */
const GoertzelModule = (function() {
    'use strict';

    // --- DTMF Constants ---
    /** @type {number} Standard sample rate for DTMF processing (Hz). */
    const DTMF_SAMPLE_RATE = 16000;
    /** @type {number} Common block size for 16kHz sample rate (samples). */
    const DTMF_BLOCK_SIZE = 410;
    /** @type {number} Relative magnitude threshold factor: dominant tone must be X times stronger than others in its group. */
    const DTMF_RELATIVE_THRESHOLD_FACTOR = 2.0;
    /** @type {number} Absolute magnitude threshold: minimum energy for a tone to be considered. */
    const DTMF_ABSOLUTE_MAGNITUDE_THRESHOLD = 4e2;

    /** @type {number[]} Low frequency group for DTMF (Hz). */
    const DTMF_FREQUENCIES_LOW = [697, 770, 852, 941];
    /** @type {number[]} High frequency group for DTMF (Hz), including A,B,C,D. */
    const DTMF_FREQUENCIES_HIGH = [1209, 1336, 1477, 1633];

    /** @type {Object<string, string>} Maps DTMF frequency pairs to characters. Key: "lowFreq,highFreq". */
    const DTMF_CHARACTERS = {
        "697,1209": "1", "697,1336": "2", "697,1477": "3", "697,1633": "A",
        "770,1209": "4", "770,1336": "5", "770,1477": "6", "770,1633": "B",
        "852,1209": "7", "852,1336": "8", "852,1477": "9", "852,1633": "C",
        "941,1209": "*", "941,1336": "0", "941,1477": "#", "941,1633": "D"
    };

    // --- Call Progress Tone Frequencies (Hz) ---
    /** @type {number[]} Frequencies for Dial Tone. */
    const CPT_FREQ_DIAL_TONE = [350, 440];
    /** @type {number[]} Frequencies for Busy Signal. */
    const CPT_FREQ_BUSY_SIGNAL = [480, 620];
    /** @type {number[]} Frequencies for Reorder Tone (same as Busy). */
    const CPT_FREQ_REORDER_TONE = [480, 620];
    /** @type {number[]} Frequencies for Ringback Tone. */
    const CPT_FREQ_RINGBACK_TONE = [440, 480];
    /** @type {number[]} Frequencies for Off-Hook Warning Tone. */
    const CPT_FREQ_OFF_HOOK_WARNING = [1400, 2060, 2450, 2600];
    /** @type {number[]} Frequencies for Call Waiting Tone. */
    const CPT_FREQ_CALL_WAITING_TONE = [440];

    // --- Call Progress Tone Cadences (ms ON, ms OFF) ---
    /** @typedef {{on: number, off: number}} CadenceSpec */
    /** @type {CadenceSpec} Cadence for Busy Signal. */
    const CPT_CADENCE_BUSY_SIGNAL = { on: 500, off: 500 };
    /** @type {CadenceSpec} Cadence for Reorder Tone. */
    const CPT_CADENCE_REORDER_TONE = { on: 250, off: 250 };
    /** @type {CadenceSpec} Cadence for Ringback Tone. */
    const CPT_CADENCE_RINGBACK_TONE = { on: 2000, off: 4000 };
    /** @type {CadenceSpec} Cadence for Call Waiting Tone. */
    const CPT_CADENCE_CALL_WAITING_TONE = { on: 300, off: 9700 }; // Approximate

    // --- Call Progress Tone Parser Constants ---
    /** @type {number} Default sample rate for CPT parser (Hz). */
    const CPT_DEFAULT_SAMPLE_RATE = DTMF_SAMPLE_RATE;
    /** @type {number} Default block size for CPT parser (samples). */
    const CPT_DEFAULT_BLOCK_SIZE = DTMF_BLOCK_SIZE;
    /** @type {number} Default absolute magnitude threshold for CPT parser. */
    const CPT_DEFAULT_ABSOLUTE_MAGNITUDE_THRESHOLD = 2e2;
    /** @type {number} Default relative magnitude threshold factor for CPT parser. */
    const CPT_DEFAULT_RELATIVE_THRESHOLD_FACTOR = 1.5;
    /** @type {number} Tolerance (percentage) for CPT cadence timing. */
    const CPT_CADENCE_TOLERANCE_PERCENT = 0.25;
    /** @type {number} Minimum number of cycles for confirming a cadenced CPT. */
    const CPT_MIN_CYCLE_CONFIRMATION = 1.5;


    /**
     * @class GoertzelFilter
     * @memberof AudioApp
     * @description Implements the Goertzel algorithm to detect the magnitude of a specific frequency
     * in a block of audio samples.
     */
    class GoertzelFilter {
        /**
         * Creates an instance of GoertzelFilter.
         * @param {number} targetFrequency - The specific frequency (in Hz) this filter will detect.
         * @param {number} sampleRate - The sample rate (in Hz) of the audio signal.
         * @param {number} N - The block size (number of samples) for one analysis window.
         *                   Coefficients are calculated based on this N, and for the most
         *                   straightforward interpretation of getMagnitudeSquared(), exactly
         *                   N samples should be processed after a reset.
         */
        constructor(targetFrequency, sampleRate, N) {
            if (N <= 0) {
                throw new Error("GoertzelFilter: Block size N must be positive.");
            }
            if (sampleRate <= 0) {
                throw new Error("GoertzelFilter: Sample rate must be positive.");
            }
            if (targetFrequency <= 0 || targetFrequency >= sampleRate / 2) {
                // Technically can work, but typically target is < Nyquist
                console.warn("GoertzelFilter: Target frequency is very low or near/above Nyquist frequency. Results may be suboptimal.");
            }

            /** @type {number} The target frequency for this filter instance. */
            this.targetFrequency = targetFrequency;
            /** @type {number} The sample rate assumed by this filter instance. */
            this.sampleRate = sampleRate;
            /** @type {number} The block size (N) used for coefficient calculation. */
            this.N = N;

            // Precompute coefficients
            /** @private @type {number} Normalized frequency (DFT bin index). */
            const k = Math.floor(0.5 + (this.N * this.targetFrequency) / this.sampleRate);
            /** @private @type {number} Angular frequency. */
            this.omega = (2 * Math.PI * k) / this.N;
            /** @private @type {number} Cosine of omega. */
            this.cosine = Math.cos(this.omega);
            /** @private @type {number} Sine of omega. */
            this.sine = Math.sin(this.omega);
            /** @private @type {number} Filter coefficient (2 * cos(omega)). */
            this.coeff = 2 * this.cosine;

            /** @private @type {number} Represents s[n-1] state variable. */
            this.q1 = 0;
            /** @private @type {number} Represents s[n-2] state variable. */
            this.q2 = 0;
        }

        /**
         * Resets the internal state of the filter (q1 and q2).
         * Call this before processing a new independent block of N samples.
         * @public
         */
        reset() {
            this.q1 = 0;
            this.q2 = 0;
        }

        /**
         * Processes a single audio sample through the filter.
         * This updates the internal state variables q1 and q2.
         * @public
         * @param {number} sample - The audio sample value.
         */
        processSample(sample) {
            const q0 = sample + this.coeff * this.q1 - this.q2;
            this.q2 = this.q1;
            this.q1 = q0;
        }

        /**
         * Processes a block (array or Float32Array) of audio samples.
         * Each sample in the block is run through processSample.
         * @public
         * @param {number[] | Float32Array} samples - The block of audio samples.
         */
        processBlock(samples) {
            for (let i = 0; i < samples.length; i++) {
                // Inline processSample for minor optimization in a loop
                const q0 = samples[i] + this.coeff * this.q1 - this.q2;
                this.q2 = this.q1;
                this.q1 = q0;
            }
        }

        /**
         * Calculates the squared magnitude of the target frequency component.
         * This value is proportional to the power of the signal at the target frequency.
         * It does not reset the filter's internal state.
         * @public
         * @returns {number} The squared magnitude.
         */
        getMagnitudeSquared() {
            const realPart = this.q1 - this.q2 * this.cosine;
            const imagPart = this.q2 * this.sine;
            return realPart * realPart + imagPart * imagPart;
        }
    }

    /**
     * @class DTMFParser
     * @memberof AudioApp
     * @description Parses DTMF tones from audio blocks using Goertzel filters.
     */
    class DTMFParser {
        /**
         * Creates an instance of DTMFParser.
         * @param {number} [sampleRate=DTMF_SAMPLE_RATE] - Sample rate of the audio.
         * @param {number} [blockSize=DTMF_BLOCK_SIZE] - Size of audio blocks to process.
         * @param {number} [threshold=DTMF_ABSOLUTE_MAGNITUDE_THRESHOLD] - Absolute magnitude threshold for tone detection.
         * @param {number} [relativeThresholdFactor=DTMF_RELATIVE_THRESHOLD_FACTOR] - Relative threshold factor for distinguishing tones.
         */
        constructor(sampleRate = DTMF_SAMPLE_RATE, blockSize = DTMF_BLOCK_SIZE, threshold = DTMF_ABSOLUTE_MAGNITUDE_THRESHOLD, relativeThresholdFactor = DTMF_RELATIVE_THRESHOLD_FACTOR) {
            /** @type {number} Sample rate in Hz. */
            this.sampleRate = sampleRate;
            /** @type {number} Block size in samples. */
            this.blockSize = blockSize;
            /** @type {number} Absolute magnitude detection threshold. */
            this.threshold = threshold;
            /** @type {number} Relative magnitude threshold factor. */
            this.relativeThresholdFactor = relativeThresholdFactor;

            /** @private @type {AudioApp.GoertzelFilter[]} Filters for low DTMF frequencies. */
            this.lowGroupFilters = DTMF_FREQUENCIES_LOW.map(freq =>
                new GoertzelFilter(freq, this.sampleRate, this.blockSize) // Changed: Use GoertzelFilter directly
            );
            /** @private @type {AudioApp.GoertzelFilter[]} Filters for high DTMF frequencies. */
            this.highGroupFilters = DTMF_FREQUENCIES_HIGH.map(freq =>
                new GoertzelFilter(freq, this.sampleRate, this.blockSize) // Changed: Use GoertzelFilter directly
            );
            /** @private @type {number} Counter for processed blocks (for debugging/logging). */
            this.processedBlocksCounter = 0;
        }

        /**
         * Processes a block of audio data to detect a DTMF tone.
         * @public
         * @param {Float32Array | number[]} audioBlock - The audio data to process. Must match blockSize.
         * @returns {string | null} The detected DTMF character ('0'-'9', '*', '#', 'A'-'D'), or null if no tone is detected.
         */
        processAudioBlock(audioBlock) {
            this.processedBlocksCounter++;
            if (audioBlock.length !== this.blockSize) {
                // console.warn(`DTMFParser: Audio block length (${audioBlock.length}) does not match expected block size (${this.blockSize}). Results may be inaccurate.`);
            }

            /** @type {number} */ let maxLowMag = -1;
            /** @type {number} */ let detectedLowFreq = -1;
            /** @type {Object<number, number>} */ const lowMagnitudes = {};

            this.lowGroupFilters.forEach(filter => {
                filter.reset();
                filter.processBlock(audioBlock);
                const magSq = filter.getMagnitudeSquared();
                lowMagnitudes[filter.targetFrequency] = magSq;
                if (magSq > maxLowMag) {
                    maxLowMag = magSq;
                    detectedLowFreq = filter.targetFrequency;
                }
            });

            /** @type {number} */ let maxHighMag = -1;
            /** @type {number} */ let detectedHighFreq = -1;
            /** @type {Object<number, number>} */ const highMagnitudes = {};

            this.highGroupFilters.forEach(filter => {
                filter.reset();
                filter.processBlock(audioBlock);
                const magSq = filter.getMagnitudeSquared();
                highMagnitudes[filter.targetFrequency] = magSq;
                if (magSq > maxHighMag) {
                    maxHighMag = magSq;
                    detectedHighFreq = filter.targetFrequency;
                }
            });

            if (maxLowMag < this.threshold || maxHighMag < this.threshold) {
                return null;
            }

            for (const freqStr in lowMagnitudes) {
                const freq = parseInt(freqStr);
                if (freq !== detectedLowFreq) {
                    if (lowMagnitudes[freq] * this.relativeThresholdFactor > maxLowMag) {
                        return null;
                    }
                }
            }

            for (const freqStr in highMagnitudes) {
                const freq = parseInt(freqStr);
                if (freq !== detectedHighFreq) {
                    if (highMagnitudes[freq] * this.relativeThresholdFactor > maxHighMag) {
                        return null;
                    }
                }
            }

            const dtmfKey = `${detectedLowFreq},${detectedHighFreq}`;
            const detectedChar = DTMF_CHARACTERS[dtmfKey];

            return detectedChar || null;
        }
    }

    /**
     * @typedef {Object} CadenceState
     * @property {CadenceSpec} spec - The ON/OFF duration specification.
     * @property {number[]} frequencies - The frequencies that constitute the tone.
     * @property {'ON' | 'OFF'} phase - Current phase of the cadence ('ON' or 'OFF').
     * @property {number} timerBlocks - Number of blocks spent in the current phase.
     * @property {number} cyclesDetected - Number of full ON/OFF cycles detected.
     * @property {any[]} history - Optional history for complex pattern matching.
     * @property {number} onBlocksTarget - Target number of blocks for the ON phase.
     * @property {number} offBlocksTarget - Target number of blocks for the OFF phase.
     */

    /**
     * @typedef {Object} ContinuousToneState
     * @property {number[]} requiredFreqs - Frequencies that must be present.
     * @property {number} presentBlocks - Number of consecutive blocks the tone has been present.
     * @property {number} neededBlocks - Number of consecutive blocks needed to confirm the tone.
     */

    /**
     * @class CallProgressToneParser
     * @memberof AudioApp
     * @description Parses call progress tones (e.g., busy, ringback) from audio blocks.
     */
    class CallProgressToneParser {
        /**
         * Creates an instance of CallProgressToneParser.
         * @param {number} [sampleRate=CPT_DEFAULT_SAMPLE_RATE] - Sample rate of the audio.
         * @param {number} [blockSize=CPT_DEFAULT_BLOCK_SIZE] - Size of audio blocks to process.
         * @param {number} [absoluteMagnitudeThreshold=CPT_DEFAULT_ABSOLUTE_MAGNITUDE_THRESHOLD] - Absolute magnitude threshold.
         * @param {number} [relativeThresholdFactor=CPT_DEFAULT_RELATIVE_THRESHOLD_FACTOR] - Relative threshold factor.
         */
        constructor(
            sampleRate = CPT_DEFAULT_SAMPLE_RATE,
            blockSize = CPT_DEFAULT_BLOCK_SIZE,
            absoluteMagnitudeThreshold = CPT_DEFAULT_ABSOLUTE_MAGNITUDE_THRESHOLD,
            relativeThresholdFactor = CPT_DEFAULT_RELATIVE_THRESHOLD_FACTOR
        ) {
            /** @type {number} Sample rate in Hz. */
            this.sampleRate = sampleRate;
            /** @type {number} Block size in samples. */
            this.blockSize = blockSize;
            /** @type {number} Absolute magnitude detection threshold. */
            this.absoluteMagnitudeThreshold = absoluteMagnitudeThreshold;
            /** @type {number} Relative magnitude threshold factor for multi-frequency tones. */
            this.relativeThresholdFactor = relativeThresholdFactor;

            /** @type {number} Duration of one audio block in milliseconds. */
            this.blockDurationMs = (this.blockSize / this.sampleRate) * 1000;

            /** @private @type {Set<number>} Unique frequencies used by CPTs. */
            const allCptFrequencies = new Set([
                ...CPT_FREQ_DIAL_TONE, ...CPT_FREQ_BUSY_SIGNAL,
                ...CPT_FREQ_RINGBACK_TONE, ...CPT_FREQ_OFF_HOOK_WARNING,
                ...CPT_FREQ_CALL_WAITING_TONE
            ]);

            /** @private @type {Object<number, AudioApp.GoertzelFilter>} Goertzel filters for each CPT frequency. */
            this.filters = {};
            allCptFrequencies.forEach(freq => {
                this.filters[freq] = new GoertzelFilter(freq, this.sampleRate, this.blockSize); // Changed: Use GoertzelFilter directly
            });

            /**
             * @private
             * @type {Object<string, CadenceState>} State for cadenced tones.
             */
            this.cadenceStates = {
                Busy: this._initCadenceState(CPT_CADENCE_BUSY_SIGNAL, CPT_FREQ_BUSY_SIGNAL),
                Reorder: this._initCadenceState(CPT_CADENCE_REORDER_TONE, CPT_FREQ_REORDER_TONE),
                Ringback: this._initCadenceState(CPT_CADENCE_RINGBACK_TONE, CPT_FREQ_RINGBACK_TONE),
                CallWaiting: this._initCadenceState(CPT_CADENCE_CALL_WAITING_TONE, CPT_FREQ_CALL_WAITING_TONE),
            };

            /**
             * @private
             * @type {Object<string, ContinuousToneState>} State for continuous tones.
             */
            this.continuousToneStates = {
                DialTone: { requiredFreqs: CPT_FREQ_DIAL_TONE, presentBlocks: 0, neededBlocks: 2 },
                OffHookWarning: { requiredFreqs: CPT_FREQ_OFF_HOOK_WARNING, presentBlocks: 0, neededBlocks: 2 }
            };
        }

        /**
         * Initializes the state object for a cadenced tone.
         * @private
         * @param {CadenceSpec} cadenceSpec - The ON/OFF duration specification.
         * @param {number[]} frequencies - The frequencies that constitute the tone.
         * @returns {CadenceState} The initialized state object.
         */
        _initCadenceState(cadenceSpec, frequencies) {
            return {
                spec: cadenceSpec,
                frequencies: frequencies,
                phase: 'OFF',
                timerBlocks: 0,
                cyclesDetected: 0,
                history: [],
                onBlocksTarget: Math.round(cadenceSpec.on / this.blockDurationMs),
                offBlocksTarget: Math.round(cadenceSpec.off / this.blockDurationMs),
            };
        }

        /**
         * Checks if a single frequency is present based on its magnitude.
         * @private
         * @param {number} freq - The frequency to check.
         * @param {Object<number, number>} magnitudes - Object mapping frequencies to their magnitudes.
         * @returns {boolean} True if the frequency is considered present.
         */
        _checkFrequencyPresence(freq, magnitudes) {
            return magnitudes[freq] >= this.absoluteMagnitudeThreshold;
        }

        /**
         * Checks if multiple required frequencies are present.
         * @private
         * @param {number[]} requiredFreqs - Array of frequencies that should be present.
         * @param {Object<number, number>} magnitudes - Object mapping frequencies to their magnitudes.
         * @param {boolean} [allowSingleComponent=false] - If true, allows detection if at least one component of a multi-frequency tone is present.
         * @returns {boolean} True if the required frequencies are considered present according to the criteria.
         */
        _checkMultiFrequencyPresence(requiredFreqs, magnitudes, allowSingleComponent = false) {
            let detectedCount = 0;
            for (const freq of requiredFreqs) {
                if (magnitudes[freq] && magnitudes[freq] >= this.absoluteMagnitudeThreshold) {
                    detectedCount++;
                } else {
                    if (!allowSingleComponent && requiredFreqs.length > 1) return false;
                }
            }
            if (requiredFreqs.length === 1) return detectedCount === 1;
            return allowSingleComponent ? detectedCount > 0 : detectedCount === requiredFreqs.length;
        }

        /**
         * Updates the cadence state for a given tone based on current activity.
         * @private
         * @param {string} toneName - The name of the tone (key in this.cadenceStates).
         * @param {boolean} isToneActiveNow - Whether the tone's frequencies are currently detected.
         * @returns {boolean} True if the cadence for this tone is confirmed.
         */
        _updateCadenceState(toneName, isToneActiveNow) {
            const state = this.cadenceStates[toneName];
            const toleranceOn = Math.ceil(state.onBlocksTarget * CPT_CADENCE_TOLERANCE_PERCENT);
            const toleranceOff = Math.ceil(state.offBlocksTarget * CPT_CADENCE_TOLERANCE_PERCENT);

            if (isToneActiveNow) {
                if (state.phase === 'OFF') {
                    if (state.timerBlocks >= state.offBlocksTarget - toleranceOff || state.cyclesDetected === 0) {
                        state.cyclesDetected += 0.5;
                    } else {
                        state.cyclesDetected = 0;
                    }
                    state.phase = 'ON';
                    state.timerBlocks = 0;
                }
                state.timerBlocks++;
            } else {
                if (state.phase === 'ON') {
                    if (state.timerBlocks >= state.onBlocksTarget - toleranceOn) {
                        state.cyclesDetected += 0.5;
                    } else {
                        state.cyclesDetected = 0;
                    }
                    state.phase = 'OFF';
                    state.timerBlocks = 0;
                }
                state.timerBlocks++;
                if (state.timerBlocks > state.offBlocksTarget + toleranceOff && state.cyclesDetected < CPT_MIN_CYCLE_CONFIRMATION) {
                    state.cyclesDetected = 0;
                }
            }
            return state.cyclesDetected >= CPT_MIN_CYCLE_CONFIRMATION;
        }

        /**
         * Processes a block of audio data to detect call progress tones.
         * @public
         * @param {Float32Array | number[]} audioBlock - The audio data to process. Must match blockSize.
         * @returns {string | null} The name of the detected CPT (e.g., "Dial Tone", "Busy Signal"), or null if no tone is confirmed.
         */
        processAudioBlock(audioBlock) {
            if (audioBlock.length !== this.blockSize) {
                console.warn(`CallProgressToneParser: Audio block length (${audioBlock.length}) does not match expected block size (${this.blockSize}).`);
                return null;
            }

            /** @type {Object<number, number>} */ const magnitudes = {};
            for (const freq in this.filters) {
                this.filters[freq].reset();
                this.filters[freq].processBlock(audioBlock);
                magnitudes[freq] = this.filters[freq].getMagnitudeSquared();
            }

            const dialTonePresent = this._checkMultiFrequencyPresence(CPT_FREQ_DIAL_TONE, magnitudes);
            if (dialTonePresent) {
                this.continuousToneStates.DialTone.presentBlocks++;
                if (this.continuousToneStates.DialTone.presentBlocks >= this.continuousToneStates.DialTone.neededBlocks) {
                    for (const tone in this.cadenceStates) this.cadenceStates[tone].cyclesDetected = 0;
                    return "Dial Tone";
                }
            } else {
                this.continuousToneStates.DialTone.presentBlocks = 0;
            }

            const offHookPresent = this._checkMultiFrequencyPresence(CPT_FREQ_OFF_HOOK_WARNING, magnitudes);
            if (offHookPresent) {
                this.continuousToneStates.OffHookWarning.presentBlocks++;
                 if (this.continuousToneStates.OffHookWarning.presentBlocks >= this.continuousToneStates.OffHookWarning.neededBlocks) {
                    for (const tone in this.cadenceStates) this.cadenceStates[tone].cyclesDetected = 0;
                    return "Off-Hook Warning";
                }
            } else {
                 this.continuousToneStates.OffHookWarning.presentBlocks = 0;
            }

            if (this.continuousToneStates.DialTone.presentBlocks >= this.continuousToneStates.DialTone.neededBlocks ||
                this.continuousToneStates.OffHookWarning.presentBlocks >= this.continuousToneStates.OffHookWarning.neededBlocks) {
                // Return early if a continuous tone is confirmed
            }

            const busyToneActive = this._checkMultiFrequencyPresence(CPT_FREQ_BUSY_SIGNAL, magnitudes);
            if (this._updateCadenceState('Busy', busyToneActive)) {
                return "Busy Signal";
            }

            const reorderToneActive = this._checkMultiFrequencyPresence(CPT_FREQ_REORDER_TONE, magnitudes);
            if (this._updateCadenceState('Reorder', reorderToneActive)) {
                return "Fast Busy / Reorder Tone";
            }

            const ringbackToneActive = this._checkMultiFrequencyPresence(CPT_FREQ_RINGBACK_TONE, magnitudes);
            if (this._updateCadenceState('Ringback', ringbackToneActive)) {
                return "Ringback Tone";
            }

            const callWaitingToneActive = this._checkMultiFrequencyPresence(CPT_FREQ_CALL_WAITING_TONE, magnitudes, true);
            if (this._updateCadenceState('CallWaiting', callWaitingToneActive)) {
                return "Call Waiting Tone";
            }

            return null;
        }
    }

    /**
     * @typedef {Object} GoertzelModuleReturn
     * @property {typeof GoertzelFilter} GoertzelFilter
     * @property {typeof DTMFParser} DTMFParser
     * @property {typeof CallProgressToneParser} CallProgressToneParser
     * @property {number} DTMF_SAMPLE_RATE
     * @property {number} DTMF_BLOCK_SIZE
     * @property {number[]} CPT_FREQ_DIAL_TONE
     * @property {number[]} CPT_FREQ_BUSY_SIGNAL
     * @property {number[]} CPT_FREQ_REORDER_TONE
     * @property {number[]} CPT_FREQ_RINGBACK_TONE
     * @property {number[]} CPT_FREQ_OFF_HOOK_WARNING
     * @property {number[]} CPT_FREQ_CALL_WAITING_TONE
     * @property {CadenceSpec} CPT_CADENCE_BUSY_SIGNAL
     * @property {CadenceSpec} CPT_CADENCE_REORDER_TONE
     * @property {CadenceSpec} CPT_CADENCE_RINGBACK_TONE
     * @property {CadenceSpec} CPT_CADENCE_CALL_WAITING_TONE
     * @property {number} CPT_DEFAULT_SAMPLE_RATE
     * @property {number} CPT_DEFAULT_BLOCK_SIZE
     * @property {number} CPT_DEFAULT_ABSOLUTE_MAGNITUDE_THRESHOLD
     * @property {number} CPT_DEFAULT_RELATIVE_THRESHOLD_FACTOR
     * @property {number} CPT_CADENCE_TOLERANCE_PERCENT
     * @property {number} CPT_MIN_CYCLE_CONFIRMATION
     */

    /** @type {GoertzelModuleReturn} */
    return {
        GoertzelFilter: GoertzelFilter,
        DTMFParser: DTMFParser,
        CallProgressToneParser: CallProgressToneParser,
        DTMF_SAMPLE_RATE: DTMF_SAMPLE_RATE,
        DTMF_BLOCK_SIZE: DTMF_BLOCK_SIZE,

        CPT_FREQ_DIAL_TONE: CPT_FREQ_DIAL_TONE,
        CPT_FREQ_BUSY_SIGNAL: CPT_FREQ_BUSY_SIGNAL,
        CPT_FREQ_REORDER_TONE: CPT_FREQ_REORDER_TONE,
        CPT_FREQ_RINGBACK_TONE: CPT_FREQ_RINGBACK_TONE,
        CPT_FREQ_OFF_HOOK_WARNING: CPT_FREQ_OFF_HOOK_WARNING,
        CPT_FREQ_CALL_WAITING_TONE: CPT_FREQ_CALL_WAITING_TONE,
        CPT_CADENCE_BUSY_SIGNAL: CPT_CADENCE_BUSY_SIGNAL,
        CPT_CADENCE_REORDER_TONE: CPT_CADENCE_REORDER_TONE,
        CPT_CADENCE_RINGBACK_TONE: CPT_CADENCE_RINGBACK_TONE,
        CPT_CADENCE_CALL_WAITING_TONE: CPT_CADENCE_CALL_WAITING_TONE,

        CPT_DEFAULT_SAMPLE_RATE: CPT_DEFAULT_SAMPLE_RATE,
        CPT_DEFAULT_BLOCK_SIZE: CPT_DEFAULT_BLOCK_SIZE,
        CPT_DEFAULT_ABSOLUTE_MAGNITUDE_THRESHOLD: CPT_DEFAULT_ABSOLUTE_MAGNITUDE_THRESHOLD,
        CPT_DEFAULT_RELATIVE_THRESHOLD_FACTOR: CPT_DEFAULT_RELATIVE_THRESHOLD_FACTOR,
        CPT_CADENCE_TOLERANCE_PERCENT: CPT_CADENCE_TOLERANCE_PERCENT,
        CPT_MIN_CYCLE_CONFIRMATION: CPT_MIN_CYCLE_CONFIRMATION
    };
})();

/** @type {typeof GoertzelModule.GoertzelFilter} */
AudioApp.GoertzelFilter = GoertzelModule.GoertzelFilter;
/** @type {typeof GoertzelModule.DTMFParser} */
AudioApp.DTMFParser = GoertzelModule.DTMFParser;
/** @type {typeof GoertzelModule.CallProgressToneParser} */
AudioApp.CallProgressToneParser = GoertzelModule.CallProgressToneParser;

/** @type {number} Standard sample rate for DTMF processing (Hz). */
AudioApp.DTMFParser.DTMF_SAMPLE_RATE = GoertzelModule.DTMF_SAMPLE_RATE;
/** @type {number} Common block size for DTMF processing (samples). */
AudioApp.DTMFParser.DTMF_BLOCK_SIZE = GoertzelModule.DTMF_BLOCK_SIZE;

/**
 * @namespace AudioApp.CPT_CONSTANTS
 * @description Constants related to Call Progress Tones.
 * @property {number[]} CPT_FREQ_DIAL_TONE
 * @property {number[]} CPT_FREQ_BUSY_SIGNAL
 * @property {number[]} CPT_FREQ_REORDER_TONE
 * @property {number[]} CPT_FREQ_RINGBACK_TONE
 * @property {number[]} CPT_FREQ_OFF_HOOK_WARNING
 * @property {number[]} CPT_FREQ_CALL_WAITING_TONE
 * @property {CadenceSpec} CPT_CADENCE_BUSY_SIGNAL
 * @property {CadenceSpec} CPT_CADENCE_REORDER_TONE
 * @property {CadenceSpec} CPT_CADENCE_RINGBACK_TONE
 * @property {CadenceSpec} CPT_CADENCE_CALL_WAITING_TONE
 * @property {number} CPT_DEFAULT_SAMPLE_RATE
 * @property {number} CPT_DEFAULT_BLOCK_SIZE
 * @property {number} CPT_DEFAULT_ABSOLUTE_MAGNITUDE_THRESHOLD
 * @property {number} CPT_DEFAULT_RELATIVE_THRESHOLD_FACTOR
 * @property {number} CPT_CADENCE_TOLERANCE_PERCENT
 * @property {number} CPT_MIN_CYCLE_CONFIRMATION
 */
AudioApp.CPT_CONSTANTS = {
    CPT_FREQ_DIAL_TONE: GoertzelModule.CPT_FREQ_DIAL_TONE,
    CPT_FREQ_BUSY_SIGNAL: GoertzelModule.CPT_FREQ_BUSY_SIGNAL,
    CPT_FREQ_REORDER_TONE: GoertzelModule.CPT_FREQ_REORDER_TONE,
    CPT_FREQ_RINGBACK_TONE: GoertzelModule.CPT_FREQ_RINGBACK_TONE,
    CPT_FREQ_OFF_HOOK_WARNING: GoertzelModule.CPT_FREQ_OFF_HOOK_WARNING,
    CPT_FREQ_CALL_WAITING_TONE: GoertzelModule.CPT_FREQ_CALL_WAITING_TONE,
    CPT_CADENCE_BUSY_SIGNAL: GoertzelModule.CPT_CADENCE_BUSY_SIGNAL,
    CPT_CADENCE_REORDER_TONE: GoertzelModule.CPT_CADENCE_REORDER_TONE,
    CPT_CADENCE_RINGBACK_TONE: GoertzelModule.CPT_CADENCE_RINGBACK_TONE,
    CPT_CADENCE_CALL_WAITING_TONE: GoertzelModule.CPT_CADENCE_CALL_WAITING_TONE,

    CPT_DEFAULT_SAMPLE_RATE: GoertzelModule.CPT_DEFAULT_SAMPLE_RATE,
    CPT_DEFAULT_BLOCK_SIZE: GoertzelModule.CPT_DEFAULT_BLOCK_SIZE,
    CPT_DEFAULT_ABSOLUTE_MAGNITUDE_THRESHOLD: GoertzelModule.CPT_DEFAULT_ABSOLUTE_MAGNITUDE_THRESHOLD,
    CPT_DEFAULT_RELATIVE_THRESHOLD_FACTOR: GoertzelModule.CPT_DEFAULT_RELATIVE_THRESHOLD_FACTOR,
    CPT_CADENCE_TOLERANCE_PERCENT: GoertzelModule.CPT_CADENCE_TOLERANCE_PERCENT,
    CPT_MIN_CYCLE_CONFIRMATION: GoertzelModule.CPT_MIN_CYCLE_CONFIRMATION
};

// Example Usage (for testing or a DTMF detector module):
/*
if (typeof AudioApp.GoertzelFilter !== 'undefined') {
    const SAMPLE_RATE = 8000; // Example
    const N_SAMPLES_PER_BLOCK = 205; // Common for DTMF at 8kHz

    // DTMF Frequencies
    const dtmfLowFreqs = [697, 770, 852, 941];
    const dtmfHighFreqs = [1209, 1336, 1477]; // Excluding 1633 for A,B,C,D for now

    const lowGroupFilters = dtmfLowFreqs.map(freq =>
        new AudioApp.GoertzelFilter(freq, SAMPLE_RATE, N_SAMPLES_PER_BLOCK)
    );
    const highGroupFilters = dtmfHighFreqs.map(freq =>
        new AudioApp.GoertzelFilter(freq, SAMPLE_RATE, N_SAMPLES_PER_BLOCK)
    );

    // Assume `audioBlock` is a Float32Array of N_SAMPLES_PER_BLOCK audio data
    function detectDTMF(audioBlock) {
        if (audioBlock.length !== N_SAMPLES_PER_BLOCK) {
            console.warn("Audio block length does not match N_SAMPLES_PER_BLOCK for Goertzel filters.");
            // Handle this case: either pad/truncate, or re-initialize filters with audioBlock.length
            // For simplicity here, we'll assume it matches.
        }

        let maxLowMag = -1, detectedLowFreq = -1;
        lowGroupFilters.forEach(filter => {
            filter.reset();
            filter.processBlock(audioBlock);
            const magSq = filter.getMagnitudeSquared();
            if (magSq > maxLowMag) {
                maxLowMag = magSq;
                detectedLowFreq = filter.targetFrequency;
            }
        });

        let maxHighMag = -1, detectedHighFreq = -1;
        highGroupFilters.forEach(filter => {
            filter.reset();
            filter.processBlock(audioBlock);
            const magSq = filter.getMagnitudeSquared();
            if (magSq > maxHighMag) {
                maxHighMag = magSq;
                detectedHighFreq = filter.targetFrequency;
            }
        });

        // Example thresholds (these need careful tuning!)
        const dtmfThreshold = 1e5; // Arbitrary, depends on N, input signal level, etc.
        const relativeThresholdFactor = 5; // Dominant tone should be X times stronger

        // Basic check if dominant tones are strong enough
        if (maxLowMag > dtmfThreshold && maxHighMag > dtmfThreshold) {
            // Add more checks: e.g., ensure the detected freqs are significantly stronger
            // than other freqs in their group.
            // For now, just log:
            console.log(`Potential DTMF: Low Freq ${detectedLowFreq} (MagSq ${maxLowMag.toExponential(2)}), High Freq ${detectedHighFreq} (MagSq ${maxHighMag.toExponential(2)})`);
            // Map (detectedLowFreq, detectedHighFreq) to a digit here
            return { low: detectedLowFreq, high: detectedHighFreq };
        }
        return null;
    }

    // To test:
    // const testSignal = new Float32Array(N_SAMPLES_PER_BLOCK);
    // // Fill testSignal with, e.g., sin(2*pi*697*t/8000) + sin(2*pi*1209*t/8000)
    // // detectDTMF(testSignal);
}
*/
````
--- End of File: vibe-player/js/goertzel.js ---
--- File: vibe-player/js/player/audioEngine.js ---
````javascript
// --- /vibe-player/js/player/audioEngine.js --- // Updated Path
// Manages Web Audio API, AudioWorklet loading/communication, decoding, resampling, and playback control.
// Uses Rubberband WASM via an AudioWorkletProcessor for time-stretching and pitch/formant shifting.

/** @namespace AudioApp */
var AudioApp = AudioApp || {};

/**
 * @namespace AudioApp.audioEngine
 * @description Manages Web Audio API, AudioWorklet loading/communication,
 * decoding, resampling, and playback control.
 */
AudioApp.audioEngine = (function() {
    'use strict';

    // --- Web Audio API & Worklet State ---
    /** @type {AudioContext|null} The main AudioContext. */
    let audioCtx = null;
    /** @type {GainNode|null} Master gain node for volume control. */
    let gainNode = null;
    /** @type {AudioWorkletNode|null} The node hosting the Rubberband processor. */
    let workletNode = null;
    /** @type {AudioBuffer|null} The currently loaded and decoded audio buffer. */
    let currentDecodedBuffer = null;

    /** @type {boolean} Tracks the desired playback state (play/pause) sent to the worklet. */
    let isPlaying = false;
    /** @type {boolean} Indicates if the AudioWorklet processor is ready. */
    let workletReady = false;
    /** @type {number} Current playback time in seconds within the source audio, as tracked by the worklet or seek commands. */
    let currentWorkletTime = 0.0;
    /** @type {number} Current playback speed factor. */
    let currentPlaybackSpeed = 1.0;
    /** @type {number} Current pitch shift scale. */
    let currentPitchScale = 1.0;
    /** @type {number} Current formant shift scale. */
    let currentFormantScale = 1.0;

    // --- WASM Resources ---
    /** @type {ArrayBuffer|null} Stores the fetched WASM binary for Rubberband. */
    let wasmBinary = null;
    /** @type {string|null} Stores the text of the WASM loader script. */
    let loaderScriptText = null;


    /**
     * Initializes the Audio Engine: sets up AudioContext and pre-fetches WASM resources.
     * @public
     * @async
     * @returns {Promise<void>}
     */
    async function init() {
        console.log("AudioEngine: Initializing...");
        setupAudioContext();
        await preFetchWorkletResources();
        console.log("AudioEngine: Initialized.");
    }


    /**
     * Creates or resets the AudioContext and main GainNode.
     * @private
     * @returns {boolean} True if the AudioContext is ready, false otherwise.
     */
    function setupAudioContext() {
        if (audioCtx && audioCtx.state !== 'closed') { return true; }
        try {
            if (audioCtx && audioCtx.state === 'closed') {
                 console.log("AudioEngine: Recreating closed AudioContext.");
            }
            audioCtx = new (window.AudioContext || window.webkitAudioContext)();
            gainNode = audioCtx.createGain();
            gainNode.gain.value = 1.0; // Default gain
            gainNode.connect(audioCtx.destination);
            workletNode = null; // Reset worklet node on context recreation
            workletReady = false;
            console.log(`AudioEngine: AudioContext created/reset (state: ${audioCtx.state}). Sample Rate: ${audioCtx.sampleRate}Hz`);
            if (audioCtx.state === 'suspended') {
                 console.warn("AudioEngine: AudioContext is suspended. User interaction (e.g., click) is needed to resume audio playback.");
            }
            return true;
        } catch (e) {
             console.error("AudioEngine: Failed to create AudioContext.", e);
             audioCtx = null; gainNode = null; workletNode = null; workletReady = false;
             dispatchEngineEvent('audioapp:engineError', { type: 'context', error: new Error("Web Audio API not supported or context creation failed.") });
             return false;
        }
    }

    /**
     * Pre-fetches WASM binary and loader script for the AudioWorklet.
     * Uses paths from `AudioApp.Constants`.
     * @private
     * @async
     * @returns {Promise<void>}
     */
    async function preFetchWorkletResources() {
        console.log("AudioEngine: Pre-fetching WASM resources...");
        try {
            if (!AudioApp.Constants) {
                throw new Error("AudioApp.Constants module not found. Cannot fetch resources.");
            }
            const wasmResponse = await fetch(AudioApp.Constants.WASM_BINARY_URL);
            if (!wasmResponse.ok) throw new Error(`Fetch failed (${wasmResponse.status}) for WASM binary: ${AudioApp.Constants.WASM_BINARY_URL}`);
            wasmBinary = await wasmResponse.arrayBuffer();

            const loaderResponse = await fetch(AudioApp.Constants.LOADER_SCRIPT_URL);
            if (!loaderResponse.ok) throw new Error(`Fetch failed (${loaderResponse.status}) for Loader script: ${AudioApp.Constants.LOADER_SCRIPT_URL}`);
            loaderScriptText = await loaderResponse.text();
            console.log("AudioEngine: WASM resources fetched successfully.");
        } catch (fetchError) {
            console.error("AudioEngine: Failed to fetch WASM/Loader resources:", fetchError);
            wasmBinary = null; loaderScriptText = null; // Ensure resources are null on error
            dispatchEngineEvent('audioapp:engineError', { type: 'resource', error: fetchError });
        }
    }


    /**
     * Loads an audio file, decodes it, and sets up the AudioWorklet for playback.
     * @public
     * @async
     * @param {File} file - The audio file to load.
     * @returns {Promise<void>} Resolves when setup is complete.
     * @throws {Error} If any critical step fails (e.g., context creation, decoding, worklet setup).
     */
     async function loadAndProcessFile(file) {
        if (!audioCtx || audioCtx.state === 'closed') {
             if (!setupAudioContext()) { throw new Error("AudioContext could not be created/reset for loading file."); }
        }
        if (audioCtx.state === 'suspended') { // Attempt to resume context if suspended
             await audioCtx.resume().catch(e => console.warn("AudioEngine: Context resume failed during load.", e));
             if (audioCtx.state !== 'running') {
                 throw new Error(`AudioContext could not be resumed (state: ${audioCtx.state}). User interaction might be required.`);
             }
        }

        await cleanupCurrentWorklet(); // Clean up any existing worklet instance
        currentDecodedBuffer = null; isPlaying = false; currentWorkletTime = 0.0; currentFormantScale = 1.0;

        try {
            const arrayBuffer = await file.arrayBuffer();
            currentDecodedBuffer = await audioCtx.decodeAudioData(arrayBuffer);
            dispatchEngineEvent('audioapp:audioLoaded', { audioBuffer: currentDecodedBuffer });

            if (!wasmBinary || !loaderScriptText) {
                throw new Error("Cannot setup Worklet: WASM/Loader resources are missing. Ensure preFetchWorkletResources succeeded.");
            }
            await setupAndStartWorklet(currentDecodedBuffer);
        } catch (error) {
            console.error("AudioEngine: Error during load/decode/worklet setup:", error);
            currentDecodedBuffer = null;
            const errorType = error.message.includes("decodeAudioData") ? 'decodingError'
                              : error.message.includes("Worklet") ? 'workletError'
                              : 'loadError';
            dispatchEngineEvent(`audioapp:${errorType}`, { error: error });
            throw error; // Re-throw for the caller (app.js) to handle UI state
        }
    }

    /**
     * Resamples an AudioBuffer to 16kHz mono Float32Array using OfflineAudioContext.
     * @private
     * @param {AudioBuffer} audioBuffer - The original decoded audio buffer.
     * @returns {Promise<Float32Array>} A promise resolving to the resampled PCM data.
     */
    function convertAudioBufferTo16kHzMonoFloat32(audioBuffer) {
        if (!AudioApp.Constants) return Promise.reject(new Error("AudioApp.Constants not found for resampling."));
        const targetSampleRate = AudioApp.Constants.VAD_SAMPLE_RATE;
        const targetLength = Math.ceil(audioBuffer.duration * targetSampleRate);

        if (!targetLength || targetLength <= 0) return Promise.resolve(new Float32Array(0));

        try {
            const offlineCtx = new OfflineAudioContext(1, targetLength, targetSampleRate);
            const src = offlineCtx.createBufferSource();
            src.buffer = audioBuffer;
            src.connect(offlineCtx.destination);
            src.start();
            return offlineCtx.startRendering().then(renderedBuffer => renderedBuffer.getChannelData(0))
                .catch(err => { throw new Error(`Audio resampling rendering failed: ${err.message}`); });
        } catch (offlineCtxError) {
            return Promise.reject(new Error(`OfflineContext creation failed: ${offlineCtxError.message}`));
        }
    }

    /**
     * Public wrapper to resample an AudioBuffer to 16kHz mono Float32Array.
     * @public
     * @async
     * @param {AudioBuffer} audioBuffer - The original decoded audio buffer.
     * @returns {Promise<Float32Array>} A promise resolving to the resampled PCM data.
     */
    async function resampleTo16kMono(audioBuffer) {
        console.log("AudioEngine: Resampling audio to 16kHz mono...");
        try {
             const pcm16k = await convertAudioBufferTo16kHzMonoFloat32(audioBuffer);
             console.log(`AudioEngine: Resampled to ${pcm16k.length} samples @ 16kHz.`);
             return pcm16k;
        } catch(error) {
             console.error("AudioEngine: Error during public resampling call:", error);
             dispatchEngineEvent('audioapp:resamplingError', { error: error });
             throw error;
        }
    }


    /**
     * Cleans up the current AudioWorkletNode: sends a 'cleanup' message,
     * removes listeners, and disconnects the node.
     * @private
     * @async
     * @returns {Promise<void>}
     */
    async function cleanupCurrentWorklet() {
        workletReady = false;
        if (workletNode) {
            console.log("[AudioEngine] Cleaning up previous worklet node...");
            try {
                postWorkletMessage({ type: 'cleanup' });
                await new Promise(resolve => setTimeout(resolve, 50)); // Brief delay for message processing

                if (workletNode.port) { // Check if port still exists
                    workletNode.port.onmessage = null;
                }
                workletNode.onprocessorerror = null;
                workletNode.disconnect();
            } catch (e) {
                console.warn("[AudioEngine] Error during worklet cleanup:", e);
            } finally {
                workletNode = null;
            }
        }
    }

    /**
     * Sets up the AudioWorklet processor: adds the module, creates the node,
     * connects it, and sends initial configuration and audio data.
     * @private
     * @async
     * @param {AudioBuffer} decodedBuffer - The audio buffer to process.
     * @returns {Promise<void>}
     * @throws {Error} If prerequisites are missing or setup fails.
     */
    async function setupAndStartWorklet(decodedBuffer) {
        if (!audioCtx || !decodedBuffer || !wasmBinary || !loaderScriptText || !gainNode || !AudioApp.Constants) {
            throw new Error("Cannot setup worklet - prerequisites missing.");
        }
        await cleanupCurrentWorklet(); // Ensure previous instance is cleared

        try {
            await audioCtx.audioWorklet.addModule(AudioApp.Constants.PROCESSOR_SCRIPT_URL);
            const wasmBinaryTransfer = wasmBinary.slice(0); // Create a transferable copy
            const processorOpts = {
                sampleRate: audioCtx.sampleRate,
                numberOfChannels: decodedBuffer.numberOfChannels,
                wasmBinary: wasmBinaryTransfer,
                loaderScriptText: loaderScriptText
            };

            workletNode = new AudioWorkletNode(audioCtx, AudioApp.Constants.PROCESSOR_NAME, {
                numberOfInputs: 0, numberOfOutputs: 1,
                outputChannelCount: [decodedBuffer.numberOfChannels],
                processorOptions: processorOpts
            });

            setupWorkletMessageHandler();
            workletNode.onprocessorerror = (event) => {
                console.error(`[AudioEngine] Critical Processor Error:`, event);
                dispatchEngineEvent('audioapp:engineError', { type: 'workletProcessor', error: new Error("Processor crashed or encountered a critical error.") });
                cleanupCurrentWorklet(); workletReady = false; isPlaying = false;
                dispatchEngineEvent('audioapp:playbackStateChanged', { isPlaying: false });
            };

            workletNode.connect(gainNode);

            const channelData = []; const transferListAudio = [];
            for (let i = 0; i < decodedBuffer.numberOfChannels; i++) {
                const dataArray = decodedBuffer.getChannelData(i);
                const bufferCopy = dataArray.buffer.slice(dataArray.byteOffset, dataArray.byteOffset + dataArray.byteLength);
                channelData.push(bufferCopy);
                transferListAudio.push(bufferCopy);
            }
            postWorkletMessage({ type: 'load-audio', channelData: channelData }, transferListAudio);
        } catch (error) {
            console.error("[AudioEngine] Error setting up Worklet Node:", error);
            await cleanupCurrentWorklet();
            throw error;
        }
    }

    /**
     * Sets up the message handler for communication from the AudioWorkletProcessor.
     * @private
     */
    function setupWorkletMessageHandler() {
        if (!workletNode?.port) return;
        workletNode.port.onmessage = (event) => {
            const data = event.data;
            switch(data.type) {
                case 'status':
                    console.log(`[WorkletStatus] ${data.message}`);
                    if (data.message === 'processor-ready') {
                        workletReady = true; dispatchEngineEvent('audioapp:workletReady');
                    } else if (data.message === 'Playback ended') {
                        dispatchEngineEvent('audioapp:playbackEnded');
                    } else if (data.message === 'Processor cleaned up') {
                        workletReady = false; isPlaying = false;
                    }
                    break;
                case 'error':
                    console.error(`[WorkletError] ${data.message}`);
                    dispatchEngineEvent('audioapp:engineError', { type: 'workletRuntime', error: new Error(data.message) });
                    workletReady = false; isPlaying = false;
                    dispatchEngineEvent('audioapp:playbackStateChanged', { isPlaying: false });
                    break;
                case 'playback-state':
                    dispatchEngineEvent('audioapp:playbackStateChanged', { isPlaying: data.isPlaying });
                    break;
                case 'time-update':
                    if (typeof data.currentTime === 'number' && currentDecodedBuffer) {
                        currentWorkletTime = data.currentTime;
                    }
                    break;
                default:
                    console.warn("[AudioEngine] Unhandled message from worklet:", data.type, data);
            }
        };
    }

    /**
     * Safely posts a message to the AudioWorkletProcessor.
     * @private
     * @param {object} message - The message object.
     * @param {Transferable[]} [transferList=[]] - Optional array of transferable objects.
     */
    function postWorkletMessage(message, transferList = []) {
        if (workletNode?.port) {
            try {
                workletNode.port.postMessage(message, transferList);
            } catch (error) {
                console.error("[AudioEngine] Error posting message to worklet:", error, "Message type:", message.type);
                if (message.type !== 'cleanup') { // Avoid error loops on cleanup
                    dispatchEngineEvent('audioapp:engineError', { type: 'workletComm', error: error });
                }
                cleanupCurrentWorklet(); workletReady = false; isPlaying = false;
                dispatchEngineEvent('audioapp:playbackStateChanged', { isPlaying: false });
            }
        } else {
            if (workletReady || message.type !== 'cleanup') { // Don't warn if not ready and trying to cleanup
                console.warn(`[AudioEngine] Cannot post message (${message.type}): Worklet node or port not available.`);
            }
        }
    }


    /**
     * Toggles the playback state (play/pause).
     * @public
     * @async
     * @returns {Promise<void>}
     */
    async function togglePlayPause() {
        if (!workletReady || !audioCtx) {
            console.warn("AudioEngine: Cannot toggle play/pause - Worklet or AudioContext not ready."); return;
        }
        if (audioCtx.state === 'suspended') {
            try { await audioCtx.resume(); }
            catch (err) {
                dispatchEngineEvent('audioapp:engineError', { type: 'contextResume', error: err }); return;
            }
        }
        if (audioCtx.state !== 'running') {
             console.error(`AudioEngine: AudioContext not running (state: ${audioCtx.state}). Cannot toggle playback.`); return;
        }
        const targetIsPlaying = !isPlaying;
        postWorkletMessage({ type: targetIsPlaying ? 'play' : 'pause' });
        isPlaying = targetIsPlaying; // Update desired state
    }

    /**
     * Jumps playback position relative to the current source time.
     * @public
     * @param {number} seconds - Seconds to jump (positive or negative).
     */
    function jumpBy(seconds) {
        if (!workletReady || !currentDecodedBuffer) return;
        seek(currentWorkletTime + seconds);
    }

    /**
     * Seeks playback to an absolute time in seconds within the source audio.
     * @public
     * @param {number} time - The target time in seconds.
     */
    function seek(time) {
        if (!workletReady || !currentDecodedBuffer || isNaN(currentDecodedBuffer.duration)) return;
        const targetTime = Math.max(0, Math.min(time, currentDecodedBuffer.duration));
        postWorkletMessage({ type: 'seek', positionSeconds: targetTime });
        currentWorkletTime = targetTime; // Update internal time immediately
    }

    /**
     * Sets the playback speed (rate).
     * @public
     * @param {number} speed - Desired playback speed (e.g., 1.0 for normal).
     */
    function setSpeed(speed) {
         const rate = Math.max(0.25, Math.min(parseFloat(String(speed)) || 1.0, 2.0));
         if (currentPlaybackSpeed !== rate) {
             currentPlaybackSpeed = rate;
             if (workletReady) postWorkletMessage({ type: 'set-speed', value: rate });
             dispatchEngineEvent('audioapp:internalSpeedChanged', { speed: rate });
         }
    }

    /**
     * Sets the pitch shift scale.
     * @public
     * @param {number} pitch - Desired pitch scale (e.g., 1.0 for normal).
     */
    function setPitch(pitch) {
        const scale = Math.max(0.25, Math.min(parseFloat(String(pitch)) || 1.0, 2.0));
        if (currentPitchScale !== scale) {
            currentPitchScale = scale;
            if (workletReady) postWorkletMessage({ type: 'set-pitch', value: scale });
        }
    }

    /**
     * Sets the formant shift scale.
     * @public
     * @param {number} formant - Desired formant scale (e.g., 1.0 for normal).
     */
    function setFormant(formant) {
        const scale = Math.max(0.5, Math.min(parseFloat(String(formant)) || 1.0, 2.0));
        if (currentFormantScale !== scale) {
            currentFormantScale = scale;
            if (workletReady) postWorkletMessage({ type: 'set-formant', value: scale });
        }
    }

    /**
     * Sets the master gain (volume) level.
     * @public
     * @param {number} gain - Desired gain level (0.0 to 5.0, 1.0 is normal).
     */
    function setGain(gain) {
        if (!gainNode || !audioCtx || audioCtx.state === 'closed') return;
        const value = Math.max(0.0, Math.min(parseFloat(String(gain)) || 1.0, 5.0));
        gainNode.gain.setTargetAtTime(value, audioCtx.currentTime, 0.015); // Smooth transition
    }

    /**
     * Gets the current playback time (source time) and total duration.
     * @public
     * @returns {{currentTime: number, duration: number}}
     */
    function getCurrentTime() {
        return {
            currentTime: currentWorkletTime,
            duration: currentDecodedBuffer?.duration || 0
        };
    }

    /**
     * Returns the active AudioContext instance.
     * @public
     * @returns {AudioContext|null}
     */
    function getAudioContext() {
        return audioCtx;
    }


    /**
     * Cleans up all audio resources.
     * @public
     */
    function cleanup() {
        console.log("AudioEngine: Cleaning up resources...");
        cleanupCurrentWorklet().finally(() => {
            if (audioCtx && audioCtx.state !== 'closed') {
                audioCtx.close().then(() => console.log("AudioEngine: AudioContext closed."))
                           .catch(e => console.warn("AudioEngine: Error closing AudioContext:", e));
            }
            audioCtx = null; gainNode = null; workletNode = null; currentDecodedBuffer = null;
            wasmBinary = null; loaderScriptText = null;
            workletReady = false; isPlaying = false;
            currentWorkletTime = 0.0; currentPlaybackSpeed = 1.0; currentPitchScale = 1.0; currentFormantScale = 1.0;
        });
    }


    /**
     * Dispatches a custom event on the document.
     * @private
     * @param {string} eventName - The name of the event.
     * @param {Object<string, any>} [detail={}] - Data to pass with the event.
     */
    function dispatchEngineEvent(eventName, detail = {}) {
        document.dispatchEvent(new CustomEvent(eventName, { detail: detail }));
    }

    /**
     * @typedef {Object} AudioEnginePublicInterface
     * @property {function(): Promise<void>} init
     * @property {function(File): Promise<void>} loadAndProcessFile
     * @property {function(AudioBuffer): Promise<Float32Array>} resampleTo16kMono
     * @property {function(): Promise<void>} togglePlayPause
     * @property {function(number): void} jumpBy
     * @property {function(number): void} seek
     * @property {function(number): void} setSpeed
     * @property {function(number): void} setPitch
     * @property {function(number): void} setFormant
     * @property {function(number): void} setGain
     * @property {function(): {currentTime: number, duration: number}} getCurrentTime
     * @property {function(): (AudioContext|null)} getAudioContext
     * @property {function(): void} cleanup
     */

    /** @type {AudioEnginePublicInterface} */
    return {
        init: init,
        loadAndProcessFile: loadAndProcessFile,
        resampleTo16kMono: resampleTo16kMono,
        togglePlayPause: togglePlayPause,
        jumpBy: jumpBy,
        seek: seek,
        setSpeed: setSpeed,
        setPitch: setPitch,
        setFormant: setFormant,
        setGain: setGain,
        getCurrentTime: getCurrentTime,
        getAudioContext: getAudioContext,
        cleanup: cleanup
    };
})();
// --- /vibe-player/js/player/audioEngine.js --- // Updated Path

````
--- End of File: vibe-player/js/player/audioEngine.js ---
--- File: vibe-player/js/player/rubberbandProcessor.js ---
````javascript
// --- /vibe-player/js/player/rubberbandProcessor.js --- // Updated Path
// AudioWorkletProcessor for real-time time-stretching using Rubberband WASM.

// Constants cannot be accessed here directly, but name is needed for registration.
/** @const {string} Name of the AudioWorkletProcessor. */
const PROCESSOR_NAME = 'rubberband-processor';

/**
 * @class RubberbandProcessor
 * @extends AudioWorkletProcessor
 * @description Processes audio using the Rubberband library compiled to WASM.
 * Handles loading Rubberband WASM, managing its state, processing audio frames
 * for time-stretching and pitch-shifting, and communicating with the main thread.
 * Runs within an AudioWorkletGlobalScope.
 */
class RubberbandProcessor extends AudioWorkletProcessor {

    /**
     * Initializes the processor instance. Sets up initial state and message handling.
     * WASM/Rubberband initialization happens asynchronously via message handler or first process call.
     * @constructor
     * @param {AudioWorkletNodeOptions} options - Options passed from the AudioWorkletNode constructor.
     * @param {object} options.processorOptions - Custom options.
     * @param {number} options.processorOptions.sampleRate - The sample rate of the audio context.
     * @param {number} options.processorOptions.numberOfChannels - The number of channels in the input audio.
     * @param {ArrayBuffer} options.processorOptions.wasmBinary - The pre-fetched WASM binary of Rubberband.
     * @param {string} options.processorOptions.loaderScriptText - The text of the Rubberband WASM loader script.
     */
    constructor(options) {
        super(options); // Pass options to base constructor
        console.log("[Worklet] RubberbandProcessor created.");

        // --- State Initialization ---
        /** @private @type {object} Options passed from the main thread. */
        this.processorOpts = options.processorOptions || {};
        /** @private @type {number} Sample rate of the audio context. */
        this.sampleRate = this.processorOpts.sampleRate || sampleRate; // sampleRate is global in AudioWorkletGlobalScope
        /** @private @type {number} Number of audio channels. */
        this.numberOfChannels = this.processorOpts.numberOfChannels || 0;
        /** @private @type {ArrayBuffer|null} The WASM binary. */
        this.wasmBinary = this.processorOpts.wasmBinary;
        /** @private @type {string|null} The WASM loader script text. */
        this.loaderScriptText = this.processorOpts.loaderScriptText;

        /** @private @type {object|null} Exported functions from the WASM module. */
        this.wasmModule = null;
        /** @private @type {boolean} Flag indicating if WASM and Rubberband are initialized. */
        this.wasmReady = false;
        /** @private @type {number} Pointer to the RubberbandStretcher instance in WASM memory. */
        this.rubberbandStretcher = 0; // Using 'number' as it's an opaque pointer (integer).

        /** @private @type {boolean} Current playback state. */
        this.isPlaying = false;
        /** @private @type {number} Target speed ratio for time-stretching. */
        this.currentTargetSpeed = 1.0;
        /** @private @type {number} Target pitch scale. */
        this.currentTargetPitchScale = 1.0;
        /** @private @type {number} Target formant scale. */
        this.currentTargetFormantScale = 1.0;
        /** @private @type {number} Last applied stretch ratio to Rubberband. */
        this.lastAppliedStretchRatio = 1.0;
        /** @private @type {number} Last applied pitch scale to Rubberband. */
        this.lastAppliedPitchScale = 1.0;
        /** @private @type {number} Last applied formant scale to Rubberband. */
        this.lastAppliedFormantScale = 1.0;

        /** @private @type {boolean} Flag indicating if Rubberband state needs reset (e.g., after seek). */
        this.resetNeeded = true;
        /** @private @type {boolean} Flag indicating if the end of the source audio has been processed. */
        this.streamEnded = false;
        /** @private @type {boolean} Flag indicating if the final block has been sent to `rubberband_process`. */
        this.finalBlockSent = false;
        /** @private @type {number} Current playback position in the source audio, in seconds. */
        this.playbackPositionInSeconds = 0.0;

        /** @private @type {number} Pointer to the array of input channel buffer pointers in WASM memory. */
        this.inputPtrs = 0;
        /** @private @type {number} Pointer to the array of output channel buffer pointers in WASM memory. */
        this.outputPtrs = 0;
        /** @private @type {number[]} Array of pointers to individual input channel buffers in WASM memory. */
        this.inputChannelBuffers = [];
        /** @private @type {number[]} Array of pointers to individual output channel buffers in WASM memory. */
        this.outputChannelBuffers = [];
        /** @private @type {number} Fixed block size for WASM memory buffers (in frames). */
        this.blockSizeWasm = 1024;

        /** @private @type {Float32Array[]|null} Array of Float32Arrays holding the original audio data for each channel. */
        this.originalChannels = null;
        /** @private @type {boolean} Flag indicating if audio data has been loaded into the processor. */
        this.audioLoaded = false;
        /** @private @type {number} Duration of the loaded audio in seconds. */
        this.sourceDurationSeconds = 0;

        if (this.port) {
            this.port.onmessage = this.handleMessage.bind(this);
        } else {
            console.error("[Worklet] CONSTRUCTOR: Message port is not available! Cannot receive messages.");
        }

        if (!this.wasmBinary) this.postErrorAndStop("WASM binary missing in processorOptions.");
        if (!this.loaderScriptText) this.postErrorAndStop("Loader script text missing in processorOptions.");
        if (!this.sampleRate || this.sampleRate <= 0) this.postErrorAndStop(`Invalid SampleRate provided: ${this.sampleRate}`);
        if (!this.numberOfChannels || this.numberOfChannels <= 0) this.postErrorAndStop(`Invalid NumberOfChannels provided: ${this.numberOfChannels}`);

        console.log("[Worklet] RubberbandProcessor instance constructed. Waiting for audio data or commands.");
    }

    /**
     * Initializes the WASM module and the RubberbandStretcher instance.
     * This involves evaluating a loader script and using a custom `instantiateWasm` hook.
     * It also allocates memory within the WASM heap for audio buffers.
     * @private
     * @async
     * @returns {Promise<void>} Resolves when initialization is complete, or rejects on error.
     */
    async initializeWasmAndRubberband() {
        if (this.wasmReady) return; // Avoid re-initialization
        if (!this.wasmBinary || !this.loaderScriptText) {
            this.postErrorAndStop("Cannot initialize WASM: Resources missing."); return;
        }
        this.postStatus("Initializing WASM & Rubberband...");
        try {
            /** @type {function(WebAssembly.Imports, function(WebAssembly.Instance, WebAssembly.Module): void): object} */
            const instantiateWasm = (imports, successCallback) => {
                WebAssembly.instantiate(this.wasmBinary, imports)
                    .then(output => successCallback(output.instance, output.module))
                    .catch(error => this.postError(`WASM Hook Instantiate Error: ${error.message}`));
                return {}; // Emscripten convention
            };

            /** @type {function(object): Promise<object>} */
            let loaderFunc;
            try { // Security Note: Using Function constructor can be risky if loaderScriptText is from untrusted source.
                const getLoaderFactory = new Function('moduleArg', `${this.loaderScriptText}; return Rubberband;`);
                loaderFunc = getLoaderFactory();
                if (typeof loaderFunc !== 'function') throw new Error("Loader script did not return an async function.");
            } catch (e) { throw new Error(`Loader script evaluation error: ${e.message}`); }

            this.wasmModule = await loaderFunc({ instantiateWasm: instantiateWasm });
            if (!this.wasmModule || typeof this.wasmModule._rubberband_new !== 'function') {
                 throw new Error("WASM module loaded, but essential Rubberband exports not found.");
            }

            const RBOptions = this.wasmModule.RubberBandOptionFlag || {};
            const options = (RBOptions.ProcessRealTime ?? 0x01) | (RBOptions.PitchHighQuality ?? 0x02000000) | (RBOptions.PhaseIndependent ?? 0x2000);
            this.rubberbandStretcher = this.wasmModule._rubberband_new(this.sampleRate, this.numberOfChannels, options, 1.0, 1.0);
            if (!this.rubberbandStretcher) throw new Error("_rubberband_new failed to create stretcher instance.");

            const pointerSize = 4; const frameSize = 4; // Assuming 32-bit floats and pointers
            this.inputPtrs = this.wasmModule._malloc(this.numberOfChannels * pointerSize);
            this.outputPtrs = this.wasmModule._malloc(this.numberOfChannels * pointerSize);
            if (!this.inputPtrs || !this.outputPtrs) throw new Error("Failed to allocate memory for channel pointer arrays.");

            for (let i = 0; i < this.numberOfChannels; ++i) {
                const bufferSizeBytes = this.blockSizeWasm * frameSize;
                const inputBuf = this.wasmModule._malloc(bufferSizeBytes);
                const outputBuf = this.wasmModule._malloc(bufferSizeBytes);
                if (!inputBuf || !outputBuf) { this.cleanupWasmMemory(); throw new Error(`Buffer malloc failed for Channel ${i}.`); }
                this.inputChannelBuffers.push(inputBuf); this.outputChannelBuffers.push(outputBuf);
                this.wasmModule.HEAPU32[(this.inputPtrs / pointerSize) + i] = inputBuf;
                this.wasmModule.HEAPU32[(this.outputPtrs / pointerSize) + i] = outputBuf;
            }
            this.wasmReady = true; this.postStatus('processor-ready');
        } catch (error) {
            console.error(`[Worklet] WASM/Rubberband Init Error: ${error.message}`, error.stack);
            this.postError(`Init Error: ${error.message}`);
            this.wasmReady = false; this.rubberbandStretcher = 0; this.cleanupWasmMemory();
        }
    }

    /**
      * Handles messages received from the main AudioEngine via the processor's port.
      * @private
      * @param {MessageEvent<object>} event - The event containing the message data.
      * @param {string} event.data.type - Message type (e.g., 'load-audio', 'play', 'seek').
      * @param {*} [event.data.value] - Optional value associated with the message.
      * @param {ArrayBuffer[]} [event.data.channelData] - Audio data for 'load-audio'.
      * @param {number} [event.data.positionSeconds] - Seek position for 'seek'.
      */
    handleMessage(event) {
        const data = event.data;
        try {
            switch (data.type) {
                case 'load-audio':
                    this.playbackPositionInSeconds = 0; this.resetNeeded = true; this.streamEnded = false; this.finalBlockSent = false;
                    this.currentTargetSpeed = 1.0; this.lastAppliedStretchRatio = 1.0;
                    this.currentTargetPitchScale = 1.0; this.lastAppliedPitchScale = 1.0;
                    this.currentTargetFormantScale = 1.0; this.lastAppliedFormantScale = 1.0;
                    this.audioLoaded = false; this.originalChannels = null; this.sourceDurationSeconds = 0;

                    if (data.channelData && Array.isArray(data.channelData) && data.channelData.length === this.numberOfChannels) {
                        this.originalChannels = data.channelData.map(buffer => new Float32Array(buffer));
                        this.audioLoaded = true;
                        this.sourceDurationSeconds = (this.originalChannels[0]?.length || 0) / this.sampleRate;
                        if (!this.wasmReady) { this.initializeWasmAndRubberband(); } else { this.postStatus('processor-ready'); }
                    } else { this.postError('Invalid audio data received for loading.'); }
                    break;
                case 'play':
                    if (this.wasmReady && this.audioLoaded) {
                        if (!this.isPlaying) {
                            if (this.streamEnded || this.playbackPositionInSeconds >= this.sourceDurationSeconds) {
                                this.playbackPositionInSeconds = 0; this.resetNeeded = true; this.streamEnded = false; this.finalBlockSent = false;
                            }
                            this.isPlaying = true; this.port?.postMessage({ type: 'playback-state', isPlaying: true });
                        }
                    } else { this.postError(`Cannot play: ${!this.wasmReady ? 'WASM not ready' : 'Audio not loaded'}.`); this.port?.postMessage({ type: 'playback-state', isPlaying: false }); }
                    break;
                case 'pause':
                    if (this.isPlaying) { this.isPlaying = false; this.port?.postMessage({ type: 'playback-state', isPlaying: false }); }
                    break;
                case 'set-speed':
                     if (this.wasmReady && typeof data.value === 'number') this.currentTargetSpeed = Math.max(0.01, data.value);
                     break;
                 case 'set-pitch':
                     if (this.wasmReady && typeof data.value === 'number') this.currentTargetPitchScale = Math.max(0.1, data.value);
                     break;
                 case 'set-formant':
                    if (this.wasmReady && typeof data.value === 'number') this.currentTargetFormantScale = Math.max(0.1, data.value);
                    break;
                case 'seek':
                    if (this.wasmReady && this.audioLoaded && typeof data.positionSeconds === 'number') {
                        this.playbackPositionInSeconds = Math.max(0, Math.min(data.positionSeconds, this.sourceDurationSeconds));
                        this.resetNeeded = true; this.streamEnded = false; this.finalBlockSent = false;
                    } break;
                case 'cleanup': this.cleanup(); break;
                default: console.warn("[Worklet] Received unknown message type:", data.type);
            }
        } catch (error) {
             this.postError(`Error in handleMessage ('${data.type}'): ${error.message}`);
             this.isPlaying = false; this.port?.postMessage({ type: 'playback-state', isPlaying: false });
        }
    }

    /**
     * Core audio processing method. Called by the AudioWorklet system at regular intervals.
     * Manages audio data flow to/from Rubberband WASM, applies parameter changes, and handles playback state.
     * @param {Float32Array[][]} inputs - Input audio buffers (not used by this processor as it's a source).
     * @param {Float32Array[][]} outputs - Output audio buffers to be filled by this processor.
     *                                     Structure: `outputs[0][channelIndex][sampleIndex]`
     * @param {Record<string, Float32Array>} parameters - Real-time audio parameters (not used by this processor).
     * @returns {boolean} Returns `true` to keep the processor alive, `false` to terminate it.
     */
    process(inputs, outputs, parameters) {
        if (!this.wasmReady || !this.audioLoaded || !this.rubberbandStretcher || !this.wasmModule) {
            this.outputSilence(outputs); return true;
        }
        if (!this.isPlaying) {
            this.outputSilence(outputs); return true;
        }

        const outputBuffer = outputs[0];
        if (!outputBuffer || outputBuffer.length !== this.numberOfChannels || !outputBuffer[0]) {
            this.outputSilence(outputs); return true; // Should not happen if configured correctly
        }
        const outputBlockSize = outputBuffer[0].length; // e.g., 128 frames
        if (outputBlockSize === 0) return true;

        if (this.streamEnded) { // If stream previously ended, check if Rubberband has any remaining buffered samples
             const availableInRb = this.wasmModule._rubberband_available?.(this.rubberbandStretcher) ?? 0;
             if (Math.max(0, availableInRb) <= 0) { this.outputSilence(outputs); return true; }
        }

        try {
            const sourceChannels = /** @type {Float32Array[]} */ (this.originalChannels); // Assert type as it's checked by audioLoaded
            const targetStretchRatio = 1.0 / Math.max(0.01, this.currentTargetSpeed);
            const safeStretchRatio = Math.max(0.05, Math.min(20.0, targetStretchRatio));
            const safeTargetPitch = Math.max(0.1, this.currentTargetPitchScale);
            const safeTargetFormant = Math.max(0.1, this.currentTargetFormantScale);

            const ratioChanged = Math.abs(safeStretchRatio - this.lastAppliedStretchRatio) > 1e-6;
            const pitchChanged = Math.abs(safeTargetPitch - this.lastAppliedPitchScale) > 1e-6;
            const formantChanged = Math.abs(safeTargetFormant - this.lastAppliedFormantScale) > 1e-6;

            if (this.resetNeeded) {
                this.wasmModule._rubberband_reset(this.rubberbandStretcher);
                this.wasmModule._rubberband_set_time_ratio(this.rubberbandStretcher, safeStretchRatio);
                this.wasmModule._rubberband_set_pitch_scale(this.rubberbandStretcher, safeTargetPitch);
                this.wasmModule._rubberband_set_formant_scale(this.rubberbandStretcher, safeTargetFormant);
                this.lastAppliedStretchRatio = safeStretchRatio; this.lastAppliedPitchScale = safeTargetPitch; this.lastAppliedFormantScale = safeTargetFormant;
                this.resetNeeded = false; this.finalBlockSent = false; this.streamEnded = false;
            } else {
                if (ratioChanged) { this.wasmModule._rubberband_set_time_ratio(this.rubberbandStretcher, safeStretchRatio); this.lastAppliedStretchRatio = safeStretchRatio; }
                if (pitchChanged) { this.wasmModule._rubberband_set_pitch_scale(this.rubberbandStretcher, safeTargetPitch); this.lastAppliedPitchScale = safeTargetPitch; }
                if (formantChanged) { this.wasmModule._rubberband_set_formant_scale(this.rubberbandStretcher, safeTargetFormant); this.lastAppliedFormantScale = safeTargetFormant; }
            }

            let inputFramesNeeded = Math.ceil(outputBlockSize / safeStretchRatio) + 4; // Recommended buffer
            inputFramesNeeded = Math.max(1, inputFramesNeeded);
            let readPosInSourceSamples = Math.round(this.playbackPositionInSeconds * this.sampleRate);
            readPosInSourceSamples = Math.max(0, Math.min(readPosInSourceSamples, sourceChannels[0].length));
            let actualInputProvided = Math.min(inputFramesNeeded, sourceChannels[0].length - readPosInSourceSamples);
            actualInputProvided = Math.max(0, actualInputProvided); // Ensure non-negative

            const isFinalDataBlock = (readPosInSourceSamples + actualInputProvided) >= sourceChannels[0].length;
            const sendFinalFlag = isFinalDataBlock && !this.finalBlockSent;

            if (actualInputProvided > 0 || sendFinalFlag) {
                for (let i = 0; i < this.numberOfChannels; i++) {
                    const wasmInputBufferView = new Float32Array(this.wasmModule.HEAPF32.buffer, this.inputChannelBuffers[i], this.blockSizeWasm);
                    if (actualInputProvided > 0) {
                        const inputSlice = sourceChannels[i].subarray(readPosInSourceSamples, readPosInSourceSamples + actualInputProvided);
                        wasmInputBufferView.set(inputSlice.subarray(0, Math.min(inputSlice.length, this.blockSizeWasm)));
                        if (inputSlice.length < this.blockSizeWasm) wasmInputBufferView.fill(0.0, inputSlice.length);
                    } else { wasmInputBufferView.fill(0.0); }
                }
                this.wasmModule._rubberband_process(this.rubberbandStretcher, this.inputPtrs, actualInputProvided, sendFinalFlag ? 1 : 0);
                this.playbackPositionInSeconds += (actualInputProvided / this.sampleRate);
                this.playbackPositionInSeconds = Math.min(this.playbackPositionInSeconds, this.sourceDurationSeconds);

                let correctedTime = this.playbackPositionInSeconds;
                try {
                    const latencySamples = this.wasmModule._rubberband_get_latency?.(this.rubberbandStretcher) ?? 0;
                    if (latencySamples >= 0 && this.sampleRate > 0) {
                        const totalLatencySeconds = (latencySamples / this.sampleRate) + (outputBlockSize / this.sampleRate);
                        correctedTime = Math.max(0, this.playbackPositionInSeconds - totalLatencySeconds);
                    }
                } catch(e) { /* ignore latency error */ }
                this.port?.postMessage({type: 'time-update', currentTime: correctedTime });
                if (sendFinalFlag) this.finalBlockSent = true;
            }

            let totalRetrieved = 0;
            const tempOutputBuffers = Array.from({ length: this.numberOfChannels }, () => new Float32Array(outputBlockSize));
            let availableInRb;
            do {
                 availableInRb = this.wasmModule._rubberband_available?.(this.rubberbandStretcher) ?? 0;
                 availableInRb = Math.max(0, availableInRb);
                 if (availableInRb <= 0) break;
                const neededNow = outputBlockSize - totalRetrieved; if (neededNow <= 0) break;
                const framesToRetrieve = Math.min(availableInRb, neededNow, this.blockSizeWasm);
                if (framesToRetrieve <= 0) break;
                const retrieved = this.wasmModule._rubberband_retrieve?.(this.rubberbandStretcher, this.outputPtrs, framesToRetrieve) ?? -1;
                if (retrieved > 0) {
                    for (let i = 0; i < this.numberOfChannels; i++) {
                        const wasmOutputBufferView = new Float32Array(this.wasmModule.HEAPF32.buffer, this.outputChannelBuffers[i], retrieved);
                        tempOutputBuffers[i].set(wasmOutputBufferView.subarray(0, Math.min(retrieved, tempOutputBuffers[i].length - totalRetrieved)), totalRetrieved);
                    }
                    totalRetrieved += retrieved;
                } else { availableInRb = 0; break; }
            } while (totalRetrieved < outputBlockSize);

            for (let i = 0; i < this.numberOfChannels; ++i) {
                 if (outputBuffer[i]) {
                     outputBuffer[i].set(tempOutputBuffers[i].subarray(0, Math.min(totalRetrieved, outputBlockSize)));
                     if (totalRetrieved < outputBlockSize) outputBuffer[i].fill(0.0, totalRetrieved);
                 }
            }

            if (this.finalBlockSent && availableInRb <= 0 && totalRetrieved < outputBlockSize) {
                if (!this.streamEnded) {
                    this.streamEnded = true; this.isPlaying = false;
                    this.postStatus('Playback ended'); this.port?.postMessage({ type: 'playback-state', isPlaying: false });
                }
            }
        } catch (error) {
            console.error(`[Worklet] Processing Error: ${error.message}`, error.stack);
            this.postError(`Processing Error: ${error.message}`);
            this.isPlaying = false; this.streamEnded = true; this.outputSilence(outputs);
            this.port?.postMessage({ type: 'playback-state', isPlaying: false });
        }
        return true;
    }

    /**
      * Fills the output audio buffers with silence (zeros).
      * @private
      * @param {Float32Array[][]} outputs - The output buffers from the `process` method.
      */
    outputSilence(outputs) {
        if (!outputs?.[0]?.[0]) return; // Ensure valid structure
        for (let channel = 0; channel < outputs[0].length; ++channel) {
            outputs[0][channel]?.fill(0.0); // Fill each channel buffer with 0.0
        }
    }

    /**
     * Posts a status message to the main thread.
     * @private
     * @param {string} message - The status message.
     */
    postStatus(message) {
        try { this.port?.postMessage({ type: 'status', message }); }
        catch (e) { console.error(`[Worklet] FAILED to post status '${message}':`, e.message); }
    }

    /**
     * Posts an error message to the main thread.
     * @private
     * @param {string} message - The error message.
     */
    postError(message) {
         try { this.port?.postMessage({ type: 'error', message }); }
         catch (e) { console.error(`[Worklet] FAILED to post error '${message}':`, e.message); }
    }

    /**
     * Posts an error message and initiates cleanup of the processor.
     * @private
     * @param {string} message - The error message.
     */
    postErrorAndStop(message) {
        this.postError(message);
        this.cleanup();
    }

    /**
     * Frees WASM memory allocated for input/output channel buffers and pointer arrays.
     * @private
     */
    cleanupWasmMemory() {
        if (this.wasmModule?._free) {
            try {
                this.inputChannelBuffers.forEach(ptr => { if (ptr) this.wasmModule._free(ptr); });
                this.outputChannelBuffers.forEach(ptr => { if (ptr) this.wasmModule._free(ptr); });
                if (this.inputPtrs) this.wasmModule._free(this.inputPtrs);
                if (this.outputPtrs) this.wasmModule._free(this.outputPtrs);
            } catch (e) { console.error("[Worklet] Error during explicit WASM memory cleanup:", e.message); }
        }
        this.inputPtrs = 0; this.outputPtrs = 0;
        this.inputChannelBuffers = []; this.outputChannelBuffers = [];
    }

    /**
     * Cleans up all resources used by the processor, including the Rubberband instance and WASM memory.
     * Resets the processor's state.
     * @private
     */
    cleanup() {
        console.log("[Worklet] Cleanup initiated.");
        this.isPlaying = false;
        if (this.wasmReady && this.rubberbandStretcher !== 0 && this.wasmModule?._rubberband_delete) {
            try { this.wasmModule._rubberband_delete(this.rubberbandStretcher); }
            catch (e) { console.error("[Worklet] Error deleting Rubberband instance:", e.message); }
        }
        this.rubberbandStretcher = 0;
        this.cleanupWasmMemory();
        this.wasmReady = false; this.audioLoaded = false;
        this.originalChannels = null; this.wasmModule = null;
        // Keep wasmBinary & loaderScriptText if re-init is possible without new options.
        // For full cleanup, these would be nulled too:
        // this.wasmBinary = null; this.loaderScriptText = null;
        this.playbackPositionInSeconds = 0; this.streamEnded = true;
        this.finalBlockSent = false; this.resetNeeded = true;
        this.postStatus("Processor cleaned up");
    }
}

try {
    if (typeof registerProcessor === 'function' && typeof sampleRate !== 'undefined') { // `sampleRate` is global in AudioWorkletGlobalScope
        registerProcessor(PROCESSOR_NAME, RubberbandProcessor);
    } else {
        console.error("[Worklet] `registerProcessor` or global `sampleRate` is not defined. Cannot register RubberbandProcessor.");
        // Attempt to notify main thread about this critical failure if postMessage is available
        if (typeof self !== 'undefined' && self.postMessage) {
            self.postMessage({ type: 'error', message: 'Worklet environment error: registerProcessor or sampleRate undefined.' });
        }
    }
} catch (error) {
    console.error(`[Worklet] CRITICAL: Failed to register processor '${PROCESSOR_NAME}'. Error: ${error.message}`, error.stack);
    if (typeof self !== 'undefined' && self.postMessage) {
        self.postMessage({ type: 'error', message: `Failed to register processor ${PROCESSOR_NAME}: ${error.message}` });
    }
}
// --- /vibe-player/js/player/rubberbandProcessor.js --- // Updated Path

````
--- End of File: vibe-player/js/player/rubberbandProcessor.js ---
--- File: vibe-player/js/sparkles.js ---
````javascript
// ─────────────────────────────────────────────────────────────────────────────
//  sparkles.js
//  A self-contained sparkle/dot effect that you can turn on/off by calling
//    sparkle(true)  or  sparkle(false)  or  sparkle() to toggle.
//  No external CSS or other files needed.
// ─────────────────────────────────────────────────────────────────────────────

(function () {
    'use strict';
    // ───────────────────────────────────────────────────────────────────────────
    //  CONFIGURATION CONSTANTS
    // ───────────────────────────────────────────────────────────────────────────
    /** @const {number} Maximum number of concurrent sparkles. */
    const MAX_SPARKLES = 1000;
    /** @const {number} Base lifetime for sparkles (in animation ticks). Stars live 2x this, then dots live 2x this. */
    const SPARKLE_LIFETIME = 40;
    /** @const {number} Controls spawn density along mouse path; smaller means more sparkles. */
    const SPARKLE_DISTANCE = 10;

    // ───────────────────────────────────────────────────────────────────────────
    //  INTERNAL STATE
    // ───────────────────────────────────────────────────────────────────────────
    /** @type {HTMLCanvasElement|null} The canvas element for drawing sparkles. */
    let canvas = null;
    /** @type {CanvasRenderingContext2D|null} The 2D rendering context of the canvas. */
    let ctx = null;
    /** @type {number} Current width of the document viewport. */
    let docW = 0;
    /** @type {number} Current height of the document viewport. */
    let docH = 0;

    /** @type {boolean} Flag indicating if the sparkle system has been initialized. */
    let isInitialized = false;
    /** @type {boolean} Flag indicating if sparkles are currently enabled. */
    let sparklesEnabled = false;
    /** @type {boolean} Flag indicating if the animation loop is currently running. */
    let animationRunning = false;
    /** @type {number} Timestamp of the last sparkle spawn attempt. */
    let lastSpawnTime = 0;

    /**
     * @typedef {Object} SparkleParticle
     * @property {boolean} active - Whether the particle is currently active and should be drawn/updated.
     * @property {number} x - The x-coordinate of the particle.
     * @property {number} y - The y-coordinate of the particle.
     * @property {number} ticksLeft - Remaining lifetime of the particle in animation ticks.
     * @property {string} color - The color of the particle (CSS color string).
     */

    /** @type {SparkleParticle[]} Pool for star particles. */
    const stars = [];
    /** @type {SparkleParticle[]} Pool for tiny dot particles. */
    const tinnies = [];

    for (let i = 0; i < MAX_SPARKLES; i++) {
        stars.push({active: false, x: 0, y: 0, ticksLeft: 0, color: ""});
        tinnies.push({active: false, x: 0, y: 0, ticksLeft: 0, color: ""});
    }

    /** @type {string[]} Precomputed pool of random RGB color strings for sparkles. */
    const COLOR_POOL = [];
    (function buildColorPool() {
        for (let i = 0; i < 512; i++) {
            const c1 = 255;
            const c2 = Math.floor(Math.random() * 256);
            const c3 = Math.floor(Math.random() * (256 - c2 / 2));
            const arr = [c1, c2, c3];
            arr.sort(() => 0.5 - Math.random()); // Shuffle to vary which component is dominant
            COLOR_POOL.push(`rgb(${arr[0]}, ${arr[1]}, ${arr[2]})`);
        }
    })();

    // ───────────────────────────────────────────────────────────────────────────
    //  INITIALIZATION (runs once when DOMContentLoaded fires)
    // ───────────────────────────────────────────────────────────────────────────
    /**
     * Initializes the sparkle system: creates canvas, sets up listeners.
     * This function is called once when the DOM is ready.
     * @private
     */
    function initialize() {
        if (isInitialized) return;
        isInitialized = true;

        canvas = document.createElement("canvas");
        canvas.style.position = "fixed";
        canvas.style.top = "0";
        canvas.style.left = "0";
        canvas.style.width = "100%";
        canvas.style.height = "100%";
        canvas.style.pointerEvents = "none"; // Canvas doesn't intercept mouse events
        canvas.style.zIndex = "999"; // Ensure it's on top (adjust if needed)
        document.body.appendChild(canvas);
        ctx = canvas.getContext("2d");

        handleResize();
        window.addEventListener("resize", handleResize);
        document.addEventListener("mousemove", onMouseMove);

        if (sparklesEnabled && !animationRunning) {
            animationRunning = true;
            requestAnimationFrame(animate);
        }
    }

    /**
     * Handles window resize events by updating canvas dimensions to match the viewport.
     * @private
     */
    function handleResize() {
        if (!canvas) return;
        docW = window.innerWidth;
        docH = window.innerHeight;
        canvas.width = docW;
        canvas.height = docH;
    }

    // ───────────────────────────────────────────────────────────────────────────
    //  SPAWNING LOGIC: place a “star” in the pool (or convert an old one to a dot)
    // ───────────────────────────────────────────────────────────────────────────
    /**
     * Spawns a new star particle at the given coordinates.
     * If all star slots are active, it may replace the oldest star, converting it to a dot.
     * @private
     * @param {number} x - The x-coordinate for the new star.
     * @param {number} y - The y-coordinate for the new star.
     */
    function spawnStar(x, y) {
        if (!ctx || x + 5 >= docW || y + 5 >= docH || x < 0 || y < 0) return;

        let chosenIdx = -1;
        let minTicks = SPARKLE_LIFETIME * 2 + 1; // Sentinel for oldest active star

        for (let i = 0; i < MAX_SPARKLES; i++) {
            const s = stars[i];
            if (!s.active) { // Found an inactive slot
                chosenIdx = i;
                minTicks = null; // Mark that we found a truly free slot
                break;
            } else if (s.ticksLeft < minTicks) { // Found an active star older than current minTicks
                minTicks = s.ticksLeft;
                chosenIdx = i;
            }
        }

        // If minTicks is not null here, it means all slots were active,
        // and chosenIdx points to the star with the least ticksLeft (oldest).
        if (minTicks !== null && chosenIdx !== -1) {
            const oldStar = stars[chosenIdx];
            // Convert the old star to a "tinny" dot
            const tinny = tinnies[chosenIdx];
            tinny.active = true;
            tinny.x = oldStar.x;
            tinny.y = oldStar.y;
            tinny.ticksLeft = SPARKLE_LIFETIME * 2;
            tinny.color = oldStar.color;
        }

        // Initialize the chosen slot (either inactive or oldest) as a new star
        if (chosenIdx !== -1) {
            const newStar = stars[chosenIdx];
            const col = COLOR_POOL[Math.floor(Math.random() * COLOR_POOL.length)];
            newStar.active = true;
            newStar.x = x;
            newStar.y = y;
            newStar.ticksLeft = SPARKLE_LIFETIME * 2;
            newStar.color = col;
        }
    }

    // ───────────────────────────────────────────────────────────────────────────
    //  ANIMATION LOOP: update and draw all active stars and dots each frame
    // ───────────────────────────────────────────────────────────────────────────
    /**
     * The main animation loop. Updates and draws all active particles.
     * Requests the next frame if particles are active or sparkles are enabled.
     * @private
     * @param {DOMHighResTimeStamp} timestamp - The current time provided by requestAnimationFrame.
     */
    function animate(timestamp) {
        if (!ctx) return;
        ctx.clearRect(0, 0, docW, docH);
        let anyAlive = false;

        // --- 1) Update & draw “stars” ---
        for (let i = 0; i < MAX_SPARKLES; i++) {
            const s = stars[i];
            if (!s.active) continue;

            s.ticksLeft--;
            if (s.ticksLeft <= 0) {
                // Convert to a “tiny” dot
                const tinny = tinnies[i];
                tinny.active = true;
                tinny.x = s.x;
                tinny.y = s.y;
                tinny.ticksLeft = SPARKLE_LIFETIME * 2;
                tinny.color = s.color;
                s.active = false;
                // anyAlive = true; // Dot is now alive
                continue; // Star is done
            }

            s.y += 1 + 3 * Math.random(); // Move downwards with some variance
            s.x += (i % 5 - 2) / 5; // Slight horizontal drift based on index

            if (s.y + 5 < docH && s.x + 5 < docW && s.x > -5 && s.y > -5) {
                const halfLife = SPARKLE_LIFETIME;
                ctx.strokeStyle = s.color;
                ctx.lineWidth = 1;
                if (s.ticksLeft > halfLife) { // First half of life: 5x5 cross
                    const cx = s.x + 2; const cy = s.y + 2;
                    ctx.beginPath();
                    ctx.moveTo(s.x, cy); ctx.lineTo(s.x + 5, cy);
                    ctx.moveTo(cx, s.y); ctx.lineTo(cx, s.y + 5);
                    ctx.stroke();
                } else { // Second half of life: 3x3 cross
                    const cx = s.x + 1; const cy = s.y + 1;
                    ctx.beginPath();
                    ctx.moveTo(s.x, cy); ctx.lineTo(s.x + 3, cy);
                    ctx.moveTo(cx, s.y); ctx.lineTo(cx, s.y + 3);
                    ctx.stroke();
                }
                anyAlive = true;
            } else {
                s.active = false; // Out of bounds
            }
        }

        // --- 2) Update & draw “tinnies” (dots) ---
        for (let i = 0; i < MAX_SPARKLES; i++) {
            const t = tinnies[i];
            if (!t.active) continue;

            t.ticksLeft--;
            if (t.ticksLeft <= 0) {
                t.active = false;
                continue;
            }

            t.y += 1 + 2 * Math.random(); // Move downwards
            t.x += (i % 4 - 2) / 4; // Slight horizontal drift

            if (t.y + 3 < docH && t.x + 3 < docW && t.x > -3 && t.y > -3) {
                const halfLife = SPARKLE_LIFETIME;
                ctx.fillStyle = t.color;
                if (t.ticksLeft > halfLife) { // First half: 2x2 square
                    ctx.fillRect(t.x, t.y, 2, 2);
                } else { // Second half: 1x1 pixel
                    ctx.fillRect(t.x + 0.5, t.y + 0.5, 1, 1);
                }
                anyAlive = true;
            } else {
                t.active = false; // Out of bounds
            }
        }

        if (anyAlive || sparklesEnabled) { // Continue if particles exist or feature is on
            animationRunning = true;
            requestAnimationFrame(animate);
        } else {
            animationRunning = false;
            if (ctx) ctx.clearRect(0, 0, docW, docH); // Final clear
        }
    }

    // ───────────────────────────────────────────────────────────────────────────
    //  MOUSEMOVE HANDLER: throttle to ≈60fps, spawn stars along the path
    // ───────────────────────────────────────────────────────────────────────────
    /**
     * Handles mouse move events to spawn sparkles.
     * Throttled to approximately 60 FPS. Spawns particles along the mouse path.
     * @private
     * @param {MouseEvent} e - The mouse event.
     */
    function onMouseMove(e) {
        if (!sparklesEnabled) return;

        const now = performance.now();
        if (now - lastSpawnTime < 16) return; // Throttle to ~60fps
        lastSpawnTime = now;

        const dx = e.movementX;
        const dy = e.movementY;
        const dist = Math.hypot(dx, dy);
        if (dist < 0.5) return; // Minimal movement

        let mx = e.clientX; // Viewport-relative X
        let my = e.clientY; // Viewport-relative Y

        const prob = dist / SPARKLE_DISTANCE; // Probability of spawning a star
        let cum = 0;
        // Calculate step to move back along the mouse path for distributed spawning
        const stepX = (dx * SPARKLE_DISTANCE * 2) / dist;
        const stepY = (dy * SPARKLE_DISTANCE * 2) / dist;

        // Iterate back along the path, spawning stars probabilistically
        // Note: original logic used Math.abs(cum) < Math.abs(dx), which might be problematic if dx is small or zero.
        // A more robust approach might be to iterate based on distance or number of steps.
        // For now, keeping it similar to original while noting potential improvement.
        let pathTraversed = 0;
        const totalPathLength = dist; // Use the actual distance for path traversal limit

        while (pathTraversed < totalPathLength) {
            if (Math.random() < prob) {
                spawnStar(mx, my);
            }
            const frac = Math.random(); // Random fraction of a step
            const dmx = stepX * frac;
            const dmy = stepY * frac;
            mx -= dmx;
            my -= dmy;
            pathTraversed += Math.hypot(dmx, dmy); // Accumulate distance traversed
        }


        if (!animationRunning && isInitialized) {
            animationRunning = true;
            requestAnimationFrame(animate);
        }
    }

    // ───────────────────────────────────────────────────────────────────────────
    //  PUBLIC API: window.sparkle(enable)
    //    - sparkle(true)  → turn ON sparkles
    //    - sparkle(false) → turn OFF immediately (clears all alive particles)
    //    - sparkle()      → toggle on/off
    // ───────────────────────────────────────────────────────────────────────────
    /**
     * @global
     * @function sparkle
     * @description Controls the sparkle effect.
     * Call with `true` to enable, `false` to disable, or no argument to toggle.
     * @param {boolean} [enable=null] - True to enable, false to disable. Toggles if null.
     */
    window.sparkle = function (enable = null) {
        if (enable === null) {
            sparklesEnabled = !sparklesEnabled;
        } else {
            sparklesEnabled = !!enable; // Coerce to boolean
        }

        if (!sparklesEnabled && isInitialized) { // If turning off
            for (let i = 0; i < MAX_SPARKLES; i++) {
                stars[i].active = false;
                tinnies[i].active = false;
            }
            // Animation loop will stop itself if no particles are alive and sparklesEnabled is false
        }

        if (sparklesEnabled && isInitialized && !animationRunning) {
            animationRunning = true;
            requestAnimationFrame(animate);
        }
    };

    // ───────────────────────────────────────────────────────────────────────────
    //  WAIT FOR DOM TO BE READY, THEN INITIALIZE
    // ───────────────────────────────────────────────────────────────────────────
    if (document.readyState === "complete" || document.readyState === "interactive") {
        initialize();
    } else {
        document.addEventListener("DOMContentLoaded", initialize);
    }

})();
````
--- End of File: vibe-player/js/sparkles.js ---
--- File: vibe-player/js/uiManager.js ---
````javascript
// --- /vibe-player/js/uiManager.js ---
// Handles DOM manipulation, UI event listeners, and dispatches UI events.

/** @namespace AudioApp */
var AudioApp = AudioApp || {}; // Ensure namespace exists

/**
 * @namespace AudioApp.uiManager
 * @description Manages UI elements, interactions, and events for the Vibe Player.
 */
AudioApp.uiManager = (function() {
    'use strict';

    // === Module Dependencies ===
    /**
     * @private
     * @type {AudioApp.Utils} Reference to the Utils module.
     */
    const Utils = AudioApp.Utils;

    // --- DOM Element References ---
    // File/Info
    /** @type {HTMLButtonElement|null} Button to trigger file selection. */
    let chooseFileButton = null;
    /** @type {HTMLInputElement|null} Hidden input element for file selection. */
    let hiddenAudioFile = null;
    /** @type {HTMLInputElement|null} Input element for audio URL. */
    let audioUrlInput = null;
    /** @type {HTMLButtonElement|null} Button to load audio from URL. */
    let loadUrlButton = null;
    /** @type {HTMLSpanElement|null} Span to display URL loading errors. */
    let urlLoadingErrorDisplay = null;
    /** @type {HTMLSpanElement|null} Span to display the current file name. */
    let fileNameDisplay = null;
    /** @type {HTMLParagraphElement|null} Paragraph to display file information or status messages. */
    let fileInfo = null;
    /** @type {HTMLDivElement|null} Container for the VAD progress bar. */
    let vadProgressContainer = null;
    /** @type {HTMLSpanElement|null} The VAD progress bar element itself. */
    let vadProgressBar = null;
    /** @type {HTMLDivElement|null} Div to display detected DTMF tones. */
    let dtmfDisplay = null;
    /** @type {HTMLDivElement|null} Div to display detected Call Progress Tones. */
    let cptDisplayElement = null;

    // Drop Zone
    /** @type {HTMLDivElement|null} Overlay for drag-and-drop functionality. */
    let dropZoneOverlay = null;
    /** @type {HTMLDivElement|null} Message displayed within the drop zone. */
    let dropZoneMessage = null;

    // Buttons
    /** @type {HTMLButtonElement|null} Button to play or pause audio. */
    let playPauseButton = null;
    /** @type {HTMLButtonElement|null} Button to jump backward in audio. */
    let jumpBackButton = null;
    /** @type {HTMLButtonElement|null} Button to jump forward in audio. */
    let jumpForwardButton = null;
    /** @type {HTMLInputElement|null} Input for specifying jump time in seconds. */
    let jumpTimeInput = null;

    // Time & Seek
    /** @type {HTMLDivElement|null} Div to display current time and duration. */
    let timeDisplay = null;
    /** @type {HTMLInputElement|null} Seek bar (slider) for audio playback. */
    let seekBar = null;

    // Sliders & Displays & Markers
    /** @type {HTMLInputElement|null} Slider for playback speed control. */
    let playbackSpeedControl = null;
    /** @type {HTMLSpanElement|null} Span to display current playback speed value. */
    let speedValueDisplay = null;
    /** @type {HTMLDivElement|null} Container for speed slider markers. */
    let speedMarkers = null;
    /** @type {HTMLInputElement|null} Slider for pitch control. */
    let pitchControl = null;
    /** @type {HTMLSpanElement|null} Span to display current pitch value. */
    let pitchValueDisplay = null;
    /** @type {HTMLDivElement|null} Container for pitch slider markers. */
    let pitchMarkers = null;
    // Formant controls are referenced but not actively used in current logic, kept for potential future use.
    /** @type {HTMLInputElement|null} */ let formantControl = null;
    /** @type {HTMLSpanElement|null} */ let formantValueDisplay = null;
    /** @type {HTMLDivElement|null} */ let formantMarkers = null;
    /** @type {HTMLInputElement|null} Slider for gain (volume) control. */
    let gainControl = null;
    /** @type {HTMLSpanElement|null} Span to display current gain value. */
    let gainValueDisplay = null;
    /** @type {HTMLDivElement|null} Container for gain slider markers. */
    let gainMarkers = null;
    /** @type {HTMLInputElement|null} Slider for VAD positive threshold. */
    let vadThresholdSlider = null;
    /** @type {HTMLSpanElement|null} Span to display current VAD positive threshold value. */
    let vadThresholdValueDisplay = null;
    /** @type {HTMLInputElement|null} Slider for VAD negative threshold. */
    let vadNegativeThresholdSlider = null;
    /** @type {HTMLSpanElement|null} Span to display current VAD negative threshold value. */
    let vadNegativeThresholdValueDisplay = null;

    // VAD Output
    /** @type {HTMLPreElement|null} Element to display detected speech regions. */
    let speechRegionsDisplay = null;

    /**
     * Initializes the UI Manager. Assigns DOM elements, sets up event listeners, and resets the UI.
     * @public
     */
    function init() {
        console.log("UIManager: Initializing...");
        if (!Utils) {
            console.error("UIManager: CRITICAL - AudioApp.Utils not found! UI might not function correctly.");
            return;
        }
        assignDOMElements();
        initializeSliderMarkers();
        setupEventListeners();
        resetUI();
        console.log("UIManager: Initialized.");
    }

    /**
     * @private
     * @const {Object<string, string>}
     * @description Conceptual mapping of functional names to DOM element IDs.
     */
    const DOM_ELEMENT_IDS = {
        DTMF_DISPLAY: 'dtmfDisplay',
        CPT_DISPLAY: 'cpt-display-content'
    };

    /**
     * Assigns DOM elements to module-level variables.
     * @private
     */
    function assignDOMElements() {
        chooseFileButton = /** @type {HTMLButtonElement|null} */ (document.getElementById('chooseFileButton'));
        hiddenAudioFile = /** @type {HTMLInputElement|null} */ (document.getElementById('hiddenAudioFile'));
        audioUrlInput = /** @type {HTMLInputElement|null} */ (document.getElementById('audioUrlInput'));
        loadUrlButton = /** @type {HTMLButtonElement|null} */ (document.getElementById('loadUrlButton'));
        urlLoadingErrorDisplay = /** @type {HTMLSpanElement|null} */ (document.getElementById('urlLoadingErrorDisplay'));
        fileNameDisplay = /** @type {HTMLSpanElement|null} */ (document.getElementById('fileNameDisplay'));
        fileInfo = /** @type {HTMLParagraphElement|null} */ (document.getElementById('fileInfo'));
        vadProgressContainer = /** @type {HTMLDivElement|null} */ (document.getElementById('vadProgressContainer'));
        vadProgressBar = /** @type {HTMLSpanElement|null} */ (document.getElementById('vadProgressBar'));

        dropZoneOverlay = /** @type {HTMLDivElement|null} */ (document.getElementById('dropZoneOverlay'));
        dropZoneMessage = /** @type {HTMLDivElement|null} */ (document.getElementById('dropZoneMessage'));

        playPauseButton = /** @type {HTMLButtonElement|null} */ (document.getElementById('playPause'));
        jumpBackButton = /** @type {HTMLButtonElement|null} */ (document.getElementById('jumpBack'));
        jumpForwardButton = /** @type {HTMLButtonElement|null} */ (document.getElementById('jumpForward'));
        jumpTimeInput = /** @type {HTMLInputElement|null} */ (document.getElementById('jumpTime'));

        seekBar = /** @type {HTMLInputElement|null} */ (document.getElementById('seekBar'));
        timeDisplay = /** @type {HTMLDivElement|null} */ (document.getElementById('timeDisplay'));

        playbackSpeedControl = /** @type {HTMLInputElement|null} */ (document.getElementById('playbackSpeed'));
        speedValueDisplay = /** @type {HTMLSpanElement|null} */ (document.getElementById('speedValue'));
        speedMarkers = /** @type {HTMLDivElement|null} */ (document.getElementById('speedMarkers'));
        pitchControl = /** @type {HTMLInputElement|null} */ (document.getElementById('pitchControl'));
        pitchValueDisplay = /** @type {HTMLSpanElement|null} */ (document.getElementById('pitchValue'));
        pitchMarkers = /** @type {HTMLDivElement|null} */ (document.getElementById('pitchMarkers'));
        gainControl = /** @type {HTMLInputElement|null} */ (document.getElementById('gainControl'));
        gainValueDisplay = /** @type {HTMLSpanElement|null} */ (document.getElementById('gainValue'));
        gainMarkers = /** @type {HTMLDivElement|null} */ (document.getElementById('gainMarkers'));

        vadThresholdSlider = /** @type {HTMLInputElement|null} */ (document.getElementById('vadThreshold'));
        vadThresholdValueDisplay = /** @type {HTMLSpanElement|null} */ (document.getElementById('vadThresholdValue'));
        vadNegativeThresholdSlider = /** @type {HTMLInputElement|null} */ (document.getElementById('vadNegativeThreshold'));
        vadNegativeThresholdValueDisplay = /** @type {HTMLSpanElement|null} */ (document.getElementById('vadNegativeThresholdValue'));

        speechRegionsDisplay = /** @type {HTMLPreElement|null} */ (document.getElementById('speechRegionsDisplay'));
        dtmfDisplay = /** @type {HTMLDivElement|null} */ (document.getElementById(DOM_ELEMENT_IDS.DTMF_DISPLAY));
        cptDisplayElement = /** @type {HTMLDivElement|null} */ (document.getElementById(DOM_ELEMENT_IDS.CPT_DISPLAY));

        // Basic checks for critical elements
        if (!chooseFileButton || !playPauseButton || !seekBar) {
            console.warn("UIManager: Some critical UI elements (chooseFile, playPause, seekBar) not found.");
        }
        if (!dtmfDisplay) console.warn("UIManager: DTMF display element not found.");
        if (!cptDisplayElement) console.warn(`UIManager: CPT display element (ID: ${DOM_ELEMENT_IDS.CPT_DISPLAY}) not found.`);
    }

    /**
     * Initializes positions of markers (like 0.5x, 1x, 2x) for sliders.
     * @private
     */
    function initializeSliderMarkers() {
        /** @type {Array<{slider: HTMLInputElement|null, markersDiv: HTMLDivElement|null}>} */
        const markerConfigs = [
            { slider: playbackSpeedControl, markersDiv: speedMarkers },
            { slider: pitchControl, markersDiv: pitchMarkers },
            { slider: gainControl, markersDiv: gainMarkers }
        ];
        markerConfigs.forEach(config => {
            const { slider, markersDiv } = config;
            if (!slider || !markersDiv) return;
            const min = parseFloat(slider.min);
            const max = parseFloat(slider.max);
            const range = max - min;
            if (range <= 0) return; // Avoid division by zero or negative range
            /** @type {NodeListOf<HTMLSpanElement>} */
            const markers = markersDiv.querySelectorAll('span[data-value]');
            markers.forEach(span => {
                const value = parseFloat(span.dataset.value || "");
                if (!isNaN(value)) {
                    const percent = ((value - min) / range) * 100;
                    span.style.left = `${percent}%`;
                }
            });
        });
    }

    /**
     * Sets up all general UI event listeners.
     * @private
     */
    function setupEventListeners() {
        chooseFileButton?.addEventListener('click', () => { hiddenAudioFile?.click(); });
        hiddenAudioFile?.addEventListener('change', (e) => {
            const target = /** @type {HTMLInputElement} */ (e.target);
            const file = target.files?.[0];
            if (file) {
                updateFileName(file.name);
                dispatchUIEvent('audioapp:fileSelected', { file: file });
            } else {
                updateFileName("");
            }
        });

        loadUrlButton?.addEventListener('click', () => {
            const audioUrl = audioUrlInput?.value.trim();
            if (audioUrl) {
                dispatchUIEvent('audioapp:urlSelected', { url: audioUrl });
            } else {
                console.warn("UIManager: Load URL button clicked, but URL is empty.");
                if (audioUrlInput) {
                    audioUrlInput.focus();
                    setUrlInputStyle('error');
                }
            }
        });

        audioUrlInput?.addEventListener('keypress', (event) => {
            if (event.key === 'Enter') {
                event.preventDefault();
                const audioUrl = audioUrlInput?.value.trim();
                if (audioUrl) {
                    dispatchUIEvent('audioapp:urlSelected', { url: audioUrl });
                } else {
                    console.warn("UIManager: Enter pressed in URL input, but URL is empty.");
                    if (audioUrlInput) {
                        audioUrlInput.focus();
                        setUrlInputStyle('error');
                    }
                }
            }
        });

        audioUrlInput?.addEventListener('keydown', (event) => {
            if (event.key === 'Escape') {
                event.preventDefault();
                unfocusUrlInput();
            }
        });

        audioUrlInput?.addEventListener('input', () => {
            if (!audioUrlInput) return;
            const currentStyles = audioUrlInput.classList;
            if (currentStyles.contains('url-style-success') || currentStyles.contains('url-style-file')) {
                setUrlInputStyle('modified');
            } else if (currentStyles.contains('url-style-error')) {
                setUrlInputStyle('default');
            } else if (currentStyles.contains('url-style-default')) {
                setUrlInputStyle('modified');
            }
        });

        seekBar?.addEventListener('input', (e) => {
            const target = /** @type {HTMLInputElement} */ (e.target);
            const fraction = parseFloat(target.value);
            if (!isNaN(fraction)) { dispatchUIEvent('audioapp:seekBarInput', { fraction: fraction }); }
        });
        playPauseButton?.addEventListener('click', () => dispatchUIEvent('audioapp:playPauseClicked'));
        jumpBackButton?.addEventListener('click', () => dispatchUIEvent('audioapp:jumpClicked', { seconds: -getJumpTime() }));
        jumpForwardButton?.addEventListener('click', () => dispatchUIEvent('audioapp:jumpClicked', { seconds: getJumpTime() }));

        setupSliderListeners(playbackSpeedControl, speedValueDisplay, 'audioapp:speedChanged', 'speed', 'x');
        setupSliderListeners(pitchControl, pitchValueDisplay, 'audioapp:pitchChanged', 'pitch', 'x');
        setupSliderListeners(gainControl, gainValueDisplay, 'audioapp:gainChanged', 'gain', 'x');

        speedMarkers?.addEventListener('click', (e) => handleMarkerClick(/** @type {MouseEvent} */ (e), playbackSpeedControl));
        pitchMarkers?.addEventListener('click', (e) => handleMarkerClick(/** @type {MouseEvent} */ (e), pitchControl));
        gainMarkers?.addEventListener('click', (e) => handleMarkerClick(/** @type {MouseEvent} */ (e), gainControl));

        vadThresholdSlider?.addEventListener('input', handleVadSliderInput);
        vadNegativeThresholdSlider?.addEventListener('input', handleVadSliderInput);

        document.addEventListener('keydown', handleKeyDown);
    }

    /**
     * Sets up an event listener for a slider control.
     * @private
     * @param {HTMLInputElement|null} slider - The slider element.
     * @param {HTMLSpanElement|null} valueDisplay - The element to display the slider's value.
     * @param {string} eventName - The name of the custom event to dispatch.
     * @param {string} detailKey - The key for the value in the event detail object.
     * @param {string} [suffix=''] - Suffix to append to the displayed value.
     */
    function setupSliderListeners(slider, valueDisplay, eventName, detailKey, suffix = '') {
        if (!slider || !valueDisplay) return;
        slider.addEventListener('input', () => {
            const value = parseFloat(slider.value);
            valueDisplay.textContent = value.toFixed(2) + suffix;
            dispatchUIEvent(eventName, { [detailKey]: value });
        });
    }

    /**
     * Handles keydown events for global shortcuts.
     * @private
     * @param {KeyboardEvent} e - The keyboard event.
     */
    function handleKeyDown(e) {
        const target = /** @type {HTMLElement} */ (e.target);
        // Ignore key events if the target is an input field where typing is expected.
        const isTextInput = target instanceof HTMLInputElement && ['text', 'number', 'search', 'email', 'password', 'url'].includes(target.type);
        const isTextArea = target instanceof HTMLTextAreaElement;
        if (isTextInput || isTextArea) return;

        let handled = false;
        /** @type {string|null} */ let eventKey = null;
        switch (e.code) {
            case 'Space': eventKey = 'Space'; handled = true; break;
            case 'ArrowLeft': eventKey = 'ArrowLeft'; handled = true; break;
            case 'ArrowRight': eventKey = 'ArrowRight'; handled = true; break;
        }
        if (eventKey) { dispatchUIEvent('audioapp:keyPressed', { key: eventKey }); }
        if (handled) { e.preventDefault(); } // Prevent default browser action (e.g., scrolling on space)
    }

    /**
     * Updates the DTMF display box with detected tones.
     * @public
     * @param {string | string[]} tones - The detected DTMF tone(s). Can be a single string or an array of strings.
     */
    function updateDtmfDisplay(tones) {
        if (!dtmfDisplay) return;
        if (Array.isArray(tones) && tones.length > 0) {
            dtmfDisplay.textContent = tones.join(', ');
        } else if (typeof tones === 'string' && tones.length > 0 && tones.trim() !== "") {
            dtmfDisplay.textContent = tones;
        } else if (Array.isArray(tones) && tones.length === 0) {
            dtmfDisplay.textContent = "No DTMF detected.";
        } else {
            dtmfDisplay.textContent = "N/A";
        }
    }

    /**
     * Updates the Call Progress Tones display box.
     * @public
     * @param {string[]} tones - An array of detected CPT names.
     */
    function updateCallProgressTonesDisplay(tones) {
        if (!cptDisplayElement) {
            console.error("UIManager: CPT display element not found.");
            return;
        }
        if (Array.isArray(tones) && tones.length > 0) {
            cptDisplayElement.textContent = tones.join(', ');
        } else if (Array.isArray(tones) && tones.length === 0) {
            cptDisplayElement.textContent = "No ringtone detected.";
        } else {
            cptDisplayElement.textContent = "N/A";
        }
    }

    /**
     * Handles input events from VAD threshold sliders.
     * @private
     * @param {Event} e - The input event.
     */
    function handleVadSliderInput(e) {
        const slider = /** @type {HTMLInputElement} */ (e.target);
        const value = parseFloat(slider.value);
        /** @type {string|null} */ let type = null;
        if (slider === vadThresholdSlider && vadThresholdValueDisplay) {
            vadThresholdValueDisplay.textContent = value.toFixed(2); type = 'positive';
        } else if (slider === vadNegativeThresholdSlider && vadNegativeThresholdValueDisplay) {
            vadNegativeThresholdValueDisplay.textContent = value.toFixed(2); type = 'negative';
        }
        if (type) { dispatchUIEvent('audioapp:thresholdChanged', { type: type, value: value }); }
    }

    /**
     * Handles clicks on slider markers to set the slider value.
     * @private
     * @param {MouseEvent} event - The click event.
     * @param {HTMLInputElement|null} sliderElement - The slider element associated with the markers.
     */
     function handleMarkerClick(event, sliderElement) {
        if (!sliderElement || sliderElement.disabled) return;
        const target = /** @type {HTMLElement} */ (event.target);
        if (target.tagName === 'SPAN' && target.dataset.value) {
            const value = parseFloat(target.dataset.value);
            if (!isNaN(value)) {
                sliderElement.value = String(value);
                // Dispatch 'input' event to trigger associated listeners (e.g., value display update, app logic)
                sliderElement.dispatchEvent(new Event('input', { bubbles: true }));
            }
        }
    }

    /**
     * Gets the current gain value from the gain control slider.
     * @public
     * @returns {number} The current gain value (default is 1.0).
     */
    function getGainValue() {
        return gainControl ? parseFloat(gainControl.value) : 1.0;
    }

    /**
     * Sets the gain value on the UI slider and display.
     * @public
     * @param {number} value - The gain value to set.
     */
    function setGainValue(value) {
        if (gainControl) {
            gainControl.value = String(value);
        }
        if (gainValueDisplay) {
            const numericValue = parseFloat(String(value)); // Ensure it's a number
            gainValueDisplay.textContent = numericValue.toFixed(2) + 'x';
        }
    }

    /**
     * Sets the value of the audio URL input field.
     * @public
     * @param {string} text The text to set as the value.
     */
    function setAudioUrlInputValue(text) {
        if (audioUrlInput) {
            audioUrlInput.value = text;
        }
    }

    /**
     * Removes focus from the audio URL input field.
     * @public
     */
    function unfocusUrlInput() {
        if (audioUrlInput) {
            audioUrlInput.blur();
        }
    }

    /**
     * Dispatches a custom UI event.
     * @private
     * @param {string} eventName - The name of the event.
     * @param {Object<string, any>} [detail={}] - The detail object for the event.
     */
    function dispatchUIEvent(eventName, detail = {}) {
        document.dispatchEvent(new CustomEvent(eventName, { detail: detail }));
    }

    // --- Public Methods for Updating UI ---
    /**
     * Sets the error message for URL loading.
     * @public
     * @param {string} message - The error message to display.
     */
    function setUrlLoadingError(message) {
        if (urlLoadingErrorDisplay) {
            urlLoadingErrorDisplay.textContent = message;
        }
    }

    /**
     * Sets the visual style of the URL input field.
     * @public
     * @param {'success' | 'error' | 'file' | 'default' | 'modified'} styleType - The style to apply.
     */
    function setUrlInputStyle(styleType) {
        if (!audioUrlInput) return;
        audioUrlInput.classList.remove('url-style-success', 'url-style-error', 'url-style-file', 'url-style-default', 'url-style-modified');
        audioUrlInput.classList.add(`url-style-${styleType}`);
    }

    /**
     * Resets the entire UI to its initial state.
     * @public
     */
    function resetUI() {
        console.log("UIManager: Resetting UI");
        updateFileName("");
        setFileInfo("No file selected.");
        setPlayButtonState(false);
        updateTimeDisplay(0, 0);
        updateSeekBar(0);
        setSpeechRegionsText("None");
        updateVadDisplay(0.5, 0.35, true); // Reset VAD sliders and mark as N/A
        showVadProgress(false);
        updateVadProgress(0);
        if (dtmfDisplay) dtmfDisplay.textContent = "N/A";
        if (cptDisplayElement) cptDisplayElement.textContent = "N/A";
        if (urlLoadingErrorDisplay) urlLoadingErrorDisplay.textContent = "";
        setAudioUrlInputValue("");
        setUrlInputStyle('default');

        if (playbackSpeedControl && speedValueDisplay) { playbackSpeedControl.value = "1.0"; speedValueDisplay.textContent = "1.00x"; }
        if (pitchControl && pitchValueDisplay) { pitchControl.value = "1.0"; pitchValueDisplay.textContent = "1.00x"; }
        if (gainControl && gainValueDisplay) { gainControl.value = "1.0"; gainValueDisplay.textContent = "1.00x"; }
        if (jumpTimeInput) jumpTimeInput.value = "5";

        enableSeekBar(false);
        // Playback controls are typically enabled/disabled based on worklet readiness, not full reset.
    }

    /**
     * Updates the displayed file name.
     * @public
     * @param {string} text - The file name to display.
     */
    function updateFileName(text) { if (fileNameDisplay) { fileNameDisplay.textContent = text; fileNameDisplay.title = text; } }

    /**
     * Sets the general file information/status message.
     * @public
     * @param {string} text - The message to display.
     */
    function setFileInfo(text) { if (fileInfo) { fileInfo.textContent = text; fileInfo.title = text; } }

    /**
     * Sets the state of the play/pause button.
     * @public
     * @param {boolean} isPlaying - True if audio is playing, false otherwise.
     */
    function setPlayButtonState(isPlaying) { if (playPauseButton) playPauseButton.textContent = isPlaying ? 'Pause' : 'Play'; }

    /**
     * Updates the time display (current time / duration).
     * @public
     * @param {number} currentTime - The current playback time in seconds.
     * @param {number} duration - The total duration of the audio in seconds.
     */
    function updateTimeDisplay(currentTime, duration) {
        if (timeDisplay && Utils) {
            timeDisplay.textContent = `${Utils.formatTime(currentTime)} / ${Utils.formatTime(duration)}`;
        } else if (timeDisplay) {
             timeDisplay.textContent = `Err / Err`; // Fallback if Utils is not available
        }
    }

    /**
     * Updates the position of the seek bar.
     * @public
     * @param {number} fraction - The progress fraction (0 to 1).
     */
    function updateSeekBar(fraction) {
        if (seekBar) {
            const clampedFraction = Math.max(0, Math.min(1, fraction));
            // Only update if significantly different to avoid fighting with user input
            if (Math.abs(parseFloat(seekBar.value) - clampedFraction) > 1e-6 ) {
                seekBar.value = String(clampedFraction);
            }
        }
    }

    /**
     * Sets the text content for the speech regions display.
     * @public
     * @param {string | Array<{start: number, end: number}>} regionsOrText - Either a string message or an array of speech region objects.
     */
    function setSpeechRegionsText(regionsOrText) {
        if (!speechRegionsDisplay) return;
        if (typeof regionsOrText === 'string') {
            speechRegionsDisplay.textContent = regionsOrText;
        } else if (Array.isArray(regionsOrText)) {
             if (regionsOrText.length > 0) {
                 speechRegionsDisplay.textContent = regionsOrText.map(r => `Start: ${r.start.toFixed(2)}s, End: ${r.end.toFixed(2)}s`).join('\n');
             } else {
                 speechRegionsDisplay.textContent = "No speech detected.";
             }
        } else {
            speechRegionsDisplay.textContent = "None"; // Default fallback
        }
    }

    /**
     * Updates the VAD threshold sliders and their value displays.
     * @public
     * @param {number} positive - The positive VAD threshold value.
     * @param {number} negative - The negative VAD threshold value.
     * @param {boolean} [isNA=false] - If true, sets displays to "N/A" and resets sliders to default.
     */
    function updateVadDisplay(positive, negative, isNA = false) {
        if (isNA) {
            if (vadThresholdValueDisplay) vadThresholdValueDisplay.textContent = "N/A";
            if (vadNegativeThresholdValueDisplay) vadNegativeThresholdValueDisplay.textContent = "N/A";
            if (vadThresholdSlider) vadThresholdSlider.value = "0.5"; // Default value
            if (vadNegativeThresholdSlider) vadNegativeThresholdSlider.value = "0.35"; // Default value
        } else {
            if (vadThresholdSlider) vadThresholdSlider.value = String(positive);
            if (vadThresholdValueDisplay) vadThresholdValueDisplay.textContent = positive.toFixed(2);
            if (vadNegativeThresholdSlider) vadNegativeThresholdSlider.value = String(negative);
            if (vadNegativeThresholdValueDisplay) vadNegativeThresholdValueDisplay.textContent = negative.toFixed(2);
        }
    }

    /**
     * Enables or disables main playback controls.
     * @public
     * @param {boolean} enable - True to enable, false to disable.
     */
    function enablePlaybackControls(enable) {
        if (playPauseButton) playPauseButton.disabled = !enable;
        if (jumpBackButton) jumpBackButton.disabled = !enable;
        if (jumpForwardButton) jumpForwardButton.disabled = !enable;
        if (playbackSpeedControl) playbackSpeedControl.disabled = !enable;
        if (pitchControl) pitchControl.disabled = !enable;
        // Note: Gain control is typically always enabled.
    }

    /**
     * Enables or disables the seek bar.
     * @public
     * @param {boolean} enable - True to enable, false to disable.
     */
     function enableSeekBar(enable) { if (seekBar) seekBar.disabled = !enable; }

    /**
     * Enables or disables VAD threshold controls.
     * @public
     * @param {boolean} enable - True to enable, false to disable.
     */
    function enableVadControls(enable) {
        if (vadThresholdSlider) vadThresholdSlider.disabled = !enable;
        if (vadNegativeThresholdSlider) vadNegativeThresholdSlider.disabled = !enable;
        if (!enable) {
            updateVadDisplay(0.5, 0.35, true); // Reset display values to N/A and sliders to default if disabling
        }
    }

    /**
     * Gets the current jump time value from the input field.
     * @public
     * @returns {number} The jump time in seconds (default is 5).
     */
    function getJumpTime() { return parseFloat(jumpTimeInput?.value || "5") || 5; }

    /**
     * Updates the VAD progress bar percentage.
     * @public
     * @param {number} percentage - The progress percentage (0 to 100).
     */
    function updateVadProgress(percentage) {
        if (!vadProgressBar) return;
        const clampedPercentage = Math.max(0, Math.min(100, percentage));
        vadProgressBar.style.width = `${clampedPercentage}%`;
    }

    /**
     * Shows or hides the VAD progress bar container.
     * @public
     * @param {boolean} show - True to show, false to hide.
     */
    function showVadProgress(show) {
        if (!vadProgressContainer) return;
        vadProgressContainer.style.display = show ? 'block' : 'none';
    }

    /**
     * Shows the drop zone overlay with file information.
     * @public
     * @param {File} file The file being dragged over.
     */
    function showDropZone(file) {
        if (dropZoneOverlay && dropZoneMessage) {
            dropZoneOverlay.style.display = 'flex';
            // Assuming Utils.formatBytes is not available or moved, displaying size in bytes.
            dropZoneMessage.textContent = `File: ${file.name}, Size: ${file.size} bytes`;
            document.body.classList.add('blurred-background');
        }
    }

    /**
     * Hides the drop zone overlay.
     * @public
     */
    function hideDropZone() {
        if (dropZoneOverlay && dropZoneMessage) {
            dropZoneOverlay.style.display = 'none';
            dropZoneMessage.textContent = '';
            document.body.classList.remove('blurred-background');
        }
    }

    /**
     * Gets the current playback speed value.
     * @public
     * @returns {number} The current playback speed.
     */
    function getPlaybackSpeedValue() {
        return playbackSpeedControl ? parseFloat(playbackSpeedControl.value) : 1.0;
    }

    /**
     * Sets the playback speed value on the UI.
     * @public
     * @param {number} value - The playback speed to set.
     */
    function setPlaybackSpeedValue(value) {
        if (playbackSpeedControl) {
            playbackSpeedControl.value = String(value);
        }
        if (speedValueDisplay) {
            speedValueDisplay.textContent = parseFloat(String(value)).toFixed(2) + 'x';
        }
    }

    /**
     * Gets the current pitch value.
     * @public
     * @returns {number} The current pitch value.
     */
    function getPitchValue() {
        return pitchControl ? parseFloat(pitchControl.value) : 1.0;
    }

    /**
     * Sets the pitch value on the UI.
     * @public
     * @param {number} value - The pitch value to set.
     */
    function setPitchValue(value) {
        if (pitchControl) {
            pitchControl.value = String(value);
        }
        if (pitchValueDisplay) {
            pitchValueDisplay.textContent = parseFloat(String(value)).toFixed(2) + 'x';
        }
    }

    /**
     * Gets the current VAD positive threshold value.
     * @public
     * @returns {number} The current VAD positive threshold.
     */
    function getVadPositiveThresholdValue() {
        return vadThresholdSlider ? parseFloat(vadThresholdSlider.value) : 0.5; // Default based on HTML
    }

    /**
     * Sets the VAD positive threshold value on the UI.
     * @public
     * @param {number} value - The VAD positive threshold to set.
     */
    function setVadPositiveThresholdValue(value) {
        if (vadThresholdSlider) {
            vadThresholdSlider.value = String(value);
        }
        if (vadThresholdValueDisplay) {
            vadThresholdValueDisplay.textContent = parseFloat(String(value)).toFixed(2);
        }
    }

    /**
     * Gets the current VAD negative threshold value.
     * @public
     * @returns {number} The current VAD negative threshold.
     */
    function getVadNegativeThresholdValue() {
        return vadNegativeThresholdSlider ? parseFloat(vadNegativeThresholdSlider.value) : 0.35; // Default based on HTML
    }

    /**
     * Sets the VAD negative threshold value on the UI.
     * @public
     * @param {number} value - The VAD negative threshold to set.
     */
    function setVadNegativeThresholdValue(value) {
        if (vadNegativeThresholdSlider) {
            vadNegativeThresholdSlider.value = String(value);
        }
        if (vadNegativeThresholdValueDisplay) {
            vadNegativeThresholdValueDisplay.textContent = parseFloat(String(value)).toFixed(2);
        }
    }

    /**
     * @typedef {Object} UIManagerPublicInterface
     * @property {function(): void} init
     * @property {function(): void} resetUI
     * @property {function(string): void} setFileInfo
     * @property {function(string): void} updateFileName
     * @property {function(boolean): void} setPlayButtonState
     * @property {function(number, number): void} updateTimeDisplay
     * @property {function(string|string[]): void} updateDtmfDisplay
     * @property {function(string[]): void} updateCallProgressTonesDisplay
     * @property {function(number): void} updateSeekBar
     * @property {function(string|Array<{start: number, end: number}>): void} setSpeechRegionsText
     * @property {function(number, number, boolean=): void} updateVadDisplay
     * @property {function(boolean): void} enablePlaybackControls
     * @property {function(boolean): void} enableSeekBar
     * @property {function(boolean): void} enableVadControls
     * @property {function(): number} getJumpTime
     * @property {function(number): void} updateVadProgress
     * @property {function(boolean): void} showVadProgress
     * @property {function(string): void} setUrlLoadingError
     * @property {function('success'|'error'|'file'|'default'|'modified'): void} setUrlInputStyle
     * @property {function(): void} unfocusUrlInput
     * @property {function(string): void} setAudioUrlInputValue
     * @property {function(File): void} showDropZone
     * @property {function(): void} hideDropZone
     * @property {function(): number} getPlaybackSpeedValue
     * @property {function(): number} getPitchValue
     * @property {function(): number} getVadPositiveThresholdValue
     * @property {function(): number} getVadNegativeThresholdValue
     * @property {function(): number} getGainValue
     * @property {function(number): void} setPlaybackSpeedValue
     * @property {function(number): void} setPitchValue
     * @property {function(number): void} setVadPositiveThresholdValue
     * @property {function(number): void} setVadNegativeThresholdValue
     * @property {function(number): void} setGainValue
     */

    /** @type {UIManagerPublicInterface} */
    return {
        init: init,
        resetUI: resetUI,
        setFileInfo: setFileInfo,
        updateFileName: updateFileName,
        setPlayButtonState: setPlayButtonState,
        updateTimeDisplay: updateTimeDisplay,
        updateDtmfDisplay: updateDtmfDisplay,
        updateCallProgressTonesDisplay: updateCallProgressTonesDisplay,
        updateSeekBar: updateSeekBar,
        setSpeechRegionsText: setSpeechRegionsText,
        updateVadDisplay: updateVadDisplay,
        enablePlaybackControls: enablePlaybackControls,
        enableSeekBar: enableSeekBar,
        enableVadControls: enableVadControls,
        getJumpTime: getJumpTime,
        updateVadProgress: updateVadProgress,
        showVadProgress: showVadProgress,
        setUrlLoadingError: setUrlLoadingError,
        setUrlInputStyle: setUrlInputStyle,
        unfocusUrlInput: unfocusUrlInput,
        setAudioUrlInputValue: setAudioUrlInputValue,
        showDropZone: showDropZone,
        hideDropZone: hideDropZone,
        // New Getters
        getPlaybackSpeedValue: getPlaybackSpeedValue,
        getPitchValue: getPitchValue,
        getVadPositiveThresholdValue: getVadPositiveThresholdValue,
        getVadNegativeThresholdValue: getVadNegativeThresholdValue,
        getGainValue: getGainValue,
        // New Setters
        setPlaybackSpeedValue: setPlaybackSpeedValue,
        setPitchValue: setPitchValue,
        setVadPositiveThresholdValue: setVadPositiveThresholdValue,
        setVadNegativeThresholdValue: setVadNegativeThresholdValue,
        setGainValue: setGainValue
    };
})();
// --- /vibe-player/js/uiManager.js ---

````
--- End of File: vibe-player/js/uiManager.js ---
--- File: vibe-player/js/utils.js ---
````javascript
// --- /vibe-player/js/utils.js ---
// General utility functions for the Vibe Player application.

/** @namespace AudioApp */
var AudioApp = AudioApp || {}; // Ensure main namespace exists

/**
 * @namespace AudioApp.Utils
 * @description Provides utility functions for the Vibe Player application.
 */
AudioApp.Utils = (function() {
    'use strict';

    /**
     * Formats time in seconds to a mm:ss string.
     * @param {number} sec - Time in seconds.
     * @returns {string} Formatted time string (e.g., "0:00", "1:23").
     */
    function formatTime(sec) {
        if (isNaN(sec) || sec < 0) sec = 0;
        const minutes = Math.floor(sec / 60);
        const seconds = Math.floor(sec % 60);
        return `${minutes}:${seconds < 10 ? '0' + seconds : seconds}`;
    }

    /**
     * Helper function to yield control back to the main event loop.
     * Uses `setTimeout(resolve, 0)` inside a Promise.
     * @async
     * @returns {Promise<void>} Resolves on the next tick, allowing other microtasks/macrotasks to run.
     */
    async function yieldToMainThread() {
        return new Promise(resolve => setTimeout(resolve, 0));
    }

    /**
     * Generates a Hann window array for FFT.
     * The Hann window is a taper function used to reduce spectral leakage in FFT processing.
     * @param {number} length - The desired window length (number of samples). Must be a positive integer.
     * @returns {number[]|null} The Hann window array of the specified length, or null if length is invalid.
     * Each element is a float between 0 and 1.
     */
    function hannWindow(length) {
        if (length <= 0 || !Number.isInteger(length)) {
            console.error("Utils.hannWindow: Length must be a positive integer.");
            return null;
        }
        /** @type {number[]} */
        let windowArr = new Array(length);
        if (length === 1) {
            windowArr[0] = 1; // Single point window is 1
            return windowArr;
        }
        const denom = length - 1; // Denominator for the cosine argument
        for (let i = 0; i < length; i++) {
            windowArr[i] = 0.5 * (1 - Math.cos((2 * Math.PI * i) / denom));
        }
        return windowArr;
    }

     /**
     * Viridis colormap function. Maps a normalized value (0 to 1) to an RGB color.
     * The Viridis colormap is designed to be perceptually uniform.
     * @param {number} t - Normalized value (0 to 1). Values outside this range will be clamped.
     * @returns {number[]} Array containing [r, g, b] values (each 0-255).
     */
     function viridisColor(t) {
         /** @type {Array<Array<number>>} Colormap definition: [value, r, g, b] */
         const colors = [ // [normalized_value, R, G, B]
             [0.0, 68, 1, 84], [0.1, 72, 40, 120], [0.2, 62, 74, 137], [0.3, 49, 104, 142],
             [0.4, 38, 130, 142], [0.5, 31, 155, 137], [0.6, 53, 178, 126], [0.7, 109, 199, 104],
             [0.8, 170, 217, 70], [0.9, 235, 231, 35], [1.0, 253, 231, 37] // Last point
         ];
         t = Math.max(0, Math.min(1, t)); // Clamp t to [0, 1]

         /** @type {Array<number>} */ let c1 = colors[0];
         /** @type {Array<number>} */ let c2 = colors[colors.length - 1];

         for (let i = 0; i < colors.length - 1; i++) {
             if (t >= colors[i][0] && t <= colors[i + 1][0]) {
                 c1 = colors[i];
                 c2 = colors[i + 1];
                 break;
             }
         }

         const range = c2[0] - c1[0];
         const ratio = (range === 0) ? 0 : (t - c1[0]) / range; // Avoid division by zero

         const r = Math.round(c1[1] + ratio * (c2[1] - c1[1]));
         const g = Math.round(c1[2] + ratio * (c2[2] - c1[2]));
         const b = Math.round(c1[3] + ratio * (c2[3] - c1[3]));
         return [r, g, b];
     }


    /**
     * Returns a function, that, as long as it continues to be invoked, will not
     * be triggered. The function will be called after it stops being called for
     * N milliseconds. If `immediate` is passed, trigger the function on the
     * leading edge, instead of the trailing.
     *
     * @template {Function} F
     * @param {F} func - The function to debounce.
     * @param {number} wait - The number of milliseconds to delay before invoking the function.
     * @param {boolean} [immediate=false] - If true, trigger the function on the leading edge instead of the trailing.
     * @returns {(...args: Parameters<F>) => void} The new debounced function.
     */
    function debounce(func, wait, immediate = false) {
        /** @type {number | undefined | null} */
        let timeout;
        // Using 'function' syntax for 'this' and 'arguments'
        return function executedFunction() {
            // @ts-ignore
            const context = this;
            const args = arguments; // arguments is not typed with ...args in JSDoc well

            const later = function() {
                timeout = null;
                if (!immediate) {
                    func.apply(context, args);
                }
            };

            const callNow = immediate && !timeout;
            clearTimeout(timeout);
            timeout = setTimeout(later, wait);

            if (callNow) {
                func.apply(context, args);
            }
        };
    }

    /**
     * @typedef {Object} UtilsPublicInterface
     * @property {function(number): string} formatTime - Formats time in seconds to mm:ss.
     * @property {function(): Promise<void>} yieldToMainThread - Yields control to the main event loop.
     * @property {function(number): (number[]|null)} hannWindow - Generates a Hann window array.
     * @property {function(number): number[]} viridisColor - Viridis colormap function.
     * @property {function(Function, number, boolean=): Function} debounce - Debounces a function.
     */

    /** @type {UtilsPublicInterface} */
    return {
        formatTime,
        yieldToMainThread,
        hannWindow,
        viridisColor,
        debounce
    };

})(); // End of AudioApp.Utils IIFE
// --- /vibe-player/js/utils.js ---

````
--- End of File: vibe-player/js/utils.js ---
--- File: vibe-player/js/vad/sileroProcessor.js ---
````javascript
// --- /vibe-player/js/vad/sileroProcessor.js --- // Updated Path
// Performs VAD analysis frame-by-frame using the SileroWrapper.
// Encapsulates the logic for iterating through audio data and calculating speech regions.

/** @namespace AudioApp */
var AudioApp = AudioApp || {};

/**
 * @namespace AudioApp.sileroProcessor
 * @description Processes audio data using the Silero VAD model via a wrapper.
 * Provides functions to analyze audio for speech regions and recalculate them with different thresholds.
 * @param {AudioApp.sileroWrapper} wrapper - The Silero VAD wrapper module.
 */
AudioApp.sileroProcessor = (function(wrapper) {
    'use strict';

    /**
     * @private
     * @type {AudioApp.Constants} Reference to the Constants module.
     */
    const Constants = AudioApp.Constants;
    /**
     * @private
     * @type {AudioApp.Utils} Reference to the Utils module.
     */
    const Utils = AudioApp.Utils;

    if (!wrapper || typeof wrapper.isAvailable !== 'function' || !wrapper.isAvailable()) {
        console.error("SileroProcessor: CRITICAL - AudioApp.sileroWrapper is not available or not functional!");
        /** @type {SileroProcessorPublicInterface} */
        const nonFunctionalInterface = {
             analyzeAudio: () => Promise.reject(new Error("Silero VAD Wrapper not available")),
             recalculateSpeechRegions: () => {
                console.error("SileroProcessor: Cannot recalculate, VAD wrapper not available.");
                return [];
            }
        };
        return nonFunctionalInterface;
    }
    if (!Constants) {
         console.error("SileroProcessor: CRITICAL - AudioApp.Constants not available!");
         /** @type {SileroProcessorPublicInterface} */
         const errorInterface = { analyzeAudio: () => Promise.reject(new Error("Constants not available")), recalculateSpeechRegions: () => [] };
         return errorInterface;
    }
     if (!Utils) {
          console.error("SileroProcessor: CRITICAL - AudioApp.Utils not available!");
          /** @type {SileroProcessorPublicInterface} */
          const errorInterface = { analyzeAudio: () => Promise.reject(new Error("Utils not available")), recalculateSpeechRegions: () => [] };
          return errorInterface;
     }

    /**
     * @typedef {object} VadRegion
     * @property {number} start - Start time of the speech region in seconds.
     * @property {number} end - End time of the speech region in seconds.
     */

    /**
     * @typedef {object} VadAnalysisOptions
     * @property {number} [frameSamples=AudioApp.Constants.DEFAULT_VAD_FRAME_SAMPLES] - Number of samples per VAD frame.
     * @property {number} [positiveSpeechThreshold=0.5] - Probability threshold to start or continue a speech segment.
     * @property {number} [negativeSpeechThreshold] - Probability threshold to consider stopping speech. Defaults to `positiveSpeechThreshold - 0.15`.
     * @property {number} [redemptionFrames=7] - Number of consecutive frames below `negativeSpeechThreshold` needed to end a speech segment.
     * @property {string} [modelPath] - Path to the ONNX VAD model (typically handled by the wrapper).
     * @property {function({processedFrames: number, totalFrames: number}): void} [onProgress] - Optional callback for progress updates.
     */

    /**
     * @typedef {object} VadResult
     * @property {VadRegion[]} regions - Array of detected speech regions.
     * @property {Float32Array} probabilities - Raw probability for each processed frame.
     * @property {number} frameSamples - Frame size (in samples) used in the analysis.
     * @property {number} sampleRate - Sample rate of the audio data used (should be `AudioApp.Constants.VAD_SAMPLE_RATE`).
     * @property {number} initialPositiveThreshold - The positive speech threshold used for this result.
     * @property {number} initialNegativeThreshold - The negative speech threshold used for this result.
     * @property {number} redemptionFrames - The number of redemption frames used for this result.
     */

    /**
     * Analyzes 16kHz mono PCM audio data for speech regions using the Silero VAD model.
     * @public
     * @async
     * @param {Float32Array} pcmData - The 16kHz mono Float32Array audio data.
     * @param {VadAnalysisOptions} [options={}] - VAD parameters and callback.
     * @returns {Promise<VadResult>} A promise resolving to the VAD results.
     * @throws {Error} If analysis fails (e.g., wrapper error, invalid input data).
     */
    async function analyzeAudio(pcmData, options = {}) {
        if (!(pcmData instanceof Float32Array)) {
            console.warn("SileroProcessor: VAD input data is not Float32Array. Attempting conversion.");
            try { pcmData = new Float32Array(pcmData); }
            catch (e) {
                const err = /** @type {Error} */ (e);
                console.error("SileroProcessor: Failed to convert VAD input data to Float32Array.", err);
                throw new Error(`VAD input data must be a Float32Array or convertible: ${err.message}`);
            }
        }

        const frameSamples = options.frameSamples || Constants.DEFAULT_VAD_FRAME_SAMPLES;
        const positiveThreshold = options.positiveSpeechThreshold !== undefined ? options.positiveSpeechThreshold : 0.5;
        const negativeThreshold = options.negativeSpeechThreshold !== undefined ? options.negativeSpeechThreshold : Math.max(0.01, positiveThreshold - 0.15);
        const redemptionFrames = options.redemptionFrames !== undefined ? options.redemptionFrames : 7;
        const onProgress = typeof options.onProgress === 'function' ? options.onProgress : () => {};

         if (!pcmData || pcmData.length === 0 || frameSamples <= 0) {
             console.log("SileroProcessor: No audio data or invalid frame size for VAD analysis.");
             // Ensure onProgress is called even for empty data, to complete any UI state
             setTimeout(() => onProgress({ processedFrames: 0, totalFrames: 0 }), 0);
             /** @type {VadResult} */
             const emptyResult = {
                 regions: [], probabilities: new Float32Array(),
                 frameSamples: frameSamples, sampleRate: Constants.VAD_SAMPLE_RATE,
                 initialPositiveThreshold: positiveThreshold, initialNegativeThreshold: negativeThreshold,
                 redemptionFrames: redemptionFrames
             };
             return emptyResult;
         }

        try { wrapper.reset_state(); }
        catch (e) {
            const err = /** @type {Error} */ (e);
            console.error("SileroProcessor: Error resetting VAD state via wrapper:", err);
            throw new Error(`Failed to reset Silero VAD state: ${err.message}`);
        }

        /** @type {number[]} */ const allProbabilities = [];
        const totalFrames = Math.floor(pcmData.length / frameSamples);
        let processedFrames = 0;
        const startTime = performance.now();

        try {
            for (let i = 0; (i + frameSamples) <= pcmData.length; i += frameSamples) {
                const frame = pcmData.slice(i, i + frameSamples);
                const probability = await wrapper.process(frame);
                allProbabilities.push(probability);
                processedFrames++;

                if (processedFrames === 1 || processedFrames === totalFrames || (processedFrames % Constants.VAD_PROGRESS_REPORT_INTERVAL === 0)) {
                     onProgress({ processedFrames, totalFrames });
                }
                if (processedFrames % Constants.VAD_YIELD_INTERVAL === 0 && processedFrames < totalFrames) {
                     await Utils.yieldToMainThread();
                }
            }
        } catch (e) {
            const err = /** @type {Error} */ (e);
            console.error(`SileroProcessor: Error during VAD frame processing after ${((performance.now() - startTime)/1000).toFixed(2)}s:`, err);
             setTimeout(() => onProgress({ processedFrames, totalFrames }), 0); // Final progress update on error
            throw new Error(`VAD inference failed: ${err.message}`);
        }
        console.log(`SileroProcessor: VAD analysis of ${totalFrames} frames took ${((performance.now() - startTime)/1000).toFixed(2)}s.`);
        setTimeout(() => onProgress({ processedFrames, totalFrames }), 0); // Ensure final progress is reported

        const probabilities = new Float32Array(allProbabilities);
        const initialRegions = recalculateSpeechRegions(probabilities, {
            frameSamples, sampleRate: Constants.VAD_SAMPLE_RATE,
            positiveSpeechThreshold: positiveThreshold, negativeSpeechThreshold: negativeThreshold,
            redemptionFrames
        });
        console.log(`SileroProcessor: Initially detected ${initialRegions.length} speech regions.`);

        /** @type {VadResult} */
        const result = {
            regions: initialRegions, probabilities, frameSamples,
            sampleRate: Constants.VAD_SAMPLE_RATE,
            initialPositiveThreshold: positiveThreshold, initialNegativeThreshold: negativeThreshold,
            redemptionFrames
        };
        return result;
    }

    /**
     * @typedef {object} RecalculateOptions
     * @property {number} frameSamples - Samples per frame used during original analysis.
     * @property {number} sampleRate - Sample rate used (should be `AudioApp.Constants.VAD_SAMPLE_RATE`).
     * @property {number} positiveSpeechThreshold - Current positive threshold (e.g., from UI slider).
     * @property {number} negativeSpeechThreshold - Current negative threshold.
     * @property {number} redemptionFrames - Redemption frames value used.
     */

    /**
     * Recalculates speech regions from stored probabilities using potentially new thresholds.
     * Does not re-run the VAD model; operates only on the probability array.
     * @public
     * @param {Float32Array} probabilities - Probabilities for each frame from `analyzeAudio`.
     * @param {RecalculateOptions} options - Parameters for recalculation.
     * @returns {VadRegion[]} Newly calculated speech regions.
     */
    function recalculateSpeechRegions(probabilities, options) {
        const { frameSamples, sampleRate, positiveSpeechThreshold, negativeSpeechThreshold, redemptionFrames } = options;

         if (sampleRate !== Constants.VAD_SAMPLE_RATE) {
            console.warn(`SileroProcessor: Recalculating speech regions with sample rate ${sampleRate}, which differs from the expected VAD constant ${Constants.VAD_SAMPLE_RATE}. This may lead to incorrect timing if frameSamples is based on the original rate.`);
        }
        if (!probabilities || probabilities.length === 0 || !frameSamples || !sampleRate ||
            positiveSpeechThreshold === undefined || negativeSpeechThreshold === undefined || redemptionFrames === undefined) {
             console.warn("SileroProcessor: Invalid arguments for recalculateSpeechRegions. Returning empty array.", options);
            return [];
        }

        /** @type {VadRegion[]} */ const newRegions = [];
        let inSpeech = false;
        let regionStart = 0.0;
        let redemptionCounter = 0;

        for (let i = 0; i < probabilities.length; i++) {
            const probability = probabilities[i];
            const frameStartTime = (i * frameSamples) / sampleRate;

            if (probability >= positiveSpeechThreshold) {
                if (!inSpeech) { inSpeech = true; regionStart = frameStartTime; }
                redemptionCounter = 0; // Reset redemption if speech detected
            } else if (inSpeech) { // Only apply redemption logic if we were in speech
                if (probability < negativeSpeechThreshold) {
                    redemptionCounter++;
                    if (redemptionCounter >= redemptionFrames) {
                        // End of speech segment detected
                        const triggerFrameIndex = i - redemptionFrames + 1; // Frame that triggered end
                        const actualEnd = (triggerFrameIndex * frameSamples) / sampleRate;
                        const finalEnd = Math.max(regionStart, actualEnd); // Ensure end is not before start
                        newRegions.push({ start: regionStart, end: finalEnd });
                        inSpeech = false; redemptionCounter = 0;
                    }
                } else { // Probability is between negative and positive thresholds
                    redemptionCounter = 0; // Reset redemption if not strictly below negative threshold
                }
            }
        }
        if (inSpeech) { // If speech segment was active at the end of probabilities
            const finalEnd = (probabilities.length * frameSamples) / sampleRate;
            newRegions.push({ start: regionStart, end: finalEnd });
        }
        return newRegions;
    }

    /**
     * @typedef {Object} SileroProcessorPublicInterface
     * @property {function(Float32Array, VadAnalysisOptions=): Promise<VadResult>} analyzeAudio
     * @property {function(Float32Array, RecalculateOptions): VadRegion[]} recalculateSpeechRegions
     */

    /** @type {SileroProcessorPublicInterface} */
    return {
        analyzeAudio: analyzeAudio,
        recalculateSpeechRegions: recalculateSpeechRegions
    };

})(AudioApp.sileroWrapper);
// --- /vibe-player/js/vad/sileroProcessor.js --- // Updated Path

````
--- End of File: vibe-player/js/vad/sileroProcessor.js ---
--- File: vibe-player/js/vad/sileroWrapper.js ---
````javascript
// --- /vibe-player/js/vad/sileroWrapper.js --- // Updated Path
// Wraps the ONNX Runtime session for the Silero VAD model.
// Manages ONNX session creation, state tensors, and inference calls.

/** @namespace AudioApp */
var AudioApp = AudioApp || {};

/**
 * @namespace AudioApp.sileroWrapper
 * @description Wraps the ONNX Runtime session for the Silero VAD (Voice Activity Detection) model.
 * This module handles the creation of an ONNX inference session, manages the model's
 * recurrent state tensors (h, c), and provides methods to process audio frames for VAD.
 * @param {object} globalOrt - The global ONNX Runtime object (typically `window.ort`).
 */
AudioApp.sileroWrapper = (function(globalOrt) {
    'use strict';

    if (!globalOrt) {
        console.error("SileroWrapper: CRITICAL - ONNX Runtime (ort) object not found globally!");
        /** @type {SileroWrapperPublicInterface} */
        const nonFunctionalInterface = {
            create: () => Promise.resolve(false),
            process: () => Promise.reject(new Error("ONNX Runtime not available")),
            reset_state: () => { console.error("SileroWrapper: ONNX Runtime not available, cannot reset state."); },
            isAvailable: () => false // Changed to a function
        };
        return nonFunctionalInterface;
    }

    /** @type {ort.InferenceSession|null} The ONNX inference session. */
    let session = null;
    /** @type {ort.Tensor|null} Tensor holding the sample rate (e.g., 16000), required as int64 by some models. */
    let sampleRateTensor = null;
    /** @type {ort.Tensor|null} Hidden state 'c' tensor for the VAD model's RNN. */
    let state_c = null;
    /** @type {ort.Tensor|null} Hidden state 'h' tensor for the VAD model's RNN. */
    let state_h = null;

    /**
     * @const
     * @private
     * @type {number[]} Standard Silero state tensor dimensions: [num_layers*num_directions, batch_size, hidden_size].
     * Example: [2*1, 1, 64] for a common configuration.
     */
    const stateDims = [2, 1, 64];
    /**
     * @const
     * @private
     * @type {number} Total number of elements in a state tensor (product of stateDims).
     */
    const stateSize = stateDims.reduce((a, b) => a * b, 1); // Calculate product of dimensions


    /**
     * Creates and loads the Silero VAD ONNX InferenceSession.
     * This function is idempotent; it will only create the session once.
     * It also initializes or resets the model's recurrent state tensors.
     * @public
     * @async
     * @param {number} sampleRate - The sample rate required by the model (e.g., 16000 Hz).
     * @param {string} [uri='./model/silero_vad.onnx'] - Path to the ONNX model file.
     * @returns {Promise<boolean>} True if the session is ready, false on failure.
     */
    async function create(sampleRate, uri = './model/silero_vad.onnx') {
        if (session) {
            console.log("SileroWrapper: Session already exists. Resetting state for potential new audio stream.");
            try { reset_state(); } catch (e) { console.warn("SileroWrapper: Error resetting state for existing session:", e); }
            return true;
        }

        /** @type {ort.InferenceSession.SessionOptions} */
        const opt = {
            executionProviders: ["wasm"],
            logSeverityLevel: 3, // 0:Verbose, 1:Info, 2:Warning, 3:Error, 4:Fatal
            logVerbosityLevel: 3, // Corresponds to logSeverityLevel for most cases
            wasm: {
                wasmPaths: 'lib/' // Path to ort-wasm.wasm, ort-wasm-simd.wasm etc. relative to HTML
            }
        };

        try {
            console.log(`SileroWrapper: Creating ONNX InferenceSession from URI: ${uri} with options:`, JSON.stringify(opt));
            session = await globalOrt.InferenceSession.create(uri, opt);
            // Sample rate tensor needs to be int64 for some Silero models
            sampleRateTensor = new globalOrt.Tensor("int64", [BigInt(sampleRate)], [1]); // Shape [1] for scalar
            reset_state(); // Initialize state tensors
            console.log("SileroWrapper: ONNX session and initial states created successfully.");
            return true;
        } catch (e) {
            const err = /** @type {Error} */ (e);
            console.error("SileroWrapper: Failed to create ONNX InferenceSession:", err.message, err.stack);
            if (err.message.includes("WebAssembly") || err.message.includes(".wasm")) {
                console.error("SileroWrapper: Hint - Ensure ONNX WASM files (e.g., ort-wasm.wasm) are in the 'lib/' folder and served correctly by the web server.");
            }
            session = null; // Ensure session is null if creation fails
            return false;
        }
    }

    /**
     * Resets the hidden state tensors (h, c) of the VAD model to zero.
     * This should be called before processing a new independent audio stream.
     * @public
     * @throws {Error} If the ONNX Runtime `ort.Tensor` constructor is not available.
     */
    function reset_state() {
        if (!globalOrt?.Tensor) {
            console.error("SileroWrapper: Cannot reset state - ONNX Runtime (ort.Tensor) is not available.");
            state_c = null; state_h = null; // Prevent further errors if process is called
            throw new Error("ONNX Runtime Tensor constructor not available. Silero VAD cannot function.");
        }
        try {
            state_c = new globalOrt.Tensor("float32", new Float32Array(stateSize).fill(0.0), stateDims);
            state_h = new globalOrt.Tensor("float32", new Float32Array(stateSize).fill(0.0), stateDims);
        } catch (tensorError) {
             const err = /** @type {Error} */ (tensorError);
             console.error("SileroWrapper: Error creating zero-filled state tensors:", err.message, err.stack);
             state_c = null; state_h = null; // Invalidate state on error
             throw err; // Re-throw to indicate failure
        }
    }

    /**
     * Processes a single audio frame through the Silero VAD model.
     * `create()` must have been successfully called before using this method.
     * The internal recurrent state of the model is updated after each call.
     * @public
     * @async
     * @param {Float32Array} audioFrame - A Float32Array of audio samples for one frame (e.g., 1536 samples at 16kHz).
     * @returns {Promise<number>} The VAD probability score (0.0 to 1.0) for the frame.
     * @throws {Error} If the session is not initialized, state tensors are missing, input is invalid, or inference fails.
     */
    async function process(audioFrame) {
        if (!session || !state_c || !state_h || !sampleRateTensor) {
            throw new Error("SileroWrapper: VAD session or state not initialized. Call create() and ensure it succeeds before processing audio.");
        }
        if (!(audioFrame instanceof Float32Array)) {
             throw new Error(`SileroWrapper: Input audioFrame must be a Float32Array, but received type ${typeof audioFrame}.`);
        }

        try {
            const inputTensor = new globalOrt.Tensor("float32", audioFrame, [1, audioFrame.length]); // Shape: [batch_size=1, num_samples]
            /** @type {Record<string, ort.Tensor>} */
            const feeds = {
                input: inputTensor,
                h: state_h,
                c: state_c,
                sr: sampleRateTensor
            };

            const outputMap = await session.run(feeds);

            if (outputMap.hn && outputMap.cn) { // 'hn' and 'cn' are typical output names for new states
                state_h = outputMap.hn;
                state_c = outputMap.cn;
            } else {
                 console.warn("SileroWrapper: Model outputs 'hn' and 'cn' for recurrent state update were not found. Subsequent VAD results may be incorrect.");
            }

            // The primary VAD probability is typically named 'output'
            if (outputMap.output?.data instanceof Float32Array && typeof outputMap.output.data[0] === 'number') {
                return outputMap.output.data[0];
            } else {
                 console.error("SileroWrapper: Unexpected model output structure. 'output' tensor with numeric data not found. Actual output:", outputMap);
                 throw new Error("SileroWrapper: Invalid model output structure for VAD probability.");
            }
        } catch (e) {
            const err = /** @type {Error} */ (e);
            console.error("SileroWrapper: ONNX session run (inference) failed:", err.message, err.stack);
            // Consider whether to reset state here or let the caller decide. For now, re-throw.
            throw err;
        }
    }

    /**
     * Checks if the Silero VAD wrapper is available and operational (ONNX Runtime loaded).
     * @public
     * @returns {boolean} True if available, false otherwise.
     */
    function isAvailable() {
        return !!globalOrt;
    }

    /**
     * @typedef {Object} SileroWrapperPublicInterface
     * @property {function(number, string=): Promise<boolean>} create - Creates the ONNX session.
     * @property {function(Float32Array): Promise<number>} process - Processes an audio frame.
     * @property {function(): void} reset_state - Resets the model's recurrent state.
     * @property {function(): boolean} isAvailable - Checks if the ONNX runtime is available.
     */

    /** @type {SileroWrapperPublicInterface} */
    return {
        create: create,
        process: process,
        reset_state: reset_state,
        isAvailable: isAvailable // Changed to a function
    };

})(window.ort);
// --- /vibe-player/js/vad/sileroWrapper.js --- // Updated Path

````
--- End of File: vibe-player/js/vad/sileroWrapper.js ---
--- File: vibe-player/js/vad/vad.worker.js ---
````javascript
// --- /vibe-player/js/vad/vad.worker.js --- (CORRECTED)
// This worker handles Silero VAD model loading and audio analysis.

// DO NOT declare AudioApp here. Let the first imported script do it.
// let AudioApp = {}; // <--- REMOVE THIS LINE

// 1. Import Dependencies
try {
    // The first script in this list (`constants.js`) will create the AudioApp namespace.
    // The rest will attach to it.
    importScripts(
        '../constants.js',
        '../utils.js',
        './sileroWrapper.js',
        './sileroProcessor.js'
    );
} catch (e) {
    console.error("VAD Worker: Failed to import scripts.", e);
    self.postMessage({ type: 'error', payload: { message: 'Worker script import failed.' } });
}

// 2. Listen for Messages
self.onmessage = async (event) => {
    // Ensure dependencies are loaded before proceeding.
    if (!AudioApp.sileroWrapper || !AudioApp.sileroProcessor) {
        self.postMessage({ type: 'error', payload: { message: 'Worker VAD modules are missing.' }});
        return;
    }

    const { type, payload } = event.data;

    try {
        if (type === 'init') {
            const modelReady = await AudioApp.sileroWrapper.create(AudioApp.Constants.VAD_SAMPLE_RATE);
            if (modelReady) {
                self.postMessage({ type: 'model_ready' });
            } else {
                throw new Error("Failed to create Silero VAD model in worker.");
            }
        } else if (type === 'analyze') {
            const { pcmData } = payload;

            // The progress callback will now post a message back to the main thread.
            const progressCallback = (progress) => {
                self.postMessage({ type: 'progress', payload: progress });
            };

            const vadResult = await AudioApp.sileroProcessor.analyzeAudio(pcmData, { onProgress: progressCallback });

            // Post the final result back.
            self.postMessage({ type: 'result', payload: vadResult });
        }
    } catch (e) {
        console.error('VAD Worker: Error during processing.', e);
        self.postMessage({ type: 'error', payload: { message: e.message } });
    }
};

````
--- End of File: vibe-player/js/vad/vad.worker.js ---
--- File: vibe-player/js/vad/vadAnalyzer.js ---
````javascript
// --- /vibe-player/js/vad/vadAnalyzer.js --- // Updated Path
// Manages VAD state (analysis results, current thresholds) and uses SileroProcessor
// to perform analysis and recalculations. Acts as a bridge between app controller and processor.

/** @namespace AudioApp */
var AudioApp = AudioApp || {};

/**
 * @namespace AudioApp.vadAnalyzer
 * @description Manages Voice Activity Detection (VAD) state, including analysis results
 * and current thresholds. It uses the `AudioApp.sileroProcessor` for performing the
 * actual VAD analysis and recalculating speech regions based on new parameters.
 * @param {AudioApp.sileroProcessor} processor - The Silero VAD processor module.
 */
AudioApp.vadAnalyzer = (function(processor) {
    'use strict';

    /**
     * @private
     * @type {AudioApp.Constants} Reference to the Constants module.
     */
    const Constants = AudioApp.Constants;

    if (!processor) {
        console.error("VadAnalyzer: CRITICAL - AudioApp.sileroProcessor dependency is not available!");
        /** @type {VadAnalyzerPublicInterface} */
        const nonFunctionalInterface = {
            analyze: () => Promise.reject(new Error("VAD Processor not available")),
            recalculate: () => { console.error("VadAnalyzer: Cannot recalculate, VAD Processor not available."); return []; },
            getCurrentRegions: () => [],
            handleThresholdUpdate: () => { console.error("VadAnalyzer: Cannot handle threshold update, VAD Processor not available."); return []; },
            getFrameSamples: () => Constants?.DEFAULT_VAD_FRAME_SAMPLES || 1536 // Fallback if Constants is also missing
        };
        return nonFunctionalInterface;
    }
     if (!Constants) {
          console.error("VadAnalyzer: CRITICAL - AudioApp.Constants module not available!");
          /** @type {VadAnalyzerPublicInterface} */
          const errorInterface = {
               analyze: () => Promise.reject(new Error("AudioApp.Constants not available for VadAnalyzer")),
               recalculate: () => [], getCurrentRegions: () => [], handleThresholdUpdate: () => [],
               getFrameSamples: () => 1536 // Hardcoded fallback if Constants is missing
          };
          return errorInterface;
     }

    /**
     * @private
     * @type {AudioApp.sileroProcessor.VadResult|null} Stores the latest VAD results.
     * @see {@link AudioApp.sileroProcessor.VadResult} for type definition.
     */
    let currentVadResults = null;
    /**
     * @private
     * @type {number} Current positive speech threshold used for VAD.
     */
    let currentPositiveThreshold = 0.5; // Default
    /**
     * @private
     * @type {number} Current negative speech threshold used for VAD.
     */
    let currentNegativeThreshold = 0.35; // Default


    /**
     * @typedef {object} VadAnalyzerAnalysisOptions
     * @property {function({processedFrames: number, totalFrames: number}): void} [onProgress] - Optional callback for progress updates during analysis.
     * @property {number} [frameSamples] - Optional override for the number of samples per VAD frame.
     *                                      Defaults to `AudioApp.Constants.DEFAULT_VAD_FRAME_SAMPLES`.
     */

    /**
     * Runs the initial VAD analysis on the provided PCM data using the configured `sileroProcessor`.
     * Stores the analysis results internally, including probabilities and initial speech regions.
     * @public
     * @async
     * @param {Float32Array} pcm16k - The 16kHz mono PCM audio data as a Float32Array.
     * @param {VadAnalyzerAnalysisOptions} [options={}] - Configuration options for the analysis.
     * @returns {Promise<AudioApp.sileroProcessor.VadResult>} The full VAD results object from the processor.
     * @throws {Error} If the analysis in the underlying processor fails.
     */
    async function analyze(pcm16k, options = {}) {
        currentVadResults = null; // Reset previous results
        // Reset thresholds to defaults before new analysis, processor will use these for initial regions.
        currentPositiveThreshold = 0.5;
        currentNegativeThreshold = 0.35;

        /** @type {AudioApp.sileroProcessor.VadAnalysisOptions} */
        const processorOptions = {
             positiveSpeechThreshold: currentPositiveThreshold,
             negativeSpeechThreshold: currentNegativeThreshold,
             frameSamples: options.frameSamples || Constants.DEFAULT_VAD_FRAME_SAMPLES,
             onProgress: options.onProgress
        };

        console.log("VadAnalyzer: Starting VAD analysis via sileroProcessor...");
        try {
            const results = await processor.analyzeAudio(pcm16k, processorOptions);
            currentVadResults = results;
            // Update internal thresholds to match those used for the initial analysis by the processor
            currentPositiveThreshold = results.initialPositiveThreshold;
            currentNegativeThreshold = results.initialNegativeThreshold;
            console.log("VadAnalyzer: VAD analysis successful.");
            return currentVadResults;
        } catch (error) {
            const err = /** @type {Error} */ (error);
            console.error("VadAnalyzer: VAD analysis failed -", err.message, err.stack);
            currentVadResults = null; // Clear results on failure
            throw err; // Re-throw for the caller (e.g., app.js) to handle
        }
    }

     /**
     * Handles updates to VAD thresholds (e.g., from UI sliders via app.js).
     * Updates the internal threshold state and triggers a recalculation of speech regions.
     * @public
     * @param {'positive' | 'negative'} type - The type of threshold being updated.
     * @param {number} value - The new threshold value.
     * @returns {AudioApp.sileroProcessor.VadRegion[]} The newly recalculated speech regions.
     * Returns an empty array if VAD analysis has not been performed yet.
     * @see {@link AudioApp.sileroProcessor.VadRegion} for region object structure.
     */
     function handleThresholdUpdate(type, value) {
        if (!currentVadResults) {
            console.warn("VadAnalyzer: Cannot handle threshold update - no VAD results available. Call analyze() first.");
            return [];
        }
        if (type === 'positive') {
            currentPositiveThreshold = value;
        } else if (type === 'negative') {
            currentNegativeThreshold = value;
        } else {
            console.warn(`VadAnalyzer: Unknown threshold type '${type}'. No update performed.`);
            return currentVadResults.regions || []; // Return existing regions if type is unknown
        }
        return recalculate(); // Recalculate with the new threshold
    }


    /**
     * Recalculates speech regions using the stored probabilities from the last analysis
     * and the current internal positive and negative threshold values.
     * This method delegates the actual calculation logic to the `sileroProcessor`.
     * The `regions` array within the stored `currentVadResults` is updated with the new regions.
     * @public
     * @returns {AudioApp.sileroProcessor.VadRegion[]} The recalculated speech regions.
     * Returns an empty array if VAD analysis results (especially probabilities) are not available.
     * @see {@link AudioApp.sileroProcessor.VadRegion} for region object structure.
     */
    function recalculate() {
        if (!currentVadResults || !currentVadResults.probabilities) {
            console.warn("VadAnalyzer: Cannot recalculate speech regions - VAD results or probabilities are missing. Call analyze() first.");
            return [];
        }

        /** @type {AudioApp.sileroProcessor.RecalculateOptions} */
        const optionsForRecalc = {
            frameSamples: currentVadResults.frameSamples,
            sampleRate: currentVadResults.sampleRate,
            positiveSpeechThreshold: currentPositiveThreshold,
            negativeSpeechThreshold: currentNegativeThreshold,
            redemptionFrames: currentVadResults.redemptionFrames
        };

        const newRegions = processor.recalculateSpeechRegions(currentVadResults.probabilities, optionsForRecalc);
        currentVadResults.regions = newRegions; // Update the stored regions
        return newRegions;
    }

    /**
     * Retrieves the currently calculated speech regions.
     * These regions are based on the latest analysis or recalculation.
     * @public
     * @returns {AudioApp.sileroProcessor.VadRegion[]} An array of speech region objects.
     * Returns an empty array if no VAD analysis has been performed or if no regions were detected.
     * @see {@link AudioApp.sileroProcessor.VadRegion} for region object structure.
     */
    function getCurrentRegions() {
        return currentVadResults?.regions || [];
    }

    /**
     * Gets the number of samples per frame used in the last successful VAD analysis.
     * This is useful for UI elements like progress bars that need to relate frame counts to time.
     * @public
     * @returns {number} The frame size in samples. Defaults to `AudioApp.Constants.DEFAULT_VAD_FRAME_SAMPLES` if no analysis has been run.
     */
    function getFrameSamples() {
        return currentVadResults?.frameSamples || Constants.DEFAULT_VAD_FRAME_SAMPLES;
    }

    /**
     * @typedef {Object} VadAnalyzerPublicInterface
     * @property {function(Float32Array, VadAnalyzerAnalysisOptions=): Promise<AudioApp.sileroProcessor.VadResult>} analyze
     * @property {function(): AudioApp.sileroProcessor.VadRegion[]} recalculate
     * @property {function('positive'|'negative', number): AudioApp.sileroProcessor.VadRegion[]} handleThresholdUpdate
     * @property {function(): AudioApp.sileroProcessor.VadRegion[]} getCurrentRegions
     * @property {function(): number} getFrameSamples
     */

    /** @type {VadAnalyzerPublicInterface} */
    return {
        analyze: analyze,
        recalculate: recalculate,
        handleThresholdUpdate: handleThresholdUpdate,
        getCurrentRegions: getCurrentRegions,
        getFrameSamples: getFrameSamples
    };

})(AudioApp.sileroProcessor);
// --- /vibe-player/js/vad/vadAnalyzer.js --- // Updated Path

````
--- End of File: vibe-player/js/vad/vadAnalyzer.js ---
--- File: vibe-player/js/visualizers/spectrogram.worker.js ---
````javascript
// --- /vibe-player/js/visualizers/spectrogram.worker.js ---
// This worker handles the computationally intensive task of calculating the spectrogram.

// 1. Import Dependencies
try {
    // These paths are relative to this worker file's location.
    importScripts('../../lib/fft.js', '../constants.js', '../utils.js');
} catch (e) {
    console.error("Spectrogram Worker: Failed to import scripts.", e);
    self.postMessage({ type: 'error', detail: 'Worker script import failed.' });
}

// 2. Listen for Messages
self.onmessage = (event) => {
    // Verify that dependencies loaded correctly before proceeding.
    if (typeof self.FFT === 'undefined' || typeof self.AudioApp === 'undefined') {
        self.postMessage({ type: 'error', detail: 'Worker dependencies are missing.' });
        return;
    }

    const { type, payload } = event.data;

    if (type === 'compute') {
        try {
            const { channelData, sampleRate, duration, fftSize, targetSlices } = payload;

            // Access the globally loaded scripts via the 'self' scope.
            const Constants = self.AudioApp.Constants;
            const Utils = self.AudioApp.Utils;
            const FFT = self.FFT;

            // 3. Run Computation
            const spectrogramData = computeSpectrogram(channelData, sampleRate, duration, fftSize, targetSlices, FFT, Constants, Utils);

            // 4. Post Result Back (with Transferable objects for performance)
            if (spectrogramData) {
                const transferable = spectrogramData.map(arr => arr.buffer);
                self.postMessage({ type: 'result', payload: { spectrogramData } }, transferable);
            } else {
                 self.postMessage({ type: 'result', payload: { spectrogramData: [] } }); // Send empty result
            }
        } catch (e) {
            console.error('Spectrogram Worker: Error during computation.', e);
            self.postMessage({ type: 'error', detail: e.message });
        }
    }
};

// THIS FUNCTION IS A DIRECT COPY FROM THE ORIGINAL spectrogramVisualizer.js
function computeSpectrogram(channelData, sampleRate, duration, actualFftSize, targetSlices, FFTConstructor, Constants, Utils) {
    if (!channelData) { console.error("Worker: Invalid channelData."); return null; }
    const totalSamples = channelData.length;
    const hopDivisor = duration < Constants.SPEC_SHORT_FILE_HOP_THRESHOLD_S ? Constants.SPEC_SHORT_HOP_DIVISOR : Constants.SPEC_NORMAL_HOP_DIVISOR;
    const hopSize = Math.max(1, Math.floor(actualFftSize / hopDivisor));
    const padding = Constants.SPEC_CENTER_WINDOWS ? Math.floor(actualFftSize / 2) : 0;
    const rawSliceCount = Constants.SPEC_CENTER_WINDOWS ? Math.ceil(totalSamples / hopSize)
        : (totalSamples < actualFftSize ? 0 : Math.floor((totalSamples - actualFftSize) / hopSize) + 1);

    if (rawSliceCount <= 0) { console.warn("Worker: Not enough audio samples for FFT."); return []; }

    const fftInstance = new FFTConstructor(actualFftSize, sampleRate);
    const complexBuffer = fftInstance.createComplexArray();
    const fftInput = new Array(actualFftSize);
    const windowFunc = Utils.hannWindow(actualFftSize);
    if (!windowFunc) { console.error("Worker: Failed to generate Hann window."); return null; }

    const rawSpec = [];
    for (let i = 0; i < rawSliceCount; i++) {
        const windowCenterSample = i * hopSize;
        const windowFetchStart = windowCenterSample - padding;
        for (let j = 0; j < actualFftSize; j++) {
            const sampleIndex = windowFetchStart + j;
            let sampleValue = 0.0;
            if (sampleIndex >= 0 && sampleIndex < totalSamples) {
                sampleValue = channelData[sampleIndex];
            } else if (sampleIndex < 0) {
                sampleValue = totalSamples > 0 ? channelData[0] : 0.0;
            } else {
                sampleValue = totalSamples > 0 ? channelData[totalSamples - 1] : 0.0;
            }
            fftInput[j] = sampleValue * windowFunc[j];
        }
        fftInstance.realTransform(complexBuffer, fftInput);
        const numBins = actualFftSize / 2;
        const magnitudes = new Float32Array(numBins);
        for (let k = 0; k < numBins; k++) {
            const re = complexBuffer[k * 2], im = complexBuffer[k * 2 + 1];
            magnitudes[k] = Math.sqrt(re * re + im * im);
        }
        rawSpec.push(magnitudes);
    }

    if (rawSpec.length === 0) return [];
    if (rawSpec.length === targetSlices) return rawSpec;

    const numFreqBins = rawSpec[0].length;
    const finalSpec = new Array(targetSlices);
    for (let i = 0; i < targetSlices; i++) {
         const rawPos = (rawSpec.length > 1) ? (i / (targetSlices - 1)) * (rawSpec.length - 1) : 0;
         const index1 = Math.floor(rawPos);
         const index2 = Math.min(rawSpec.length - 1, Math.ceil(rawPos));
         const factor = rawPos - index1;
         const magnitudes1 = rawSpec[index1], magnitudes2 = rawSpec[index2];
         finalSpec[i] = new Float32Array(numFreqBins);
         if (index1 === index2 || factor === 0) {
             finalSpec[i].set(magnitudes1);
         } else {
             for (let k = 0; k < numFreqBins; k++) {
                 finalSpec[i][k] = magnitudes1[k] * (1.0 - factor) + magnitudes2[k] * factor;
             }
         }
    }
    return finalSpec;
}
````
--- End of File: vibe-player/js/visualizers/spectrogram.worker.js ---
--- File: vibe-player/js/visualizers/spectrogramVisualizer.js ---
````javascript
// --- /vibe-player/js/visualizers/spectrogramVisualizer.js --- (CORRECTED)
// Handles orchestrating the Spectrogram worker and rendering the results to a canvas.

AudioApp.spectrogramVisualizer = (function(globalFFT) {
    'use strict';

    const Constants = AudioApp.Constants;
    const Utils = AudioApp.Utils;

    // DOM Elements
    let spectrogramCanvas = null, spectrogramCtx = null, spectrogramSpinner = null,
        spectrogramProgressIndicator = null, cachedSpectrogramCanvas = null;

    let getSharedAudioBuffer = null;
    let currentMaxFreqIndex = Constants.SPEC_DEFAULT_MAX_FREQ_INDEX;
    let worker = null;
    let lastAudioBuffer = null; // Cache the audio buffer for the current job

    function init(getAudioBufferCallback) {
        console.log("SpectrogramVisualizer: Initializing...");
        assignDOMElements();
        getSharedAudioBuffer = getAudioBufferCallback;

        try {
            worker = new Worker('js/visualizers/spectrogram.worker.js');
            worker.onmessage = handleWorkerMessage;
            worker.onerror = handleWorkerError;
        } catch (e) {
             console.error("SpectrogramVisualizer: Failed to create Web Worker.", e);
             worker = null;
        }

        if (spectrogramCanvas) {
            spectrogramCanvas.addEventListener('click', handleCanvasClick);
            spectrogramCanvas.addEventListener('dblclick', handleCanvasDoubleClick);
        }
    }

    function handleWorkerError(e) {
        console.error("SpectrogramVisualizer: Received error from worker:", e);
        showSpinner(false);
        if (spectrogramCtx && spectrogramCanvas) {
            spectrogramCtx.fillStyle = '#D32F2F';
            spectrogramCtx.textAlign = 'center';
            spectrogramCtx.font = '14px sans-serif';
            spectrogramCtx.fillText(`Worker Error: ${e.message}`, spectrogramCanvas.width / 2, spectrogramCanvas.height / 2);
        }
    }

    function handleWorkerMessage(event) {
        const { type, payload, detail } = event.data;
        if (type === 'result') {
            const { spectrogramData } = payload;
            const audioBuffer = lastAudioBuffer;

            if (!audioBuffer) {
                console.warn("SpectrogramVisualizer: Worker returned a result, but there is no longer an active audio buffer. Ignoring.");
                showSpinner(false);
                return;
            }

            if (spectrogramData && spectrogramData.length > 0) {
                const actualFftSize = audioBuffer.duration < Constants.SPEC_SHORT_FILE_FFT_THRESHOLD_S ? Constants.SPEC_SHORT_FFT_SIZE : Constants.SPEC_NORMAL_FFT_SIZE;
                drawSpectrogramAsync(spectrogramData, spectrogramCanvas, audioBuffer.sampleRate, actualFftSize)
                    .catch(error => console.error("SpectrogramVisualizer: Error during async drawing.", error))
                    .finally(() => showSpinner(false));
            } else {
                console.warn("SpectrogramVisualizer: Worker returned empty or null data.");
                showSpinner(false);
            }
        } else if (type === 'error') {
            handleWorkerError({ message: detail });
        }
    }

    async function computeAndDrawSpectrogram(audioBufferFromParam) {
        lastAudioBuffer = audioBufferFromParam || (getSharedAudioBuffer ? getSharedAudioBuffer() : null);

        if (!lastAudioBuffer) { console.warn("SpectrogramVisualizer: No AudioBuffer available."); return; }
        if (!spectrogramCtx || !spectrogramCanvas) { console.warn("SpectrogramVisualizer: Canvas context/element missing."); return; }
        if (!worker) {
            handleWorkerError({ message: "Worker not available or failed to load." });
            return;
        }

        console.log("SpectrogramVisualizer: Offloading spectrogram computation to worker...");
        clearVisualsInternal();
        resizeCanvasInternal();
        cachedSpectrogramCanvas = null;
        showSpinner(true);

        const actualFftSize = lastAudioBuffer.duration < Constants.SPEC_SHORT_FILE_FFT_THRESHOLD_S ? Constants.SPEC_SHORT_FFT_SIZE : Constants.SPEC_NORMAL_FFT_SIZE;
        // IMPORTANT: We must copy the data for transfer, as the original buffer might be needed elsewhere (e.g., VAD)
        const channelData = lastAudioBuffer.getChannelData(0).slice();

        worker.postMessage({
            type: 'compute',
            payload: {
                channelData: channelData,
                sampleRate: lastAudioBuffer.sampleRate,
                duration: lastAudioBuffer.duration,
                fftSize: actualFftSize,
                targetSlices: Constants.SPEC_FIXED_WIDTH
            }
        }, [channelData.buffer]);
    }

    // --- HELPER FUNCTIONS THAT WERE MISSING ---

    function assignDOMElements() {
        spectrogramCanvas = document.getElementById('spectrogramCanvas');
        spectrogramSpinner = document.getElementById('spectrogramSpinner');
        spectrogramProgressIndicator = document.getElementById('spectrogramProgressIndicator');
        if (spectrogramCanvas) {
            spectrogramCtx = spectrogramCanvas.getContext('2d');
        } else {
            console.error("SpectrogramVisualizer: Could not find 'spectrogramCanvas' element.");
        }
    }

    function handleCanvasClick(e) {
        if (!spectrogramCanvas) return;
        const rect = spectrogramCanvas.getBoundingClientRect();
        if (!rect || rect.width <= 0) return;
        const clickXRelative = e.clientX - rect.left;
        const fraction = Math.max(0, Math.min(1, clickXRelative / rect.width));
        document.dispatchEvent(new CustomEvent('audioapp:seekRequested', { detail: { fraction: fraction } }));
    }

    function handleCanvasDoubleClick(e) {
        e.preventDefault();
        if (!spectrogramCanvas || !Constants.SPEC_MAX_FREQS?.length) return;

        currentMaxFreqIndex = (currentMaxFreqIndex + 1) % Constants.SPEC_MAX_FREQS.length;
        const audioBufferForRedraw = lastAudioBuffer || (getSharedAudioBuffer ? getSharedAudioBuffer() : null);
        if (audioBufferForRedraw) {
            computeAndDrawSpectrogram(audioBufferForRedraw);
        }
    }

    function drawSpectrogramAsync(spectrogramData, canvas, sampleRate, actualFftSize) {
        return new Promise((resolve, reject) => {
            if (!canvas || !spectrogramData?.[0] || !Constants || !Utils) {
                return reject(new Error("SpectrogramVisualizer: Missing dependencies for async draw."));
            }
            const displayCtx = canvas.getContext('2d');
            if (!displayCtx) return reject(new Error("SpectrogramVisualizer: Could not get 2D context from display canvas."));

            displayCtx.clearRect(0, 0, canvas.width, canvas.height);
            displayCtx.fillStyle = '#000'; displayCtx.fillRect(0, 0, canvas.width, canvas.height);

            const dataWidth = spectrogramData.length; const displayHeight = canvas.height;
            if (!cachedSpectrogramCanvas || cachedSpectrogramCanvas.width !== dataWidth || cachedSpectrogramCanvas.height !== displayHeight) {
                 cachedSpectrogramCanvas = document.createElement('canvas');
                 cachedSpectrogramCanvas.width = dataWidth; cachedSpectrogramCanvas.height = displayHeight;
            }
            const offCtx = cachedSpectrogramCanvas.getContext('2d');
            if (!offCtx) return reject(new Error("SpectrogramVisualizer: Could not get context from offscreen canvas."));

            const numBins = actualFftSize / 2;
            const nyquist = sampleRate / 2;
            const currentSpecMaxFreq = Constants.SPEC_MAX_FREQS[currentMaxFreqIndex];
            const maxBinIndex = Math.min(numBins - 1, Math.floor((currentSpecMaxFreq / nyquist) * (numBins - 1)));

            const dbThreshold = -60; let maxDb = -Infinity;
            const sliceStep = Math.max(1, Math.floor(dataWidth / 100));
            const binStep = Math.max(1, Math.floor(maxBinIndex / 50));
            for (let i = 0; i < dataWidth; i += sliceStep) {
                 const magnitudes = spectrogramData[i]; if (!magnitudes) continue;
                 for (let j = 0; j <= maxBinIndex; j += binStep) {
                     if (j >= magnitudes.length) break;
                     const db = 20 * Math.log10(Math.max(1e-9, magnitudes[j]));
                     maxDb = Math.max(maxDb, Math.max(dbThreshold, db));
                 }
            }
            maxDb = Math.max(maxDb, dbThreshold + 1);
            const minDb = dbThreshold; const dbRange = maxDb - minDb;

            const fullImageData = offCtx.createImageData(dataWidth, displayHeight);
            const imgData = fullImageData.data;
            let currentSlice = 0; const chunkSize = 32;

            function drawChunk() {
                try {
                    const startSlice = currentSlice; const endSlice = Math.min(startSlice + chunkSize, dataWidth);
                    for (let i = startSlice; i < endSlice; i++) {
                        const magnitudes = spectrogramData[i]; if (!magnitudes) continue;
                        for (let y = 0; y < displayHeight; y++) {
                            const freqRatio = (displayHeight - 1 - y) / (displayHeight - 1);
                            const logFreqRatio = Math.pow(freqRatio, 2.0);
                            const binIndex = Math.min(maxBinIndex, Math.floor(logFreqRatio * maxBinIndex));
                            const magnitude = magnitudes[binIndex] || 0;
                            const db = 20 * Math.log10(Math.max(1e-9, magnitude));
                            const normValue = dbRange > 0 ? (Math.max(minDb, db) - minDb) / dbRange : 0;
                            const [r, g, b] = Utils.viridisColor(normValue);
                            const idx = (i + y * dataWidth) * 4;
                            imgData[idx] = r; imgData[idx + 1] = g; imgData[idx + 2] = b; imgData[idx + 3] = 255;
                        }
                    }
                    offCtx.putImageData(fullImageData, 0, 0, startSlice, 0, endSlice - startSlice, displayHeight);
                    currentSlice = endSlice;
                    if (currentSlice < dataWidth) { requestAnimationFrame(drawChunk); }
                    else {
                        displayCtx.drawImage(cachedSpectrogramCanvas, 0, 0, canvas.width, canvas.height);
                        resolve();
                    }
                } catch (error) { reject(error); }
            }
            requestAnimationFrame(drawChunk);
        });
    }

    function updateProgressIndicator(currentTime, duration) {
        if (!spectrogramCanvas || !spectrogramProgressIndicator) return;
        if (isNaN(duration) || duration <= 0) {
            spectrogramProgressIndicator.style.left = "0px"; return;
        }
        const fraction = Math.max(0, Math.min(1, currentTime / duration));
        spectrogramProgressIndicator.style.left = `${fraction * spectrogramCanvas.clientWidth}px`;
    }

    function clearVisualsInternal() {
         if (spectrogramCtx && spectrogramCanvas) {
            spectrogramCtx.clearRect(0, 0, spectrogramCanvas.width, spectrogramCanvas.height);
            spectrogramCtx.fillStyle = '#000';
            spectrogramCtx.fillRect(0, 0, spectrogramCanvas.width, spectrogramCanvas.height);
        }
        updateProgressIndicator(0, 1);
    }

    function clearVisuals() {
        clearVisualsInternal();
        cachedSpectrogramCanvas = null;
    }

    function showSpinner(show) {
        if (spectrogramSpinner) {
            spectrogramSpinner.style.display = show ? 'inline' : 'none';
        }
    }

    function resizeCanvasInternal() {
         if (!spectrogramCanvas) return false;
        const { width, height } = spectrogramCanvas.getBoundingClientRect();
        const roundedWidth = Math.round(width); const roundedHeight = Math.round(height);
        if (spectrogramCanvas.width !== roundedWidth || spectrogramCanvas.height !== roundedHeight) {
            spectrogramCanvas.width = roundedWidth; spectrogramCanvas.height = roundedHeight;
             if(spectrogramCtx) {
                  spectrogramCtx.fillStyle = '#000';
                  spectrogramCtx.fillRect(0, 0, roundedWidth, roundedHeight);
             }
            return true;
        }
        return false;
    }

    function resizeAndRedraw(audioBuffer) {
        const wasResized = resizeCanvasInternal();
        if (wasResized && cachedSpectrogramCanvas && spectrogramCtx && spectrogramCanvas) {
             spectrogramCtx.drawImage(cachedSpectrogramCanvas, 0, 0, spectrogramCanvas.width, spectrogramCanvas.height);
        }
        const { currentTime = 0, duration = 0 } = AudioApp.audioEngine?.getCurrentTime() || {};
        updateProgressIndicator(currentTime, duration || (audioBuffer ? audioBuffer.duration : 0));
    }

    return {
        init: init,
        computeAndDrawSpectrogram: computeAndDrawSpectrogram,
        resizeAndRedraw: resizeAndRedraw,
        updateProgressIndicator: updateProgressIndicator,
        clearVisuals: clearVisuals,
        showSpinner: showSpinner
    };
})(window.FFT);

````
--- End of File: vibe-player/js/visualizers/spectrogramVisualizer.js ---
--- File: vibe-player/js/visualizers/waveformVisualizer.js ---
````javascript
// --- /vibe-player/js/visualizers/waveformVisualizer.js ---
// Handles drawing the Waveform visualization to a canvas element.

/** @namespace AudioApp */
var AudioApp = AudioApp || {};

/**
 * @namespace AudioApp.waveformVisualizer
 * @description Manages the rendering of the audio waveform, including highlighting speech regions
 * and displaying a playback progress indicator.
 */
AudioApp.waveformVisualizer = (function() {
    'use strict';

    /**
     * @private
     * @type {AudioApp.Constants} Reference to the Constants module.
     */
    const Constants = AudioApp.Constants;
    /**
     * @private
     * @type {AudioApp.Utils} Reference to the Utils module (not directly used in this snippet but assumed available if needed).
     */
    const Utils = AudioApp.Utils;

    /** @type {HTMLCanvasElement|null} The canvas element for the waveform. */
    let waveformCanvas = null;
    /** @type {CanvasRenderingContext2D|null} The 2D rendering context of the waveform canvas. */
    let waveformCtx = null;
    /** @type {HTMLDivElement|null} The element used to indicate playback progress on the waveform. */
    let waveformProgressIndicator = null;


    /**
     * Initializes the Waveform Visualizer.
     * Retrieves DOM elements and sets up event listeners.
     * @public
     */
    function init() {
        console.log("WaveformVisualizer: Initializing...");
        assignDOMElements();
        if (waveformCanvas) {
            waveformCanvas.addEventListener('click', handleCanvasClick);
        } else {
            console.warn("WaveformVisualizer: Waveform canvas element not found during init.");
        }
        console.log("WaveformVisualizer: Initialized.");
    }

    /**
     * Assigns DOM elements to module-level variables.
     * @private
     */
    function assignDOMElements() {
        waveformCanvas = /** @type {HTMLCanvasElement|null} */ (document.getElementById('waveformCanvas'));
        waveformProgressIndicator = /** @type {HTMLDivElement|null} */ (document.getElementById('waveformProgressIndicator'));
        if (waveformCanvas) {
            waveformCtx = waveformCanvas.getContext('2d');
        } else {
            console.error("WaveformVisualizer: Could not find 'waveformCanvas' element.");
        }
        if (!waveformProgressIndicator) {
            console.warn("WaveformVisualizer: Could not find 'waveformProgressIndicator' element.");
        }
    }


    /**
     * Handles click events on the waveform canvas, dispatching a seek request.
     * @private
     * @param {MouseEvent} e - The MouseEvent from the click.
     */
    function handleCanvasClick(e) {
        if (!waveformCanvas) return;
        const rect = waveformCanvas.getBoundingClientRect();
        if (!rect || rect.width <= 0) return; // Avoid division by zero if canvas has no width
        const clickXRelative = e.clientX - rect.left;
        const fraction = Math.max(0, Math.min(1, clickXRelative / rect.width)); // Clamp fraction to [0, 1]
        document.dispatchEvent(new CustomEvent('audioapp:seekRequested', { detail: { fraction: fraction } }));
    }


    /**
     * @typedef {object} SpeechRegion
     * @property {number} start - Start time of the speech region in seconds.
     * @property {number} end - End time of the speech region in seconds.
     */

    /**
     * Computes waveform data from an AudioBuffer and draws it on the canvas.
     * Highlights speech regions if provided.
     * @public
     * @async
     * @param {AudioBuffer} audioBuffer - The audio data to visualize.
     * @param {SpeechRegion[]|null|undefined} speechRegions - Optional array of speech regions to highlight.
     * If null or empty, the waveform is drawn with a loading/default color.
     * @returns {Promise<void>} Resolves when the waveform has been drawn.
     */
    async function computeAndDrawWaveform(audioBuffer, speechRegions) {
        if (!audioBuffer) { console.warn("WaveformVisualizer: computeAndDrawWaveform called with no AudioBuffer."); return; }
        if (!waveformCtx || !waveformCanvas) { console.warn("WaveformVisualizer: Canvas context/element missing for drawing."); return; }

        resizeCanvasInternal(); // Ensure canvas dimensions are up-to-date
        const width = waveformCanvas.width;

        const waveformData = computeWaveformData(audioBuffer, width);
        drawWaveform(waveformData, waveformCanvas, waveformCtx, speechRegions, audioBuffer.duration, width);
        updateProgressIndicator(0, audioBuffer.duration); // Reset progress indicator
    }

    /**
     * Redraws the waveform, primarily to update speech region highlighting.
     * Recomputes waveform data based on the current canvas size.
     * @public
     * @param {AudioBuffer|null} audioBuffer - The current audio buffer.
     * @param {SpeechRegion[]} speechRegions - The speech regions to highlight.
     */
    function redrawWaveformHighlight(audioBuffer, speechRegions) {
         if (!audioBuffer) { console.warn("WaveformVisualizer: Cannot redraw highlight, AudioBuffer missing."); return; }
         if (!waveformCanvas || !waveformCtx) { console.warn("WaveformVisualizer: Cannot redraw highlight, canvas/context missing."); return; }
         const width = waveformCanvas.width;
         if (width <= 0) { console.warn("WaveformVisualizer: Cannot redraw highlight, canvas width is zero or invalid."); return; }

         const waveformData = computeWaveformData(audioBuffer, width);
         drawWaveform(waveformData, waveformCanvas, waveformCtx, speechRegions, audioBuffer.duration, width);
    }


    /**
     * @typedef {object} WaveformMinMax
     * @property {number} min - Minimum sample value in the segment.
     * @property {number} max - Maximum sample value in the segment.
     */

    /**
     * Computes simplified waveform data (min/max pairs for each pixel column).
     * @private
     * @param {AudioBuffer} buffer - The audio buffer to process.
     * @param {number} targetWidth - The target width in pixels for the waveform display.
     * @returns {WaveformMinMax[]} An array of min/max objects, one for each pixel column.
     */
    function computeWaveformData(buffer, targetWidth) {
        if (!buffer?.getChannelData || targetWidth <= 0) return [];
        const channelCount = buffer.numberOfChannels;
        const bufferLength = buffer.length;
        if (bufferLength === 0) return [];

        /** @type {Float32Array} */
        let sourceData;
        if (channelCount === 1) {
            sourceData = buffer.getChannelData(0);
        } else { // Mix down to mono if multi-channel
            sourceData = new Float32Array(bufferLength);
            for (let ch = 0; ch < channelCount; ch++) {
                const chData = buffer.getChannelData(ch);
                for (let i = 0; i < bufferLength; i++) {
                    sourceData[i] += chData[i];
                }
            }
            for (let i = 0; i < bufferLength; i++) { sourceData[i] /= channelCount; }
        }

        const samplesPerPixel = Math.max(1, Math.floor(bufferLength / targetWidth));
        /** @type {WaveformMinMax[]} */
        const waveform = [];
        for (let i = 0; i < targetWidth; i++) {
            const start = Math.floor(i * samplesPerPixel);
            const end = Math.min(start + samplesPerPixel, bufferLength);
            if (start >= end) { waveform.push({min: 0, max: 0}); continue; }

            let min = 1.0, max = -1.0;
            for (let j = start; j < end; j++) {
                const sample = sourceData[j];
                if (sample < min) min = sample;
                if (sample > max) max = sample;
            }
            waveform.push({min, max});
        }
        return waveform;
    }


    /**
     * Draws the computed waveform data onto the canvas.
     * Highlights speech regions using specific colors defined in `AudioApp.Constants`.
     * @private
     * @param {WaveformMinMax[]} waveformData - Array of min/max values per pixel column.
     * @param {HTMLCanvasElement} canvas - The canvas element to draw on.
     * @param {CanvasRenderingContext2D} ctx - The 2D rendering context of the canvas.
     * @param {SpeechRegion[]|null|undefined} speechRegions - Array of speech time regions to highlight.
     * @param {number} audioDuration - Total duration of the audio in seconds.
     * @param {number} width - The current width of the canvas.
     */
     function drawWaveform(waveformData, canvas, ctx, speechRegions, audioDuration, width) {
        if (!ctx || !Constants) { console.error("WaveformVisualizer: Missing context or Constants for drawing."); return; }

        const { height } = canvas;
        ctx.clearRect(0, 0, width, height);
        ctx.fillStyle = '#000'; ctx.fillRect(0, 0, width, height); // Background

        if (!waveformData || waveformData.length === 0 || !audioDuration || audioDuration <= 0) {
            ctx.fillStyle = '#888'; ctx.textAlign = 'center'; ctx.font = '12px sans-serif';
            ctx.fillText("No waveform data available", width / 2, height / 2);
            return;
        }

        const dataLen = waveformData.length;
        const halfHeight = height / 2;
        const scale = halfHeight * Constants.WAVEFORM_HEIGHT_SCALE;
        const pixelsPerSecond = width / audioDuration;
        const initialDraw = !speechRegions || speechRegions.length === 0;
        const defaultColor = initialDraw ? Constants.WAVEFORM_COLOR_LOADING : Constants.WAVEFORM_COLOR_DEFAULT;
        const speechPixelRegions = initialDraw ? [] : (speechRegions || []).map(r => ({
            startPx: r.start * pixelsPerSecond, endPx: r.end * pixelsPerSecond
        }));
        const pixelWidth = width / dataLen; // Width of each bar in the waveform

        // Draw non-speech/loading parts
        ctx.fillStyle = defaultColor;
        ctx.beginPath();
        for (let i = 0; i < dataLen; i++) {
            const x = i * pixelWidth;
            const currentPixelEnd = x + pixelWidth;
            let isOutsideSpeech = true;
            if (!initialDraw) {
                for (const region of speechPixelRegions) {
                    if (x < region.endPx && currentPixelEnd > region.startPx) { isOutsideSpeech = false; break; }
                }
            }
            if (isOutsideSpeech) {
                const { min, max } = waveformData[i];
                const y1 = halfHeight - (max * scale); const y2 = halfHeight - (min * scale);
                ctx.rect(x, y1, pixelWidth, Math.max(1, y2 - y1)); // Ensure rect has at least 1px height
            }
        }
        ctx.fill();

        // Draw speech highlights
        if (!initialDraw) {
            ctx.fillStyle = Constants.WAVEFORM_COLOR_SPEECH;
            ctx.beginPath();
            for (let i = 0; i < dataLen; i++) {
                const x = i * pixelWidth;
                const currentPixelEnd = x + pixelWidth;
                let isInsideSpeech = false;
                for (const region of speechPixelRegions) {
                    if (x < region.endPx && currentPixelEnd > region.startPx) { isInsideSpeech = true; break; }
                }
                if (isInsideSpeech) {
                    const { min, max } = waveformData[i];
                    const y1 = halfHeight - (max * scale); const y2 = halfHeight - (min * scale);
                    ctx.rect(x, y1, pixelWidth, Math.max(1, y2 - y1));
                }
            }
            ctx.fill();
        }
    }


    /**
     * Updates the position of the playback progress indicator on the waveform.
     * @public
     * @param {number} currentTime - The current playback time in seconds.
     * @param {number} duration - The total duration of the audio in seconds.
     */
    function updateProgressIndicator(currentTime, duration) {
        if (!waveformCanvas || !waveformProgressIndicator) return;
        if (isNaN(duration) || duration <= 0) {
            waveformProgressIndicator.style.left = "0px"; return;
        }
        const fraction = Math.max(0, Math.min(1, currentTime / duration));
        const waveformWidth = waveformCanvas.clientWidth;
        waveformProgressIndicator.style.left = waveformWidth > 0 ? `${fraction * waveformWidth}px` : "0px";
    }

    /**
     * Clears the waveform canvas and resets the progress indicator.
     * @public
     */
    function clearVisuals() {
        console.log("WaveformVisualizer: Clearing visuals.");
        if (waveformCtx && waveformCanvas) {
            waveformCtx.clearRect(0, 0, waveformCanvas.width, waveformCanvas.height);
            waveformCtx.fillStyle = '#000'; // Explicitly set black background
            waveformCtx.fillRect(0, 0, waveformCanvas.width, waveformCanvas.height);
        }
        updateProgressIndicator(0, 1); // Reset progress indicator
    }

    /**
     * Resizes the canvas element to match its CSS-defined display size.
     * This is important for ensuring crisp rendering.
     * @private
     * @returns {boolean} True if the canvas was resized, false otherwise.
     */
    function resizeCanvasInternal() {
        if (!waveformCanvas) return false;
        const { width, height } = waveformCanvas.getBoundingClientRect();
        const roundedWidth = Math.max(10, Math.round(width)); // Ensure minimum size
        const roundedHeight = Math.max(10, Math.round(height));
        if (waveformCanvas.width !== roundedWidth || waveformCanvas.height !== roundedHeight) {
            waveformCanvas.width = roundedWidth;
            waveformCanvas.height = roundedHeight;
             if(waveformCtx) { // Redraw background if context exists
                  waveformCtx.fillStyle = '#000';
                  waveformCtx.fillRect(0, 0, roundedWidth, roundedHeight);
             }
            return true;
        }
        return false;
    }

    /**
     * Handles window resize events. Adjusts canvas dimensions and redraws the waveform
     * using the provided audio buffer and speech regions.
     * @public
     * @param {AudioBuffer|null} audioBuffer - The current audio buffer.
     * @param {SpeechRegion[]|null} speechRegions - Current speech regions to highlight.
     */
    function resizeAndRedraw(audioBuffer, speechRegions) {
        const wasResized = resizeCanvasInternal();
        if (wasResized && audioBuffer) {
            redrawWaveformHighlight(audioBuffer, speechRegions || []);
        } else if (wasResized) {
            clearVisuals(); // Clear if resized but no audio buffer to redraw
        }
        // Always update progress indicator, as its position depends on clientWidth
        const { currentTime = 0, duration = 0 } = AudioApp.audioEngine?.getCurrentTime() || {};
        updateProgressIndicator(currentTime, duration || (audioBuffer ? audioBuffer.duration : 0));
    }

    /**
     * @typedef {Object} WaveformVisualizerPublicInterface
     * @property {function(): void} init
     * @property {function(AudioBuffer, SpeechRegion[]|null|undefined): Promise<void>} computeAndDrawWaveform
     * @property {function(AudioBuffer|null, SpeechRegion[]): void} redrawWaveformHighlight
     * @property {function(AudioBuffer|null, SpeechRegion[]|null): void} resizeAndRedraw
     * @property {function(number, number): void} updateProgressIndicator
     * @property {function(): void} clearVisuals
     */

    /** @type {WaveformVisualizerPublicInterface} */
    return {
        init: init,
        computeAndDrawWaveform: computeAndDrawWaveform,
        redrawWaveformHighlight: redrawWaveformHighlight,
        resizeAndRedraw: resizeAndRedraw,
        updateProgressIndicator: updateProgressIndicator,
        clearVisuals: clearVisuals
    };

})();
// --- /vibe-player/js/visualizers/waveformVisualizer.js ---
````
--- End of File: vibe-player/js/visualizers/waveformVisualizer.js ---
--- File: vibe-player/lib/fft.js ---
````javascript
// --- /vibe-player/lib/fft.js ---
// NOTE: This is 3rd party code (adapted). JSDoc annotations not added here.
'use strict';

// =============================================
// == Fast Fourier Transform (FFT) Library ==
// Based on https://github.com/indutny/fft.js
// Creates a global FFT constructor.
// =============================================

function FFT(size) {
  this.size = size | 0;
  if (this.size <= 1 || (this.size & (this.size - 1)) !== 0)
    throw new Error('FFT size must be a power of two and bigger than 1');

  this._csize = size << 1;

  var table = new Array(this.size * 2);
  for (var i = 0; i < table.length; i += 2) {
    const angle = Math.PI * i / this.size;
    table[i] = Math.cos(angle);
    table[i + 1] = -Math.sin(angle);
  }
  this.table = table;

  var power = 0;
  for (var t = 1; this.size > t; t <<= 1)
    power++;

  this._width = power % 2 === 0 ? power - 1 : power;

  this._bitrev = new Array(1 << this._width);
  for (var j = 0; j < this._bitrev.length; j++) {
    this._bitrev[j] = 0;
    for (var shift = 0; shift < this._width; shift += 2) {
      var revShift = this._width - shift - 2;
      this._bitrev[j] |= ((j >>> shift) & 3) << revShift;
    }
  }

  this._out = null;
  this._data = null;
  this._inv = 0;
}

FFT.prototype.fromComplexArray = function fromComplexArray(complex, storage) {
  var res = storage || new Array(complex.length >>> 1);
  for (var i = 0; i < complex.length; i += 2)
    res[i >>> 1] = complex[i];
  return res;
};

FFT.prototype.createComplexArray = function createComplexArray() {
  const res = new Array(this._csize);
  for (var i = 0; i < res.length; i++)
    res[i] = 0;
  return res;
};

FFT.prototype.toComplexArray = function toComplexArray(input, storage) {
  var res = storage || this.createComplexArray();
  for (var i = 0; i < res.length; i += 2) {
    res[i] = input[i >>> 1];
    res[i + 1] = 0;
  }
  return res;
};

FFT.prototype.completeSpectrum = function completeSpectrum(spectrum) {
  var size = this._csize;
  var half = size >>> 1;
  for (var i = 2; i < half; i += 2) {
    spectrum[size - i] = spectrum[i];
    spectrum[size - i + 1] = -spectrum[i + 1];
  }
};

FFT.prototype.transform = function transform(out, data) {
  if (out === data) throw new Error('Input and output buffers must be different');
  this._out = out; this._data = data; this._inv = 0; this._transform4();
  this._out = null; this._data = null;
};

FFT.prototype.realTransform = function realTransform(out, data) {
  if (out === data) throw new Error('Input and output buffers must be different');
  this._out = out; this._data = data; this._inv = 0; this._realTransform4();
  this._out = null; this._data = null;
};

FFT.prototype.inverseTransform = function inverseTransform(out, data) {
  if (out === data) throw new Error('Input and output buffers must be different');
  this._out = out; this._data = data; this._inv = 1; this._transform4();
  for (var i = 0; i < out.length; i++) out[i] /= this.size;
  this._out = null; this._data = null;
};

FFT.prototype._transform4 = function _transform4() {
  var out = this._out, size = this._csize, width = this._width;
  var step = 1 << width, len = (size / step) << 1, bitrev = this._bitrev;
  var outOff, t;
  if (len === 4) { for (outOff = 0, t = 0; outOff < size; outOff += len, t++) this._singleTransform2(outOff, bitrev[t], step); }
  else { for (outOff = 0, t = 0; outOff < size; outOff += len, t++) this._singleTransform4(outOff, bitrev[t], step); }
  var inv = this._inv ? -1 : 1, table = this.table;
  for (step >>= 2; step >= 2; step >>= 2) {
    len = (size / step) << 1; var quarterLen = len >>> 2;
    for (outOff = 0; outOff < size; outOff += len) {
      var limit = outOff + quarterLen;
      for (var i = outOff, k = 0; i < limit; i += 2, k += step) {
        const A = i, B = A + quarterLen, C = B + quarterLen, D = C + quarterLen;
        const Ar = out[A], Ai = out[A + 1], Br = out[B], Bi = out[B + 1], Cr = out[C], Ci = out[C + 1], Dr = out[D], Di = out[D + 1];
        const MAr = Ar, MAi = Ai;
        const tableBr = table[k], tableBi = inv * table[k + 1]; const MBr = Br * tableBr - Bi * tableBi, MBi = Br * tableBi + Bi * tableBr;
        const tableCr = table[2 * k], tableCi = inv * table[2 * k + 1]; const MCr = Cr * tableCr - Ci * tableCi, MCi = Cr * tableCi + Ci * tableCr;
        const tableDr = table[3 * k], tableDi = inv * table[3 * k + 1]; const MDr = Dr * tableDr - Di * tableDi, MDi = Dr * tableDi + Di * tableDr;
        const T0r = MAr + MCr, T0i = MAi + MCi, T1r = MAr - MCr, T1i = MAi - MCi; const T2r = MBr + MDr, T2i = MBi + MDi, T3r = inv * (MBr - MDr), T3i = inv * (MBi - MDi);
        const FAr = T0r + T2r, FAi = T0i + T2i, FCr = T0r - T2r, FCi = T0i - T2i; const FBr = T1r + T3i, FBi = T1i - T3r, FDr = T1r - T3i, FDi = T1i + T3r;
        out[A] = FAr; out[A + 1] = FAi; out[B] = FBr; out[B + 1] = FBi; out[C] = FCr; out[C + 1] = FCi; out[D] = FDr; out[D + 1] = FDi;
      }
    }
  }
};
FFT.prototype._singleTransform2 = function _singleTransform2(outOff, off, step) {
  const out = this._out, data = this._data; const evenR = data[off], evenI = data[off + 1]; const oddR = data[off + step], oddI = data[off + step + 1];
  const leftR = evenR + oddR, leftI = evenI + oddI; const rightR = evenR - oddR, rightI = evenI - oddI;
  out[outOff] = leftR; out[outOff + 1] = leftI; out[outOff + 2] = rightR; out[outOff + 3] = rightI;
};
FFT.prototype._singleTransform4 = function _singleTransform4(outOff, off, step) {
  const out = this._out, data = this._data; const inv = this._inv ? -1 : 1; const step2 = step * 2, step3 = step * 3;
  const Ar = data[off], Ai = data[off + 1], Br = data[off + step], Bi = data[off + step + 1], Cr = data[off + step2], Ci = data[off + step2 + 1], Dr = data[off + step3], Di = data[off + step3 + 1];
  const T0r = Ar + Cr, T0i = Ai + Ci, T1r = Ar - Cr, T1i = Ai - Ci; const T2r = Br + Dr, T2i = Bi + Di, T3r = inv * (Br - Dr), T3i = inv * (Bi - Di);
  const FAr = T0r + T2r, FAi = T0i + T2i, FBr = T1r + T3i, FBi = T1i - T3r; const FCr = T0r - T2r, FCi = T0i - T2i, FDr = T1r - T3i, FDi = T1i + T3r;
  out[outOff] = FAr; out[outOff + 1] = FAi; out[outOff + 2] = FBr; out[outOff + 3] = FBi; out[outOff + 4] = FCr; out[outOff + 5] = FCi; out[outOff + 6] = FDr; out[outOff + 7] = FDi;
};
FFT.prototype._realTransform4 = function _realTransform4() {
  var out = this._out, size = this._csize, width = this._width;
  var step = 1 << width, len = (size / step) << 1, bitrev = this._bitrev;
  var outOff, t;
  if (len === 4) { for (outOff = 0, t = 0; outOff < size; outOff += len, t++) this._singleRealTransform2(outOff, bitrev[t] >>> 1, step >>> 1); }
  else { for (outOff = 0, t = 0; outOff < size; outOff += len, t++) this._singleRealTransform4(outOff, bitrev[t] >>> 1, step >>> 1); }
  var inv = this._inv ? -1 : 1, table = this.table;
  for (step >>= 2; step >= 2; step >>= 2) {
    len = (size / step) << 1; var halfLen = len >>> 1, quarterLen = halfLen >>> 1, hquarterLen = quarterLen >>> 1;
    for (outOff = 0; outOff < size; outOff += len) {
      for (var i = 0, k = 0; i <= hquarterLen; i += 2, k += step) {
        var A = outOff + i, B = A + quarterLen, C = B + quarterLen, D = C + quarterLen;
        var Ar = out[A], Ai = out[A + 1], Br = out[B], Bi = out[B + 1], Cr = out[C], Ci = out[C + 1], Dr = out[D], Di = out[D + 1];
        var MAr = Ar, MAi = Ai;
        var tableBr = table[k], tableBi = inv * table[k + 1]; var MBr = Br * tableBr - Bi * tableBi, MBi = Br * tableBi + Bi * tableBr;
        var tableCr = table[2 * k], tableCi = inv * table[2 * k + 1]; var MCr = Cr * tableCr - Ci * tableCi, MCi = Cr * tableCi + Ci * tableCr;
        var tableDr = table[3 * k], tableDi = inv * table[3 * k + 1]; var MDr = Dr * tableDr - Di * tableDi, MDi = Dr * tableDi + Di * tableDr;
        var T0r = MAr + MCr, T0i = MAi + MCi, T1r = MAr - MCr, T1i = MAi - MCi; var T2r = MBr + MDr, T2i = MBi + MDi, T3r = inv * (MBr - MDr), T3i = inv * (MBi - MDi);
        var FAr = T0r + T2r, FAi = T0i + T2i, FBr = T1r + T3i, FBi = T1i - T3r;
        out[A] = FAr; out[A + 1] = FAi; out[B] = FBr; out[B + 1] = FBi;
        if (i === 0) { var FCr = T0r - T2r, FCi = T0i - T2i; out[C] = FCr; out[C + 1] = FCi; continue; }
        if (i === hquarterLen) continue;
        var ST0r = T1r, ST0i = -T1i, ST1r = T0r, ST1i = -T0i; var ST2r = -inv * T3i, ST2i = -inv * T3r, ST3r = -inv * T2i, ST3i = -inv * T2r;
        var SFAr = ST0r + ST2r, SFAi = ST0i + ST2i, SFBr = ST1r + ST3i, SFBi = ST1i - ST3r;
        var SA = outOff + quarterLen - i, SB = outOff + halfLen - i;
        out[SA] = SFAr; out[SA + 1] = SFAi; out[SB] = SFBr; out[SB + 1] = SFBi;
      }
    }
  }
};
FFT.prototype._singleRealTransform2 = function _singleRealTransform2(outOff, off, step) {
  const out = this._out, data = this._data; const evenR = data[off], oddR = data[off + step];
  const leftR = evenR + oddR, rightR = evenR - oddR;
  out[outOff] = leftR; out[outOff + 1] = 0; out[outOff + 2] = rightR; out[outOff + 3] = 0;
};
FFT.prototype._singleRealTransform4 = function _singleRealTransform4(outOff, off, step) {
  const out = this._out, data = this._data; const inv = this._inv ? -1 : 1; const step2 = step * 2, step3 = step * 3;
  const Ar = data[off], Br = data[off + step], Cr = data[off + step2], Dr = data[off + step3];
  const T0r = Ar + Cr, T1r = Ar - Cr, T2r = Br + Dr, T3r = inv * (Br - Dr);
  const FAr = T0r + T2r, FBr = T1r, FBi = -T3r, FCr = T0r - T2r, FDr = T1r, FDi = T3r;
  out[outOff] = FAr; out[outOff + 1] = 0; out[outOff + 2] = FBr; out[outOff + 3] = FBi;
  out[outOff + 4] = FCr; out[outOff + 5] = 0; out[outOff + 6] = FDr; out[outOff + 7] = FDi;
};

````
--- End of File: vibe-player/lib/fft.js ---
--- File: vibe-player/lib/ort-wasm-simd-threaded.jsep.mjs ---
````mjs
var ortWasmThreaded = (() => {
  var _scriptName = import.meta.url;
  
  return (
async function(moduleArg = {}) {
  var moduleRtn;

var f=moduleArg,aa,ba,ca=new Promise((a,b)=>{aa=a;ba=b}),da="object"==typeof window,ea="undefined"!=typeof WorkerGlobalScope,m="object"==typeof process&&"object"==typeof process.versions&&"string"==typeof process.versions.node&&"renderer"!=process.type,n=ea&&self.name?.startsWith("em-pthread");if(m){const {createRequire:a}=await import("module");var require=a(import.meta.url),fa=require("worker_threads");global.Worker=fa.Worker;n=(ea=!fa.je)&&"em-pthread"==fa.workerData}"use strict";
f.mountExternalData=(a,b)=>{a.startsWith("./")&&(a=a.substring(2));(f.Bd||(f.Bd=new Map)).set(a,b)};f.unmountExternalData=()=>{delete f.Bd};var SharedArrayBuffer=globalThis.SharedArrayBuffer??(new WebAssembly.Memory({initial:0,maximum:0,shared:!0})).buffer.constructor;"use strict";
let ia=()=>{const a=(c,d,e)=>(...g)=>{const h=t,k=d?.();g=c(...g);const l=d?.();k!==l&&(c=l,e(k),d=e=null);return t!=h?ha():g},b=c=>async(...d)=>{try{if(f.Cd)throw Error("Session already started");const e=f.Cd={be:d[0],errors:[]},g=await c(...d);if(f.Cd!==e)throw Error("Session mismatch");f.Dd?.flush();const h=e.errors;if(0<h.length){let k=await Promise.all(h);k=k.filter(l=>l);if(0<k.length)throw Error(k.join("\n"));}return g}finally{f.Cd=null}};f._OrtCreateSession=a(f._OrtCreateSession,()=>f._OrtCreateSession,
c=>f._OrtCreateSession=c);f._OrtRun=b(a(f._OrtRun,()=>f._OrtRun,c=>f._OrtRun=c));f._OrtRunWithBinding=b(a(f._OrtRunWithBinding,()=>f._OrtRunWithBinding,c=>f._OrtRunWithBinding=c));f._OrtBindInput=a(f._OrtBindInput,()=>f._OrtBindInput,c=>f._OrtBindInput=c);ia=void 0};
f.jsepInit=(a,b)=>{ia?.();if("webgpu"===a){[f.Dd,f.Rd,f.Vd,f.Hd,f.Ud,f.hc,f.Wd,f.Zd,f.Sd,f.Td,f.Xd]=b;const c=f.Dd;f.jsepRegisterBuffer=(d,e,g,h)=>c.registerBuffer(d,e,g,h);f.jsepGetBuffer=d=>c.getBuffer(d);f.jsepCreateDownloader=(d,e,g)=>c.createDownloader(d,e,g);f.jsepOnCreateSession=d=>{c.onCreateSession(d)};f.jsepOnReleaseSession=d=>{c.onReleaseSession(d)};f.jsepOnRunStart=d=>c.onRunStart(d);f.$d=(d,e)=>{c.upload(d,e)}}else if("webnn"===a){[f.Dd,f.Yd,f.Id,f.jsepEnsureTensor,f.Jd,f.jsepDownloadTensor]=
b;f.jsepReleaseTensorId=f.Id;f.jsepUploadTensor=f.Jd;const c=f.Dd;f.jsepOnRunStart=d=>c.onRunStart(d);f.jsepOnRunEnd=c.onRunEnd.bind(c);f.jsepRegisterMLContext=(d,e)=>{c.registerMLContext(d,e)};f.jsepOnReleaseSession=d=>{c.onReleaseSession(d)};f.jsepCreateMLTensorDownloader=(d,e)=>c.createMLTensorDownloader(d,e);f.jsepRegisterMLTensor=(d,e,g,h)=>c.registerMLTensor(d,e,g,h);f.jsepCreateMLContext=d=>c.createMLContext(d);f.jsepRegisterMLConstant=(d,e,g,h,k)=>c.registerMLConstant(d,e,g,h,k,f.Bd);f.jsepRegisterGraphInput=
c.registerGraphInput.bind(c);f.jsepIsGraphInput=c.isGraphInput.bind(c);f.jsepCreateTemporaryTensor=c.createTemporaryTensor.bind(c)}};var ja=Object.assign({},f),ka="./this.program",ma=(a,b)=>{throw b;},u="",na,oa;
if(m){var fs=require("fs"),pa=require("path");import.meta.url.startsWith("data:")||(u=pa.dirname(require("url").fileURLToPath(import.meta.url))+"/");oa=a=>{a=qa(a)?new URL(a):a;return fs.readFileSync(a)};na=async a=>{a=qa(a)?new URL(a):a;return fs.readFileSync(a,void 0)};!f.thisProgram&&1<process.argv.length&&(ka=process.argv[1].replace(/\\/g,"/"));process.argv.slice(2);ma=(a,b)=>{process.exitCode=a;throw b;}}else if(da||ea)ea?u=self.location.href:"undefined"!=typeof document&&
document.currentScript&&(u=document.currentScript.src),_scriptName&&(u=_scriptName),u.startsWith("blob:")?u="":u=u.slice(0,u.replace(/[?#].*/,"").lastIndexOf("/")+1),m||(ea&&(oa=a=>{var b=new XMLHttpRequest;b.open("GET",a,!1);b.responseType="arraybuffer";b.send(null);return new Uint8Array(b.response)}),na=async a=>{if(qa(a))return new Promise((c,d)=>{var e=new XMLHttpRequest;e.open("GET",a,!0);e.responseType="arraybuffer";e.onload=()=>{200==e.status||0==e.status&&e.response?c(e.response):d(e.status)};
e.onerror=d;e.send(null)});var b=await fetch(a,{credentials:"same-origin"});if(b.ok)return b.arrayBuffer();throw Error(b.status+" : "+b.url);});var ra=console.log.bind(console),sa=console.error.bind(console);m&&(ra=(...a)=>fs.writeSync(1,a.join(" ")+"\n"),sa=(...a)=>fs.writeSync(2,a.join(" ")+"\n"));var ta=ra,v=sa;Object.assign(f,ja);ja=null;var ua=f.wasmBinary,x,va,wa=!1,xa,y,ya,za,Aa,Ba,Ca,Da,A,Ea,Fa,qa=a=>a.startsWith("file://");function B(){x.buffer!=y.buffer&&C();return y}
function D(){x.buffer!=y.buffer&&C();return ya}function Ga(){x.buffer!=y.buffer&&C();return za}function Ha(){x.buffer!=y.buffer&&C();return Aa}function E(){x.buffer!=y.buffer&&C();return Ba}function F(){x.buffer!=y.buffer&&C();return Ca}function Ia(){x.buffer!=y.buffer&&C();return Da}function Ja(){x.buffer!=y.buffer&&C();return Fa}
if(n){var Ka;if(m){var La=fa.parentPort;La.on("message",b=>onmessage({data:b}));Object.assign(globalThis,{self:global,postMessage:b=>La.postMessage(b)})}var Ma=!1;v=function(...b){b=b.join(" ");m?fs.writeSync(2,b+"\n"):console.error(b)};self.alert=function(...b){postMessage({yd:"alert",text:b.join(" "),fe:Na()})};self.onunhandledrejection=b=>{throw b.reason||b;};function a(b){try{var c=b.data,d=c.yd;if("load"===d){let e=[];self.onmessage=g=>e.push(g);self.startWorker=()=>{postMessage({yd:"loaded"});
for(let g of e)a(g);self.onmessage=a};for(const g of c.Od)if(!f[g]||f[g].proxy)f[g]=(...h)=>{postMessage({yd:"callHandler",Nd:g,args:h})},"print"==g&&(ta=f[g]),"printErr"==g&&(v=f[g]);x=c.he;C();Ka(c.ie)}else if("run"===d){Oa(c.xd);Pa(c.xd,0,0,1,0,0);Qa();Ra(c.xd);Ma||(Sa(),Ma=!0);try{Ta(c.de,c.Fd)}catch(e){if("unwind"!=e)throw e;}}else"setimmediate"!==c.target&&("checkMailbox"===d?Ma&&Ua():d&&(v(`worker: received unknown command ${d}`),v(c)))}catch(e){throw Va(),e;}}self.onmessage=a}
function C(){var a=x.buffer;f.HEAP8=y=new Int8Array(a);f.HEAP16=za=new Int16Array(a);f.HEAPU8=ya=new Uint8Array(a);f.HEAPU16=Aa=new Uint16Array(a);f.HEAP32=Ba=new Int32Array(a);f.HEAPU32=Ca=new Uint32Array(a);f.HEAPF32=Da=new Float32Array(a);f.HEAPF64=Fa=new Float64Array(a);f.HEAP64=A=new BigInt64Array(a);f.HEAPU64=Ea=new BigUint64Array(a)}n||(x=new WebAssembly.Memory({initial:256,maximum:65536,shared:!0}),C());function Wa(){n?startWorker(f):G.Bb()}var Xa=0,Ya=null;
function Za(){Xa--;if(0==Xa&&Ya){var a=Ya;Ya=null;a()}}function H(a){a="Aborted("+a+")";v(a);wa=!0;a=new WebAssembly.RuntimeError(a+". Build with -sASSERTIONS for more info.");ba(a);throw a;}var $a;async function ab(a){if(!ua)try{var b=await na(a);return new Uint8Array(b)}catch{}if(a==$a&&ua)a=new Uint8Array(ua);else if(oa)a=oa(a);else throw"both async and sync fetching of the wasm failed";return a}
async function bb(a,b){try{var c=await ab(a);return await WebAssembly.instantiate(c,b)}catch(d){v(`failed to asynchronously prepare wasm: ${d}`),H(d)}}async function cb(a){var b=$a;if(!ua&&"function"==typeof WebAssembly.instantiateStreaming&&!qa(b)&&!m)try{var c=fetch(b,{credentials:"same-origin"});return await WebAssembly.instantiateStreaming(c,a)}catch(d){v(`wasm streaming compile failed: ${d}`),v("falling back to ArrayBuffer instantiation")}return bb(b,a)}
function db(){eb={Ta:fb,Va:gb,W:hb,la:ib,b:jb,u:kb,R:lb,Za:mb,d:nb,pb:ob,g:pb,T:qb,Ga:rb,lb:sb,nb:tb,Ha:ub,Ea:vb,wb,Da:xb,pa:yb,mb:zb,jb:Ab,Fa:Bb,kb:Cb,Ma:Db,za:Eb,eb:Fb,cb:Gb,ya:Hb,V:Ib,N:Jb,db:Kb,ma:Lb,fb:Mb,zb:Nb,hb:Ob,qb:Pb,ab:Qb,Aa:Rb,yb:Ra,Ja:Sb,S:Tb,Wa:Ub,$:Vb,G:Wb,E:Xb,m:Yb,H:Zb,B:$b,X:ac,J:bc,v:cc,O:dc,D:ec,t:fc,A:gc,z:hc,w:ic,r:jc,tb:kc,ub:lc,vb:mc,rb:nc,sb:oc,bb:pc,Oa:qc,La:rc,y:sc,ja:tc,Ba:uc,Ka:vc,qa:wc,Ia:xc,ib:yc,U:zc,fa:Ac,Sa:Bc,gb:Cc,Qa:Dc,Pa:Ec,Ab:Fc,Ca:Gc,ob:Hc,aa:Ic,oa:Jc,xb:Kc,
na:Lc,$a:Mc,ia:Nc,sa:Oc,ga:Pc,da:Qc,ua:Rc,p:Sc,e:Tc,c:Uc,ea:Vc,f:Wc,n:Xc,k:Yc,Y:Zc,ka:$c,j:ad,wa:bd,Ra:cd,ca:dd,Ua:ed,P:fd,K:gd,_:hd,Q:jd,Z:kd,x:ld,l:md,va:nd,i:od,h:pd,ra:qd,ta:rd,o:sd,q:td,s:ud,I:vd,C:wd,L:xd,xa:yd,_a:zd,F:Ad,Ya:Bd,ba:Cd,M:Dd,Xa:Ed,ha:Fd,a:x,Na:Gd};return{a:eb}}
var Hd={1319426:()=>"undefined"!==typeof wasmOffsetConverter,1319483:(a,b,c,d,e)=>{if("undefined"==typeof f||!f.Bd)return 1;a=I(Number(a>>>0));a.startsWith("./")&&(a=a.substring(2));a=f.Bd.get(a);if(!a)return 2;b=Number(b>>>0);c=Number(c>>>0);d=Number(d>>>0);if(b+c>a.byteLength)return 3;try{const g=a.subarray(b,b+c);switch(e){case 0:D().set(g,d>>>0);break;case 1:f.$d(d,g);break;default:return 4}return 0}catch{return 4}},1320198:(a,b,c)=>{f.Jd(a,D().subarray(b>>>0,b+c>>>0))},1320261:()=>f.Yd(),1320302:a=>
{f.Id(a)},1320338:()=>{f.Sd()},1320369:()=>{f.Td()},1320398:()=>{f.Xd()},1320423:a=>f.Rd(a),1320456:a=>f.Vd(a),1320488:(a,b,c)=>{f.Hd(Number(a),Number(b),Number(c),!0)},1320551:(a,b,c)=>{f.Hd(Number(a),Number(b),Number(c))},1320608:a=>{f.hc("Abs",a,void 0)},1320659:a=>{f.hc("Neg",a,void 0)},1320710:a=>{f.hc("Floor",a,void 0)},1320763:a=>{f.hc("Ceil",a,void 0)},1320815:a=>{f.hc("Reciprocal",a,void 0)},1320873:a=>{f.hc("Sqrt",a,void 0)},1320925:a=>{f.hc("Exp",a,void 0)},1320976:a=>{f.hc("Erf",a,void 0)},
1321027:a=>{f.hc("Sigmoid",a,void 0)},1321082:(a,b,c)=>{f.hc("HardSigmoid",a,{alpha:b,beta:c})},1321161:a=>{f.hc("Log",a,void 0)},1321212:a=>{f.hc("Sin",a,void 0)},1321263:a=>{f.hc("Cos",a,void 0)},1321314:a=>{f.hc("Tan",a,void 0)},1321365:a=>{f.hc("Asin",a,void 0)},1321417:a=>{f.hc("Acos",a,void 0)},1321469:a=>{f.hc("Atan",a,void 0)},1321521:a=>{f.hc("Sinh",a,void 0)},1321573:a=>{f.hc("Cosh",a,void 0)},1321625:a=>{f.hc("Asinh",a,void 0)},1321678:a=>{f.hc("Acosh",a,void 0)},1321731:a=>{f.hc("Atanh",
a,void 0)},1321784:a=>{f.hc("Tanh",a,void 0)},1321836:a=>{f.hc("Not",a,void 0)},1321887:(a,b,c)=>{f.hc("Clip",a,{min:b,max:c})},1321956:a=>{f.hc("Clip",a,void 0)},1322008:(a,b)=>{f.hc("Elu",a,{alpha:b})},1322066:a=>{f.hc("Gelu",a,void 0)},1322118:a=>{f.hc("Relu",a,void 0)},1322170:(a,b)=>{f.hc("LeakyRelu",a,{alpha:b})},1322234:(a,b)=>{f.hc("ThresholdedRelu",a,{alpha:b})},1322304:(a,b)=>{f.hc("Cast",a,{to:b})},1322362:a=>{f.hc("Add",a,void 0)},1322413:a=>{f.hc("Sub",a,void 0)},1322464:a=>{f.hc("Mul",
a,void 0)},1322515:a=>{f.hc("Div",a,void 0)},1322566:a=>{f.hc("Pow",a,void 0)},1322617:a=>{f.hc("Equal",a,void 0)},1322670:a=>{f.hc("Greater",a,void 0)},1322725:a=>{f.hc("GreaterOrEqual",a,void 0)},1322787:a=>{f.hc("Less",a,void 0)},1322839:a=>{f.hc("LessOrEqual",a,void 0)},1322898:(a,b,c,d,e)=>{f.hc("ReduceMean",a,{keepDims:!!b,noopWithEmptyAxes:!!c,axes:d?Array.from(E().subarray(Number(d)>>>0,Number(e)>>>0)):[]})},1323073:(a,b,c,d,e)=>{f.hc("ReduceMax",a,{keepDims:!!b,noopWithEmptyAxes:!!c,axes:d?
Array.from(E().subarray(Number(d)>>>0,Number(e)>>>0)):[]})},1323247:(a,b,c,d,e)=>{f.hc("ReduceMin",a,{keepDims:!!b,noopWithEmptyAxes:!!c,axes:d?Array.from(E().subarray(Number(d)>>>0,Number(e)>>>0)):[]})},1323421:(a,b,c,d,e)=>{f.hc("ReduceProd",a,{keepDims:!!b,noopWithEmptyAxes:!!c,axes:d?Array.from(E().subarray(Number(d)>>>0,Number(e)>>>0)):[]})},1323596:(a,b,c,d,e)=>{f.hc("ReduceSum",a,{keepDims:!!b,noopWithEmptyAxes:!!c,axes:d?Array.from(E().subarray(Number(d)>>>0,Number(e)>>>0)):[]})},1323770:(a,
b,c,d,e)=>{f.hc("ReduceL1",a,{keepDims:!!b,noopWithEmptyAxes:!!c,axes:d?Array.from(E().subarray(Number(d)>>>0,Number(e)>>>0)):[]})},1323943:(a,b,c,d,e)=>{f.hc("ReduceL2",a,{keepDims:!!b,noopWithEmptyAxes:!!c,axes:d?Array.from(E().subarray(Number(d)>>>0,Number(e)>>>0)):[]})},1324116:(a,b,c,d,e)=>{f.hc("ReduceLogSum",a,{keepDims:!!b,noopWithEmptyAxes:!!c,axes:d?Array.from(E().subarray(Number(d)>>>0,Number(e)>>>0)):[]})},1324293:(a,b,c,d,e)=>{f.hc("ReduceSumSquare",a,{keepDims:!!b,noopWithEmptyAxes:!!c,
axes:d?Array.from(E().subarray(Number(d)>>>0,Number(e)>>>0)):[]})},1324473:(a,b,c,d,e)=>{f.hc("ReduceLogSumExp",a,{keepDims:!!b,noopWithEmptyAxes:!!c,axes:d?Array.from(E().subarray(Number(d)>>>0,Number(e)>>>0)):[]})},1324653:a=>{f.hc("Where",a,void 0)},1324706:(a,b,c)=>{f.hc("Transpose",a,{perm:b?Array.from(E().subarray(Number(b)>>>0,Number(c)>>>0)):[]})},1324830:(a,b,c,d)=>{f.hc("DepthToSpace",a,{blocksize:b,mode:I(c),format:d?"NHWC":"NCHW"})},1324963:(a,b,c,d)=>{f.hc("DepthToSpace",a,{blocksize:b,
mode:I(c),format:d?"NHWC":"NCHW"})},1325096:(a,b,c,d,e,g,h,k,l,p,q,r,w,z,J)=>{f.hc("ConvTranspose",a,{format:l?"NHWC":"NCHW",autoPad:b,dilations:[c],group:d,kernelShape:[e],pads:[g,h],strides:[k],wIsConst:()=>!!B()[p>>>0],outputPadding:q?Array.from(E().subarray(Number(q)>>>0,Number(r)>>>0)):[],outputShape:w?Array.from(E().subarray(Number(w)>>>0,Number(z)>>>0)):[],activation:I(J)})},1325529:(a,b,c,d,e,g,h,k,l,p,q,r,w,z)=>{f.hc("ConvTranspose",a,{format:k?"NHWC":"NCHW",autoPad:b,dilations:Array.from(E().subarray(Number(c)>>>
0,(Number(c)>>>0)+2>>>0)),group:d,kernelShape:Array.from(E().subarray(Number(e)>>>0,(Number(e)>>>0)+2>>>0)),pads:Array.from(E().subarray(Number(g)>>>0,(Number(g)>>>0)+4>>>0)),strides:Array.from(E().subarray(Number(h)>>>0,(Number(h)>>>0)+2>>>0)),wIsConst:()=>!!B()[l>>>0],outputPadding:p?Array.from(E().subarray(Number(p)>>>0,Number(q)>>>0)):[],outputShape:r?Array.from(E().subarray(Number(r)>>>0,Number(w)>>>0)):[],activation:I(z)})},1326190:(a,b,c,d,e,g,h,k,l,p,q,r,w,z,J)=>{f.hc("ConvTranspose",a,{format:l?
"NHWC":"NCHW",autoPad:b,dilations:[c],group:d,kernelShape:[e],pads:[g,h],strides:[k],wIsConst:()=>!!B()[p>>>0],outputPadding:q?Array.from(E().subarray(Number(q)>>>0,Number(r)>>>0)):[],outputShape:w?Array.from(E().subarray(Number(w)>>>0,Number(z)>>>0)):[],activation:I(J)})},1326623:(a,b,c,d,e,g,h,k,l,p,q,r,w,z)=>{f.hc("ConvTranspose",a,{format:k?"NHWC":"NCHW",autoPad:b,dilations:Array.from(E().subarray(Number(c)>>>0,(Number(c)>>>0)+2>>>0)),group:d,kernelShape:Array.from(E().subarray(Number(e)>>>0,
(Number(e)>>>0)+2>>>0)),pads:Array.from(E().subarray(Number(g)>>>0,(Number(g)>>>0)+4>>>0)),strides:Array.from(E().subarray(Number(h)>>>0,(Number(h)>>>0)+2>>>0)),wIsConst:()=>!!B()[l>>>0],outputPadding:p?Array.from(E().subarray(Number(p)>>>0,Number(q)>>>0)):[],outputShape:r?Array.from(E().subarray(Number(r)>>>0,Number(w)>>>0)):[],activation:I(z)})},1327284:(a,b)=>{f.hc("GlobalAveragePool",a,{format:b?"NHWC":"NCHW"})},1327375:(a,b,c,d,e,g,h,k,l,p,q,r,w,z)=>{f.hc("AveragePool",a,{format:z?"NHWC":"NCHW",
auto_pad:b,ceil_mode:c,count_include_pad:d,storage_order:e,dilations:g?Array.from(E().subarray(Number(g)>>>0,Number(h)>>>0)):[],kernel_shape:k?Array.from(E().subarray(Number(k)>>>0,Number(l)>>>0)):[],pads:p?Array.from(E().subarray(Number(p)>>>0,Number(q)>>>0)):[],strides:r?Array.from(E().subarray(Number(r)>>>0,Number(w)>>>0)):[]})},1327854:(a,b)=>{f.hc("GlobalAveragePool",a,{format:b?"NHWC":"NCHW"})},1327945:(a,b,c,d,e,g,h,k,l,p,q,r,w,z)=>{f.hc("AveragePool",a,{format:z?"NHWC":"NCHW",auto_pad:b,ceil_mode:c,
count_include_pad:d,storage_order:e,dilations:g?Array.from(E().subarray(Number(g)>>>0,Number(h)>>>0)):[],kernel_shape:k?Array.from(E().subarray(Number(k)>>>0,Number(l)>>>0)):[],pads:p?Array.from(E().subarray(Number(p)>>>0,Number(q)>>>0)):[],strides:r?Array.from(E().subarray(Number(r)>>>0,Number(w)>>>0)):[]})},1328424:(a,b)=>{f.hc("GlobalMaxPool",a,{format:b?"NHWC":"NCHW"})},1328511:(a,b,c,d,e,g,h,k,l,p,q,r,w,z)=>{f.hc("MaxPool",a,{format:z?"NHWC":"NCHW",auto_pad:b,ceil_mode:c,count_include_pad:d,
storage_order:e,dilations:g?Array.from(E().subarray(Number(g)>>>0,Number(h)>>>0)):[],kernel_shape:k?Array.from(E().subarray(Number(k)>>>0,Number(l)>>>0)):[],pads:p?Array.from(E().subarray(Number(p)>>>0,Number(q)>>>0)):[],strides:r?Array.from(E().subarray(Number(r)>>>0,Number(w)>>>0)):[]})},1328986:(a,b)=>{f.hc("GlobalMaxPool",a,{format:b?"NHWC":"NCHW"})},1329073:(a,b,c,d,e,g,h,k,l,p,q,r,w,z)=>{f.hc("MaxPool",a,{format:z?"NHWC":"NCHW",auto_pad:b,ceil_mode:c,count_include_pad:d,storage_order:e,dilations:g?
Array.from(E().subarray(Number(g)>>>0,Number(h)>>>0)):[],kernel_shape:k?Array.from(E().subarray(Number(k)>>>0,Number(l)>>>0)):[],pads:p?Array.from(E().subarray(Number(p)>>>0,Number(q)>>>0)):[],strides:r?Array.from(E().subarray(Number(r)>>>0,Number(w)>>>0)):[]})},1329548:(a,b,c,d,e)=>{f.hc("Gemm",a,{alpha:b,beta:c,transA:d,transB:e})},1329652:a=>{f.hc("MatMul",a,void 0)},1329706:(a,b,c,d)=>{f.hc("ArgMax",a,{keepDims:!!b,selectLastIndex:!!c,axis:d})},1329814:(a,b,c,d)=>{f.hc("ArgMin",a,{keepDims:!!b,
selectLastIndex:!!c,axis:d})},1329922:(a,b)=>{f.hc("Softmax",a,{axis:b})},1329985:(a,b)=>{f.hc("Concat",a,{axis:b})},1330045:(a,b,c,d,e)=>{f.hc("Split",a,{axis:b,numOutputs:c,splitSizes:d?Array.from(E().subarray(Number(d)>>>0,Number(e)>>>0)):[]})},1330201:a=>{f.hc("Expand",a,void 0)},1330255:(a,b)=>{f.hc("Gather",a,{axis:Number(b)})},1330326:(a,b)=>{f.hc("GatherElements",a,{axis:Number(b)})},1330405:(a,b)=>{f.hc("GatherND",a,{batch_dims:Number(b)})},1330484:(a,b,c,d,e,g,h,k,l,p,q)=>{f.hc("Resize",
a,{antialias:b,axes:c?Array.from(E().subarray(Number(c)>>>0,Number(d)>>>0)):[],coordinateTransformMode:I(e),cubicCoeffA:g,excludeOutside:h,extrapolationValue:k,keepAspectRatioPolicy:I(l),mode:I(p),nearestMode:I(q)})},1330846:(a,b,c,d,e,g,h)=>{f.hc("Slice",a,{starts:b?Array.from(E().subarray(Number(b)>>>0,Number(c)>>>0)):[],ends:d?Array.from(E().subarray(Number(d)>>>0,Number(e)>>>0)):[],axes:g?Array.from(E().subarray(Number(g)>>>0,Number(h)>>>0)):[]})},1331110:a=>{f.hc("Tile",a,void 0)},1331162:(a,
b,c)=>{f.hc("InstanceNormalization",a,{epsilon:b,format:c?"NHWC":"NCHW"})},1331276:(a,b,c)=>{f.hc("InstanceNormalization",a,{epsilon:b,format:c?"NHWC":"NCHW"})},1331390:a=>{f.hc("Range",a,void 0)},1331443:(a,b)=>{f.hc("Einsum",a,{equation:I(b)})},1331524:(a,b,c,d,e)=>{f.hc("Pad",a,{mode:b,value:c,pads:d?Array.from(E().subarray(Number(d)>>>0,Number(e)>>>0)):[]})},1331667:(a,b,c,d,e,g)=>{f.hc("BatchNormalization",a,{epsilon:b,momentum:c,spatial:!!e,trainingMode:!!d,format:g?"NHWC":"NCHW"})},1331836:(a,
b,c,d,e,g)=>{f.hc("BatchNormalization",a,{epsilon:b,momentum:c,spatial:!!e,trainingMode:!!d,format:g?"NHWC":"NCHW"})},1332005:(a,b,c)=>{f.hc("CumSum",a,{exclusive:Number(b),reverse:Number(c)})},1332102:(a,b,c)=>{f.hc("DequantizeLinear",a,{axis:b,blockSize:c})},1332192:(a,b,c,d,e)=>{f.hc("GridSample",a,{align_corners:b,mode:I(c),padding_mode:I(d),format:e?"NHWC":"NCHW"})},1332362:(a,b,c,d,e)=>{f.hc("GridSample",a,{align_corners:b,mode:I(c),padding_mode:I(d),format:e?"NHWC":"NCHW"})},1332532:(a,b)=>
{f.hc("ScatterND",a,{reduction:I(b)})},1332617:(a,b,c,d,e,g,h,k,l)=>{f.hc("Attention",a,{numHeads:b,isUnidirectional:c,maskFilterValue:d,scale:e,doRotary:g,qkvHiddenSizes:h?Array.from(E().subarray(Number(k)>>>0,Number(k)+h>>>0)):[],pastPresentShareBuffer:!!l})},1332889:a=>{f.hc("BiasAdd",a,void 0)},1332944:a=>{f.hc("BiasSplitGelu",a,void 0)},1333005:a=>{f.hc("FastGelu",a,void 0)},1333061:(a,b,c,d,e,g,h,k,l,p,q,r,w,z,J,la)=>{f.hc("Conv",a,{format:r?"NHWC":"NCHW",auto_pad:b,dilations:c?Array.from(E().subarray(Number(c)>>>
0,Number(d)>>>0)):[],group:e,kernel_shape:g?Array.from(E().subarray(Number(g)>>>0,Number(h)>>>0)):[],pads:k?Array.from(E().subarray(Number(k)>>>0,Number(l)>>>0)):[],strides:p?Array.from(E().subarray(Number(p)>>>0,Number(q)>>>0)):[],w_is_const:()=>!!B()[Number(w)>>>0],activation:I(z),activation_params:J?Array.from(Ia().subarray(Number(J)>>>0,Number(la)>>>0)):[]})},1333645:a=>{f.hc("Gelu",a,void 0)},1333697:(a,b,c,d,e,g,h,k,l)=>{f.hc("GroupQueryAttention",a,{numHeads:b,kvNumHeads:c,scale:d,softcap:e,
doRotary:g,rotaryInterleaved:h,smoothSoftmax:k,localWindowSize:l})},1333914:(a,b,c,d)=>{f.hc("LayerNormalization",a,{axis:b,epsilon:c,simplified:!!d})},1334025:(a,b,c,d)=>{f.hc("LayerNormalization",a,{axis:b,epsilon:c,simplified:!!d})},1334136:(a,b,c,d,e,g)=>{f.hc("MatMulNBits",a,{k:b,n:c,accuracyLevel:d,bits:e,blockSize:g})},1334263:(a,b,c,d,e,g)=>{f.hc("MultiHeadAttention",a,{numHeads:b,isUnidirectional:c,maskFilterValue:d,scale:e,doRotary:g})},1334422:(a,b)=>{f.hc("QuickGelu",a,{alpha:b})},1334486:(a,
b,c,d,e)=>{f.hc("RotaryEmbedding",a,{interleaved:!!b,numHeads:c,rotaryEmbeddingDim:d,scale:e})},1334625:(a,b,c)=>{f.hc("SkipLayerNormalization",a,{epsilon:b,simplified:!!c})},1334727:(a,b,c)=>{f.hc("SkipLayerNormalization",a,{epsilon:b,simplified:!!c})},1334829:(a,b,c,d)=>{f.hc("GatherBlockQuantized",a,{gatherAxis:b,quantizeAxis:c,blockSize:d})},1334950:a=>{f.Wd(a)},1334984:(a,b)=>f.Zd(Number(a),Number(b),f.Cd.be,f.Cd.errors)};
function gb(a,b,c){return Id(async()=>{await f.Ud(Number(a),Number(b),Number(c))})}function fb(){return"undefined"!==typeof wasmOffsetConverter}class Jd{name="ExitStatus";constructor(a){this.message=`Program terminated with exit(${a})`;this.status=a}}
var Kd=a=>{a.terminate();a.onmessage=()=>{}},Ld=[],Pd=a=>{0==K.length&&(Md(),Nd(K[0]));var b=K.pop();if(!b)return 6;Od.push(b);L[a.xd]=b;b.xd=a.xd;var c={yd:"run",de:a.ce,Fd:a.Fd,xd:a.xd};m&&b.unref();b.postMessage(c,a.Ld);return 0},M=0,P=(a,b,...c)=>{for(var d=2*c.length,e=N(),g=Qd(8*d),h=g>>>3,k=0;k<c.length;k++){var l=c[k];"bigint"==typeof l?(A[h+2*k]=1n,A[h+2*k+1]=l):(A[h+2*k]=0n,Ja()[h+2*k+1>>>0]=l)}a=Rd(a,0,d,g,b);O(e);return a};
function Gd(a){if(n)return P(0,1,a);xa=a;if(!(0<M)){for(var b of Od)Kd(b);for(b of K)Kd(b);K=[];Od=[];L={};wa=!0}ma(a,new Jd(a))}function Sd(a){if(n)return P(1,0,a);Hc(a)}var Hc=a=>{xa=a;if(n)throw Sd(a),"unwind";Gd(a)},K=[],Od=[],Td=[],L={};function Ud(){for(var a=f.numThreads-1;a--;)Md();Ld.unshift(()=>{Xa++;Vd(()=>Za())})}var Xd=a=>{var b=a.xd;delete L[b];K.push(a);Od.splice(Od.indexOf(a),1);a.xd=0;Wd(b)};function Qa(){Td.forEach(a=>a())}
var Nd=a=>new Promise(b=>{a.onmessage=g=>{g=g.data;var h=g.yd;if(g.Ed&&g.Ed!=Na()){var k=L[g.Ed];k?k.postMessage(g,g.Ld):v(`Internal error! Worker sent a message "${h}" to target pthread ${g.Ed}, but that thread no longer exists!`)}else if("checkMailbox"===h)Ua();else if("spawnThread"===h)Pd(g);else if("cleanupThread"===h)Xd(L[g.ee]);else if("loaded"===h)a.loaded=!0,m&&!a.xd&&a.unref(),b(a);else if("alert"===h)alert(`Thread ${g.fe}: ${g.text}`);else if("setimmediate"===g.target)a.postMessage(g);else if("callHandler"===
h)f[g.Nd](...g.args);else h&&v(`worker sent an unknown command ${h}`)};a.onerror=g=>{v(`${"worker sent an error!"} ${g.filename}:${g.lineno}: ${g.message}`);throw g;};m&&(a.on("message",g=>a.onmessage({data:g})),a.on("error",g=>a.onerror(g)));var c=[],d=[],e;for(e of d)f.propertyIsEnumerable(e)&&c.push(e);a.postMessage({yd:"load",Od:c,he:x,ie:va})});function Vd(a){n?a():Promise.all(K.map(Nd)).then(a)}
function Md(){var a=new Worker(new URL(import.meta.url),{type:"module",workerData:"em-pthread",name:"em-pthread"});K.push(a)}var Oa=a=>{C();var b=F()[a+52>>>2>>>0];a=F()[a+56>>>2>>>0];Yd(b,b-a);O(b)},Ta=(a,b)=>{M=0;a=Zd(a,b);0<M?xa=a:$d(a)},ae=[],be=0;function hb(a){a>>>=0;var b=new ce(a);if(0==B()[b.wd+12>>>0]){var c=1;B()[b.wd+12>>>0]=c;be--}c=0;B()[b.wd+13>>>0]=c;ae.push(b);de(a);return ee(a)}var Q=0,ib=()=>{R(0,0);var a=ae.pop();fe(a.Gd);Q=0};
class ce{constructor(a){this.Gd=a;this.wd=a-24}}function pb(a){Q||=a>>>0;throw Q;}var ie=a=>{var b=Q;if(!b)return ge(0),0;var c=new ce(b);F()[c.wd+16>>>2>>>0]=b;var d=F()[c.wd+4>>>2>>>0];if(!d)return ge(0),b;for(var e of a){if(0===e||e===d)break;if(he(e,d,c.wd+16))return ge(e),b}ge(d);return b};function jb(){return ie([])}function kb(a){return ie([a>>>0])}function lb(a,b){return ie([a>>>0,b>>>0])}
var mb=()=>{var a=ae.pop();a||H("no exception to throw");var b=a.Gd;if(0==B()[a.wd+13>>>0]){ae.push(a);var c=1;B()[a.wd+13>>>0]=c;c=0;B()[a.wd+12>>>0]=c;be++}Q=b;throw Q;};function nb(a,b,c){a>>>=0;var d=new ce(a);b>>>=0;c>>>=0;F()[d.wd+16>>>2>>>0]=0;F()[d.wd+4>>>2>>>0]=b;F()[d.wd+8>>>2>>>0]=c;Q=a;be++;throw Q;}function je(a,b,c,d){return n?P(2,1,a,b,c,d):ob(a,b,c,d)}
function ob(a,b,c,d){a>>>=0;b>>>=0;c>>>=0;d>>>=0;if("undefined"==typeof SharedArrayBuffer)return 6;var e=[];if(n&&0===e.length)return je(a,b,c,d);a={ce:c,xd:a,Fd:d,Ld:e};return n?(a.yd="spawnThread",postMessage(a,e),0):Pd(a)}
var ke="undefined"!=typeof TextDecoder?new TextDecoder:void 0,le=(a,b=0,c=NaN)=>{b>>>=0;var d=b+c;for(c=b;a[c]&&!(c>=d);)++c;if(16<c-b&&a.buffer&&ke)return ke.decode(a.buffer instanceof ArrayBuffer?a.subarray(b,c):a.slice(b,c));for(d="";b<c;){var e=a[b++];if(e&128){var g=a[b++]&63;if(192==(e&224))d+=String.fromCharCode((e&31)<<6|g);else{var h=a[b++]&63;e=224==(e&240)?(e&15)<<12|g<<6|h:(e&7)<<18|g<<12|h<<6|a[b++]&63;65536>e?d+=String.fromCharCode(e):(e-=65536,d+=String.fromCharCode(55296|e>>10,56320|
e&1023))}}else d+=String.fromCharCode(e)}return d},I=(a,b)=>(a>>>=0)?le(D(),a,b):"";function qb(a,b,c){return n?P(3,1,a,b,c):0}function rb(a,b){if(n)return P(4,1,a,b)}
var me=a=>{for(var b=0,c=0;c<a.length;++c){var d=a.charCodeAt(c);127>=d?b++:2047>=d?b+=2:55296<=d&&57343>=d?(b+=4,++c):b+=3}return b},ne=(a,b,c)=>{var d=D();b>>>=0;if(0<c){var e=b;c=b+c-1;for(var g=0;g<a.length;++g){var h=a.charCodeAt(g);if(55296<=h&&57343>=h){var k=a.charCodeAt(++g);h=65536+((h&1023)<<10)|k&1023}if(127>=h){if(b>=c)break;d[b++>>>0]=h}else{if(2047>=h){if(b+1>=c)break;d[b++>>>0]=192|h>>6}else{if(65535>=h){if(b+2>=c)break;d[b++>>>0]=224|h>>12}else{if(b+3>=c)break;d[b++>>>0]=240|h>>18;
d[b++>>>0]=128|h>>12&63}d[b++>>>0]=128|h>>6&63}d[b++>>>0]=128|h&63}}d[b>>>0]=0;a=b-e}else a=0;return a};function sb(a,b){if(n)return P(5,1,a,b)}function tb(a,b,c){if(n)return P(6,1,a,b,c)}function ub(a,b,c){return n?P(7,1,a,b,c):0}function vb(a,b){if(n)return P(8,1,a,b)}function wb(a,b,c){if(n)return P(9,1,a,b,c)}function xb(a,b,c,d){if(n)return P(10,1,a,b,c,d)}function yb(a,b,c,d){if(n)return P(11,1,a,b,c,d)}function zb(a,b,c,d){if(n)return P(12,1,a,b,c,d)}function Ab(a){if(n)return P(13,1,a)}
function Bb(a,b){if(n)return P(14,1,a,b)}function Cb(a,b,c){if(n)return P(15,1,a,b,c)}var Db=()=>H(""),oe,S=a=>{for(var b="";D()[a>>>0];)b+=oe[D()[a++>>>0]];return b},pe={},qe={},re={},T;function se(a,b,c={}){var d=b.name;if(!a)throw new T(`type "${d}" must have a positive integer typeid pointer`);if(qe.hasOwnProperty(a)){if(c.Pd)return;throw new T(`Cannot register type '${d}' twice`);}qe[a]=b;delete re[a];pe.hasOwnProperty(a)&&(b=pe[a],delete pe[a],b.forEach(e=>e()))}
function U(a,b,c={}){return se(a,b,c)}var te=(a,b,c)=>{switch(b){case 1:return c?d=>B()[d>>>0]:d=>D()[d>>>0];case 2:return c?d=>Ga()[d>>>1>>>0]:d=>Ha()[d>>>1>>>0];case 4:return c?d=>E()[d>>>2>>>0]:d=>F()[d>>>2>>>0];case 8:return c?d=>A[d>>>3]:d=>Ea[d>>>3];default:throw new TypeError(`invalid integer width (${b}): ${a}`);}};
function Eb(a,b,c){a>>>=0;c>>>=0;b=S(b>>>0);U(a,{name:b,fromWireType:d=>d,toWireType:function(d,e){if("bigint"!=typeof e&&"number"!=typeof e)throw null===e?e="null":(d=typeof e,e="object"===d||"array"===d||"function"===d?e.toString():""+e),new TypeError(`Cannot convert "${e}" to ${this.name}`);"number"==typeof e&&(e=BigInt(e));return e},zd:V,readValueFromPointer:te(b,c,-1==b.indexOf("u")),Ad:null})}var V=8;
function Fb(a,b,c,d){a>>>=0;b=S(b>>>0);U(a,{name:b,fromWireType:function(e){return!!e},toWireType:function(e,g){return g?c:d},zd:V,readValueFromPointer:function(e){return this.fromWireType(D()[e>>>0])},Ad:null})}var ue=[],W=[];function Yb(a){a>>>=0;9<a&&0===--W[a+1]&&(W[a]=void 0,ue.push(a))}
var X=a=>{if(!a)throw new T("Cannot use deleted val. handle = "+a);return W[a]},Y=a=>{switch(a){case void 0:return 2;case null:return 4;case !0:return 6;case !1:return 8;default:const b=ue.pop()||W.length;W[b]=a;W[b+1]=1;return b}};function ve(a){return this.fromWireType(F()[a>>>2>>>0])}var we={name:"emscripten::val",fromWireType:a=>{var b=X(a);Yb(a);return b},toWireType:(a,b)=>Y(b),zd:V,readValueFromPointer:ve,Ad:null};function Gb(a){return U(a>>>0,we)}
var xe=(a,b)=>{switch(b){case 4:return function(c){return this.fromWireType(Ia()[c>>>2>>>0])};case 8:return function(c){return this.fromWireType(Ja()[c>>>3>>>0])};default:throw new TypeError(`invalid float width (${b}): ${a}`);}};function Hb(a,b,c){a>>>=0;c>>>=0;b=S(b>>>0);U(a,{name:b,fromWireType:d=>d,toWireType:(d,e)=>e,zd:V,readValueFromPointer:xe(b,c),Ad:null})}
function Ib(a,b,c,d,e){a>>>=0;c>>>=0;b=S(b>>>0);-1===e&&(e=4294967295);e=k=>k;if(0===d){var g=32-8*c;e=k=>k<<g>>>g}var h=b.includes("unsigned")?function(k,l){return l>>>0}:function(k,l){return l};U(a,{name:b,fromWireType:e,toWireType:h,zd:V,readValueFromPointer:te(b,c,0!==d),Ad:null})}
function Jb(a,b,c){function d(g){var h=F()[g>>>2>>>0];g=F()[g+4>>>2>>>0];return new e(B().buffer,g,h)}a>>>=0;var e=[Int8Array,Uint8Array,Int16Array,Uint16Array,Int32Array,Uint32Array,Float32Array,Float64Array,BigInt64Array,BigUint64Array][b];c=S(c>>>0);U(a,{name:c,fromWireType:d,zd:V,readValueFromPointer:d},{Pd:!0})}
function Kb(a,b){a>>>=0;b=S(b>>>0);U(a,{name:b,fromWireType:function(c){for(var d=F()[c>>>2>>>0],e=c+4,g,h=e,k=0;k<=d;++k){var l=e+k;if(k==d||0==D()[l>>>0])h=I(h,l-h),void 0===g?g=h:(g+=String.fromCharCode(0),g+=h),h=l+1}Z(c);return g},toWireType:function(c,d){d instanceof ArrayBuffer&&(d=new Uint8Array(d));var e="string"==typeof d;if(!(e||d instanceof Uint8Array||d instanceof Uint8ClampedArray||d instanceof Int8Array))throw new T("Cannot pass non-string to std::string");var g=e?me(d):d.length;var h=
ye(4+g+1),k=h+4;F()[h>>>2>>>0]=g;if(e)ne(d,k,g+1);else if(e)for(e=0;e<g;++e){var l=d.charCodeAt(e);if(255<l)throw Z(h),new T("String has UTF-16 code units that do not fit in 8 bits");D()[k+e>>>0]=l}else for(e=0;e<g;++e)D()[k+e>>>0]=d[e];null!==c&&c.push(Z,h);return h},zd:V,readValueFromPointer:ve,Ad(c){Z(c)}})}
var ze="undefined"!=typeof TextDecoder?new TextDecoder("utf-16le"):void 0,Ae=(a,b)=>{var c=a>>1;for(var d=c+b/2;!(c>=d)&&Ha()[c>>>0];)++c;c<<=1;if(32<c-a&&ze)return ze.decode(D().slice(a,c));c="";for(d=0;!(d>=b/2);++d){var e=Ga()[a+2*d>>>1>>>0];if(0==e)break;c+=String.fromCharCode(e)}return c},Be=(a,b,c)=>{c??=2147483647;if(2>c)return 0;c-=2;var d=b;c=c<2*a.length?c/2:a.length;for(var e=0;e<c;++e){var g=a.charCodeAt(e);Ga()[b>>>1>>>0]=g;b+=2}Ga()[b>>>1>>>0]=0;return b-d},Ce=a=>2*a.length,De=(a,b)=>
{for(var c=0,d="";!(c>=b/4);){var e=E()[a+4*c>>>2>>>0];if(0==e)break;++c;65536<=e?(e-=65536,d+=String.fromCharCode(55296|e>>10,56320|e&1023)):d+=String.fromCharCode(e)}return d},Ee=(a,b,c)=>{b>>>=0;c??=2147483647;if(4>c)return 0;var d=b;c=d+c-4;for(var e=0;e<a.length;++e){var g=a.charCodeAt(e);if(55296<=g&&57343>=g){var h=a.charCodeAt(++e);g=65536+((g&1023)<<10)|h&1023}E()[b>>>2>>>0]=g;b+=4;if(b+4>c)break}E()[b>>>2>>>0]=0;return b-d},Fe=a=>{for(var b=0,c=0;c<a.length;++c){var d=a.charCodeAt(c);55296<=
d&&57343>=d&&++c;b+=4}return b};
function Lb(a,b,c){a>>>=0;b>>>=0;c>>>=0;c=S(c);if(2===b){var d=Ae;var e=Be;var g=Ce;var h=k=>Ha()[k>>>1>>>0]}else 4===b&&(d=De,e=Ee,g=Fe,h=k=>F()[k>>>2>>>0]);U(a,{name:c,fromWireType:k=>{for(var l=F()[k>>>2>>>0],p,q=k+4,r=0;r<=l;++r){var w=k+4+r*b;if(r==l||0==h(w))q=d(q,w-q),void 0===p?p=q:(p+=String.fromCharCode(0),p+=q),q=w+b}Z(k);return p},toWireType:(k,l)=>{if("string"!=typeof l)throw new T(`Cannot pass non-string to C++ string type ${c}`);var p=g(l),q=ye(4+p+b);F()[q>>>2>>>0]=p/b;e(l,q+4,p+b);
null!==k&&k.push(Z,q);return q},zd:V,readValueFromPointer:ve,Ad(k){Z(k)}})}function Mb(a,b){a>>>=0;b=S(b>>>0);U(a,{Qd:!0,name:b,zd:0,fromWireType:()=>{},toWireType:()=>{}})}function Nb(a){Pa(a>>>0,!ea,1,!da,131072,!1);Qa()}var Ge=a=>{if(!wa)try{if(a(),!(0<M))try{n?$d(xa):Hc(xa)}catch(b){b instanceof Jd||"unwind"==b||ma(1,b)}}catch(b){b instanceof Jd||"unwind"==b||ma(1,b)}};
function Ra(a){a>>>=0;"function"===typeof Atomics.ge&&(Atomics.ge(E(),a>>>2,a).value.then(Ua),a+=128,Atomics.store(E(),a>>>2,1))}var Ua=()=>{var a=Na();a&&(Ra(a),Ge(He))};function Ob(a,b){a>>>=0;a==b>>>0?setTimeout(Ua):n?postMessage({Ed:a,yd:"checkMailbox"}):(a=L[a])&&a.postMessage({yd:"checkMailbox"})}var Ie=[];function Pb(a,b,c,d,e){b>>>=0;d/=2;Ie.length=d;c=e>>>0>>>3;for(e=0;e<d;e++)Ie[e]=A[c+2*e]?A[c+2*e+1]:Ja()[c+2*e+1>>>0];return(b?Hd[b]:Je[a])(...Ie)}var Qb=()=>{M=0};
function Rb(a){a>>>=0;n?postMessage({yd:"cleanupThread",ee:a}):Xd(L[a])}function Sb(a){m&&L[a>>>0].ref()}var Le=(a,b)=>{var c=qe[a];if(void 0===c)throw a=Ke(a),c=S(a),Z(a),new T(`${b} has unknown type ${c}`);return c},Me=(a,b,c)=>{var d=[];a=a.toWireType(d,c);d.length&&(F()[b>>>2>>>0]=Y(d));return a};function Tb(a,b,c){b>>>=0;c>>>=0;a=X(a>>>0);b=Le(b,"emval::as");return Me(b,c,a)}function Ub(a,b){b>>>=0;a=X(a>>>0);b=Le(b,"emval::as");return b.toWireType(null,a)}var Ne=a=>{try{a()}catch(b){H(b)}};
function Oe(){var a=G,b={};for(let [c,d]of Object.entries(a))b[c]="function"==typeof d?(...e)=>{Pe.push(c);try{return d(...e)}finally{wa||(Pe.pop(),t&&1===Qe&&0===Pe.length&&(Qe=0,M+=1,Ne(Re),"undefined"!=typeof Fibers&&Fibers.le()))}}:d;return b}var Qe=0,t=null,Se=0,Pe=[],Te={},Ue={},Ve=0,We=null,Xe=[];function ha(){return new Promise((a,b)=>{We={resolve:a,reject:b}})}
function Ye(){var a=ye(65548),b=a+12;F()[a>>>2>>>0]=b;F()[a+4>>>2>>>0]=b+65536;b=Pe[0];var c=Te[b];void 0===c&&(c=Ve++,Te[b]=c,Ue[c]=b);b=c;E()[a+8>>>2>>>0]=b;return a}function Ze(){var a=E()[t+8>>>2>>>0];a=G[Ue[a]];--M;return a()}
function $e(a){if(!wa){if(0===Qe){var b=!1,c=!1;a((d=0)=>{if(!wa&&(Se=d,b=!0,c)){Qe=2;Ne(()=>af(t));"undefined"!=typeof MainLoop&&MainLoop.Md&&MainLoop.resume();d=!1;try{var e=Ze()}catch(k){e=k,d=!0}var g=!1;if(!t){var h=We;h&&(We=null,(d?h.reject:h.resolve)(e),g=!0)}if(d&&!g)throw e;}});c=!0;b||(Qe=1,t=Ye(),"undefined"!=typeof MainLoop&&MainLoop.Md&&MainLoop.pause(),Ne(()=>bf(t)))}else 2===Qe?(Qe=0,Ne(cf),Z(t),t=null,Xe.forEach(Ge)):H(`invalid state: ${Qe}`);return Se}}
function Id(a){return $e(b=>{a().then(b)})}function Vb(a){a>>>=0;return Id(async()=>{var b=await X(a);return Y(b)})}var df=[];function Wb(a,b,c,d){c>>>=0;d>>>=0;a=df[a>>>0];b=X(b>>>0);return a(null,b,c,d)}var ef={},ff=a=>{var b=ef[a];return void 0===b?S(a):b};function Xb(a,b,c,d,e){c>>>=0;d>>>=0;e>>>=0;a=df[a>>>0];b=X(b>>>0);c=ff(c);return a(b,b[c],d,e)}var gf=()=>"object"==typeof globalThis?globalThis:Function("return this")();
function Zb(a){a>>>=0;if(0===a)return Y(gf());a=ff(a);return Y(gf()[a])}var hf=a=>{var b=df.length;df.push(a);return b},jf=(a,b)=>{for(var c=Array(a),d=0;d<a;++d)c[d]=Le(F()[b+4*d>>>2>>>0],"parameter "+d);return c},kf=(a,b)=>Object.defineProperty(b,"name",{value:a});
function lf(a){var b=Function;if(!(b instanceof Function))throw new TypeError(`new_ called with constructor type ${typeof b} which is not a function`);var c=kf(b.name||"unknownFunctionName",function(){});c.prototype=b.prototype;c=new c;a=b.apply(c,a);return a instanceof Object?a:c}
function $b(a,b,c){b=jf(a,b>>>0);var d=b.shift();a--;var e="return function (obj, func, destructorsRef, args) {\n",g=0,h=[];0===c&&h.push("obj");for(var k=["retType"],l=[d],p=0;p<a;++p)h.push("arg"+p),k.push("argType"+p),l.push(b[p]),e+=`  var arg${p} = argType${p}.readValueFromPointer(args${g?"+"+g:""});\n`,g+=b[p].zd;e+=`  var rv = ${1===c?"new func":"func.call"}(${h.join(", ")});\n`;d.Qd||(k.push("emval_returnValue"),l.push(Me),e+="  return emval_returnValue(retType, destructorsRef, rv);\n");k.push(e+
"};\n");a=lf(k)(...l);c=`methodCaller<(${b.map(q=>q.name).join(", ")}) => ${d.name}>`;return hf(kf(c,a))}function ac(a){a=ff(a>>>0);return Y(f[a])}function bc(a,b){b>>>=0;a=X(a>>>0);b=X(b);return Y(a[b])}function cc(a){a>>>=0;9<a&&(W[a+1]+=1)}function dc(){return Y([])}function ec(a){a=X(a>>>0);for(var b=Array(a.length),c=0;c<a.length;c++)b[c]=a[c];return Y(b)}function fc(a){return Y(ff(a>>>0))}function gc(){return Y({})}
function hc(a){a>>>=0;for(var b=X(a);b.length;){var c=b.pop();b.pop()(c)}Yb(a)}function ic(a,b,c){b>>>=0;c>>>=0;a=X(a>>>0);b=X(b);c=X(c);a[b]=c}function jc(a,b){b>>>=0;a=Le(a>>>0,"_emval_take_value");a=a.readValueFromPointer(b);return Y(a)}
function kc(a,b){a=-9007199254740992>a||9007199254740992<a?NaN:Number(a);b>>>=0;a=new Date(1E3*a);E()[b>>>2>>>0]=a.getUTCSeconds();E()[b+4>>>2>>>0]=a.getUTCMinutes();E()[b+8>>>2>>>0]=a.getUTCHours();E()[b+12>>>2>>>0]=a.getUTCDate();E()[b+16>>>2>>>0]=a.getUTCMonth();E()[b+20>>>2>>>0]=a.getUTCFullYear()-1900;E()[b+24>>>2>>>0]=a.getUTCDay();a=(a.getTime()-Date.UTC(a.getUTCFullYear(),0,1,0,0,0,0))/864E5|0;E()[b+28>>>2>>>0]=a}
var mf=a=>0===a%4&&(0!==a%100||0===a%400),nf=[0,31,60,91,121,152,182,213,244,274,305,335],of=[0,31,59,90,120,151,181,212,243,273,304,334];
function lc(a,b){a=-9007199254740992>a||9007199254740992<a?NaN:Number(a);b>>>=0;a=new Date(1E3*a);E()[b>>>2>>>0]=a.getSeconds();E()[b+4>>>2>>>0]=a.getMinutes();E()[b+8>>>2>>>0]=a.getHours();E()[b+12>>>2>>>0]=a.getDate();E()[b+16>>>2>>>0]=a.getMonth();E()[b+20>>>2>>>0]=a.getFullYear()-1900;E()[b+24>>>2>>>0]=a.getDay();var c=(mf(a.getFullYear())?nf:of)[a.getMonth()]+a.getDate()-1|0;E()[b+28>>>2>>>0]=c;E()[b+36>>>2>>>0]=-(60*a.getTimezoneOffset());c=(new Date(a.getFullYear(),6,1)).getTimezoneOffset();
var d=(new Date(a.getFullYear(),0,1)).getTimezoneOffset();a=(c!=d&&a.getTimezoneOffset()==Math.min(d,c))|0;E()[b+32>>>2>>>0]=a}
function mc(a){a>>>=0;var b=new Date(E()[a+20>>>2>>>0]+1900,E()[a+16>>>2>>>0],E()[a+12>>>2>>>0],E()[a+8>>>2>>>0],E()[a+4>>>2>>>0],E()[a>>>2>>>0],0),c=E()[a+32>>>2>>>0],d=b.getTimezoneOffset(),e=(new Date(b.getFullYear(),6,1)).getTimezoneOffset(),g=(new Date(b.getFullYear(),0,1)).getTimezoneOffset(),h=Math.min(g,e);0>c?E()[a+32>>>2>>>0]=Number(e!=g&&h==d):0<c!=(h==d)&&(e=Math.max(g,e),b.setTime(b.getTime()+6E4*((0<c?h:e)-d)));E()[a+24>>>2>>>0]=b.getDay();c=(mf(b.getFullYear())?nf:of)[b.getMonth()]+
b.getDate()-1|0;E()[a+28>>>2>>>0]=c;E()[a>>>2>>>0]=b.getSeconds();E()[a+4>>>2>>>0]=b.getMinutes();E()[a+8>>>2>>>0]=b.getHours();E()[a+12>>>2>>>0]=b.getDate();E()[a+16>>>2>>>0]=b.getMonth();E()[a+20>>>2>>>0]=b.getYear();a=b.getTime();return BigInt(isNaN(a)?-1:a/1E3)}function nc(a,b,c,d,e,g,h){return n?P(16,1,a,b,c,d,e,g,h):-52}function oc(a,b,c,d,e,g){if(n)return P(17,1,a,b,c,d,e,g)}var pf={},zc=()=>performance.timeOrigin+performance.now();
function pc(a,b){if(n)return P(18,1,a,b);pf[a]&&(clearTimeout(pf[a].id),delete pf[a]);if(!b)return 0;var c=setTimeout(()=>{delete pf[a];Ge(()=>qf(a,performance.timeOrigin+performance.now()))},b);pf[a]={id:c,ke:b};return 0}
function qc(a,b,c,d){a>>>=0;b>>>=0;c>>>=0;d>>>=0;var e=(new Date).getFullYear(),g=(new Date(e,0,1)).getTimezoneOffset();e=(new Date(e,6,1)).getTimezoneOffset();var h=Math.max(g,e);F()[a>>>2>>>0]=60*h;E()[b>>>2>>>0]=Number(g!=e);b=k=>{var l=Math.abs(k);return`UTC${0<=k?"-":"+"}${String(Math.floor(l/60)).padStart(2,"0")}${String(l%60).padStart(2,"0")}`};a=b(g);b=b(e);e<g?(ne(a,c,17),ne(b,d,17)):(ne(a,d,17),ne(b,c,17))}var vc=()=>Date.now(),rf=1;
function rc(a,b,c){if(!(0<=a&&3>=a))return 28;if(0===a)a=Date.now();else if(rf)a=performance.timeOrigin+performance.now();else return 52;A[c>>>0>>>3]=BigInt(Math.round(1E6*a));return 0}var sf=[],tf=(a,b)=>{sf.length=0;for(var c;c=D()[a++>>>0];){var d=105!=c;d&=112!=c;b+=d&&b%8?4:0;sf.push(112==c?F()[b>>>2>>>0]:106==c?A[b>>>3]:105==c?E()[b>>>2>>>0]:Ja()[b>>>3>>>0]);b+=d?8:4}return sf};function sc(a,b,c){a>>>=0;b=tf(b>>>0,c>>>0);return Hd[a](...b)}
function tc(a,b,c){a>>>=0;b=tf(b>>>0,c>>>0);return Hd[a](...b)}var uc=()=>{};function wc(a,b){return v(I(a>>>0,b>>>0))}var xc=()=>{M+=1;throw"unwind";};function yc(){return 4294901760}var Ac=()=>m?require("os").cpus().length:navigator.hardwareConcurrency;function Bc(){H("Cannot use emscripten_pc_get_function without -sUSE_OFFSET_CONVERTER");return 0}
function Cc(a){a>>>=0;var b=D().length;if(a<=b||4294901760<a)return!1;for(var c=1;4>=c;c*=2){var d=b*(1+.2/c);d=Math.min(d,a+100663296);a:{d=(Math.min(4294901760,65536*Math.ceil(Math.max(a,d)/65536))-x.buffer.byteLength+65535)/65536|0;try{x.grow(d);C();var e=1;break a}catch(g){}e=void 0}if(e)return!0}return!1}var uf=()=>{H("Cannot use convertFrameToPC (needed by __builtin_return_address) without -sUSE_OFFSET_CONVERTER");return 0},vf={},wf=a=>{a.forEach(b=>{var c=uf();c&&(vf[c]=b)})};
function Dc(){var a=Error().stack.toString().split("\n");"Error"==a[0]&&a.shift();wf(a);vf.Kd=uf();vf.ae=a;return vf.Kd}function Ec(a,b,c){a>>>=0;b>>>=0;if(vf.Kd==a)var d=vf.ae;else d=Error().stack.toString().split("\n"),"Error"==d[0]&&d.shift(),wf(d);for(var e=3;d[e]&&uf()!=a;)++e;for(a=0;a<c&&d[a+e];++a)E()[b+4*a>>>2>>>0]=uf();return a}
var xf={},zf=()=>{if(!yf){var a={USER:"web_user",LOGNAME:"web_user",PATH:"/",PWD:"/",HOME:"/home/web_user",LANG:("object"==typeof navigator&&navigator.languages&&navigator.languages[0]||"C").replace("-","_")+".UTF-8",_:ka||"./this.program"},b;for(b in xf)void 0===xf[b]?delete a[b]:a[b]=xf[b];var c=[];for(b in a)c.push(`${b}=${a[b]}`);yf=c}return yf},yf;
function Fc(a,b){if(n)return P(19,1,a,b);a>>>=0;b>>>=0;var c=0;zf().forEach((d,e)=>{var g=b+c;e=F()[a+4*e>>>2>>>0]=g;for(g=0;g<d.length;++g)B()[e++>>>0]=d.charCodeAt(g);B()[e>>>0]=0;c+=d.length+1});return 0}function Gc(a,b){if(n)return P(20,1,a,b);a>>>=0;b>>>=0;var c=zf();F()[a>>>2>>>0]=c.length;var d=0;c.forEach(e=>d+=e.length+1);F()[b>>>2>>>0]=d;return 0}function Ic(a){return n?P(21,1,a):52}function Jc(a,b,c,d){return n?P(22,1,a,b,c,d):52}function Kc(a,b,c,d){return n?P(23,1,a,b,c,d):70}
var Af=[null,[],[]];function Lc(a,b,c,d){if(n)return P(24,1,a,b,c,d);b>>>=0;c>>>=0;d>>>=0;for(var e=0,g=0;g<c;g++){var h=F()[b>>>2>>>0],k=F()[b+4>>>2>>>0];b+=8;for(var l=0;l<k;l++){var p=D()[h+l>>>0],q=Af[a];0===p||10===p?((1===a?ta:v)(le(q)),q.length=0):q.push(p)}e+=k}F()[d>>>2>>>0]=e;return 0}function Fd(a){return a>>>0}n||Ud();for(var Bf=Array(256),Cf=0;256>Cf;++Cf)Bf[Cf]=String.fromCharCode(Cf);oe=Bf;T=f.BindingError=class extends Error{constructor(a){super(a);this.name="BindingError"}};
f.InternalError=class extends Error{constructor(a){super(a);this.name="InternalError"}};W.push(0,1,void 0,1,null,1,!0,1,!1,1);f.count_emval_handles=()=>W.length/2-5-ue.length;var Je=[Gd,Sd,je,qb,rb,sb,tb,ub,vb,wb,xb,yb,zb,Ab,Bb,Cb,nc,oc,pc,Fc,Gc,Ic,Jc,Kc,Lc],eb,G;
(async function(){function a(d,e){G=d.exports;G=Oe();G=Df();Td.push(G.jc);va=e;Za();return G}Xa++;var b=db();if(f.instantiateWasm)return new Promise(d=>{f.instantiateWasm(b,(e,g)=>{a(e,g);d(e.exports)})});if(n)return new Promise(d=>{Ka=e=>{var g=new WebAssembly.Instance(e,db());d(a(g,e))}});$a??=f.locateFile?f.locateFile?f.locateFile("ort-wasm-simd-threaded.jsep.wasm",u):u+"ort-wasm-simd-threaded.jsep.wasm":(new URL("ort-wasm-simd-threaded.jsep.wasm",import.meta.url)).href;try{var c=await cb(b);
return a(c.instance,c.module)}catch(d){return ba(d),Promise.reject(d)}})();var Ke=a=>(Ke=G.Cb)(a),Sa=()=>(Sa=G.Db)();f._OrtInit=(a,b)=>(f._OrtInit=G.Eb)(a,b);f._OrtGetLastError=(a,b)=>(f._OrtGetLastError=G.Fb)(a,b);f._OrtCreateSessionOptions=(a,b,c,d,e,g,h,k,l,p)=>(f._OrtCreateSessionOptions=G.Gb)(a,b,c,d,e,g,h,k,l,p);f._OrtAppendExecutionProvider=(a,b)=>(f._OrtAppendExecutionProvider=G.Hb)(a,b);f._OrtAddFreeDimensionOverride=(a,b,c)=>(f._OrtAddFreeDimensionOverride=G.Ib)(a,b,c);
f._OrtAddSessionConfigEntry=(a,b,c)=>(f._OrtAddSessionConfigEntry=G.Jb)(a,b,c);f._OrtReleaseSessionOptions=a=>(f._OrtReleaseSessionOptions=G.Kb)(a);f._OrtCreateSession=(a,b,c)=>(f._OrtCreateSession=G.Lb)(a,b,c);f._OrtReleaseSession=a=>(f._OrtReleaseSession=G.Mb)(a);f._OrtGetInputOutputCount=(a,b,c)=>(f._OrtGetInputOutputCount=G.Nb)(a,b,c);f._OrtGetInputName=(a,b)=>(f._OrtGetInputName=G.Ob)(a,b);f._OrtGetOutputName=(a,b)=>(f._OrtGetOutputName=G.Pb)(a,b);f._OrtFree=a=>(f._OrtFree=G.Qb)(a);
f._OrtCreateTensor=(a,b,c,d,e,g)=>(f._OrtCreateTensor=G.Rb)(a,b,c,d,e,g);f._OrtGetTensorData=(a,b,c,d,e)=>(f._OrtGetTensorData=G.Sb)(a,b,c,d,e);f._OrtReleaseTensor=a=>(f._OrtReleaseTensor=G.Tb)(a);f._OrtCreateRunOptions=(a,b,c,d)=>(f._OrtCreateRunOptions=G.Ub)(a,b,c,d);f._OrtAddRunConfigEntry=(a,b,c)=>(f._OrtAddRunConfigEntry=G.Vb)(a,b,c);f._OrtReleaseRunOptions=a=>(f._OrtReleaseRunOptions=G.Wb)(a);f._OrtCreateBinding=a=>(f._OrtCreateBinding=G.Xb)(a);
f._OrtBindInput=(a,b,c)=>(f._OrtBindInput=G.Yb)(a,b,c);f._OrtBindOutput=(a,b,c,d)=>(f._OrtBindOutput=G.Zb)(a,b,c,d);f._OrtClearBoundOutputs=a=>(f._OrtClearBoundOutputs=G._b)(a);f._OrtReleaseBinding=a=>(f._OrtReleaseBinding=G.$b)(a);f._OrtRunWithBinding=(a,b,c,d,e)=>(f._OrtRunWithBinding=G.ac)(a,b,c,d,e);f._OrtRun=(a,b,c,d,e,g,h,k)=>(f._OrtRun=G.bc)(a,b,c,d,e,g,h,k);f._OrtEndProfiling=a=>(f._OrtEndProfiling=G.cc)(a);f._JsepOutput=(a,b,c)=>(f._JsepOutput=G.dc)(a,b,c);
f._JsepGetNodeName=a=>(f._JsepGetNodeName=G.ec)(a);
var Na=()=>(Na=G.fc)(),Z=f._free=a=>(Z=f._free=G.gc)(a),ye=f._malloc=a=>(ye=f._malloc=G.ic)(a),Pa=(a,b,c,d,e,g)=>(Pa=G.kc)(a,b,c,d,e,g),Va=()=>(Va=G.lc)(),Rd=(a,b,c,d,e)=>(Rd=G.mc)(a,b,c,d,e),Wd=a=>(Wd=G.nc)(a),$d=a=>($d=G.oc)(a),qf=(a,b)=>(qf=G.pc)(a,b),He=()=>(He=G.qc)(),R=(a,b)=>(R=G.rc)(a,b),ge=a=>(ge=G.sc)(a),Yd=(a,b)=>(Yd=G.tc)(a,b),O=a=>(O=G.uc)(a),Qd=a=>(Qd=G.vc)(a),N=()=>(N=G.wc)(),fe=a=>(fe=G.xc)(a),de=a=>(de=G.yc)(a),he=(a,b,c)=>(he=G.zc)(a,b,c),ee=a=>(ee=G.Ac)(a),dynCall_iii=f.dynCall_iii=
(a,b,c)=>(dynCall_iii=f.dynCall_iii=G.Bc)(a,b,c),dynCall_vi=f.dynCall_vi=(a,b)=>(dynCall_vi=f.dynCall_vi=G.Cc)(a,b),Zd=f.dynCall_ii=(a,b)=>(Zd=f.dynCall_ii=G.Dc)(a,b),dynCall_vii=f.dynCall_vii=(a,b,c)=>(dynCall_vii=f.dynCall_vii=G.Ec)(a,b,c),Ef=f.dynCall_iiii=(a,b,c,d)=>(Ef=f.dynCall_iiii=G.Fc)(a,b,c,d),Ff=f.dynCall_viii=(a,b,c,d)=>(Ff=f.dynCall_viii=G.Gc)(a,b,c,d),Gf=f.dynCall_iiiii=(a,b,c,d,e)=>(Gf=f.dynCall_iiiii=G.Hc)(a,b,c,d,e),Hf=f.dynCall_viiii=(a,b,c,d,e)=>(Hf=f.dynCall_viiii=G.Ic)(a,b,c,
d,e),If=f.dynCall_viiiiii=(a,b,c,d,e,g,h)=>(If=f.dynCall_viiiiii=G.Jc)(a,b,c,d,e,g,h),Jf=f.dynCall_viiiiiii=(a,b,c,d,e,g,h,k)=>(Jf=f.dynCall_viiiiiii=G.Kc)(a,b,c,d,e,g,h,k),Kf=f.dynCall_ji=(a,b)=>(Kf=f.dynCall_ji=G.Lc)(a,b),dynCall_v=f.dynCall_v=a=>(dynCall_v=f.dynCall_v=G.Mc)(a),Lf=f.dynCall_viiiii=(a,b,c,d,e,g)=>(Lf=f.dynCall_viiiii=G.Nc)(a,b,c,d,e,g),Mf=f.dynCall_i=a=>(Mf=f.dynCall_i=G.Oc)(a),Nf=f.dynCall_fii=(a,b,c)=>(Nf=f.dynCall_fii=G.Pc)(a,b,c),Of=f.dynCall_viiiiiiii=(a,b,c,d,e,g,h,k,l)=>(Of=
f.dynCall_viiiiiiii=G.Qc)(a,b,c,d,e,g,h,k,l),Pf=f.dynCall_viiiiiiiiii=(a,b,c,d,e,g,h,k,l,p,q)=>(Pf=f.dynCall_viiiiiiiiii=G.Rc)(a,b,c,d,e,g,h,k,l,p,q),Qf=f.dynCall_jiii=(a,b,c,d)=>(Qf=f.dynCall_jiii=G.Sc)(a,b,c,d),Rf=f.dynCall_dii=(a,b,c)=>(Rf=f.dynCall_dii=G.Tc)(a,b,c),Sf=f.dynCall_viiiiiiiii=(a,b,c,d,e,g,h,k,l,p)=>(Sf=f.dynCall_viiiiiiiii=G.Uc)(a,b,c,d,e,g,h,k,l,p),Tf=f.dynCall_viiiiiiiiiii=(a,b,c,d,e,g,h,k,l,p,q,r)=>(Tf=f.dynCall_viiiiiiiiiii=G.Vc)(a,b,c,d,e,g,h,k,l,p,q,r),Uf=f.dynCall_iiiiii=(a,
b,c,d,e,g)=>(Uf=f.dynCall_iiiiii=G.Wc)(a,b,c,d,e,g),Vf=f.dynCall_iij=(a,b,c)=>(Vf=f.dynCall_iij=G.Xc)(a,b,c),Wf=f.dynCall_iiiiiiiiii=(a,b,c,d,e,g,h,k,l,p)=>(Wf=f.dynCall_iiiiiiiiii=G.Yc)(a,b,c,d,e,g,h,k,l,p),Xf=f.dynCall_iiiiiiiiiii=(a,b,c,d,e,g,h,k,l,p,q)=>(Xf=f.dynCall_iiiiiiiiiii=G.Zc)(a,b,c,d,e,g,h,k,l,p,q),Yf=f.dynCall_vij=(a,b,c)=>(Yf=f.dynCall_vij=G._c)(a,b,c),Zf=f.dynCall_iiif=(a,b,c,d)=>(Zf=f.dynCall_iiif=G.$c)(a,b,c,d),$f=f.dynCall_iiij=(a,b,c,d)=>($f=f.dynCall_iiij=G.ad)(a,b,c,d),ag=f.dynCall_fiii=
(a,b,c,d)=>(ag=f.dynCall_fiii=G.bd)(a,b,c,d),bg=f.dynCall_viiiiiiiiiiiii=(a,b,c,d,e,g,h,k,l,p,q,r,w,z)=>(bg=f.dynCall_viiiiiiiiiiiii=G.cd)(a,b,c,d,e,g,h,k,l,p,q,r,w,z),cg=f.dynCall_vjiii=(a,b,c,d,e)=>(cg=f.dynCall_vjiii=G.dd)(a,b,c,d,e),dg=f.dynCall_vif=(a,b,c)=>(dg=f.dynCall_vif=G.ed)(a,b,c),eg=f.dynCall_iiiiiii=(a,b,c,d,e,g,h)=>(eg=f.dynCall_iiiiiii=G.fd)(a,b,c,d,e,g,h),fg=f.dynCall_iiiij=(a,b,c,d,e)=>(fg=f.dynCall_iiiij=G.gd)(a,b,c,d,e),gg=f.dynCall_iiiiiiii=(a,b,c,d,e,g,h,k)=>(gg=f.dynCall_iiiiiiii=
G.hd)(a,b,c,d,e,g,h,k),hg=f.dynCall_viiiiiiiiiiii=(a,b,c,d,e,g,h,k,l,p,q,r,w)=>(hg=f.dynCall_viiiiiiiiiiii=G.id)(a,b,c,d,e,g,h,k,l,p,q,r,w),ig=f.dynCall_diii=(a,b,c,d)=>(ig=f.dynCall_diii=G.jd)(a,b,c,d),jg=f.dynCall_jiiii=(a,b,c,d,e)=>(jg=f.dynCall_jiiii=G.kd)(a,b,c,d,e),kg=f.dynCall_viiij=(a,b,c,d,e)=>(kg=f.dynCall_viiij=G.ld)(a,b,c,d,e),lg=f.dynCall_fiiii=(a,b,c,d,e)=>(lg=f.dynCall_fiiii=G.md)(a,b,c,d,e),mg=f.dynCall_viiif=(a,b,c,d,e)=>(mg=f.dynCall_viiif=G.nd)(a,b,c,d,e),ng=f.dynCall_diiii=(a,
b,c,d,e)=>(ng=f.dynCall_diiii=G.od)(a,b,c,d,e),og=f.dynCall_viiid=(a,b,c,d,e)=>(og=f.dynCall_viiid=G.pd)(a,b,c,d,e),pg=f.dynCall_iiiijii=(a,b,c,d,e,g,h)=>(pg=f.dynCall_iiiijii=G.qd)(a,b,c,d,e,g,h),qg=f.dynCall_iiiiiij=(a,b,c,d,e,g,h)=>(qg=f.dynCall_iiiiiij=G.rd)(a,b,c,d,e,g,h),bf=a=>(bf=G.sd)(a),Re=()=>(Re=G.td)(),af=a=>(af=G.ud)(a),cf=()=>(cf=G.vd)();function od(a,b,c){var d=N();try{dynCall_vii(a,b,c)}catch(e){O(d);if(e!==e+0)throw e;R(1,0)}}
function Uc(a,b,c){var d=N();try{return dynCall_iii(a,b,c)}catch(e){O(d);if(e!==e+0)throw e;R(1,0)}}function md(a,b){var c=N();try{dynCall_vi(a,b)}catch(d){O(c);if(d!==d+0)throw d;R(1,0)}}function Tc(a,b){var c=N();try{return Zd(a,b)}catch(d){O(c);if(d!==d+0)throw d;R(1,0)}}function Wc(a,b,c,d){var e=N();try{return Ef(a,b,c,d)}catch(g){O(e);if(g!==g+0)throw g;R(1,0)}}function sd(a,b,c,d,e){var g=N();try{Hf(a,b,c,d,e)}catch(h){O(g);if(h!==h+0)throw h;R(1,0)}}
function Xc(a,b,c,d,e){var g=N();try{return Gf(a,b,c,d,e)}catch(h){O(g);if(h!==h+0)throw h;R(1,0)}}function pd(a,b,c,d){var e=N();try{Ff(a,b,c,d)}catch(g){O(e);if(g!==g+0)throw g;R(1,0)}}function Zc(a,b,c,d,e,g,h){var k=N();try{return eg(a,b,c,d,e,g,h)}catch(l){O(k);if(l!==l+0)throw l;R(1,0)}}function ld(a){var b=N();try{dynCall_v(a)}catch(c){O(b);if(c!==c+0)throw c;R(1,0)}}function gd(a,b,c){var d=N();try{return Vf(a,b,c)}catch(e){O(d);if(e!==e+0)throw e;R(1,0)}}
function td(a,b,c,d,e,g){var h=N();try{Lf(a,b,c,d,e,g)}catch(k){O(h);if(k!==k+0)throw k;R(1,0)}}function Dd(a,b,c){var d=N();try{Yf(a,b,c)}catch(e){O(d);if(e!==e+0)throw e;R(1,0)}}function ud(a,b,c,d,e,g,h){var k=N();try{If(a,b,c,d,e,g,h)}catch(l){O(k);if(l!==l+0)throw l;R(1,0)}}function vd(a,b,c,d,e,g,h,k){var l=N();try{Jf(a,b,c,d,e,g,h,k)}catch(p){O(l);if(p!==p+0)throw p;R(1,0)}}function Yc(a,b,c,d,e,g){var h=N();try{return Uf(a,b,c,d,e,g)}catch(k){O(h);if(k!==k+0)throw k;R(1,0)}}
function $c(a,b,c,d,e,g,h,k){var l=N();try{return gg(a,b,c,d,e,g,h,k)}catch(p){O(l);if(p!==p+0)throw p;R(1,0)}}function xd(a,b,c,d,e,g,h,k,l,p){var q=N();try{Sf(a,b,c,d,e,g,h,k,l,p)}catch(r){O(q);if(r!==r+0)throw r;R(1,0)}}function wd(a,b,c,d,e,g,h,k,l){var p=N();try{Of(a,b,c,d,e,g,h,k,l)}catch(q){O(p);if(q!==q+0)throw q;R(1,0)}}function Sc(a){var b=N();try{return Mf(a)}catch(c){O(b);if(c!==c+0)throw c;R(1,0)}}
function ad(a,b,c,d,e,g,h,k,l,p){var q=N();try{return Wf(a,b,c,d,e,g,h,k,l,p)}catch(r){O(q);if(r!==r+0)throw r;R(1,0)}}function Pc(a,b,c){var d=N();try{return Nf(a,b,c)}catch(e){O(d);if(e!==e+0)throw e;R(1,0)}}function jd(a,b,c,d){var e=N();try{return Qf(a,b,c,d)}catch(g){O(e);if(g!==g+0)throw g;R(1,0);return 0n}}function Mc(a,b,c){var d=N();try{return Rf(a,b,c)}catch(e){O(d);if(e!==e+0)throw e;R(1,0)}}
function zd(a,b,c,d,e,g,h,k,l,p,q,r){var w=N();try{Tf(a,b,c,d,e,g,h,k,l,p,q,r)}catch(z){O(w);if(z!==z+0)throw z;R(1,0)}}function yd(a,b,c,d,e,g,h,k,l,p,q){var r=N();try{Pf(a,b,c,d,e,g,h,k,l,p,q)}catch(w){O(r);if(w!==w+0)throw w;R(1,0)}}function bd(a,b,c,d,e,g,h,k,l,p,q){var r=N();try{return Xf(a,b,c,d,e,g,h,k,l,p,q)}catch(w){O(r);if(w!==w+0)throw w;R(1,0)}}function Vc(a,b,c,d){var e=N();try{return Zf(a,b,c,d)}catch(g){O(e);if(g!==g+0)throw g;R(1,0)}}
function fd(a,b,c,d){var e=N();try{return $f(a,b,c,d)}catch(g){O(e);if(g!==g+0)throw g;R(1,0)}}function Qc(a,b,c,d){var e=N();try{return ag(a,b,c,d)}catch(g){O(e);if(g!==g+0)throw g;R(1,0)}}function Bd(a,b,c,d,e,g,h,k,l,p,q,r,w,z){var J=N();try{bg(a,b,c,d,e,g,h,k,l,p,q,r,w,z)}catch(la){O(J);if(la!==la+0)throw la;R(1,0)}}function Ed(a,b,c,d,e){var g=N();try{cg(a,b,c,d,e)}catch(h){O(g);if(h!==h+0)throw h;R(1,0)}}function nd(a,b,c){var d=N();try{dg(a,b,c)}catch(e){O(d);if(e!==e+0)throw e;R(1,0)}}
function hd(a,b){var c=N();try{return Kf(a,b)}catch(d){O(c);if(d!==d+0)throw d;R(1,0);return 0n}}function dd(a,b,c,d,e){var g=N();try{return fg(a,b,c,d,e)}catch(h){O(g);if(h!==h+0)throw h;R(1,0)}}function Ad(a,b,c,d,e,g,h,k,l,p,q,r,w){var z=N();try{hg(a,b,c,d,e,g,h,k,l,p,q,r,w)}catch(J){O(z);if(J!==J+0)throw J;R(1,0)}}function Nc(a,b,c,d){var e=N();try{return ig(a,b,c,d)}catch(g){O(e);if(g!==g+0)throw g;R(1,0)}}
function kd(a,b,c,d,e){var g=N();try{return jg(a,b,c,d,e)}catch(h){O(g);if(h!==h+0)throw h;R(1,0);return 0n}}function Cd(a,b,c,d,e){var g=N();try{kg(a,b,c,d,e)}catch(h){O(g);if(h!==h+0)throw h;R(1,0)}}function Rc(a,b,c,d,e){var g=N();try{return lg(a,b,c,d,e)}catch(h){O(g);if(h!==h+0)throw h;R(1,0)}}function rd(a,b,c,d,e){var g=N();try{mg(a,b,c,d,e)}catch(h){O(g);if(h!==h+0)throw h;R(1,0)}}function Oc(a,b,c,d,e){var g=N();try{return ng(a,b,c,d,e)}catch(h){O(g);if(h!==h+0)throw h;R(1,0)}}
function qd(a,b,c,d,e){var g=N();try{og(a,b,c,d,e)}catch(h){O(g);if(h!==h+0)throw h;R(1,0)}}function ed(a,b,c,d,e,g,h){var k=N();try{return pg(a,b,c,d,e,g,h)}catch(l){O(k);if(l!==l+0)throw l;R(1,0)}}function cd(a,b,c,d,e,g,h){var k=N();try{return qg(a,b,c,d,e,g,h)}catch(l){O(k);if(l!==l+0)throw l;R(1,0)}}function Df(){var a=G;a=Object.assign({},a);var b=d=>e=>d(e)>>>0,c=d=>()=>d()>>>0;a.Cb=b(a.Cb);a.fc=c(a.fc);a.ic=b(a.ic);a.vc=b(a.vc);a.wc=c(a.wc);a.Ac=b(a.Ac);return a}f.stackSave=()=>N();
f.stackRestore=a=>O(a);f.stackAlloc=a=>Qd(a);f.setValue=function(a,b,c="i8"){c.endsWith("*")&&(c="*");switch(c){case "i1":B()[a>>>0]=b;break;case "i8":B()[a>>>0]=b;break;case "i16":Ga()[a>>>1>>>0]=b;break;case "i32":E()[a>>>2>>>0]=b;break;case "i64":A[a>>>3]=BigInt(b);break;case "float":Ia()[a>>>2>>>0]=b;break;case "double":Ja()[a>>>3>>>0]=b;break;case "*":F()[a>>>2>>>0]=b;break;default:H(`invalid type for setValue: ${c}`)}};
f.getValue=function(a,b="i8"){b.endsWith("*")&&(b="*");switch(b){case "i1":return B()[a>>>0];case "i8":return B()[a>>>0];case "i16":return Ga()[a>>>1>>>0];case "i32":return E()[a>>>2>>>0];case "i64":return A[a>>>3];case "float":return Ia()[a>>>2>>>0];case "double":return Ja()[a>>>3>>>0];case "*":return F()[a>>>2>>>0];default:H(`invalid type for getValue: ${b}`)}};f.UTF8ToString=I;f.stringToUTF8=ne;f.lengthBytesUTF8=me;
function rg(){if(0<Xa)Ya=rg;else if(n)aa(f),Wa();else{for(;0<Ld.length;)Ld.shift()(f);0<Xa?Ya=rg:(f.calledRun=!0,wa||(Wa(),aa(f)))}}rg();"use strict";f.PTR_SIZE=4;moduleRtn=ca;


  return moduleRtn;
}
);
})();
export default ortWasmThreaded;
var isPthread = globalThis.self?.name?.startsWith('em-pthread');
var isNode = typeof globalThis.process?.versions?.node == 'string';
if (isNode) isPthread = (await import('worker_threads')).workerData === 'em-pthread';

// When running as a pthread, construct a new instance on startup
isPthread && ortWasmThreaded();

````
--- End of File: vibe-player/lib/ort-wasm-simd-threaded.jsep.mjs ---
--- File: vibe-player/lib/ort-wasm-simd-threaded.mjs ---
````mjs
var ortWasmThreaded = (() => {
  var _scriptName = import.meta.url;
  
  return (
async function(moduleArg = {}) {
  var moduleRtn;

var h=moduleArg,ba,ca,da=new Promise((a,b)=>{ba=a;ca=b}),ea="object"==typeof window,l="undefined"!=typeof WorkerGlobalScope,m="object"==typeof process&&"object"==typeof process.versions&&"string"==typeof process.versions.node&&"renderer"!=process.type,n=l&&self.name?.startsWith("em-pthread");if(m){const {createRequire:a}=await import("module");var require=a(import.meta.url),fa=require("worker_threads");global.Worker=fa.Worker;n=(l=!fa.pc)&&"em-pthread"==fa.workerData}"use strict";
h.mountExternalData=(a,b)=>{a.startsWith("./")&&(a=a.substring(2));(h.Zb||(h.Zb=new Map)).set(a,b)};h.unmountExternalData=()=>{delete h.Zb};var SharedArrayBuffer=globalThis.SharedArrayBuffer??(new WebAssembly.Memory({initial:0,maximum:0,shared:!0})).buffer.constructor,ha=Object.assign({},h),ia="./this.program",ja=(a,b)=>{throw b;},q="",ka,la;
if(m){var fs=require("fs"),ma=require("path");import.meta.url.startsWith("data:")||(q=ma.dirname(require("url").fileURLToPath(import.meta.url))+"/");la=a=>{a=na(a)?new URL(a):a;return fs.readFileSync(a)};ka=async a=>{a=na(a)?new URL(a):a;return fs.readFileSync(a,void 0)};!h.thisProgram&&1<process.argv.length&&(ia=process.argv[1].replace(/\\/g,"/"));process.argv.slice(2);ja=(a,b)=>{process.exitCode=a;throw b;}}else if(ea||l)l?q=self.location.href:"undefined"!=typeof document&&
document.currentScript&&(q=document.currentScript.src),_scriptName&&(q=_scriptName),q.startsWith("blob:")?q="":q=q.slice(0,q.replace(/[?#].*/,"").lastIndexOf("/")+1),m||(l&&(la=a=>{var b=new XMLHttpRequest;b.open("GET",a,!1);b.responseType="arraybuffer";b.send(null);return new Uint8Array(b.response)}),ka=async a=>{if(na(a))return new Promise((c,d)=>{var e=new XMLHttpRequest;e.open("GET",a,!0);e.responseType="arraybuffer";e.onload=()=>{200==e.status||0==e.status&&e.response?c(e.response):d(e.status)};
e.onerror=d;e.send(null)});var b=await fetch(a,{credentials:"same-origin"});if(b.ok)return b.arrayBuffer();throw Error(b.status+" : "+b.url);});var oa=console.log.bind(console),pa=console.error.bind(console);m&&(oa=(...a)=>fs.writeSync(1,a.join(" ")+"\n"),pa=(...a)=>fs.writeSync(2,a.join(" ")+"\n"));var qa=oa,r=pa;Object.assign(h,ha);ha=null;var ra=h.wasmBinary,t,sa,ta=!1,u,w,ua,va,wa,xa,ya,y,za,na=a=>a.startsWith("file://");function A(){t.buffer!=w.buffer&&B();return w}
function D(){t.buffer!=w.buffer&&B();return ua}function Aa(){t.buffer!=w.buffer&&B();return va}function E(){t.buffer!=w.buffer&&B();return wa}function F(){t.buffer!=w.buffer&&B();return xa}function Ba(){t.buffer!=w.buffer&&B();return ya}function G(){t.buffer!=w.buffer&&B();return za}
if(n){var Ca;if(m){var Da=fa.parentPort;Da.on("message",b=>onmessage({data:b}));Object.assign(globalThis,{self:global,postMessage:b=>Da.postMessage(b)})}var Ea=!1;r=function(...b){b=b.join(" ");m?fs.writeSync(2,b+"\n"):console.error(b)};self.alert=function(...b){postMessage({Yb:"alert",text:b.join(" "),lc:Fa()})};self.onunhandledrejection=b=>{throw b.reason||b;};function a(b){try{var c=b.data,d=c.Yb;if("load"===d){let e=[];self.onmessage=f=>e.push(f);self.startWorker=()=>{postMessage({Yb:"loaded"});
for(let f of e)a(f);self.onmessage=a};for(const f of c.fc)if(!h[f]||h[f].proxy)h[f]=(...g)=>{postMessage({Yb:"callHandler",ec:f,args:g})},"print"==f&&(qa=h[f]),"printErr"==f&&(r=h[f]);t=c.nc;B();Ca(c.oc)}else if("run"===d){Ga(c.Xb);Ia(c.Xb,0,0,1,0,0);Ja();Ka(c.Xb);Ea||=!0;try{La(c.jc,c.ac)}catch(e){if("unwind"!=e)throw e;}}else"setimmediate"!==c.target&&("checkMailbox"===d?Ea&&Ma():d&&(r(`worker: received unknown command ${d}`),r(c)))}catch(e){throw Na(),e;}}self.onmessage=a}
function B(){var a=t.buffer;h.HEAP8=w=new Int8Array(a);h.HEAP16=va=new Int16Array(a);h.HEAPU8=ua=new Uint8Array(a);h.HEAPU16=new Uint16Array(a);h.HEAP32=wa=new Int32Array(a);h.HEAPU32=xa=new Uint32Array(a);h.HEAPF32=ya=new Float32Array(a);h.HEAPF64=za=new Float64Array(a);h.HEAP64=y=new BigInt64Array(a);h.HEAPU64=new BigUint64Array(a)}n||(t=new WebAssembly.Memory({initial:256,maximum:65536,shared:!0}),B());function Oa(){n?startWorker(h):H._a()}var I=0,J=null;
function Pa(){I--;if(0==I&&J){var a=J;J=null;a()}}function K(a){a="Aborted("+a+")";r(a);ta=!0;a=new WebAssembly.RuntimeError(a+". Build with -sASSERTIONS for more info.");ca(a);throw a;}var Qa;async function Ra(a){if(!ra)try{var b=await ka(a);return new Uint8Array(b)}catch{}if(a==Qa&&ra)a=new Uint8Array(ra);else if(la)a=la(a);else throw"both async and sync fetching of the wasm failed";return a}
async function Sa(a,b){try{var c=await Ra(a);return await WebAssembly.instantiate(c,b)}catch(d){r(`failed to asynchronously prepare wasm: ${d}`),K(d)}}async function Ta(a){var b=Qa;if(!ra&&"function"==typeof WebAssembly.instantiateStreaming&&!na(b)&&!m)try{var c=fetch(b,{credentials:"same-origin"});return await WebAssembly.instantiateStreaming(c,a)}catch(d){r(`wasm streaming compile failed: ${d}`),r("falling back to ArrayBuffer instantiation")}return Sa(b,a)}
function Ua(){Va={Oa:Wa,E:Xa,S:Ya,b:Za,r:$a,B:ab,Sa:bb,d:cb,la:db,g:eb,C:fb,Ba:gb,ha:hb,ja:ib,Ca:jb,za:kb,sa:lb,ya:mb,X:nb,ia:ob,fa:pb,Aa:qb,ga:rb,Ha:sb,va:tb,Ya:ub,ma:vb,Va:wb,T:xb,ua:Ka,Ea:yb,pa:zb,qa:Ab,ra:Bb,na:Cb,oa:Db,Wa:Eb,Ja:Fb,Ga:Gb,da:Hb,U:Ib,Fa:Jb,Y:Kb,Da:Lb,Za:Mb,D:Nb,N:Ob,Na:Pb,Xa:Qb,La:Rb,Ka:Sb,wa:Tb,xa:Ub,ka:Vb,I:Wb,W:Xb,ta:Yb,V:Zb,Ua:$b,Q:ac,_:bc,O:cc,L:dc,aa:ec,o:fc,e:gc,c:hc,M:ic,f:jc,m:kc,k:lc,F:mc,R:nc,j:oc,ca:pc,Ma:qc,K:rc,Pa:sc,z:tc,w:uc,H:vc,A:wc,G:xc,s:yc,l:zc,ba:Ac,i:Bc,h:Cc,
Z:Dc,$:Ec,n:Fc,p:Gc,q:Hc,v:Ic,t:Jc,x:Kc,ea:Lc,Ta:Mc,u:Nc,Ra:Oc,J:Pc,y:Qc,Qa:Rc,P:Sc,a:t,Ia:Tc};return{a:Va}}var Vc={1285017:()=>"undefined"!==typeof wasmOffsetConverter,1285074:(a,b,c,d,e)=>{if("undefined"==typeof h||!h.Zb)return 1;a=Uc(Number(a>>>0));a.startsWith("./")&&(a=a.substring(2));a=h.Zb.get(a);if(!a)return 2;b=Number(b>>>0);c=Number(c>>>0);d=Number(d>>>0);if(b+c>a.byteLength)return 3;try{const f=a.subarray(b,b+c);switch(e){case 0:D().set(f,d>>>0);break;case 1:h.qc(d,f);break;default:return 4}return 0}catch{return 4}}};
function Wa(){return"undefined"!==typeof wasmOffsetConverter}class Wc{name="ExitStatus";constructor(a){this.message=`Program terminated with exit(${a})`;this.status=a}}
var Xc=a=>{a.terminate();a.onmessage=()=>{}},Yc=[],ad=a=>{0==L.length&&(Zc(),$c(L[0]));var b=L.pop();if(!b)return 6;M.push(b);O[a.Xb]=b;b.Xb=a.Xb;var c={Yb:"run",jc:a.ic,ac:a.ac,Xb:a.Xb};m&&b.unref();b.postMessage(c,a.dc);return 0},P=0,S=(a,b,...c)=>{for(var d=2*c.length,e=Q(),f=bd(8*d),g=f>>>3,k=0;k<c.length;k++){var p=c[k];"bigint"==typeof p?(y[g+2*k]=1n,y[g+2*k+1]=p):(y[g+2*k]=0n,G()[g+2*k+1>>>0]=p)}a=cd(a,0,d,f,b);R(e);return a};
function Tc(a){if(n)return S(0,1,a);u=a;if(!(0<P)){for(var b of M)Xc(b);for(b of L)Xc(b);L=[];M=[];O={};ta=!0}ja(a,new Wc(a))}function dd(a){if(n)return S(1,0,a);Vb(a)}var Vb=a=>{u=a;if(n)throw dd(a),"unwind";Tc(a)},L=[],M=[],ed=[],O={};function fd(){for(var a=h.numThreads-1;a--;)Zc();Yc.unshift(()=>{I++;gd(()=>Pa())})}var jd=a=>{var b=a.Xb;delete O[b];L.push(a);M.splice(M.indexOf(a),1);a.Xb=0;hd(b)};function Ja(){ed.forEach(a=>a())}
var $c=a=>new Promise(b=>{a.onmessage=f=>{f=f.data;var g=f.Yb;if(f.$b&&f.$b!=Fa()){var k=O[f.$b];k?k.postMessage(f,f.dc):r(`Internal error! Worker sent a message "${g}" to target pthread ${f.$b}, but that thread no longer exists!`)}else if("checkMailbox"===g)Ma();else if("spawnThread"===g)ad(f);else if("cleanupThread"===g)jd(O[f.kc]);else if("loaded"===g)a.loaded=!0,m&&!a.Xb&&a.unref(),b(a);else if("alert"===g)alert(`Thread ${f.lc}: ${f.text}`);else if("setimmediate"===f.target)a.postMessage(f);else if("callHandler"===
g)h[f.ec](...f.args);else g&&r(`worker sent an unknown command ${g}`)};a.onerror=f=>{r(`${"worker sent an error!"} ${f.filename}:${f.lineno}: ${f.message}`);throw f;};m&&(a.on("message",f=>a.onmessage({data:f})),a.on("error",f=>a.onerror(f)));var c=[],d=[],e;for(e of d)h.propertyIsEnumerable(e)&&c.push(e);a.postMessage({Yb:"load",fc:c,nc:t,oc:sa})});function gd(a){n?a():Promise.all(L.map($c)).then(a)}
function Zc(){var a=new Worker(new URL(import.meta.url),{type:"module",workerData:"em-pthread",name:"em-pthread"});L.push(a)}var Ga=a=>{B();var b=F()[a+52>>>2>>>0];a=F()[a+56>>>2>>>0];kd(b,b-a);R(b)},ld=[],md,T=a=>{var b=ld[a];b||(a>=ld.length&&(ld.length=a+1),ld[a]=b=md.get(a));return b},La=(a,b)=>{P=0;a=T(a)(b);0<P?u=a:nd(a)},od=[],pd=0;
function Xa(a){a>>>=0;var b=new qd(a);if(0==A()[b.Wb+12>>>0]){var c=1;A()[b.Wb+12>>>0]=c;pd--}c=0;A()[b.Wb+13>>>0]=c;od.push(b);rd(a);return sd(a)}var U=0,Ya=()=>{V(0,0);var a=od.pop();td(a.bc);U=0};class qd{constructor(a){this.bc=a;this.Wb=a-24}}function eb(a){U||=a>>>0;throw U;}var vd=a=>{var b=U;if(!b)return W(0),0;var c=new qd(b);F()[c.Wb+16>>>2>>>0]=b;var d=F()[c.Wb+4>>>2>>>0];if(!d)return W(0),b;for(var e of a){if(0===e||e===d)break;if(ud(e,d,c.Wb+16))return W(e),b}W(d);return b};
function Za(){return vd([])}function $a(a){return vd([a>>>0])}function ab(a,b){return vd([a>>>0,b>>>0])}var bb=()=>{var a=od.pop();a||K("no exception to throw");var b=a.bc;if(0==A()[a.Wb+13>>>0]){od.push(a);var c=1;A()[a.Wb+13>>>0]=c;c=0;A()[a.Wb+12>>>0]=c;pd++}U=b;throw U;};function cb(a,b,c){a>>>=0;var d=new qd(a);b>>>=0;c>>>=0;F()[d.Wb+16>>>2>>>0]=0;F()[d.Wb+4>>>2>>>0]=b;F()[d.Wb+8>>>2>>>0]=c;U=a;pd++;throw U;}function wd(a,b,c,d){return n?S(2,1,a,b,c,d):db(a,b,c,d)}
function db(a,b,c,d){a>>>=0;b>>>=0;c>>>=0;d>>>=0;if("undefined"==typeof SharedArrayBuffer)return 6;var e=[];if(n&&0===e.length)return wd(a,b,c,d);a={ic:c,Xb:a,ac:d,dc:e};return n?(a.Yb="spawnThread",postMessage(a,e),0):ad(a)}
var xd="undefined"!=typeof TextDecoder?new TextDecoder:void 0,yd=(a,b=0,c=NaN)=>{b>>>=0;var d=b+c;for(c=b;a[c]&&!(c>=d);)++c;if(16<c-b&&a.buffer&&xd)return xd.decode(a.buffer instanceof ArrayBuffer?a.subarray(b,c):a.slice(b,c));for(d="";b<c;){var e=a[b++];if(e&128){var f=a[b++]&63;if(192==(e&224))d+=String.fromCharCode((e&31)<<6|f);else{var g=a[b++]&63;e=224==(e&240)?(e&15)<<12|f<<6|g:(e&7)<<18|f<<12|g<<6|a[b++]&63;65536>e?d+=String.fromCharCode(e):(e-=65536,d+=String.fromCharCode(55296|e>>10,56320|
e&1023))}}else d+=String.fromCharCode(e)}return d},Uc=(a,b)=>(a>>>=0)?yd(D(),a,b):"";function fb(a,b,c){return n?S(3,1,a,b,c):0}function gb(a,b){if(n)return S(4,1,a,b)}
var X=(a,b,c)=>{var d=D();b>>>=0;if(0<c){var e=b;c=b+c-1;for(var f=0;f<a.length;++f){var g=a.charCodeAt(f);if(55296<=g&&57343>=g){var k=a.charCodeAt(++f);g=65536+((g&1023)<<10)|k&1023}if(127>=g){if(b>=c)break;d[b++>>>0]=g}else{if(2047>=g){if(b+1>=c)break;d[b++>>>0]=192|g>>6}else{if(65535>=g){if(b+2>=c)break;d[b++>>>0]=224|g>>12}else{if(b+3>=c)break;d[b++>>>0]=240|g>>18;d[b++>>>0]=128|g>>12&63}d[b++>>>0]=128|g>>6&63}d[b++>>>0]=128|g&63}}d[b>>>0]=0;a=b-e}else a=0;return a};
function hb(a,b){if(n)return S(5,1,a,b)}function ib(a,b,c){if(n)return S(6,1,a,b,c)}function jb(a,b,c){return n?S(7,1,a,b,c):0}function kb(a,b){if(n)return S(8,1,a,b)}function lb(a,b,c){if(n)return S(9,1,a,b,c)}function mb(a,b,c,d){if(n)return S(10,1,a,b,c,d)}function nb(a,b,c,d){if(n)return S(11,1,a,b,c,d)}function ob(a,b,c,d){if(n)return S(12,1,a,b,c,d)}function pb(a){if(n)return S(13,1,a)}function qb(a,b){if(n)return S(14,1,a,b)}function rb(a,b,c){if(n)return S(15,1,a,b,c)}var sb=()=>K("");
function tb(a){Ia(a>>>0,!l,1,!ea,131072,!1);Ja()}var zd=a=>{if(!ta)try{if(a(),!(0<P))try{n?nd(u):Vb(u)}catch(b){b instanceof Wc||"unwind"==b||ja(1,b)}}catch(b){b instanceof Wc||"unwind"==b||ja(1,b)}};function Ka(a){a>>>=0;"function"===typeof Atomics.mc&&(Atomics.mc(E(),a>>>2,a).value.then(Ma),a+=128,Atomics.store(E(),a>>>2,1))}var Ma=()=>{var a=Fa();a&&(Ka(a),zd(Ad))};
function ub(a,b){a>>>=0;a==b>>>0?setTimeout(Ma):n?postMessage({$b:a,Yb:"checkMailbox"}):(a=O[a])&&a.postMessage({Yb:"checkMailbox"})}var Bd=[];function vb(a,b,c,d,e){b>>>=0;d/=2;Bd.length=d;c=e>>>0>>>3;for(e=0;e<d;e++)Bd[e]=y[c+2*e]?y[c+2*e+1]:G()[c+2*e+1>>>0];return(b?Vc[b]:Cd[a])(...Bd)}var wb=()=>{P=0};function xb(a){a>>>=0;n?postMessage({Yb:"cleanupThread",kc:a}):jd(O[a])}function yb(a){m&&O[a>>>0].ref()}
function zb(a,b){a=-9007199254740992>a||9007199254740992<a?NaN:Number(a);b>>>=0;a=new Date(1E3*a);E()[b>>>2>>>0]=a.getUTCSeconds();E()[b+4>>>2>>>0]=a.getUTCMinutes();E()[b+8>>>2>>>0]=a.getUTCHours();E()[b+12>>>2>>>0]=a.getUTCDate();E()[b+16>>>2>>>0]=a.getUTCMonth();E()[b+20>>>2>>>0]=a.getUTCFullYear()-1900;E()[b+24>>>2>>>0]=a.getUTCDay();a=(a.getTime()-Date.UTC(a.getUTCFullYear(),0,1,0,0,0,0))/864E5|0;E()[b+28>>>2>>>0]=a}
var Dd=a=>0===a%4&&(0!==a%100||0===a%400),Ed=[0,31,60,91,121,152,182,213,244,274,305,335],Fd=[0,31,59,90,120,151,181,212,243,273,304,334];
function Ab(a,b){a=-9007199254740992>a||9007199254740992<a?NaN:Number(a);b>>>=0;a=new Date(1E3*a);E()[b>>>2>>>0]=a.getSeconds();E()[b+4>>>2>>>0]=a.getMinutes();E()[b+8>>>2>>>0]=a.getHours();E()[b+12>>>2>>>0]=a.getDate();E()[b+16>>>2>>>0]=a.getMonth();E()[b+20>>>2>>>0]=a.getFullYear()-1900;E()[b+24>>>2>>>0]=a.getDay();var c=(Dd(a.getFullYear())?Ed:Fd)[a.getMonth()]+a.getDate()-1|0;E()[b+28>>>2>>>0]=c;E()[b+36>>>2>>>0]=-(60*a.getTimezoneOffset());c=(new Date(a.getFullYear(),6,1)).getTimezoneOffset();
var d=(new Date(a.getFullYear(),0,1)).getTimezoneOffset();a=(c!=d&&a.getTimezoneOffset()==Math.min(d,c))|0;E()[b+32>>>2>>>0]=a}
function Bb(a){a>>>=0;var b=new Date(E()[a+20>>>2>>>0]+1900,E()[a+16>>>2>>>0],E()[a+12>>>2>>>0],E()[a+8>>>2>>>0],E()[a+4>>>2>>>0],E()[a>>>2>>>0],0),c=E()[a+32>>>2>>>0],d=b.getTimezoneOffset(),e=(new Date(b.getFullYear(),6,1)).getTimezoneOffset(),f=(new Date(b.getFullYear(),0,1)).getTimezoneOffset(),g=Math.min(f,e);0>c?E()[a+32>>>2>>>0]=Number(e!=f&&g==d):0<c!=(g==d)&&(e=Math.max(f,e),b.setTime(b.getTime()+6E4*((0<c?g:e)-d)));E()[a+24>>>2>>>0]=b.getDay();c=(Dd(b.getFullYear())?Ed:Fd)[b.getMonth()]+
b.getDate()-1|0;E()[a+28>>>2>>>0]=c;E()[a>>>2>>>0]=b.getSeconds();E()[a+4>>>2>>>0]=b.getMinutes();E()[a+8>>>2>>>0]=b.getHours();E()[a+12>>>2>>>0]=b.getDate();E()[a+16>>>2>>>0]=b.getMonth();E()[a+20>>>2>>>0]=b.getYear();a=b.getTime();return BigInt(isNaN(a)?-1:a/1E3)}function Cb(a,b,c,d,e,f,g){return n?S(16,1,a,b,c,d,e,f,g):-52}function Db(a,b,c,d,e,f){if(n)return S(17,1,a,b,c,d,e,f)}var Y={},Nb=()=>performance.timeOrigin+performance.now();
function Eb(a,b){if(n)return S(18,1,a,b);Y[a]&&(clearTimeout(Y[a].id),delete Y[a]);if(!b)return 0;var c=setTimeout(()=>{delete Y[a];zd(()=>Gd(a,performance.timeOrigin+performance.now()))},b);Y[a]={id:c,rc:b};return 0}
function Fb(a,b,c,d){a>>>=0;b>>>=0;c>>>=0;d>>>=0;var e=(new Date).getFullYear(),f=(new Date(e,0,1)).getTimezoneOffset();e=(new Date(e,6,1)).getTimezoneOffset();var g=Math.max(f,e);F()[a>>>2>>>0]=60*g;E()[b>>>2>>>0]=Number(f!=e);b=k=>{var p=Math.abs(k);return`UTC${0<=k?"-":"+"}${String(Math.floor(p/60)).padStart(2,"0")}${String(p%60).padStart(2,"0")}`};a=b(f);b=b(e);e<f?(X(a,c,17),X(b,d,17)):(X(a,d,17),X(b,c,17))}var Jb=()=>Date.now(),Hd=1;
function Gb(a,b,c){if(!(0<=a&&3>=a))return 28;if(0===a)a=Date.now();else if(Hd)a=performance.timeOrigin+performance.now();else return 52;y[c>>>0>>>3]=BigInt(Math.round(1E6*a));return 0}var Id=[];function Hb(a,b,c){a>>>=0;b>>>=0;c>>>=0;Id.length=0;for(var d;d=D()[b++>>>0];){var e=105!=d;e&=112!=d;c+=e&&c%8?4:0;Id.push(112==d?F()[c>>>2>>>0]:106==d?y[c>>>3]:105==d?E()[c>>>2>>>0]:G()[c>>>3>>>0]);c+=e?8:4}return Vc[a](...Id)}var Ib=()=>{};function Kb(a,b){return r(Uc(a>>>0,b>>>0))}
var Lb=()=>{P+=1;throw"unwind";};function Mb(){return 4294901760}var Ob=()=>m?require("os").cpus().length:navigator.hardwareConcurrency;function Pb(){K("Cannot use emscripten_pc_get_function without -sUSE_OFFSET_CONVERTER");return 0}
function Qb(a){a>>>=0;var b=D().length;if(a<=b||4294901760<a)return!1;for(var c=1;4>=c;c*=2){var d=b*(1+.2/c);d=Math.min(d,a+100663296);a:{d=(Math.min(4294901760,65536*Math.ceil(Math.max(a,d)/65536))-t.buffer.byteLength+65535)/65536|0;try{t.grow(d);B();var e=1;break a}catch(f){}e=void 0}if(e)return!0}return!1}var Jd=()=>{K("Cannot use convertFrameToPC (needed by __builtin_return_address) without -sUSE_OFFSET_CONVERTER");return 0},Z={},Kd=a=>{a.forEach(b=>{var c=Jd();c&&(Z[c]=b)})};
function Rb(){var a=Error().stack.toString().split("\n");"Error"==a[0]&&a.shift();Kd(a);Z.cc=Jd();Z.hc=a;return Z.cc}function Sb(a,b,c){a>>>=0;b>>>=0;if(Z.cc==a)var d=Z.hc;else d=Error().stack.toString().split("\n"),"Error"==d[0]&&d.shift(),Kd(d);for(var e=3;d[e]&&Jd()!=a;)++e;for(a=0;a<c&&d[a+e];++a)E()[b+4*a>>>2>>>0]=Jd();return a}
var Ld={},Nd=()=>{if(!Md){var a={USER:"web_user",LOGNAME:"web_user",PATH:"/",PWD:"/",HOME:"/home/web_user",LANG:("object"==typeof navigator&&navigator.languages&&navigator.languages[0]||"C").replace("-","_")+".UTF-8",_:ia||"./this.program"},b;for(b in Ld)void 0===Ld[b]?delete a[b]:a[b]=Ld[b];var c=[];for(b in a)c.push(`${b}=${a[b]}`);Md=c}return Md},Md;
function Tb(a,b){if(n)return S(19,1,a,b);a>>>=0;b>>>=0;var c=0;Nd().forEach((d,e)=>{var f=b+c;e=F()[a+4*e>>>2>>>0]=f;for(f=0;f<d.length;++f)A()[e++>>>0]=d.charCodeAt(f);A()[e>>>0]=0;c+=d.length+1});return 0}function Ub(a,b){if(n)return S(20,1,a,b);a>>>=0;b>>>=0;var c=Nd();F()[a>>>2>>>0]=c.length;var d=0;c.forEach(e=>d+=e.length+1);F()[b>>>2>>>0]=d;return 0}function Wb(a){return n?S(21,1,a):52}function Xb(a,b,c,d){return n?S(22,1,a,b,c,d):52}function Yb(a,b,c,d){return n?S(23,1,a,b,c,d):70}
var Od=[null,[],[]];function Zb(a,b,c,d){if(n)return S(24,1,a,b,c,d);b>>>=0;c>>>=0;d>>>=0;for(var e=0,f=0;f<c;f++){var g=F()[b>>>2>>>0],k=F()[b+4>>>2>>>0];b+=8;for(var p=0;p<k;p++){var v=D()[g+p>>>0],x=Od[a];0===v||10===v?((1===a?qa:r)(yd(x)),x.length=0):x.push(v)}e+=k}F()[d>>>2>>>0]=e;return 0}function Sc(a){return a>>>0}n||fd();var Cd=[Tc,dd,wd,fb,gb,hb,ib,jb,kb,lb,mb,nb,ob,pb,qb,rb,Cb,Db,Eb,Tb,Ub,Wb,Xb,Yb,Zb],Va,H;
(async function(){function a(d,e){H=d.exports;H=Pd();ed.push(H.Eb);md=H.Cb;sa=e;Pa();return H}I++;var b=Ua();if(h.instantiateWasm)return new Promise(d=>{h.instantiateWasm(b,(e,f)=>{a(e,f);d(e.exports)})});if(n)return new Promise(d=>{Ca=e=>{var f=new WebAssembly.Instance(e,Ua());d(a(f,e))}});Qa??=h.locateFile?h.locateFile?h.locateFile("ort-wasm-simd-threaded.wasm",q):q+"ort-wasm-simd-threaded.wasm":(new URL("ort-wasm-simd-threaded.wasm",import.meta.url)).href;try{var c=await Ta(b);return a(c.instance,
c.module)}catch(d){return ca(d),Promise.reject(d)}})();h._OrtInit=(a,b)=>(h._OrtInit=H.$a)(a,b);h._OrtGetLastError=(a,b)=>(h._OrtGetLastError=H.ab)(a,b);h._OrtCreateSessionOptions=(a,b,c,d,e,f,g,k,p,v)=>(h._OrtCreateSessionOptions=H.bb)(a,b,c,d,e,f,g,k,p,v);h._OrtAppendExecutionProvider=(a,b)=>(h._OrtAppendExecutionProvider=H.cb)(a,b);h._OrtAddFreeDimensionOverride=(a,b,c)=>(h._OrtAddFreeDimensionOverride=H.db)(a,b,c);h._OrtAddSessionConfigEntry=(a,b,c)=>(h._OrtAddSessionConfigEntry=H.eb)(a,b,c);
h._OrtReleaseSessionOptions=a=>(h._OrtReleaseSessionOptions=H.fb)(a);h._OrtCreateSession=(a,b,c)=>(h._OrtCreateSession=H.gb)(a,b,c);h._OrtReleaseSession=a=>(h._OrtReleaseSession=H.hb)(a);h._OrtGetInputOutputCount=(a,b,c)=>(h._OrtGetInputOutputCount=H.ib)(a,b,c);h._OrtGetInputName=(a,b)=>(h._OrtGetInputName=H.jb)(a,b);h._OrtGetOutputName=(a,b)=>(h._OrtGetOutputName=H.kb)(a,b);h._OrtFree=a=>(h._OrtFree=H.lb)(a);h._OrtCreateTensor=(a,b,c,d,e,f)=>(h._OrtCreateTensor=H.mb)(a,b,c,d,e,f);
h._OrtGetTensorData=(a,b,c,d,e)=>(h._OrtGetTensorData=H.nb)(a,b,c,d,e);h._OrtReleaseTensor=a=>(h._OrtReleaseTensor=H.ob)(a);h._OrtCreateRunOptions=(a,b,c,d)=>(h._OrtCreateRunOptions=H.pb)(a,b,c,d);h._OrtAddRunConfigEntry=(a,b,c)=>(h._OrtAddRunConfigEntry=H.qb)(a,b,c);h._OrtReleaseRunOptions=a=>(h._OrtReleaseRunOptions=H.rb)(a);h._OrtCreateBinding=a=>(h._OrtCreateBinding=H.sb)(a);h._OrtBindInput=(a,b,c)=>(h._OrtBindInput=H.tb)(a,b,c);h._OrtBindOutput=(a,b,c,d)=>(h._OrtBindOutput=H.ub)(a,b,c,d);
h._OrtClearBoundOutputs=a=>(h._OrtClearBoundOutputs=H.vb)(a);h._OrtReleaseBinding=a=>(h._OrtReleaseBinding=H.wb)(a);h._OrtRunWithBinding=(a,b,c,d,e)=>(h._OrtRunWithBinding=H.xb)(a,b,c,d,e);h._OrtRun=(a,b,c,d,e,f,g,k)=>(h._OrtRun=H.yb)(a,b,c,d,e,f,g,k);h._OrtEndProfiling=a=>(h._OrtEndProfiling=H.zb)(a);var Fa=()=>(Fa=H.Ab)();h._free=a=>(h._free=H.Bb)(a);h._malloc=a=>(h._malloc=H.Db)(a);
var Ia=(a,b,c,d,e,f)=>(Ia=H.Fb)(a,b,c,d,e,f),Na=()=>(Na=H.Gb)(),cd=(a,b,c,d,e)=>(cd=H.Hb)(a,b,c,d,e),hd=a=>(hd=H.Ib)(a),nd=a=>(nd=H.Jb)(a),Gd=(a,b)=>(Gd=H.Kb)(a,b),Ad=()=>(Ad=H.Lb)(),V=(a,b)=>(V=H.Mb)(a,b),W=a=>(W=H.Nb)(a),kd=(a,b)=>(kd=H.Ob)(a,b),R=a=>(R=H.Pb)(a),bd=a=>(bd=H.Qb)(a),Q=()=>(Q=H.Rb)(),td=a=>(td=H.Sb)(a),rd=a=>(rd=H.Tb)(a),ud=(a,b,c)=>(ud=H.Ub)(a,b,c),sd=a=>(sd=H.Vb)(a);function Bc(a,b,c){var d=Q();try{T(a)(b,c)}catch(e){R(d);if(e!==e+0)throw e;V(1,0)}}
function hc(a,b,c){var d=Q();try{return T(a)(b,c)}catch(e){R(d);if(e!==e+0)throw e;V(1,0)}}function zc(a,b){var c=Q();try{T(a)(b)}catch(d){R(c);if(d!==d+0)throw d;V(1,0)}}function gc(a,b){var c=Q();try{return T(a)(b)}catch(d){R(c);if(d!==d+0)throw d;V(1,0)}}function jc(a,b,c,d){var e=Q();try{return T(a)(b,c,d)}catch(f){R(e);if(f!==f+0)throw f;V(1,0)}}function Fc(a,b,c,d,e){var f=Q();try{T(a)(b,c,d,e)}catch(g){R(f);if(g!==g+0)throw g;V(1,0)}}
function kc(a,b,c,d,e){var f=Q();try{return T(a)(b,c,d,e)}catch(g){R(f);if(g!==g+0)throw g;V(1,0)}}function Cc(a,b,c,d){var e=Q();try{T(a)(b,c,d)}catch(f){R(e);if(f!==f+0)throw f;V(1,0)}}function mc(a,b,c,d,e,f,g){var k=Q();try{return T(a)(b,c,d,e,f,g)}catch(p){R(k);if(p!==p+0)throw p;V(1,0)}}function yc(a){var b=Q();try{T(a)()}catch(c){R(b);if(c!==c+0)throw c;V(1,0)}}function uc(a,b,c){var d=Q();try{return T(a)(b,c)}catch(e){R(d);if(e!==e+0)throw e;V(1,0)}}
function Gc(a,b,c,d,e,f){var g=Q();try{T(a)(b,c,d,e,f)}catch(k){R(g);if(k!==k+0)throw k;V(1,0)}}function Qc(a,b,c){var d=Q();try{T(a)(b,c)}catch(e){R(d);if(e!==e+0)throw e;V(1,0)}}function Hc(a,b,c,d,e,f,g){var k=Q();try{T(a)(b,c,d,e,f,g)}catch(p){R(k);if(p!==p+0)throw p;V(1,0)}}function Ic(a,b,c,d,e,f,g,k){var p=Q();try{T(a)(b,c,d,e,f,g,k)}catch(v){R(p);if(v!==v+0)throw v;V(1,0)}}function lc(a,b,c,d,e,f){var g=Q();try{return T(a)(b,c,d,e,f)}catch(k){R(g);if(k!==k+0)throw k;V(1,0)}}
function nc(a,b,c,d,e,f,g,k){var p=Q();try{return T(a)(b,c,d,e,f,g,k)}catch(v){R(p);if(v!==v+0)throw v;V(1,0)}}function Kc(a,b,c,d,e,f,g,k,p,v){var x=Q();try{T(a)(b,c,d,e,f,g,k,p,v)}catch(z){R(x);if(z!==z+0)throw z;V(1,0)}}function Jc(a,b,c,d,e,f,g,k,p){var v=Q();try{T(a)(b,c,d,e,f,g,k,p)}catch(x){R(v);if(x!==x+0)throw x;V(1,0)}}function fc(a){var b=Q();try{return T(a)()}catch(c){R(b);if(c!==c+0)throw c;V(1,0)}}
function oc(a,b,c,d,e,f,g,k,p,v){var x=Q();try{return T(a)(b,c,d,e,f,g,k,p,v)}catch(z){R(x);if(z!==z+0)throw z;V(1,0)}}function cc(a,b,c){var d=Q();try{return T(a)(b,c)}catch(e){R(d);if(e!==e+0)throw e;V(1,0)}}function wc(a,b,c,d){var e=Q();try{return T(a)(b,c,d)}catch(f){R(e);if(f!==f+0)throw f;V(1,0);return 0n}}function $b(a,b,c){var d=Q();try{return T(a)(b,c)}catch(e){R(d);if(e!==e+0)throw e;V(1,0)}}
function Mc(a,b,c,d,e,f,g,k,p,v,x,z){var C=Q();try{T(a)(b,c,d,e,f,g,k,p,v,x,z)}catch(N){R(C);if(N!==N+0)throw N;V(1,0)}}function Lc(a,b,c,d,e,f,g,k,p,v,x){var z=Q();try{T(a)(b,c,d,e,f,g,k,p,v,x)}catch(C){R(z);if(C!==C+0)throw C;V(1,0)}}function pc(a,b,c,d,e,f,g,k,p,v,x){var z=Q();try{return T(a)(b,c,d,e,f,g,k,p,v,x)}catch(C){R(z);if(C!==C+0)throw C;V(1,0)}}function ic(a,b,c,d){var e=Q();try{return T(a)(b,c,d)}catch(f){R(e);if(f!==f+0)throw f;V(1,0)}}
function tc(a,b,c,d){var e=Q();try{return T(a)(b,c,d)}catch(f){R(e);if(f!==f+0)throw f;V(1,0)}}function dc(a,b,c,d){var e=Q();try{return T(a)(b,c,d)}catch(f){R(e);if(f!==f+0)throw f;V(1,0)}}function Oc(a,b,c,d,e,f,g,k,p,v,x,z,C,N){var aa=Q();try{T(a)(b,c,d,e,f,g,k,p,v,x,z,C,N)}catch(Ha){R(aa);if(Ha!==Ha+0)throw Ha;V(1,0)}}function Rc(a,b,c,d,e){var f=Q();try{T(a)(b,c,d,e)}catch(g){R(f);if(g!==g+0)throw g;V(1,0)}}function Ac(a,b,c){var d=Q();try{T(a)(b,c)}catch(e){R(d);if(e!==e+0)throw e;V(1,0)}}
function vc(a,b){var c=Q();try{return T(a)(b)}catch(d){R(c);if(d!==d+0)throw d;V(1,0);return 0n}}function rc(a,b,c,d,e){var f=Q();try{return T(a)(b,c,d,e)}catch(g){R(f);if(g!==g+0)throw g;V(1,0)}}function Nc(a,b,c,d,e,f,g,k,p,v,x,z,C){var N=Q();try{T(a)(b,c,d,e,f,g,k,p,v,x,z,C)}catch(aa){R(N);if(aa!==aa+0)throw aa;V(1,0)}}function ac(a,b,c,d){var e=Q();try{return T(a)(b,c,d)}catch(f){R(e);if(f!==f+0)throw f;V(1,0)}}
function xc(a,b,c,d,e){var f=Q();try{return T(a)(b,c,d,e)}catch(g){R(f);if(g!==g+0)throw g;V(1,0);return 0n}}function Pc(a,b,c,d,e){var f=Q();try{T(a)(b,c,d,e)}catch(g){R(f);if(g!==g+0)throw g;V(1,0)}}function ec(a,b,c,d,e){var f=Q();try{return T(a)(b,c,d,e)}catch(g){R(f);if(g!==g+0)throw g;V(1,0)}}function Ec(a,b,c,d,e){var f=Q();try{T(a)(b,c,d,e)}catch(g){R(f);if(g!==g+0)throw g;V(1,0)}}function bc(a,b,c,d,e){var f=Q();try{return T(a)(b,c,d,e)}catch(g){R(f);if(g!==g+0)throw g;V(1,0)}}
function Dc(a,b,c,d,e){var f=Q();try{T(a)(b,c,d,e)}catch(g){R(f);if(g!==g+0)throw g;V(1,0)}}function sc(a,b,c,d,e,f,g){var k=Q();try{return T(a)(b,c,d,e,f,g)}catch(p){R(k);if(p!==p+0)throw p;V(1,0)}}function qc(a,b,c,d,e,f,g){var k=Q();try{return T(a)(b,c,d,e,f,g)}catch(p){R(k);if(p!==p+0)throw p;V(1,0)}}function Pd(){var a=H;a=Object.assign({},a);var b=d=>()=>d()>>>0,c=d=>e=>d(e)>>>0;a.Ab=b(a.Ab);a.Db=c(a.Db);a.Qb=c(a.Qb);a.Rb=b(a.Rb);a.Vb=c(a.Vb);return a}h.stackSave=()=>Q();h.stackRestore=a=>R(a);
h.stackAlloc=a=>bd(a);h.setValue=function(a,b,c="i8"){c.endsWith("*")&&(c="*");switch(c){case "i1":A()[a>>>0]=b;break;case "i8":A()[a>>>0]=b;break;case "i16":Aa()[a>>>1>>>0]=b;break;case "i32":E()[a>>>2>>>0]=b;break;case "i64":y[a>>>3]=BigInt(b);break;case "float":Ba()[a>>>2>>>0]=b;break;case "double":G()[a>>>3>>>0]=b;break;case "*":F()[a>>>2>>>0]=b;break;default:K(`invalid type for setValue: ${c}`)}};
h.getValue=function(a,b="i8"){b.endsWith("*")&&(b="*");switch(b){case "i1":return A()[a>>>0];case "i8":return A()[a>>>0];case "i16":return Aa()[a>>>1>>>0];case "i32":return E()[a>>>2>>>0];case "i64":return y[a>>>3];case "float":return Ba()[a>>>2>>>0];case "double":return G()[a>>>3>>>0];case "*":return F()[a>>>2>>>0];default:K(`invalid type for getValue: ${b}`)}};h.UTF8ToString=Uc;h.stringToUTF8=X;
h.lengthBytesUTF8=a=>{for(var b=0,c=0;c<a.length;++c){var d=a.charCodeAt(c);127>=d?b++:2047>=d?b+=2:55296<=d&&57343>=d?(b+=4,++c):b+=3}return b};function Qd(){if(0<I)J=Qd;else if(n)ba(h),Oa();else{for(;0<Yc.length;)Yc.shift()(h);0<I?J=Qd:(h.calledRun=!0,ta||(Oa(),ba(h)))}}Qd();"use strict";h.PTR_SIZE=4;moduleRtn=da;


  return moduleRtn;
}
);
})();
export default ortWasmThreaded;
var isPthread = globalThis.self?.name?.startsWith('em-pthread');
var isNode = typeof globalThis.process?.versions?.node == 'string';
if (isNode) isPthread = (await import('worker_threads')).workerData === 'em-pthread';

// When running as a pthread, construct a new instance on startup
isPthread && ortWasmThreaded();

````
--- End of File: vibe-player/lib/ort-wasm-simd-threaded.mjs ---
--- File: vibe-player/lib/rubberband-loader.js ---
````javascript
// --- START OF FILE rubberband.js (Self-Contained Loader + Options) ---

// ** MODIFIED Emscripten Loader for AudioWorklet **
// Original source: Emscripten-generated loader for Rubberband library (@echogarden)
// Modifications:
// - Removed Node.js support, file loading, script path detection.
// - Executes via new Function(), expects WASM binary via moduleArg.wasmBinary.
// - Expects instantiation hook via moduleArg.instantiateWasm.
// - Includes RubberBandOptionFlag constants directly on the resolved Module object.
// - Removed 'export default'.
// - Structure adjusted to return the async loader function, not invoke it immediately.

var Rubberband = (() => { // Outer IIFE defines Rubberband scope

  // This async function is what the outer IIFE will return
  return (
    async function (moduleArg = {}) { // Accepts { wasmBinary, instantiateWasm, ... }
      var Module = moduleArg; // Use the provided argument object directly
      var moduleRtn;

      // --- Promise for readiness ---
      var readyPromiseResolve, readyPromiseReject;
      var readyPromise = new Promise((resolve, reject) => {
        readyPromiseResolve = resolve;
        readyPromiseReject = reject;
      });

      // --- Basic Environment (Assume Worker/Worklet like) ---
      var out = Module["print"] || console.log.bind(console);
      var err = Module["printErr"] || console.error.bind(console);

      // --- State ---
      var wasmMemory;
      var ABORT = false;
      var runtimeInitialized = false;
      var HEAP8, HEAPU8, HEAP16, HEAPU16, HEAP32, HEAPU32, HEAPF32, HEAPF64;

      function updateMemoryViews() {
        if (!wasmMemory) return; // Prevent errors if called too early
        var b = wasmMemory.buffer;
        Module["HEAP8"] = HEAP8 = new Int8Array(b); Module["HEAP16"] = HEAP16 = new Int16Array(b);
        Module["HEAPU8"] = HEAPU8 = new Uint8Array(b); Module["HEAPU16"] = HEAPU16 = new Uint16Array(b);
        Module["HEAP32"] = HEAP32 = new Int32Array(b); Module["HEAPU32"] = HEAPU32 = new Uint32Array(b);
        Module["HEAPF32"] = HEAPF32 = new Float32Array(b); Module["HEAPF64"] = HEAPF64 = new Float64Array(b);
      }

      // --- Lifecycle Callbacks ---
      var __ATINIT__ = []; var __ATPOSTRUN__ = [];
      function addOnInit(cb) { __ATINIT__.unshift(cb) }
      function addOnPostRun(cb) { __ATPOSTRUN__.unshift(cb) }
      function callRuntimeCallbacks(callbacks) { callbacks.forEach(f => f(Module)) };

      // --- Dependency Tracking (Simplified) ---
      var runDependencies = 0; var dependenciesFulfilled = null;
      function addRunDependency(id) { runDependencies++; }
      function removeRunDependency(id) {
        runDependencies--;
        if (runDependencies == 0 && dependenciesFulfilled) {
          var callback = dependenciesFulfilled; dependenciesFulfilled = null; callback();
        }
      }

      // --- Abort ---
      function abort(what) {
        Module["onAbort"]?.(what); what = "Aborted(" + what + ")"; err(what); ABORT = true;
        var e = new WebAssembly.RuntimeError(what); readyPromiseReject(e); throw e;
      }

      // --- WASM Instantiation ---
      var wasmExports;
      function createWasm() {
        // NOTE: 'a' is the expected import object name, 'n' is memory, 'o' is init func.
        // These might change if rubberband.wasm is rebuilt with different settings.
        var info = { a: wasmImports };

        function receiveInstance(instance, module) {
          wasmExports = instance.exports;
          wasmMemory = wasmExports["n"]; // Hardcoded memory export name
          updateMemoryViews();
          addOnInit(wasmExports["o"]); // Hardcoded init function export name
          removeRunDependency("wasm-instantiate");
          return wasmExports;
        }

        addRunDependency("wasm-instantiate");

        if (Module["instantiateWasm"]) {
          try {
            var exports = Module["instantiateWasm"](info, receiveInstance);
            // Handle potential sync return (less likely for WASM)
            if (exports instanceof WebAssembly.Instance) { receiveInstance(exports); }
          } catch (e) {
            err(`Module.instantiateWasm callback failed with error: ${e}`);
            readyPromiseReject(e);
          }
        } else {
          var missingHookError = new Error("Fatal error: 'instantiateWasm' hook not provided to the WASM loader module.");
          err(missingHookError.message); readyPromiseReject(missingHookError); return {};
        }
        return {}; // Required for async preparation
      }

       // --- Minimal Stubs needed *before* assignExports/runtime ---
       // Need a *basic* UTF8ToString for error reporting during init
       const _UTF8ToString_stub = (ptr) => {
           if (!ptr || !HEAPU8) return ""; let str = ''; let i = ptr;
           while (HEAPU8[i] && i < ptr + 1024) { // Limit length for safety
              str += String.fromCharCode(HEAPU8[i++]);
           } return str;
       };
       const ___assert_fail = (condition, filename, line, func) => { abort(`Assertion failed: ${_UTF8ToString_stub(condition)}`) };
       const ___cxa_throw = (ptr, type, destructor) => { abort(`Exception thrown from WASM: ptr=${ptr} type=${type}`) };
       const __abort_js = () => { abort("") };
       const __emscripten_memcpy_js = (dest, src, num) => HEAPU8?.copyWithin(dest, src, src + num); // Check HEAPU8 exists
       const _emscripten_date_now = () => Date.now();
       const _emscripten_resize_heap = requestedSize => { err("_emscripten_resize_heap called - Not implemented."); return false; };
       const _environ_get = (__environ, environ_buf) => 0;
       const _environ_sizes_get = (penviron_count, penviron_buf_size) => { HEAPU32[penviron_count>>2]=0; HEAPU32[penviron_buf_size>>2]=0; return 0; };
       const __tzset_js = () => {};
       const _fd_close = (fd) => 0;
       const _fd_read = (fd, iov, iovcnt, pnum) => { HEAPU32[pnum >> 2] = 0; return 0; };
       const _fd_seek = (fd, offset_low, offset_high, whence, newOffset) => { HEAP32[newOffset>>2]=0; HEAP32[newOffset+4>>2]=0; return 0; };
       const _fd_write = (fd, iov, iovcnt, pnum) => { // Basic logging stub
         let num = 0; try { for (let i = 0; i < iovcnt; i++) { let ptr = HEAPU32[iov >> 2]; let len = HEAPU32[iov + 4 >> 2]; iov += 8; let str = _UTF8ToString_stub(ptr); /* Basic ASCII ok for debug */ if (fd === 1) out(str); else err(str); num += len; } HEAPU32[pnum >> 2] = num; } catch(e) { /* ignore errors during logging */ } return 0;
       };

      // --- Stack variables (will be assigned in assignExports) ---
      var stackSave, stackRestore, stackAlloc, __emscripten_stack_alloc, __emscripten_stack_restore, _emscripten_stack_get_current;

      // --- WASM Imports Object ---
      // These keys ('a', 'b', 'c'...) MUST match what rubberband.wasm expects.
      var wasmImports = {
        b: ___assert_fail, a: ___cxa_throw, j: __abort_js, i: __emscripten_memcpy_js,
        l: __tzset_js, h: _emscripten_date_now, e: _emscripten_resize_heap,
        m: _environ_get, d: _environ_sizes_get, f: _fd_close, g: _fd_read,
        k: _fd_seek, c: _fd_write,
        // Add other imports if rubberband.wasm requires them (check browser console errors)
      };

      // --- Runtime Initialization ---
      function initRuntime() { runtimeInitialized = true; callRuntimeCallbacks(__ATINIT__); }
      function postRun() { callRuntimeCallbacks(__ATPOSTRUN__); }

      // --- Main Execution Logic ---
      var calledRun;
      dependenciesFulfilled = function runCaller() { if (!calledRun) run(); if (!calledRun) dependenciesFulfilled = runCaller; };
      function run() {
        if (runDependencies > 0) return; // Wait for WASM etc.
        // No preRun needed unless user adds callbacks
        if (calledRun) return; calledRun = true; Module["calledRun"] = true;
        if (ABORT) return;
        initRuntime(); // Calls __ATINIT__ (which includes assignExports)
        readyPromiseResolve(Module); // Resolve the main promise HERE
        Module["onRuntimeInitialized"]?.();
        postRun();
      }

      // --- assignExports Function (Called via __ATINIT__) ---
      function assignExports() {
        if (!wasmExports) { console.error("WASM Exports not available during assignExports!"); abort("WASM exports missing"); return; }

        // Define helpers *locally* within this scope
        updateMemoryViews(); // Ensure HEAP views are ready

        const getValue = (ptr,type="i8")=>{ /* ... as in previous correct version ... */ if(!HEAPU8) return 0; if(type.endsWith("*"))type="*"; switch(type){ case"i1":return HEAP8[ptr]; case"i8":return HEAP8[ptr]; case"i16":return HEAP16[ptr>>1]; case"i32":return HEAP32[ptr>>2]; case"i64":abort("getValue(i64)"); return 0; case"float":return HEAPF32[ptr>>2]; case"double":return HEAPF64[ptr>>3]; case"*":return HEAPU32[ptr>>2]; default:abort(`invalid type for getValue: ${type}`); return 0;} };
        const setValue = (ptr,value,type="i8")=>{ /* ... as in previous correct version ... */ if(!HEAPU8) return; if(type.endsWith("*"))type="*"; switch(type){ case"i1":HEAP8[ptr]=value;break; case"i8":HEAP8[ptr]=value;break; case"i16":HEAP16[ptr>>1]=value;break; case"i32":HEAP32[ptr>>2]=value;break; case"i64":abort("setValue(i64)"); break; case"float":HEAPF32[ptr>>2]=value;break; case"double":HEAPF64[ptr>>3]=value;break; case"*":HEAPU32[ptr>>2]=value;break; default:abort(`invalid type for setValue: ${type}`);}};
        const UTF8Decoder = typeof TextDecoder!="undefined"?new TextDecoder('utf8'):undefined;
        const UTF8ArrayToString = (heapOrArray, idx = 0, maxBytesToRead = Infinity)=>{ /* ... as in previous correct version ... */ var endIdx = Math.min(idx + maxBytesToRead, heapOrArray.length); var endPtr = idx; while (heapOrArray[endPtr] && endPtr < endIdx) ++endPtr; if (endPtr - idx > 16 && heapOrArray.buffer && UTF8Decoder) { return UTF8Decoder.decode(heapOrArray.subarray(idx, endPtr)); } else { var str = "";while(idx<endPtr){var u0=heapOrArray[idx++];if(!(u0&128)){str+=String.fromCharCode(u0);continue}var u1=heapOrArray[idx++]&63;if((u0&224)==192){str+=String.fromCharCode((u0&31)<<6|u1);continue}var u2=heapOrArray[idx++]&63;if((u0&240)==224){u0=(u0&15)<<12|u1<<6|u2}else{u0=(u0&7)<<18|u1<<12|u2<<6|heapOrArray[idx++]&63}if(u0<0x10000){str+=String.fromCharCode(u0)}else{var ch=u0-0x10000;str+=String.fromCharCode(0xD800|(ch>>10),0xDC00|(ch&0x3FF))}}return str; }};
        const UTF8ToString = (ptr, maxBytesToRead) => ptr ? UTF8ArrayToString(HEAPU8, ptr, maxBytesToRead) : "";
        const stringToUTF8Array = (str, heap, outIdx, maxBytesToWrite)=>{ /* ... as in previous correct version ... */ if(!(maxBytesToWrite>0))return 0;var startIdx=outIdx;var endIdx=outIdx+maxBytesToWrite-1;for(var i=0;i<str.length;++i){var u=str.charCodeAt(i);if(u>=0xD800&&u<=0xDFFF){var u1=str.charCodeAt(++i);u=0x10000+((u&0x3FF)<<10)|(u1&0x3FF)}if(u<=0x7F){if(outIdx>=endIdx)break;heap[outIdx++]=u}else if(u<=0x7FF){if(outIdx+1>=endIdx)break;heap[outIdx++]=0xC0|(u>>6);heap[outIdx++]=0x80|(u&63)}else if(u<=0xFFFF){if(outIdx+2>=endIdx)break;heap[outIdx++]=0xE0|(u>>12);heap[outIdx++]=0x80|((u>>6)&63);heap[outIdx++]=0x80|(u&63)}else{if(outIdx+3>=endIdx)break;heap[outIdx++]=0xF0|(u>>18);heap[outIdx++]=0x80|((u>>12)&63);heap[outIdx++]=0x80|((u>>6)&63);heap[outIdx++]=0x80|(u&63)}}heap[outIdx]=0;return outIdx-startIdx;};
        const stringToUTF8 = (str, outPtr, maxBytesToWrite) => stringToUTF8Array(str, HEAPU8, outPtr, maxBytesToWrite);
        const lengthBytesUTF8 = str => { /* ... as in previous correct version ... */ let len = 0; for (let i = 0; i < str.length; ++i) { let c = str.charCodeAt(i); if (c <= 0x7F) { len++; } else if (c <= 0x7FF) { len += 2; } else if (c >= 0xD800 && c <= 0xDFFF) { len += 4; ++i; } else { len += 3; } } return len; };

        // Assign mapped WASM functions to Module object
        // Using the export names ('q', 'r', etc.) presumed from previous attempts
        Module["_free"] = wasmExports["q"]; Module["_malloc"] = wasmExports["V"];
        Module["_rubberband_new"] = wasmExports["r"]; Module["_rubberband_delete"] = wasmExports["s"];
        Module["_rubberband_reset"] = wasmExports["t"]; Module["_rubberband_get_engine_version"] = wasmExports["u"];
        Module["_rubberband_set_time_ratio"] = wasmExports["v"]; Module["_rubberband_set_pitch_scale"] = wasmExports["w"];
        Module["_rubberband_get_time_ratio"] = wasmExports["x"]; Module["_rubberband_get_pitch_scale"] = wasmExports["y"];
        Module["_rubberband_set_formant_scale"] = wasmExports["z"]; Module["_rubberband_get_formant_scale"] = wasmExports["A"];
        Module["_rubberband_get_preferred_start_pad"] = wasmExports["B"]; Module["_rubberband_get_start_delay"] = wasmExports["C"];
        Module["_rubberband_get_latency"] = wasmExports["D"]; Module["_rubberband_set_transients_option"] = wasmExports["E"];
        Module["_rubberband_set_detector_option"] = wasmExports["F"]; Module["_rubberband_set_phase_option"] = wasmExports["G"];
        Module["_rubberband_set_formant_option"] = wasmExports["H"]; Module["_rubberband_set_pitch_option"] = wasmExports["I"];
        Module["_rubberband_set_expected_input_duration"] = wasmExports["J"]; Module["_rubberband_get_samples_required"] = wasmExports["K"];
        Module["_rubberband_set_max_process_size"] = wasmExports["L"]; Module["_rubberband_set_key_frame_map"] = wasmExports["M"];
        Module["_rubberband_study"] = wasmExports["N"]; Module["_rubberband_process"] = wasmExports["O"];
        Module["_rubberband_available"] = wasmExports["P"]; Module["_rubberband_retrieve"] = wasmExports["Q"];
        Module["_rubberband_get_channel_count"] = wasmExports["R"]; Module["_rubberband_calculate_stretch"] = wasmExports["S"];
        Module["_rubberband_set_debug_level"] = wasmExports["T"]; Module["_rubberband_set_default_debug_level"] = wasmExports["U"];

        // Assign Stack functions (CRITICAL)
        __emscripten_stack_alloc = wasmExports["X"]; __emscripten_stack_restore = wasmExports["W"];
        _emscripten_stack_get_current = wasmExports["Y"];
        stackSave = _emscripten_stack_get_current; stackRestore = __emscripten_stack_restore; stackAlloc = __emscripten_stack_alloc;
        Module["stackSave"] = stackSave; Module["stackRestore"] = stackRestore; Module["stackAlloc"] = stackAlloc;

        // Assign locally defined helpers to Module object
        Module["getValue"] = getValue; Module["setValue"] = setValue; Module["UTF8ToString"] = UTF8ToString;
        Module["stringToUTF8"] = stringToUTF8; Module["lengthBytesUTF8"] = lengthBytesUTF8;

        // *** ADD RUBBERBAND OPTIONS FLAGS ***
        Module.RubberBandOptionFlag = {
            ProcessOffline: 0x00000000, ProcessRealTime: 0x00000001,
            StretchElastic: 0x00000000, StretchPrecise: 0x00000010,
            TransientsCrisp: 0x00000000, TransientsMixed: 0x00000100, TransientsSmooth: 0x00000200,
            DetectorCompound: 0x00000000, DetectorPercussive: 0x00000400, DetectorSoft: 0x00000800,
            PhaseLaminar: 0x00000000, PhaseIndependent: 0x00002000,
            ThreadingAuto: 0x00000000, ThreadingNever: 0x00010000, ThreadingAlways: 0x00020000,
            WindowStandard: 0x00000000, WindowShort: 0x00100000, WindowLong: 0x00200000,
            SmoothingOff: 0x00000000, SmoothingOn: 0x00800000,
            FormantShifted: 0x00000000, FormantPreserved: 0x01000000,
            PitchHighSpeed: 0x00000000, PitchHighQuality: 0x02000000, PitchHighConsistency: 0x04000000,
            ChannelsApart: 0x00000000, ChannelsTogether: 0x10000000,
            EngineFaster: 0x00000000, EngineFiner: 0x20000000,
            // Add presets too if desired
            // DefaultOptions: 0x00000000, PercussiveOptions: 0x00102000,
            // Convenience aliases from your example (might be slightly different from direct enum names)
            EngineDefault: 0, // Alias for EngineFaster
            // PitchHighQuality: 0x02000000, // Already defined above
        };
         // Make sure the specific options used in the processor are available
         // These are just copies/aliases for clarity if the names differ slightly.
         Module.RubberbandOptions = Module.RubberBandOptionFlag; // Alias the whole object

      } // End assignExports

      // --- Start the process ---
      addOnInit(assignExports); // Queue exports assignment
      createWasm(); // Start WASM loading (async)

      moduleRtn = readyPromise;
      return moduleRtn; // Return the promise that resolves with the Module object
    }
  ) // <--- Inner async function is RETURNED, not invoked here
})(); // Outer IIFE is invoked immediately

// NO export default
// --- END OF FILE rubberband.js ---

````
--- End of File: vibe-player/lib/rubberband-loader.js ---
--- File: vibe-player/README.md ---
````markdown
<!-- /vibe-player/README.md -->
# Vibe Player

A simple, browser-based audio player designed for analyzing and manipulating audio files, inspired by classic desktop application aesthetics. It runs entirely client-side using static files.

## Features

*   Load local audio files (common formats supported by browser `decodeAudioData`).
*   Real-time playback control (Play, Pause, Seek).
*   Adjust playback Speed (0.25x - 2.0x) using Rubberband WASM.
*   Adjust playback Pitch (0.25x - 2.0x) using Rubberband WASM.
*   Adjust playback Gain (Volume Boost up to 5x).
*   Voice Activity Detection (VAD) using Silero VAD model (ONNX Runtime):
    *   Displays VAD progress during analysis.
    *   Highlights detected speech segments on the waveform.
    *   Allows tuning VAD thresholds (Positive/Negative) after initial analysis.
*   Visualizations:
    *   Real-time Waveform display.
    *   Spectrogram display.
*   Keyboard shortcuts for common actions (visible in the application UI).

## Usage

1.  Serve the project files using a simple static file server (e.g., `python -m http.server` or VS Code Live Server). The server should be run from the `vibe-player` directory.
2.  Open `index.html` in your web browser (Chrome/Edge/Firefox recommended).
3.  Click "Choose File..." and select an audio file.
4.  Wait for the initial processing (decoding, visuals). The waveform and spectrogram will appear.
5.  Playback controls (Play, Seek, Speed, Pitch, Gain) become active once the audio engine is ready.
6.  VAD processing runs in the background. Its progress is shown, and waveform highlights appear upon completion. VAD tuning sliders become active then.
7.  Use the controls or click on the waveform/spectrogram to interact.

## Controls

*   **Choose File...:** Select a local audio file.
*   **Speed Slider:** Adjust playback speed (0.25x - 2.0x).
*   **Pitch Slider:** Adjust playback pitch scale (0.25x - 2.0x).
*   **Gain Slider:** Adjust output volume boost (1x - 5x).
*   **Play/Pause Button:** Toggle playback.
*   **Back/Forward Buttons & Input:** Jump backward or forward by the specified number of seconds.
*   **Seek Bar / Time Display:** Shows current position / total duration. Click or drag seek bar to jump.
*   **Waveform/Spectrogram:** Click to seek to that position.
*   **VAD Threshold Sliders:** (Enabled after VAD) Adjust positive/negative thresholds to re-evaluate speech segments based on the initial analysis probabilities.
*   **(Keyboard Shortcuts are listed within the application UI)**

## Developer Notes

*   **Static Environment:** This application is designed to run entirely client-side without any build steps or server-side logic. See `architecture.md` for details.
*   **Dependencies:** Requires ONNX Runtime Web (`ort.min.js`), FFT.js, and Rubberband WASM (`rubberband.wasm`, `rubberband-loader.js`). These are included in the `/lib/` directory.
*   **Code Structure:** Uses Vanilla JS (ES6) with an IIFE module pattern. See `architecture.md`.

## Contributing / LLM Collaboration

Development involving LLM assistance should follow the guidelines outlined in `CONTRIBUTING-LLM.md`. Please ensure this file is loaded into the LLM's context before starting work. If the file is missing, please request it.
<!-- /vibe-player/README.md -->

````
--- End of File: vibe-player/README.md ---
--- File: vibe-player/REFACTOR.md ---
````markdown
# Vibe Player - Refactoring and Enhancement Plan

This document outlines proposed refactoring tasks, feature enhancements (some derived from `TODO.md`), and general code health improvements for the Vibe Player project. The goal is to enhance performance, modularity, user experience, and maintainability.

## Theme 1: Performance & Responsiveness (Offloading to Web Workers)

### 1.1. Implement VAD Processing in a Web Worker
*   **Goal:** Move Silero VAD model inference and associated audio processing (resampling if specific to VAD, frame iteration) to a Web Worker.
*   **Description/Rationale:** VAD analysis, especially on longer audio files, can be computationally intensive and block the main thread, leading to UI sluggishness. Offloading to a worker will improve UI responsiveness. Addresses "VAD Worker" TODO.
*   **Affected Components:**
    *   `vibe-player/js/vad/sileroWrapper.js`
    *   `vibe-player/js/vad/sileroProcessor.js`
    *   `vibe-player/js/vad/vadAnalyzer.js`
    *   `vibe-player/js/app.js` (orchestration)
    *   `vibe-player/js/player/audioEngine.js` (for resampling, if worker needs raw data)
*   **Proposed Action/Implementation Steps:**
    1.  Create `vad.worker.js` that will host `sileroWrapper` and `sileroProcessor` logic.
    2.  Modify `sileroWrapper` and `sileroProcessor` to operate with message passing for audio data input and VAD results output.
    3.  Update `vadAnalyzer.js` to manage communication (postMessage/onmessage) with `vad.worker.js`.
    4.  `app.js` will initiate VAD processing via `vadAnalyzer` and receive results asynchronously.
    5.  Handle ONNX model and library loading within the worker context (e.g., `importScripts` for `ort.min.js`).
    6.  Ensure resampling to 16kHz mono is handled efficiently, either in `audioEngine` before sending to worker or within the worker if it receives the full `AudioBuffer`.
*   **(Optional) Related TODOs:** "VAD Worker: Move VAD to a worker thread to prevent UI freezes."

### 1.2. Offload Waveform Data Computation to a Web Worker
*   **Goal:** Move the computation of waveform visual data (peak values for drawing) to a Web Worker.
*   **Description/Rationale:** For very long audio files, iterating through the entire `AudioBuffer` to compute min/max samples per pixel can be time-consuming and delay the initial display or cause jank during resizing.
*   **Affected Components:**
    *   `vibe-player/js/visualizers/waveformVisualizer.js`
    *   `vibe-player/js/app.js` (if orchestration changes)
*   **Proposed Action/Implementation Steps:**
    1.  Create `waveform.worker.js`.
    2.  Transfer `AudioBuffer` data (or relevant channel data) to the worker.
    3.  The worker computes the array of min/max values or the points for the path and sends it back to `waveformVisualizer.js`.
    4.  `waveformVisualizer.js` then focuses only on rendering the pre-computed data.
*   **(Optional) Related TODOs:** "Visualizer Worker: Waveform + Spectrogram processing in worker?" (partially addresses)

### 1.3. Offload Spectrogram FFT Computation to a Web Worker
*   **Goal:** Move the FFT computation for the spectrogram to a Web Worker.
*   **Description/Rationale:** FFT calculation across the entire audio duration is a significant computational load. Offloading will prevent UI freezes during initial spectrogram generation.
*   **Affected Components:**
    *   `vibe-player/js/visualizers/spectrogramVisualizer.js`
    *   `vibe-player/lib/fft.js` (or its usage)
*   **Proposed Action/Implementation Steps:**
    1.  Create `spectrogram.worker.js`.
    2.  Transfer `AudioBuffer` data to the worker.
    3.  The worker performs all FFT calculations (potentially in chunks) and sends back the spectrogram data (e.g., magnitude arrays) for rendering.
    4.  `spectrogramVisualizer.js` receives this data and handles drawing to the canvas.
*   **(Optional) Related TODOs:** "Visualizer Worker: Waveform + Spectrogram processing in worker?" (partially addresses)

### 1.4. Investigate Progressive Spectrogram Computation/Rendering
*   **Goal:** Improve perceived performance of spectrogram display by rendering it progressively as data is computed.
*   **Description/Rationale:** Instead of waiting for the entire spectrogram to be computed before drawing, display chunks as they become available. This would be particularly beneficial if full worker offloading (1.3) is complex or has large data transfer overhead for the complete result.
*   **Affected Components:**
    *   `vibe-player/js/visualizers/spectrogramVisualizer.js`
    *   (Potentially) `spectrogram.worker.js` if implemented.
*   **Proposed Action/Implementation Steps:**
    1.  Modify `spectrogramVisualizer.js` (and worker, if applicable) to process the audio in segments.
    2.  After each segment's FFT data is ready, send it back to the main thread and draw that portion of the spectrogram.
    3.  Provide visual feedback that computation is ongoing.
*   **(Optional) Related TODOs:** "Visualizer: Progressive Spectrogram: Compute/draw in chunks to show progress."

## Theme 2: State Management & Modularity

### 2.1. Introduce a Dedicated State Management Module
*   **Goal:** Centralize and manage shared application state more formally, reducing direct state manipulation in `app.js` and improving predictability.
*   **Description/Rationale:** Currently, `app.js` holds much of the core state (`currentAudioBuffer`, `workletPlaybackReady`, VAD results, etc.). A dedicated module could use a simple pub/sub model or a more structured approach (like a simplified Redux-like store) for state updates and notifications.
*   **Affected Components:**
    *   `vibe-player/js/app.js` (major refactor)
    *   All modules that currently read/write state directly from/to `app.js` (e.g., `uiManager.js`, `audioEngine.js`, `vadAnalyzer.js`).
*   **Proposed Action/Implementation Steps:**
    1.  Design a simple state store (e.g., `stateStore.js`) with methods like `getState()`, `setState()`, `subscribe()`.
    2.  Identify core shared state variables.
    3.  Refactor `app.js` and other modules to interact with `stateStore.js` for state changes and reads.
    4.  Use subscriptions to trigger UI updates or dependent logic.
*   **(Optional) Related TODOs:** "State: Central state management (event bus or simple store)."

### 2.2. Refactor `app.js` for Better Modularity
*   **Goal:** Reduce the size and complexity of `app.js` by delegating more responsibilities to specialized modules.
*   **Description/Rationale:** `app.js` currently handles a wide range of tasks (initialization, event handling for UI and audio engine, VAD orchestration, tone detection orchestration, time display). Breaking this down will improve maintainability.
*   **Affected Components:**
    *   `vibe-player/js/app.js` (major refactor)
    *   Potentially create new modules for specific orchestrations (e.g., `analysisCoordinator.js` for VAD/Tones).
*   **Proposed Action/Implementation Steps:**
    1.  Identify distinct responsibilities within `app.js`.
    2.  Consider moving VAD and Tone detection orchestration logic into a new module (e.g., `analysisOrchestrator.js`) that `app.js` calls.
    3.  Ensure event handling is clearly delineated, perhaps with more focused handlers or sub-modules.
    4.  If a state store (2.1) is implemented, `app.js` would become more of a central coordinator of modules and less of a state container.

## Theme 3: UI/UX Enhancements & Features

### 3.1. Implement Enhanced Error Handling UI
*   **Goal:** Provide more specific and user-friendly error messages and recovery options.
*   **Description/Rationale:** Current error handling is often via `console.error` or generic alerts. A dedicated UI component for errors would improve UX.
*   **Affected Components:**
    *   `vibe-player/js/uiManager.js`
    *   Error-prone areas in `audioEngine.js`, `sileroWrapper.js`, `app.js`.
*   **Proposed Action/Implementation Steps:**
    1.  Design a non-intrusive UI element for displaying errors (e.g., a toast notification, a modal, or a dedicated error panel).
    2.  Categorize common errors (e.g., file load/decode, VAD model load, audio processing).
    3.  Implement a global error handling function or service that `uiManager.js` can use to display formatted error messages.
    4.  Provide context-specific recovery actions where possible (e.g., "Try another file?").
*   **(Optional) Related TODOs:** "Error Handling: More specific error messages + UI display (not just console/alert)."

### 3.2. Add VAD Probability Graph / Enhanced Tuning UI
*   **Goal:** Visualize VAD probabilities over time and provide a more intuitive interface for tuning VAD thresholds.
*   **Description/Rationale:** Currently, VAD tuning is done with sliders after processing. Seeing the probability curve could help users set thresholds more effectively.
*   **Affected Components:**
    *   `vibe-player/js/uiManager.js`
    *   `vibe-player/js/vad/vadAnalyzer.js` (to expose probability data)
    *   `vibe-player/js/vad/sileroProcessor.js` (to collect/store detailed probabilities)
    *   New visualization component.
*   **Proposed Action/Implementation Steps:**
    1.  Modify `sileroProcessor.js` to store or stream frame-by-frame VAD probabilities.
    2.  Expose this data via `vadAnalyzer.js`.
    3.  Create a new canvas-based component in `uiManager.js` to draw the probability curve, aligning it with the waveform.
    4.  Allow users to drag threshold lines directly on this graph, or link sliders to update lines on the graph.
*   **(Optional) Related TODOs:** "VAD UI: Graph of VAD probabilities to help threshold tuning."

### 3.3. Implement "Back to Start" and Control Reset Buttons
*   **Goal:** Add UI buttons for quickly jumping to the start of the audio and resetting all playback/VAD controls to their default values.
*   **Description/Rationale:** Improves usability for common actions.
*   **Affected Components:**
    *   `vibe-player/js/uiManager.js` (new buttons and event listeners)
    *   `vibe-player/js/app.js` (handlers for these actions)
    *   `vibe-player/js/player/audioEngine.js` (for seek to 0)
    *   `vibe-player/js/vad/vadAnalyzer.js` (for resetting VAD thresholds)
*   **Proposed Action/Implementation Steps:**
    1.  Add "Back to Start" (seek to 0) and "Reset Controls" buttons to `index.html`.
    2.  In `uiManager.js`, add event listeners for these buttons, dispatching appropriate events.
    3.  In `app.js`, handle these events:
        *   For "Back to Start": Call `audioEngine.seek(0)`.
        *   For "Reset Controls": Reset speed, pitch, gain sliders/values to default; reset VAD thresholds in `vadAnalyzer` and update UI.
*   **(Optional) Related TODOs:** "UI: 'Back to Start' button.", "UI: 'Reset Controls' button (speed, pitch, gain, VAD thresholds)."

### 3.4. Implement Windows 98 Style UI Sounds
*   **Goal:** Add auditory feedback for UI interactions, mimicking classic Windows 98 UI sounds for a nostalgic feel.
*   **Description/Rationale:** Enhances the "98.css" aesthetic and provides user feedback.
*   **Affected Components:**
    *   `vibe-player/js/uiManager.js`
    *   New audio assets for UI sounds.
*   **Proposed Action/Implementation Steps:**
    1.  Source or create short, appropriate UI sound effects (e.g., click, error, notification).
    2.  In `uiManager.js`, preload these sounds.
    3.  Attach `play()` calls for these sounds to relevant UI event handlers (button clicks, slider changes, errors).
    4.  Ensure sounds are subtle and can be optionally disabled if a settings panel is implemented later.
*   **(Optional) Related TODOs:** "UI Sounds: Add Win98 style UI sounds for interactions."

### 3.5. Advanced Player Controls & Keybinds (Further Investigation)
*   **Goal:** Implement more granular controls (e.g., frame-by-frame stepping) and customizable keybinds.
*   **Description/Rationale:** Offers more power to users for detailed audio analysis.
*   **Affected Components:**
    *   `vibe-player/js/uiManager.js`
    *   `vibe-player/js/app.js`
    *   `vibe-player/js/player/audioEngine.js`
*   **Proposed Action/Implementation Steps:**
    1.  Investigate feasibility of precise frame-stepping with current `AudioEngine` and Rubberband.
    2.  Design UI for new controls if feasible.
    3.  Implement logic for new playback actions.
    4.  Design a system for managing and customizing keyboard shortcuts (potentially stored in `localStorage`).
*   **(Optional) Related TODOs:** "Advanced Controls: Frame-by-frame step (investigate feasibility).", "Keybinds: Customizable keyboard shortcuts."

### 3.6. Implement Preset Management
*   **Goal:** Allow users to save and load sets of playback and VAD parameters as named presets.
*   **Description/Rationale:** Useful for users who frequently switch between different analysis settings.
*   **Affected Components:**
    *   `vibe-player/js/uiManager.js` (UI for preset management)
    *   `vibe-player/js/app.js` (logic for saving/loading presets)
    *   Potentially `localStorage` for storing presets.
*   **Proposed Action/Implementation Steps:**
    1.  Design UI for saving current settings (speed, pitch, gain, VAD thresholds) as a named preset, and for listing/loading saved presets.
    2.  Implement functions in `app.js` to get current parameters, store them (e.g., as JSON in `localStorage`), and apply stored parameters.
    3.  Update `uiManager.js` to reflect loaded preset values.
*   **(Optional) Related TODOs:** "Presets: Save/Load settings (speed, pitch, gain, VAD thresholds)."

## Theme 4: Audio Processing Enhancements & Fixes

### 4.1. Investigate/Address Formant Shift Non-Functionality
*   **Goal:** Determine why formant shifting has no audible effect and either fix it or remove the UI element.
*   **Description/Rationale:** The formant shift control is currently implemented but does not appear to change the audio output. This needs investigation.
*   **Affected Components:**
    *   `vibe-player/js/player/rubberbandProcessor.js`
    *   `vibe-player/js/player/audioEngine.js`
    *   `vibe-player/js/uiManager.js` (if UI needs to be removed/changed)
*   **Proposed Action/Implementation Steps:**
    1.  Deep-dive into Rubberband WASM documentation and examples regarding formant shifting.
    2.  Verify the `_rubberband_set_formant_scale` call and its parameters are correctly used.
    3.  Test with various audio files and formant scale values.
    4.  If a fix is found, ensure it integrates correctly.
    5.  If it's confirmed non-functional with the current WASM build or too complex to fix, remove the formant slider from the UI.
*   **(Optional) Related TODOs:** Referenced in `architecture.md` known issues.

### 4.2. Investigate Parameter Smoothing for Speed/Pitch
*   **Goal:** Explore options for smoother transitions when changing playback speed and pitch, reducing abrupt audio changes.
*   **Description/Rationale:** Rapid changes to speed/pitch sliders can cause somewhat jarring audio output. Rubberband might have internal smoothing options, or this could be implemented in `audioEngine.js` by ramping parameter values sent to the worklet.
*   **Affected Components:**
    *   `vibe-player/js/player/audioEngine.js`
    *   `vibe-player/js/player/rubberbandProcessor.js`
*   **Proposed Action/Implementation Steps:**
    1.  Review Rubberband library options for parameter change smoothing.
    2.  If not available externally, implement ramping logic in `audioEngine.js` to gradually change speed/pitch values over a short duration (e.g., 50-100ms) when slider values are adjusted.
    3.  Test for perceived smoothness.

## Theme 5: Code Quality & Testability

### 5.1. Plan for Automated Testing
*   **Goal:** Improve code robustness and reduce regression risk by introducing an automated testing strategy.
*   **Description/Rationale:** Currently, testing is manual. Automated tests (unit, integration) would provide a safety net for refactoring and new feature development.
*   **Affected Components:** Entire codebase.
*   **Proposed Action/Implementation Steps:**
    1.  Choose a testing framework (e.g., Jest, Mocha).
    2.  Start by writing unit tests for utility functions (`utils.js`, `goertzel.js`) and core logic in modules like `vadAnalyzer.js`, `audioEngine.js` (mocking Web Audio API where necessary).
    3.  Investigate options for integration testing of UI interactions and audio processing pipeline (might require tools like Puppeteer or Playwright for browser environment).
    4.  Set up CI (e.g., GitHub Actions) to run tests automatically.
*   **(Optional) Related TODOs:** "Testing: Implement unit/integration tests."

### 5.2. General Code Cleanup During Refactoring
*   **Goal:** Improve overall code clarity, consistency, and maintainability as other refactoring tasks are undertaken.
*   **Description/Rationale:** Address any minor code smells, inconsistencies, or areas lacking clarity that are encountered during the implementation of the above themes.
*   **Affected Components:** Entire codebase.
*   **Proposed Action/Implementation Steps:**
    1.  While working on specific refactoring tasks, also address:
        *   Inconsistent naming conventions.
        *   Lack of comments for complex logic.
        *   Opportunities to simplify functions or reduce redundancy.
        *   Ensuring JSDoc annotations are accurate and complete.
    2.  This is an ongoing activity integrated with all other refactoring work.
*   **(Optional) Related TODOs:** "Code Quality: General cleanup during other refactors."

### 5.3. Review and Update JSDoc Documentation
*   **Goal:** Ensure all JSDoc comments are accurate, complete, and reflect the current state of the code, especially after refactoring.
*   **Description/Rationale:** Good documentation is crucial for maintainability and for other developers (or AI assistants) to understand the codebase.
*   **Affected Components:** Entire codebase, focusing on `*.js` files.
*   **Proposed Action/Implementation Steps:**
    1.  Systematically review JSDoc blocks for all functions, classes, and significant variables.
    2.  Verify parameter types, return types, and descriptions.
    3.  Add missing JSDoc where necessary.
    4.  Ensure consistency in style and level of detail.
    5.  Consider using a JSDoc generation tool to produce HTML documentation that can be easily browsed.

### 5.4. Consolidate Constants and Configuration
*   **Goal:** Ensure all magic numbers, string literals used in multiple places, and configuration parameters are defined in `constants.js` or a dedicated configuration module.
*   **Description/Rationale:** Improves maintainability by centralizing configurable values and making the code easier to understand.
*   **Affected Components:** Entire codebase.
*   **Proposed Action/Implementation Steps:**
    1.  Scan the codebase for hardcoded values that should be constants (e.g., VAD sample rates, UI string labels, default thresholds).
    2.  Move these to `constants.js`, organized into logical sections.
    3.  Replace hardcoded values with references to the constants.
    4.  Review if any constants are specific enough to a module that they should remain local but clearly marked.

````
--- End of File: vibe-player/REFACTOR.md ---
--- File: vibe-player/TODO.md ---
````markdown
<!-- /vibe-player/TODO.md -->
# Vibe Player - TODO & Future Ideas

This file tracks potential improvements, features, and known issues requiring further investigation for the Vibe Player project.

## Bugs / Issues

*   **[INVESTIGATE] Formant Shift:** The formant shift feature provided by Rubberband WASM is currently non-functional (no audible effect despite parameter being set). Requires deeper investigation into Rubberband flags, potential WASM build issues, or alternative approaches if the library feature is fundamentally broken in this context.

## Potential Enhancements / Features

*   **VAD Probability Graph:** Add a visualization showing the raw VAD probability scores over time, with draggable horizontal lines indicating the current positive/negative thresholds. This would make the VAD process more transparent and tuning more intuitive.
*   **VAD Worker:** Migrate Silero VAD processing (`sileroProcessor`, `sileroWrapper`) to a separate Web Worker. This would eliminate potential UI jank during analysis and allow VAD to complete even if the tab is backgrounded. Requires setting up worker communication.
*   **Visualizer Computation Worker(s):** Migrate Waveform and/or Spectrogram *computation* logic to Web Worker(s). The main thread would only handle Canvas drawing based on received data, further improving responsiveness, especially for long files.
*   **Improved Spectrogram Rendering:** Explore true progressive computation/rendering for the spectrogram, where slices are calculated and drawn incrementally, rather than computing all data upfront.
*   **Error Handling UI:** Display user-friendly error messages in the UI for issues like decoding failures, VAD errors, etc., instead of relying solely on `console.error` and generic file info updates.
*   **State Management Module (`audioPlayerState.js`):** Consider creating a dedicated module to manage playback-related state (`isPlaying`, `currentTime`, speed/pitch targets) currently spread between `app.js` and `audioEngine.js`. This could improve separation of concerns if the application grows more complex.
*   **Parameter Smoothing:** Investigate if parameter changes (speed, pitch) sent to Rubberband could benefit from smoother transitions (if supported by the library/worklet) to avoid abrupt audio changes.
*   **Preset Management:** Allow saving/loading sets of Speed/Pitch/Gain/VAD settings.
* Windows 98 sounds on click etc
* Hide VAD tuning or add a graph to show the probs, start and stop thresholds, and color that too but faded?
* more player controls? maybe up and down to change speed by 0.25? enter also to play/pause? make the keybinds modifiable? and savable in local storage? and a reset button too if so
* add a 'back to start' button near play/pause and a 'reset' button to controls / vad controls

## Code Health / Refactoring Ideas

*   **Review `app.js` Complexity:** As features are added, monitor the size and complexity of `app.js`. If it becomes too large, revisit introducing a more formal state management pattern or further decomposing its responsibilities.
*   **Review `audioEngine.js` State:** Re-evaluate if `audioEngine` can be made more stateless regarding playback parameters (see `audioPlayerState.js` idea above).
*   **Automated Testing:** Introduce some form of automated testing (e.g., unit tests for utility functions, potentially integration tests for core flows if feasible without excessive mocking) to improve regression safety (currently relies on manual testing - C5).

<!-- /vibe-player/TODO.md -->

````
--- End of File: vibe-player/TODO.md ---
--- File: vibe-player-gui-state-diagram.md ---
````markdown
```mermaid
stateDiagram-v2
    direction LR

    [*] --> S_Initial
    S_Initial: Initial (No File Loaded)

    S_Initial --> S_LoadingFile: File/URL selected
    S_LoadingFile: Loading File (Fetching/Decoding)

    S_LoadingFile --> S_ProcessingAudio: Audio Decoded (audioLoaded event)
    note right of S_LoadingFile: Can transition to S_Error on decode/load failure

    S_LoadingFile --> S_Error: Decoding/Network Error

    S_ProcessingAudio: Processing Audio (Worklet Setup, VAD/Tone Analysis Initiated)
    note right of S_ProcessingAudio
        - Worklet being set up.
        - VAD analysis starts.
        - DTMF/CPT analysis starts.
        - Initial visuals (waveform/spectrogram) drawn.
    end note
    S_ProcessingAudio --> S_Ready: Worklet Ready (workletReady event)

    S_Ready: Ready to Play (Paused by default)
    note right of S_Ready
        - Playback controls active.
        - VAD/Tone results may still be processing
          or may complete in this state.
    end note

    S_Ready --> S_Playing: Play clicked
    S_Playing: Playing Audio

    S_Playing --> S_Ready: Pause clicked
    S_Playing --> S_Ready: Playback ended
    S_Playing --> S_Playing: Seek operation

    S_Ready --> S_Ready: Seek operation

    S_Ready --> S_LoadingFile: New File/URL selected (resets flow)
    S_Playing --> S_LoadingFile: New File/URL selected (resets flow)

    S_Error: Error State (e.g., Load/Decode Failed)
    S_Error --> S_Initial: UI Reset (user can select new file)

```

````
--- End of File: vibe-player-gui-state-diagram.md ---
