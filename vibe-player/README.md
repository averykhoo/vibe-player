<!-- /vibe-player/README.md -->
# Vibe Player (Hybrid Engine)

## Overview

This project is a web-based audio player and analysis tool, **Vibe Player**, developed primarily through "vibe coding." Most of the initial code was generated by Large Language Models (LLMs like Google Gemini and OpenAI models) based on high-level prompts reflecting desired functionality or "vibes."

This current version integrates an advanced **Hybrid Audio Playback Engine** using the **Rubberband** library (compiled to WebAssembly) for high-quality, real-time time stretching, pitch shifting, and formant shifting. The integration and refactoring process were guided and executed by an advanced Gemini model to enhance modularity and maintainability under strict static-hosting constraints.

Vibe Player analyzes audio files for Voice Activity Detection (VAD) using the Silero VAD model via ONNX Runtime Web. It displays the audio waveform with detected speech regions highlighted, a spectrogram visualization, and provides flexible playback controls leveraging the Rubberband engine within an `AudioWorklet`.

The entire application uses **vanilla HTML, CSS, and JavaScript**, designed explicitly for **static file hosting** without requiring build tools, frameworks, or package managers.

## Features

*   Load local audio files (various formats supported by browser `decodeAudioData`).
*   **Advanced Playback Engine (Rubberband WASM via AudioWorklet):**
    *   High-quality real-time time stretching (Speed control: 0.25x - 2.0x).
    *   Real-time pitch shifting (Adjustable semitones).
    *   Real-time formant shifting.
    *   **Hybrid Processing:** Automatically uses a pre-computed high-quality slow version for speeds below a configurable threshold, switching seamlessly to real-time processing of the original audio for higher speeds.
    *   Configurable hybrid behavior (threshold, pre-processing speed, transition type: Abrupt, Mute, Micro-Fade).
    *   Manual source override (Original/Pre-Processed) for comparison.
*   Standard playback controls: Play/Pause, Seek (via click on visuals), Jump Back/Forward.
*   Adjustable main volume (gain).
*   **Voice Activity Detection (VAD):**
    *   Uses the pre-trained Silero VAD model via ONNX Runtime Web.
    *   Highlights detected speech regions on the waveform in orange.
    *   Adjustable VAD thresholds (Positive/Negative) for real-time sensitivity tuning (redraws waveform highlighting).
    *   Displays start/end times of detected speech segments.
*   **Visualizations:**
    *   Real-time waveform display.
    *   Spectrogram display (computed using FFT).
    *   Playback progress indicator overlaid on visualizations, synchronized with the audio worklet.
*   Keyboard shortcuts for playback.
*   Responsive canvas visualizations.
*   Pure static deployment - works via simple file serving.

## Technology Stack

*   **HTML5:** Structure and content.
*   **CSS3:** Styling and layout.
*   **JavaScript (ES5/ES6 compatible):** Application logic, DOM manipulation (LLM-generated/refactored).
*   **Web Audio API:** Audio decoding, AudioWorklet for real-time processing, master gain.
*   **Rubberband WASM:** Core library for time stretching and pitch shifting.
*   **ONNX Runtime Web:** Runs the Silero VAD ONNX model directly in the browser (via WASM).
*   **fft.js:** Simple Fast Fourier Transform library for spectrogram calculation.

## Setup & Running (For Users)

1.  **Get the Files:** Ensure you have the complete project folder, including the `lib/`, `model/`, `wasm/`, and `js/` subdirectories with their contents.
2.  **Download ONNX Runtime Web (One-time setup):**
    *   Go to the [ONNX Runtime GitHub Releases](https://github.com/microsoft/onnxruntime/releases).
    *   Find a recent release (e.g., v1.17.0 or later).
    *   Download the **web** package zip file (e.g., `onnxruntime-web-*.zip`).
    *   Extract the archive. From the `dist/` directory inside, copy the following files into this project's `lib/` folder:
        *   `ort.min.js`
        *   `ort-wasm.wasm`
        *   `ort-wasm-simd.wasm` (Recommended)
        *   *(Optional: `ort-wasm-threaded.wasm`)*
3.  **Get Rubberband WASM (One-time setup):**
    *   You need the `rubberband.wasm` file compiled from the Rubberband library.
    *   Place the `rubberband.wasm` file into the project's `wasm/` folder.
    *   *(Ensure you also have the corresponding custom `rubberband-loader.js` in the `audio/` folder, as provided in the project source).*
4.  **Serve Statically:** You need a simple local HTTP server.
    *   **Option A: Using Python:**
        *   Open your terminal.
        *   Navigate (`cd`) into the main project directory.
        *   Run: `python -m http.server 8000` (or `python3 -m http.server 8000`).
    *   **Option B: Other static servers (Node http-server, VS Code Live Server, etc.).**
5.  **Access:** Open your web browser (Chrome, Firefox, Edge recommended) and go to `http://localhost:8000`.
6.  **Use:** Load an audio file. Wait for preprocessing (VAD, slow version). Use controls to play, adjust parameters, and tune VAD.

## Deploying to GitHub Pages (Optional)

Follow standard GitHub Pages deployment: ensure all files (`index.html`, `styles.css`, `js/`, `audio/`, `vad/`, `lib/`, `model/`, `wasm/`) are in the repository root or configured path, enable Pages in repository settings for the `main` branch.

## Project Structure (File Layout)

```
./ (e.g., vibe-player/)
├── index.html              # Main HTML file, includes structure and script loading order.
├── styles.css              # All CSS styling.
├── main.js                 # Main thread application logic, orchestration, offline processing.
│
├── js/                     # Core Application Modules
│   ├── uiManager.js        # Handles DOM interactions & UI events.
│   ├── visualizer.js       # Handles all canvas drawing (Waveform, Spectrogram).
│   └── config.js           # Constants and default configuration values.
│
├── audio/                  # Audio Playback Engine Modules
│   ├── hybrid-processor.js # AudioWorkletProcessor implementation (Real-time Rubberband).
│   └── rubberband-loader.js# Custom WASM loader for Rubberband (for Worklet).
│
├── vad/                    # Voice Activity Detection Modules
│   ├── sileroWrapper.js    # Wraps ONNX Runtime session for Silero VAD.
│   ├── sileroProcessor.js  # Core VAD processing logic using the wrapper.
│   └── vadAnalyzer.js      # Manages VAD results, thresholds, and recalculations.
│
├── lib/                    # External, third-party libraries.
│   ├── ort.min.js          # ONNX Runtime core JS library.
│   ├── ort-wasm.wasm       # ONNX Runtime core WASM binary.
│   ├── ort-wasm-simd.wasm  # ONNX Runtime SIMD WASM binary.
│   └── fft.js              # FFT library (provides global 'FFT' constructor).
│
├── model/                  # Machine Learning Models.
│   └── silero_vad.onnx     # The pre-trained Silero VAD model file.
│
├── wasm/                   # Non-library WASM Binaries.
│   └── rubberband.wasm     # Rubberband WASM binary.
│
└── README.md               # This file.
```

---
---

## Developer Notes (For LLM Assistants)

**(LLM Assistant: Adhere to these patterns resulting from the Gemini-led refactoring (Nov 2023 - May 2024). The goal is maintainability under static-hosting constraints.)**

**Core Constraints & Design Philosophy:**

1.  **Static Files Only:** No server-side logic.
2.  **No Build Tools:** Vanilla JS, runs directly in modern browsers.
3.  **No Frameworks:** Vanilla JavaScript, HTML, CSS.
4.  **LLM Maintenance:** Structure prioritizes clarity, modularity, and adherence to established patterns for future LLM interaction.

**Architectural Pattern: IIFE + Global Namespace (`AudioApp`)**

*   Single global `AudioApp` created by `main.js`.
*   Modules (`js/`, `audio/`, `vad/`) use IIFEs, attaching public interfaces to `AudioApp`.
*   Internal module logic is private.
*   **LLM Task:** Place new logic in appropriate modules, respect IIFE structure, expose via `return`.

**Communication Pattern:**

*   **UI -> App:** `uiManager.js` dispatches `CustomEvent` (e.g., `audioapp:playPauseClicked`) on `document`. `main.js` listens.
*   **App <-> Worklet:** `main.js` uses `workletNode.port.postMessage()` to send commands/data (params, buffers). `hybrid-processor.js` uses `this.port.postMessage()` to send status/time updates/errors back.
*   **Internal App Calls:** `main.js` calls methods on other modules via `AudioApp.moduleName.method()`.
*   **LLM Task:** Use `CustomEvent` for UI->App. Use `postMessage` for App<->Worklet. Use direct calls within `main.js` to other modules.

**Module Responsibilities (Summary):**

*   `main.js`: **Central Orchestrator.** Event hub, `init`. Holds primary state (buffers, VAD results). Handles **ALL offline processing** (decode, resample, VAD analyze, Rubberband preprocess). Manages WASM loading (fetches Rubberband assets, triggers ORT load via `sileroWrapper`). Manages `AudioWorkletNode` lifecycle and communication.
*   `js/uiManager.js`: DOM elements, UI event listeners -> dispatches events, UI update methods. Gets/Sets UI control values.
*   `js/visualizer.js`: Canvas drawing (waveform, spectrogram), FFT usage, spectrogram caching, progress bars, resize handling, canvas clicks -> dispatches `audioapp:seekRequested`.
*   `js/config.js`: Static configuration values, paths, defaults, enums.
*   `vad/*`: VAD analysis pipeline (Wrapper -> Processor -> Analyzer). Triggered offline by `main.js`.
*   `audio/rubberband-loader.js`: **Custom** WASM loader for Rubberband, executed via `eval`/`new Function` *inside the worklet*. **Not** a standard Emscripten loader.
*   `audio/hybrid-processor.js`: **AudioWorklet.** Real-time audio output only. Initializes own Rubberband instance. Handles hybrid source switching, time/pitch/formant processing. Receives buffers/params, sends time/status.

**Key Integration Points & Changes:**

*   `main.js` now performs the offline Rubberband preprocessing (`preprocessSlowVersion`) in addition to VAD analysis.
*   `main.js` replaces the old `audioEngine.js` logic for controlling playback; it now controls the `AudioWorkletNode`.
*   The `<audio>` element is removed. `AudioContext` and `AudioWorkletNode` are the playback path.
*   Time updates for UI/Visualizer originate from the `hybrid-processor.js` worklet, relayed through `main.js`.

**Critical Dependencies & Configuration:**

*   **`lib/` Folder:** `ort.min.js`, `ort-*.wasm`, `fft.js`. **Must be present.**
*   **`model/` Folder:** `silero_vad.onnx`. **Must be present.**
*   **`wasm/` Folder:** `rubberband.wasm`. **Must be present.**
*   **`index.html` Script Load Order:** CRITICAL. Libraries -> `main.js` -> Other modules -> Init call.
*   **Paths in `js/config.js`:** Must correctly point to WASM, model, loader script relative to `index.html`.
*   **`sileroWrapper.js` (`wasmPaths`):** Must point to `lib/` correctly.
*   **`audio/rubberband-loader.js`:** Must be the *custom* loader compatible with the worklet `instantiateWasm` hook.

**(LLM Assistant: Focus on `main.js` for orchestration and offline processing, `hybrid-processor.js` for real-time audio, and maintain the established communication patterns.)**
<!-- /vibe-player/README.md -->
